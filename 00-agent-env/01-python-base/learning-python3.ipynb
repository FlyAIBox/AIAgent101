{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/LLM-101/blob/main/chapter01-llm-env/python-base/learning-python3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "iSWRfsFqU26M"
   },
   "source": [
    "# Python 3 åŸºç¡€å­¦ä¹ æ•™ç¨‹ - é¢å‘å¤§æ¨¡å‹æŠ€æœ¯åˆå­¦è€…\n",
    "\n",
    "> **æ•™ç¨‹è¯´æ˜**ï¼šæœ¬æ•™ç¨‹ä¸“ä¸ºå¤§æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯åˆå­¦è€…è®¾è®¡ï¼Œæ¶µç›–Pythonç¼–ç¨‹çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶ç»“åˆå¤§æ¨¡å‹å¼€å‘ä¸­çš„å®é™…åº”ç”¨åœºæ™¯ã€‚\n",
    "\n",
    "\n",
    "## Jupyter Notebook ä½¿ç”¨æŒ‡å—\n",
    "\n",
    "### åŸºæœ¬æ“ä½œ\n",
    "å½“ä½ åœ¨ Jupyter notebook ä¸­ç¼–è¾‘å•å…ƒæ ¼æ—¶ï¼Œéœ€è¦æŒ‰ **`<Shift> + <Enter>`** é‡æ–°è¿è¡Œå•å…ƒæ ¼ã€‚è¿™å°†ä½¿ä½ æ‰€åšçš„æ›´æ”¹å¯¹å…¶ä»–å•å…ƒæ ¼å¯ç”¨ã€‚\n",
    "\n",
    "ä½¿ç”¨ **`<Enter>`** åœ¨ä½ æ­£åœ¨ç¼–è¾‘çš„å•å…ƒæ ¼å†…åˆ›å»ºæ–°è¡Œã€‚\n",
    "\n",
    "### å•å…ƒæ ¼ç±»å‹\n",
    "\n",
    "#### ä»£ç å•å…ƒæ ¼ï¼ˆCode Cellï¼‰\n",
    "- é‡æ–°è¿è¡Œå°†æ‰§è¡Œä½ ç¼–å†™çš„ä»»ä½•Pythonè¯­å¥\n",
    "- è¦ç¼–è¾‘ç°æœ‰çš„ä»£ç å•å…ƒæ ¼ï¼Œè¯·ç‚¹å‡»å®ƒ\n",
    "- ä»£ç æ‰§è¡Œç»“æœä¼šæ˜¾ç¤ºåœ¨å•å…ƒæ ¼ä¸‹æ–¹\n",
    "\n",
    "#### Markdown å•å…ƒæ ¼ï¼ˆMarkdown Cellï¼‰\n",
    "- é‡æ–°è¿è¡Œå°†æ¸²æŸ“ markdown æ–‡æœ¬\n",
    "- è¦ç¼–è¾‘ç°æœ‰çš„ markdown å•å…ƒæ ¼ï¼Œè¯·åŒå‡»å®ƒ\n",
    "- ç”¨äºç¼–å†™è¯´æ˜æ–‡æ¡£å’Œæ•™ç¨‹å†…å®¹\n",
    "\n",
    "---\n",
    "\n",
    "## å¤§æ¨¡å‹æŠ€æœ¯ä¸­çš„Pythoné‡è¦æ€§\n",
    "\n",
    "åœ¨å¤§æ¨¡å‹ï¼ˆLLMï¼‰å¼€å‘ä¸­ï¼ŒPythonæ˜¯æœ€ä¸»è¦çš„ç¼–ç¨‹è¯­è¨€ã€‚æŒæ¡PythonåŸºç¡€å¯¹äºï¼š\n",
    "- **APIè°ƒç”¨**ï¼šä¸OpenAIã€Claudeç­‰å¤§æ¨¡å‹æœåŠ¡äº¤äº’\n",
    "- **æ•°æ®å¤„ç†**ï¼šå¤„ç†æ–‡æœ¬ã€JSONã€CSVç­‰æ ¼å¼æ•°æ®\n",
    "- **æç¤ºè¯å·¥ç¨‹**ï¼šæ„å»ºå’Œä¼˜åŒ–æç¤ºè¯æ¨¡æ¿\n",
    "- **Agentå¼€å‘**ï¼šåˆ›å»ºæ™ºèƒ½ä»£ç†å’Œè‡ªåŠ¨åŒ–å·¥å…·\n",
    "- **RAGç³»ç»Ÿ**ï¼šæ„å»ºæ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "mu9dIeWbU26S"
   },
   "source": [
    "## Jupyter Notebook å¸¸ç”¨æ“ä½œæŒ‡å—\n",
    "\n",
    "![Jupyter Notebook](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509151439200.png)\n",
    "\n",
    "åœ¨ Jupyter notebook çª—å£é¡¶éƒ¨é™„è¿‘ï¼Œæœ‰ä¸€è¡Œèœå•é€‰é¡¹ï¼ˆ`æ–‡ä»¶`ã€`ç¼–è¾‘`ã€`æŸ¥çœ‹`ã€`è¿è¡Œ` ç­‰ï¼‰å’Œä¸€è¡Œå·¥å…·æ å›¾æ ‡ï¼ˆä¿å­˜ã€æ·»åŠ å•å…ƒæ ¼ã€å‰ªåˆ‡ã€å¤åˆ¶ã€ç²˜è´´ã€è¿è¡Œç­‰ï¼‰ã€‚\n",
    "\n",
    "### å•å…ƒæ ¼ç®¡ç†\n",
    "\n",
    "#### æ’å…¥å’Œåˆ é™¤å•å…ƒæ ¼\n",
    "- ä½¿ç”¨\"åŠ å·\"å›¾æ ‡åœ¨å½“å‰é€‰ä¸­çš„å•å…ƒæ ¼ä¸‹æ–¹æ’å…¥æ–°å•å…ƒæ ¼\n",
    "- ä½¿ç”¨èœå•ä¸­çš„\"æ’å…¥\" -> \"åœ¨ä¸Šæ–¹æ’å…¥å•å…ƒæ ¼\"åœ¨ä¸Šæ–¹æ’å…¥\n",
    "- ä½¿ç”¨\"åˆ é™¤\"æŒ‰é’®æˆ–é”®ç›˜å¿«æ·é”®åˆ é™¤é€‰ä¸­çš„å•å…ƒæ ¼\n",
    "\n",
    "#### æ¸…é™¤è¾“å‡ºå’Œé‡å¯å†…æ ¸\n",
    "- ä½¿ç”¨èœå•ä¸­çš„\"å†…æ ¸\" -> \"é‡å¯\"é‡å¯Pythonå†…æ ¸\n",
    "- ç‚¹å‡»\"æ¸…é™¤æ‰€æœ‰è¾“å‡ºå¹¶é‡å¯\"æ¸…é™¤æ‰€æœ‰è¾“å‡ºç»“æœ\n",
    "- ä½¿ç”¨\"å†…æ ¸\" -> \"ä¸­æ–­\"åœæ­¢æ­£åœ¨è¿è¡Œçš„ä»£ç \n",
    "\n",
    "#### ä¿å­˜å’Œä¸‹è½½ç¬”è®°æœ¬\n",
    "- ä½¿ç”¨\"æ–‡ä»¶\" -> \"ä¿å­˜\"æˆ–Ctrl+Sä¿å­˜å½“å‰ç¬”è®°æœ¬\n",
    "- ä½¿ç”¨\"æ–‡ä»¶\" -> \"ä¸‹è½½ä¸º\" -> \"IPython Notebook (.ipynb)\"ä¸‹è½½ç¬”è®°æœ¬æ–‡ä»¶\n",
    "- æ”¯æŒå¤šç§æ ¼å¼å¯¼å‡ºï¼šHTMLã€PDFã€Pythonè„šæœ¬ç­‰\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„æœ€ä½³å®è·µ\n",
    "- **å®šæœŸä¿å­˜**ï¼šåœ¨ç¼–å†™å¤§æ¨¡å‹ç›¸å…³ä»£ç æ—¶ï¼Œç»å¸¸ä¿å­˜é¿å…æ•°æ®ä¸¢å¤±\n",
    "- **åˆ†æ­¥æ‰§è¡Œ**ï¼šå°†å¤æ‚çš„APIè°ƒç”¨åˆ†è§£ä¸ºå¤šä¸ªå•å…ƒæ ¼ï¼Œä¾¿äºè°ƒè¯•\n",
    "- **æ³¨é‡Šè¯¦ç»†**ï¼šä¸ºæ¯ä¸ªä»£ç å—æ·»åŠ æ¸…æ™°çš„æ³¨é‡Šï¼Œè¯´æ˜å…¶åœ¨å¤§æ¨¡å‹å·¥ä½œæµä¸­çš„ä½œç”¨\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "pu7CvWXCU26U"
   },
   "source": [
    "## å­¦ä¹ èµ„æºä¸å‚è€ƒèµ„æ–™\n",
    "\n",
    "### Python å®˜æ–¹æ–‡æ¡£\n",
    "- [Python 3 å®˜æ–¹æ•™ç¨‹](https://docs.python.org/3/tutorial/index.html) - Pythonå®˜æ–¹å…¥é—¨æ•™ç¨‹\n",
    "- [Python 3 è¯­è¨€å‚è€ƒ](https://docs.python.org/3/reference/index.html) - å®Œæ•´çš„è¯­è¨€è§„èŒƒ\n",
    "- [Python æ ‡å‡†åº“](https://docs.python.org/3/library/index.html) - å†…ç½®æ¨¡å—å’Œå‡½æ•°\n",
    "\n",
    "### Jupyter Notebook ç›¸å…³\n",
    "- [Jupyter Notebook å®˜æ–¹æ–‡æ¡£](https://jupyter-notebook.readthedocs.io/en/latest/notebook.html)\n",
    "- [MyBinder ä½¿ç”¨æŒ‡å—](https://mybinder.readthedocs.io/en/latest/introduction.html)\n",
    "- [Markdown è¯­æ³•å‚è€ƒ](https://daringfireball.net/projects/markdown/syntax)\n",
    "\n",
    "### å¤§æ¨¡å‹æŠ€æœ¯ç›¸å…³èµ„æº\n",
    "- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs) - OpenAI API ä½¿ç”¨æŒ‡å—\n",
    "- [Hugging Face Transformers](https://huggingface.co/docs/transformers) - é¢„è®­ç»ƒæ¨¡å‹åº“\n",
    "- [LangChain æ–‡æ¡£](https://python.langchain.com/) - å¤§æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶\n",
    "- [FastAPI æ–‡æ¡£](https://fastapi.tiangolo.com/) - æ„å»ºAPIæœåŠ¡çš„ç°ä»£æ¡†æ¶\n",
    "\n",
    "### æ¨èå­¦ä¹ è·¯å¾„\n",
    "1. **PythonåŸºç¡€** â†’ 2. **æ•°æ®å¤„ç†** â†’ 3. **APIè°ƒç”¨** â†’ 4. **å¤§æ¨¡å‹é›†æˆ** â†’ 5. **é¡¹ç›®å®æˆ˜**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iPt6FdCXPiA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## æœåŠ¡å™¨ç¯å¢ƒä¿¡æ¯æ£€æŸ¥ğŸ”§\n",
    "\n",
    "åœ¨å¼€å§‹éƒ¨ç½²æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£å½“å‰çš„è¿è¡Œç¯å¢ƒã€‚è¿™ä¸ªæ­¥éª¤éå¸¸é‡è¦ï¼Œå› ä¸ºï¼š\n",
    "\n",
    "### ğŸ¯ æ£€æŸ¥ç›®çš„\n",
    "1. **ç¡¬ä»¶ç¡®è®¤**: ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU æ˜¾å­˜è¿è¡Œæ¨¡å‹\n",
    "2. **ç³»ç»Ÿå…¼å®¹**: éªŒè¯æ“ä½œç³»ç»Ÿå’Œ Python ç‰ˆæœ¬\n",
    "3. **èµ„æºè¯„ä¼°**: äº†è§£å¯ç”¨çš„ CPUã€å†…å­˜å’Œå­˜å‚¨ç©ºé—´\n",
    "4. **ç¯å¢ƒé…ç½®**: æ£€æŸ¥ CUDA ç‰ˆæœ¬å’Œç›¸å…³ä¾èµ–\n",
    "\n",
    "### ğŸ“Š æ£€æŸ¥å†…å®¹\n",
    "- **æ“ä½œç³»ç»Ÿ**: Linux å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "- **CPU ä¿¡æ¯**: å¤„ç†å™¨å‹å·å’Œæ ¸å¿ƒæ•°\n",
    "- **å†…å­˜çŠ¶æ€**: æ€»å†…å­˜å’Œå¯ç”¨å†…å­˜\n",
    "- **GPU é…ç½®**: æ˜¾å¡å‹å·å’Œæ˜¾å­˜å¤§å°\n",
    "- **CUDA ç‰ˆæœ¬**: æ·±åº¦å­¦ä¹ æ¡†æ¶æ”¯æŒ\n",
    "- **Python ç¯å¢ƒ**: è§£é‡Šå™¨ç‰ˆæœ¬\n",
    "- **ç£ç›˜ç©ºé—´**: å¯ç”¨å­˜å‚¨ç©ºé—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9JA7pcgXT-L",
    "outputId": "4d37fca3-8318-4126-9492-d878c2b0ae81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU ä¿¡æ¯     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 2 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 3.78 GB (Available: 2.56 GB)                                                       |\n",
      "| GPU ä¿¡æ¯     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA ä¿¡æ¯    | CUDA not found                                                                     |\n",
      "| Python ç‰ˆæœ¬  | 3.10.18                                                                            |\n",
      "| Conda ç‰ˆæœ¬   | conda 24.4.0                                                                       |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 56.91 GB, Used: 13.97 GB, Free: 40.32 GB                                    |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©ä½ ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "!pip install pandas==2.2.2\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "vK2ee2v9U26W",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Python å¯¹è±¡ã€åŸºæœ¬ç±»å‹å’Œå˜é‡\n",
    "\n",
    "> **æ ¸å¿ƒæ¦‚å¿µ**ï¼šPython ä¸­çš„ä¸€åˆ‡éƒ½æ˜¯**å¯¹è±¡**ï¼Œæ¯ä¸ªå¯¹è±¡éƒ½æœ‰ä¸€ä¸ª**ç±»å‹**ã€‚è¿™ç§è®¾è®¡ä½¿å¾—Pythonéå¸¸é€‚åˆå¤§æ¨¡å‹å¼€å‘ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥è½»æ¾å¤„ç†å„ç§æ•°æ®ç±»å‹ã€‚\n",
    "\n",
    "### åŸºæœ¬æ•°æ®ç±»å‹\n",
    "\n",
    "åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦å¤„ç†ä»¥ä¸‹æ•°æ®ç±»å‹ï¼š\n",
    "\n",
    "#### æ•°å€¼ç±»å‹\n",
    "- **`int`**ï¼ˆæ•´æ•°ç±»å‹ï¼‰\n",
    "  - `10` - è¡¨ç¤ºç”¨æˆ·IDã€tokenæ•°é‡ç­‰\n",
    "  - `-3` - è¡¨ç¤ºé”™è¯¯ä»£ç ã€åç§»é‡ç­‰\n",
    "- **`float`**ï¼ˆæµ®ç‚¹æ•°ç±»å‹ï¼‰\n",
    "  - `7.41` - è¡¨ç¤ºæ¨¡å‹ç½®ä¿¡åº¦ã€ç›¸ä¼¼åº¦åˆ†æ•°ç­‰\n",
    "  - `-0.006` - è¡¨ç¤ºæŸå¤±å€¼ã€æ¢¯åº¦ç­‰\n",
    "\n",
    "#### æ–‡æœ¬ç±»å‹\n",
    "- **`str`**ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰- å¤§æ¨¡å‹å¼€å‘ä¸­æœ€å¸¸ç”¨çš„ç±»å‹\n",
    "  - `'è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨å•å¼•å·çš„å­—ç¬¦ä¸²'` - å•è¡Œæ–‡æœ¬\n",
    "  - `\"è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨åŒå¼•å·çš„å­—ç¬¦ä¸²\"` - å•è¡Œæ–‡æœ¬\n",
    "  - `'''è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨å•å¼•å·çš„ä¸‰å¼•å·å­—ç¬¦ä¸²'''` - å¤šè¡Œæ–‡æœ¬ï¼Œå¸¸ç”¨äºæç¤ºè¯\n",
    "  - `\"\"\"è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨åŒå¼•å·çš„ä¸‰å¼•å·å­—ç¬¦ä¸²\"\"\"` - å¤šè¡Œæ–‡æœ¬ï¼Œå¸¸ç”¨äºæ–‡æ¡£å­—ç¬¦ä¸²\n",
    "\n",
    "#### é€»è¾‘ç±»å‹\n",
    "- **`bool`**ï¼ˆå¸ƒå°”å€¼ç±»å‹ï¼‰\n",
    "  - `True` - è¡¨ç¤ºæˆåŠŸã€å¯ç”¨ç­‰çŠ¶æ€\n",
    "  - `False` - è¡¨ç¤ºå¤±è´¥ã€ç¦ç”¨ç­‰çŠ¶æ€\n",
    "- **`NoneType`**ï¼ˆç©ºå€¼ç±»å‹ï¼‰\n",
    "  - `None` - è¡¨ç¤ºç¼ºå¤±å€¼ã€æœªåˆå§‹åŒ–ç­‰\n",
    "\n",
    "### å˜é‡å‘½åè§„åˆ™\n",
    "\n",
    "åœ¨ Python ä¸­ï¼Œ**å˜é‡**æ˜¯ä½ åœ¨ä»£ç ä¸­æŒ‡å®šçš„åç§°ï¼Œå®ƒæ˜ å°„åˆ°ç‰¹å®šçš„**å¯¹è±¡**ã€å¯¹è±¡**å®ä¾‹**æˆ–å€¼ã€‚\n",
    "\n",
    "#### å‘½åè§„èŒƒ\n",
    "- å˜é‡ååªèƒ½åŒ…å«å­—æ¯ã€ä¸‹åˆ’çº¿ï¼ˆ`_`ï¼‰æˆ–æ•°å­—\n",
    "- å˜é‡åå¿…é¡»ä»¥å­—æ¯æˆ–ä¸‹åˆ’çº¿å¼€å¤´\n",
    "- ä¸èƒ½æœ‰ç©ºæ ¼ã€ç ´æŠ˜å·æˆ–å…¶ä»–ç‰¹æ®Šå­—ç¬¦\n",
    "- å»ºè®®ä½¿ç”¨æœ‰æ„ä¹‰çš„åç§°ï¼Œå¦‚ `user_prompt`ã€`api_response`ã€`model_config`\n",
    "\n",
    "#### å¤§æ¨¡å‹å¼€å‘ä¸­çš„å˜é‡å‘½åå»ºè®®\n",
    "```python\n",
    "# æ¨èçš„å‘½åæ–¹å¼\n",
    "user_input = \"è¯·ä»‹ç»ä¸€ä¸‹Python\"\n",
    "api_key = \"sk-...\"\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "max_tokens = 1000\n",
    "temperature = 0.7\n",
    "```\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "UyZrRnaJU26Y"
   },
   "source": [
    "## åŸºæœ¬æ“ä½œç¬¦\n",
    "\n",
    "> **é‡è¦æ¦‚å¿µ**ï¼šæ“ä½œç¬¦æ˜¯Pythonä¸­ç”¨äºå¯¹æ•°æ®è¿›è¡Œè¿ç®—çš„ç‰¹æ®Šç¬¦å·ã€‚åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä½¿ç”¨è¿™äº›æ“ä½œç¬¦æ¥å¤„ç†æ•°æ®ã€æ§åˆ¶æµç¨‹å’Œè¿›è¡Œé€»è¾‘åˆ¤æ–­ã€‚\n",
    "\n",
    "### ç®—æœ¯æ“ä½œç¬¦\n",
    "ç”¨äºæ•°å€¼è®¡ç®—ï¼Œåœ¨å¤§æ¨¡å‹å¼€å‘ä¸­å¸¸ç”¨äºï¼š\n",
    "- **`+`**ï¼ˆåŠ æ³•ï¼‰- åˆå¹¶æ–‡æœ¬ã€è®¡ç®—æ€»æ•°\n",
    "- **`-`**ï¼ˆå‡æ³•ï¼‰- è®¡ç®—å·®å€¼ã€åç§»é‡\n",
    "- **`*`**ï¼ˆä¹˜æ³•ï¼‰- é‡å¤æ–‡æœ¬ã€è®¡ç®—å€æ•°\n",
    "- **`/`**ï¼ˆé™¤æ³•ï¼‰- è®¡ç®—å¹³å‡å€¼ã€æ¯”ä¾‹\n",
    "- **`**`**ï¼ˆå¹‚è¿ç®—ï¼‰- è®¡ç®—æŒ‡æ•°ã€å¤æ‚æ•°å­¦è¿ç®—\n",
    "\n",
    "### èµ‹å€¼æ“ä½œç¬¦\n",
    "ç”¨äºç»™å˜é‡èµ‹å€¼å’Œæ›´æ–°å€¼ï¼š\n",
    "- **`=`**ï¼ˆèµ‹å€¼ï¼‰- å°†å€¼èµ‹ç»™å˜é‡\n",
    "- **`+=`**ï¼ˆç›¸åŠ å¹¶é‡æ–°èµ‹å€¼ï¼‰- ç´¯åŠ æ“ä½œï¼Œå¸¸ç”¨äºè®¡æ•°å™¨\n",
    "- **`-=`**ï¼ˆç›¸å‡å¹¶é‡æ–°èµ‹å€¼ï¼‰- é€’å‡æ“ä½œ\n",
    "- **`*=`**ï¼ˆç›¸ä¹˜å¹¶é‡æ–°èµ‹å€¼ï¼‰- å€æ•°æ“ä½œ\n",
    "\n",
    "### æ¯”è¾ƒæ“ä½œç¬¦\n",
    "ç”¨äºæ¯”è¾ƒä¸¤ä¸ªå€¼ï¼Œè¿”å› `True` æˆ– `False`ï¼š\n",
    "- **`==`**ï¼ˆç­‰äºï¼‰- æ£€æŸ¥ä¸¤ä¸ªå€¼æ˜¯å¦ç›¸ç­‰\n",
    "- **`!=`**ï¼ˆä¸ç­‰äºï¼‰- æ£€æŸ¥ä¸¤ä¸ªå€¼æ˜¯å¦ä¸ç›¸ç­‰\n",
    "- **`<`**ï¼ˆå°äºï¼‰- æ•°å€¼æ¯”è¾ƒ\n",
    "- **`<=`**ï¼ˆå°äºç­‰äºï¼‰- æ•°å€¼æ¯”è¾ƒ\n",
    "- **`>`**ï¼ˆå¤§äºï¼‰- æ•°å€¼æ¯”è¾ƒ\n",
    "- **`>=`**ï¼ˆå¤§äºç­‰äºï¼‰- æ•°å€¼æ¯”è¾ƒ\n",
    "\n",
    "### æ“ä½œç¬¦ä¼˜å…ˆçº§\n",
    "\n",
    "å½“åœ¨å•ä¸ªè¡¨è¾¾å¼ä¸­ä½¿ç”¨å¤šä¸ªæ“ä½œç¬¦æ—¶ï¼Œ**æ“ä½œç¬¦ä¼˜å…ˆçº§**å†³å®šè¡¨è¾¾å¼çš„å“ªäº›éƒ¨åˆ†æŒ‰ä»€ä¹ˆé¡ºåºæ±‚å€¼ã€‚ä¼˜å…ˆçº§è¾ƒé«˜çš„æ“ä½œç¬¦å…ˆæ±‚å€¼ï¼ˆå°±åƒæ•°å­¦ä¸­çš„ PEMDASï¼‰ã€‚ç›¸åŒä¼˜å…ˆçº§çš„æ“ä½œç¬¦ä»å·¦åˆ°å³æ±‚å€¼ã€‚\n",
    "\n",
    "**ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼š**\n",
    "1. `()` æ‹¬å·ï¼Œç”¨äºåˆ†ç»„\n",
    "2. `**` å¹‚è¿ç®—\n",
    "3. `*`, `/` ä¹˜æ³•å’Œé™¤æ³•\n",
    "4. `+`, `-` åŠ æ³•å’Œå‡æ³•\n",
    "5. `==`, `!=`, `<`, `<=`, `>`, `>=` æ¯”è¾ƒ\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„å®é™…åº”ç”¨\n",
    "\n",
    "```python\n",
    "# è®¡ç®—APIè°ƒç”¨çš„æ€»tokenæ•°\n",
    "prompt_tokens = 100\n",
    "completion_tokens = 50\n",
    "total_tokens = prompt_tokens + completion_tokens  # ä½¿ç”¨åŠ æ³•\n",
    "\n",
    "# æ£€æŸ¥æ¨¡å‹å“åº”æ˜¯å¦æˆåŠŸ\n",
    "response_status = 200\n",
    "is_success = response_status == 200  # ä½¿ç”¨æ¯”è¾ƒæ“ä½œç¬¦\n",
    "\n",
    "# ç´¯ç§¯å¤„ç†çš„æ¶ˆæ¯æ•°é‡\n",
    "message_count = 0\n",
    "message_count += 1  # ä½¿ç”¨é€’å¢æ“ä½œç¬¦\n",
    "```\n",
    "\n",
    "> å‚è€ƒï¼š[Pythonæ“ä½œç¬¦ä¼˜å…ˆçº§å®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/reference/expressions.html#operator-precedence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "sr63n3spU26b"
   },
   "outputs": [],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„æ•°å€¼å˜é‡ç¤ºä¾‹\n",
    "# è¿™äº›å˜é‡åœ¨å¤§æ¨¡å‹åº”ç”¨ä¸­å¸¸ç”¨äºé…ç½®å‚æ•°å’Œè®¡ç®—ç»“æœ\n",
    "\n",
    "num1 = 10      # æ•´æ•°ï¼š10 - å¯ç”¨äºè¡¨ç¤ºæœ€å¤§é‡è¯•æ¬¡æ•°ã€æ‰¹æ¬¡å¤§å°ç­‰\n",
    "num2 = -3      # æ•´æ•°ï¼š-3 - å¯ç”¨äºè¡¨ç¤ºé”™è¯¯ä»£ç ã€åç§»é‡ç­‰\n",
    "num3 = 7.41    # æµ®ç‚¹æ•°ï¼š7.41 - å¯ç”¨äºè¡¨ç¤ºæ¨¡å‹æ¸©åº¦å‚æ•°ã€ç½®ä¿¡åº¦ç­‰\n",
    "num4 = -.6     # æµ®ç‚¹æ•°ï¼š-0.6 - å¯ç”¨äºè¡¨ç¤ºå­¦ä¹ ç‡ã€æŸå¤±å€¼ç­‰ï¼ˆå¯çœç•¥å°æ•°ç‚¹å‰çš„0ï¼‰\n",
    "num5 = 7       # æ•´æ•°ï¼š7 - å¯ç”¨äºè¡¨ç¤ºä¸Šä¸‹æ–‡é•¿åº¦ã€æœ€å¤§è½®æ•°ç­‰\n",
    "num6 = 3       # æ•´æ•°ï¼š3 - å¯ç”¨äºè¡¨ç¤ºæœ€å°é•¿åº¦ã€é‡è¯•æ¬¡æ•°ç­‰\n",
    "num7 = 11.11   # æµ®ç‚¹æ•°ï¼š11.11 - å¯ç”¨äºè¡¨ç¤ºç›¸ä¼¼åº¦åˆ†æ•°ã€å‡†ç¡®ç‡ç­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "uLgJ_6PQU26f",
    "outputId": "75c694ed-fe5b-4d78-f598-59aa08af9d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åŠ æ³•è¿ç®—ç¤ºä¾‹ï¼š10 + (-3) = 7\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼ŒåŠ æ³•å¸¸ç”¨äºè®¡ç®—æ€»tokenæ•°ã€åˆå¹¶æ•°å€¼ç­‰\n",
    "num1 + num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "8naKnthgU26i",
    "outputId": "5bd84f07-1fa5-4a76-e079-162d322cc8a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.41"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å‡æ³•è¿ç®—ç¤ºä¾‹ï¼š-3 - 7.41 = -10.41\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå‡æ³•å¸¸ç”¨äºè®¡ç®—å·®å€¼ã€åç§»é‡ç­‰\n",
    "num2 - num3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "s6bJ2ErxU26l",
    "outputId": "98dfe967-9aad-4ad7-dbd5-5bca7190a2df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.446"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¹˜æ³•è¿ç®—ç¤ºä¾‹ï¼š7.41 * (-0.6) = -4.446\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œä¹˜æ³•å¸¸ç”¨äºè®¡ç®—åŠ æƒåˆ†æ•°ã€ç¼©æ”¾å‚æ•°ç­‰\n",
    "num3 * num4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "WJOmG5YfU26n",
    "outputId": "6a390f70-e778-4d3a-9c72-5349365837a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08571428571428572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é™¤æ³•è¿ç®—ç¤ºä¾‹ï¼š-0.6 / 7 = -0.08571428571428572\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œé™¤æ³•å¸¸ç”¨äºè®¡ç®—å¹³å‡å€¼ã€æ¯”ä¾‹ã€å½’ä¸€åŒ–ç­‰\n",
    "num4 / num5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "VQRhAgbtU26o",
    "outputId": "5b06922c-1778-4b08-ba74-7893bac3c63f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¹‚è¿ç®—ç¤ºä¾‹ï¼š7 çš„ 3 æ¬¡æ–¹ = 343\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå¹‚è¿ç®—å¸¸ç”¨äºè®¡ç®—å¤æ‚åº¦ã€æŒ‡æ•°è¡°å‡ç­‰\n",
    "num5 ** num6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "jEg0pIEEU26p",
    "outputId": "921d698a-2866-4789-8edd-c6e79c24e273"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é€’å¢æ“ä½œç¤ºä¾‹ï¼šnum7 = num7 + 4\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œé€’å¢æ“ä½œå¸¸ç”¨äºè®¡æ•°å™¨ã€ç´¯ç§¯ç»Ÿè®¡ç­‰\n",
    "num7 += 4  # ç­‰ä»·äº num7 = num7 + 4ï¼Œå°†num7çš„å€¼å¢åŠ 4\n",
    "num7       # æ˜¾ç¤ºæ›´æ–°åçš„å€¼ï¼š15.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "iJdO_162U26r",
    "outputId": "d4824491-241e-4056-d4bc-3aa6ed8a82b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é€’å‡æ“ä½œç¤ºä¾‹ï¼šnum6 = num6 - 2\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œé€’å‡æ“ä½œå¸¸ç”¨äºå€’è®¡æ—¶ã€å‡å°‘è®¡æ•°ç­‰\n",
    "num6 -= 2  # ç­‰ä»·äº num6 = num6 - 2ï¼Œå°†num6çš„å€¼å‡å°‘2\n",
    "num6       # æ˜¾ç¤ºæ›´æ–°åçš„å€¼ï¼š1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "vvLrqnFCU26s",
    "outputId": "a6b33b02-2639-4575-ccd3-a64e85ab257f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç›¸ä¹˜å¹¶é‡æ–°èµ‹å€¼ç¤ºä¾‹ï¼šnum3 = num3 * 5\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºç¼©æ”¾å‚æ•°ã€è°ƒæ•´æƒé‡ç­‰\n",
    "num3 *= 5  # ç­‰ä»·äº num3 = num3 * 5ï¼Œå°†num3çš„å€¼ä¹˜ä»¥5\n",
    "num3       # æ˜¾ç¤ºæ›´æ–°åçš„å€¼ï¼š37.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "Gywh53v3U26s",
    "outputId": "a213aaae-cfc1-4f78-c155-41ccf5840aca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-101.14999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¤æ‚è¡¨è¾¾å¼èµ‹å€¼ç¤ºä¾‹ï¼ˆæ³¨æ„æ“ä½œç¬¦ä¼˜å…ˆçº§ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå¤æ‚è¡¨è¾¾å¼å¸¸ç”¨äºè®¡ç®—ç»¼åˆåˆ†æ•°ã€æŸå¤±å‡½æ•°ç­‰\n",
    "num8 = num1 + num2 * num3  # å…ˆç®—ä¹˜æ³•(num2 * num3)ï¼Œå†ç®—åŠ æ³•(num1 + ç»“æœ)\n",
    "num8                       # æ˜¾ç¤ºè®¡ç®—ç»“æœï¼š-101.14999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "-trhGiA4U26t",
    "outputId": "dba7c08d-5de3-4942-b1bd-37d51347914b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ¯”è¾ƒæ“ä½œç¤ºä¾‹ï¼šæ£€æŸ¥ä¸¤ä¸ªè¡¨è¾¾å¼æ˜¯å¦ç›¸ç­‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œæ¯”è¾ƒæ“ä½œå¸¸ç”¨äºæ¡ä»¶åˆ¤æ–­ã€çŠ¶æ€æ£€æŸ¥ç­‰\n",
    "num1 + num2 == num5  # (10 + (-3)) == 7ï¼Œç»“æœä¸º True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "E0lFvReXU26u",
    "outputId": "5d27d2ee-acce-421b-bc70-d054a2b01b26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¸ç­‰æ¯”è¾ƒç¤ºä¾‹ï¼šæ£€æŸ¥ä¸¤ä¸ªè¡¨è¾¾å¼æ˜¯å¦ä¸ç›¸ç­‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œä¸ç­‰æ¯”è¾ƒå¸¸ç”¨äºéªŒè¯æ•°æ®å®Œæ•´æ€§ã€æ£€æŸ¥é”™è¯¯çŠ¶æ€ç­‰\n",
    "num3 != num4  # 37.05 != -0.6ï¼Œç»“æœä¸º True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "c3yxLIYQU26v",
    "outputId": "f94f80b4-b804-4c94-86df-b2dced780001"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°äºæ¯”è¾ƒç¤ºä¾‹ï¼šæ£€æŸ¥ç¬¬ä¸€ä¸ªè¡¨è¾¾å¼æ˜¯å¦å°äºç¬¬äºŒä¸ªè¡¨è¾¾å¼\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå°äºæ¯”è¾ƒå¸¸ç”¨äºé˜ˆå€¼åˆ¤æ–­ã€èŒƒå›´æ£€æŸ¥ç­‰\n",
    "num5 < num6  # 7 < 1ï¼Œç»“æœä¸º False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "spZQ1lj-U26w",
    "outputId": "73ca1895-1294-4ceb-c966-adbcab7b3817"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é“¾å¼æ¯”è¾ƒç¤ºä¾‹ï¼šæ£€æŸ¥å¤šä¸ªæ¡ä»¶æ˜¯å¦åŒæ—¶æ»¡è¶³\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œé“¾å¼æ¯”è¾ƒå¸¸ç”¨äºå¤æ‚æ¡ä»¶åˆ¤æ–­ã€å‚æ•°èŒƒå›´éªŒè¯ç­‰\n",
    "5 > 3 > 1  # ç­‰ä»·äº (5 > 3) and (3 > 1)ï¼Œç»“æœä¸º True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "0_91OiMsU26w",
    "outputId": "5cdec3ef-5e00-4226-89d0-014d717e70b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¤æ‚é“¾å¼æ¯”è¾ƒç¤ºä¾‹ï¼šæ£€æŸ¥å¤šä¸ªæ¡ä»¶æ˜¯å¦åŒæ—¶æ»¡è¶³\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå¤æ‚é“¾å¼æ¯”è¾ƒå¸¸ç”¨äºå¤šç»´åº¦å‚æ•°éªŒè¯ã€å¤æ‚ä¸šåŠ¡é€»è¾‘åˆ¤æ–­ç­‰\n",
    "5 > 3 < 4 == 3 + 1  # ç­‰ä»·äº (5 > 3) and (3 < 4) and (4 == 4)ï¼Œç»“æœä¸º True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "ohV2zhg-U26x"
   },
   "outputs": [],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„å­—ç¬¦ä¸²å˜é‡ç¤ºä¾‹\n",
    "# å­—ç¬¦ä¸²æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­æœ€å¸¸ç”¨çš„æ•°æ®ç±»å‹ï¼Œç”¨äºå­˜å‚¨æ–‡æœ¬ã€æç¤ºè¯ã€å“åº”ç­‰\n",
    "\n",
    "simple_string1 = 'an example'  # ä½¿ç”¨å•å¼•å·çš„å­—ç¬¦ä¸² - å¸¸ç”¨äºç®€å•æ–‡æœ¬\n",
    "simple_string2 = \"oranges \"    # ä½¿ç”¨åŒå¼•å·çš„å­—ç¬¦ä¸²ï¼ˆæ³¨æ„æœ«å°¾æœ‰ç©ºæ ¼ï¼‰- å¸¸ç”¨äºåŒ…å«å•å¼•å·çš„æ–‡æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "Da5UzaumU26y",
    "outputId": "f38a6afe-7a82-49c6-aa8a-abb3a4955c69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an example of using the + operator'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²è¿æ¥ç¤ºä¾‹ï¼ˆä½¿ç”¨åŠ æ³•æ“ä½œç¬¦ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå­—ç¬¦ä¸²è¿æ¥å¸¸ç”¨äºæ„å»ºæç¤ºè¯ã€åˆå¹¶æ–‡æœ¬ç‰‡æ®µç­‰\n",
    "simple_string1 + ' of using the + operator'  # å­—ç¬¦ä¸²è¿æ¥ï¼š'an example' + ' of using the + operator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "M1V77HwlU26y",
    "outputId": "7b60a8f6-a3f9-467c-da79-e9757dd3b9cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an example'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é‡è¦æ¦‚å¿µï¼šåŸå­—ç¬¦ä¸²æ²¡æœ‰è¢«ä¿®æ”¹ï¼ˆå­—ç¬¦ä¸²æ˜¯ä¸å¯å˜çš„ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œç†è§£å­—ç¬¦ä¸²ä¸å¯å˜æ€§å¾ˆé‡è¦ï¼Œæ¯æ¬¡æ“ä½œéƒ½ä¼šåˆ›å»ºæ–°å­—ç¬¦ä¸²\n",
    "simple_string1  # ä»ç„¶æ˜¯ 'an example'ï¼ŒåŸå­—ç¬¦ä¸²ä¿æŒä¸å˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "I8AwdFfVU26z",
    "outputId": "0dda5ec4-647a-45c9-b433-5945c1906d2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oranges oranges oranges oranges '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²é‡å¤ç¤ºä¾‹ï¼ˆä½¿ç”¨ä¹˜æ³•æ“ä½œç¬¦ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå­—ç¬¦ä¸²é‡å¤å¸¸ç”¨äºç”Ÿæˆæµ‹è¯•æ•°æ®ã€åˆ›å»ºåˆ†éš”ç¬¦ç­‰\n",
    "simple_string2 * 4  # å°†å­—ç¬¦ä¸²é‡å¤4æ¬¡ï¼š'oranges oranges oranges oranges '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "XU-KBSETU261",
    "outputId": "d2494cf5-02ba-4ca6-ff07-0d64e464e28e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oranges '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é‡è¦æ¦‚å¿µï¼šè¿™ä¸ªå­—ç¬¦ä¸²ä¹Ÿæ²¡æœ‰è¢«ä¿®æ”¹ï¼ˆå­—ç¬¦ä¸²ä¸å¯å˜æ€§ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œç†è§£è¿™ä¸€ç‚¹æœ‰åŠ©äºé¿å…å†…å­˜æµªè´¹å’Œæ€§èƒ½é—®é¢˜\n",
    "simple_string2  # ä»ç„¶æ˜¯ \"oranges \"ï¼ŒåŸå­—ç¬¦ä¸²ä¿æŒä¸å˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "fA6-am7YU261",
    "outputId": "663e34fe-09c2-4975-c1d2-847c56124f70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²ç›¸ç­‰æ€§æ¯”è¾ƒç¤ºä¾‹\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå­—ç¬¦ä¸²æ¯”è¾ƒå¸¸ç”¨äºéªŒè¯è¾“å…¥ã€æ£€æŸ¥çŠ¶æ€ç­‰\n",
    "simple_string1 == simple_string2  # 'an example' == 'oranges 'ï¼Œç»“æœä¸º False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "Sgi0q0oPU262",
    "outputId": "fecc18f8-c43a-4bef-b9a2-a72121075798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²ç›¸ç­‰æ€§æ¯”è¾ƒç¤ºä¾‹ï¼ˆç›¸åŒå†…å®¹ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ¯”è¾ƒå¸¸ç”¨äºéªŒè¯APIå“åº”ã€æ£€æŸ¥é…ç½®ç­‰\n",
    "simple_string1 == 'an example'  # 'an example' == 'an example'ï¼Œç»“æœä¸º True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "9P6H3TIoU263",
    "outputId": "928bc0e9-e889-46fc-d079-c4cebbae85f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an example that re-assigned the original string'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²è¿æ¥å¹¶é‡æ–°èµ‹å€¼ç¤ºä¾‹\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºæ„å»ºåŠ¨æ€æç¤ºè¯ã€ç´¯ç§¯æ–‡æœ¬å†…å®¹ç­‰\n",
    "simple_string1 += ' that re-assigned the original string'  # ä¿®æ”¹åŸå˜é‡ï¼Œè¿æ¥æ–°å­—ç¬¦ä¸²\n",
    "simple_string1  # æ˜¾ç¤ºæ›´æ–°åçš„å€¼ï¼š'an example that re-assigned the original string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "SDR72B_sU263",
    "outputId": "5984fb3e-b19d-4abf-dd8e-d699c92fbab6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oranges oranges oranges '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²é‡å¤å¹¶é‡æ–°èµ‹å€¼ç¤ºä¾‹\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºç”Ÿæˆé‡å¤å†…å®¹ã€åˆ›å»ºæ ¼å¼åŒ–æ–‡æœ¬ç­‰\n",
    "simple_string2 *= 3  # å°†å­—ç¬¦ä¸²é‡å¤3æ¬¡å¹¶é‡æ–°èµ‹å€¼\n",
    "simple_string2       # æ˜¾ç¤ºæ›´æ–°åçš„å€¼ï¼š'oranges oranges oranges '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "ylayxJ1ZU264"
   },
   "outputs": [],
   "source": [
    "# é‡è¦æé†’ï¼šå‡æ³•ã€é™¤æ³•å’Œé€’å‡æ“ä½œç¬¦ä¸é€‚ç”¨äºå­—ç¬¦ä¸²\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå¦‚æœéœ€è¦å­—ç¬¦ä¸²æ“ä½œï¼Œè¯·ä½¿ç”¨ä¸“é—¨çš„å­—ç¬¦ä¸²æ–¹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "d2_PJVjPU264"
   },
   "source": [
    "## åŸºæœ¬å®¹å™¨ç±»å‹\n",
    "\n",
    "> **æ ¸å¿ƒæ¦‚å¿µ**ï¼šå®¹å™¨æ˜¯ç”¨äºå°†å…¶ä»–å¯¹è±¡ç»„åˆåœ¨ä¸€èµ·çš„å¯¹è±¡ã€‚åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå®¹å™¨ç±»å‹æ˜¯å¤„ç†ç»“æ„åŒ–æ•°æ®çš„åŸºç¡€ã€‚\n",
    "\n",
    "### å¯å˜æ€§ä¸ä¸å¯å˜æ€§\n",
    "\n",
    "- **å¯å˜å¯¹è±¡**ï¼šåœ¨åˆ›å»ºåå¯ä»¥è¢«ä¿®æ”¹ï¼ˆå¦‚åˆ—è¡¨ã€å­—å…¸ã€é›†åˆï¼‰\n",
    "- **ä¸å¯å˜å¯¹è±¡**ï¼šåœ¨åˆ›å»ºåä¸èƒ½è¢«ä¿®æ”¹ï¼ˆå¦‚å­—ç¬¦ä¸²ã€å…ƒç»„ã€æ•°å­—ï¼‰\n",
    "\n",
    "\n",
    "### åŸºæœ¬å®¹å™¨ç±»å‹è¯¦è§£\n",
    "\n",
    "#### åºåˆ—ç±»å‹ï¼ˆæœ‰åºï¼Œæ”¯æŒç´¢å¼•ï¼‰\n",
    "- **`str`**ï¼ˆå­—ç¬¦ä¸²ï¼‰\n",
    "  - ä¸å¯å˜ï¼›é€šè¿‡æ•´æ•°ç´¢å¼•è®¿é—®\n",
    "  - é¡¹ç›®æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "  - åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºå­˜å‚¨æ–‡æœ¬ã€æç¤ºè¯ã€å“åº”ç­‰\n",
    "\n",
    "- **`list`**ï¼ˆåˆ—è¡¨ï¼‰\n",
    "  - å¯å˜ï¼›é€šè¿‡æ•´æ•°ç´¢å¼•è®¿é—®\n",
    "  - é¡¹ç›®æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "  - åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºå­˜å‚¨å¯¹è¯å†å²ã€é…ç½®å‚æ•°ã€å¤„ç†ç»“æœç­‰\n",
    "  - ç¤ºä¾‹ï¼š`[3, 5, 6, 3, 'dog', 'cat', False]`\n",
    "\n",
    "- **`tuple`**ï¼ˆå…ƒç»„ï¼‰\n",
    "  - ä¸å¯å˜ï¼›é€šè¿‡æ•´æ•°ç´¢å¼•è®¿é—®\n",
    "  - é¡¹ç›®æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "  - åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºå­˜å‚¨å›ºå®šé…ç½®ã€åæ ‡ã€çŠ¶æ€ç­‰\n",
    "  - ç¤ºä¾‹ï¼š`(3, 5, 6, 3, 'dog', 'cat', False)`\n",
    "\n",
    "#### éåºåˆ—ç±»å‹\n",
    "- **`set`**ï¼ˆé›†åˆï¼‰\n",
    "  - å¯å˜ï¼›æ— ç´¢å¼•è®¿é—®\n",
    "  - é¡¹ç›®ä¸æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "  - åªèƒ½åŒ…å«ä¸å¯å˜å¯¹è±¡\n",
    "  - ä¸åŒ…å«é‡å¤å¯¹è±¡\n",
    "  - åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºå»é‡ã€é›†åˆè¿ç®—ç­‰\n",
    "  - ç¤ºä¾‹ï¼š`{3, 5, 6, 'dog', 'cat', False}`\n",
    "\n",
    "- **`dict`**ï¼ˆå­—å…¸ï¼‰\n",
    "  - å¯å˜ï¼›é€šè¿‡é”®è®¿é—®\n",
    "  - é¡¹ç›®ä¸æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "  - åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºå­˜å‚¨é…ç½®ã€APIå“åº”ã€é”®å€¼å¯¹æ•°æ®ç­‰\n",
    "  - ç¤ºä¾‹ï¼š`{'name': 'Jane', 'age': 23, 'fav_foods': ['pizza', 'fruit', 'fish']}`\n",
    "\n",
    "### è¯­æ³•è§„åˆ™\n",
    "\n",
    "- **åˆ—è¡¨ã€å…ƒç»„ã€é›†åˆ**ï¼šä½¿ç”¨é€—å·ï¼ˆ,ï¼‰åˆ†éš”å„ä¸ªé¡¹ç›®\n",
    "- **å­—å…¸**ï¼šä½¿ç”¨å†’å·ï¼ˆ:ï¼‰åˆ†éš”é”®å’Œå€¼ï¼Œä½¿ç”¨é€—å·ï¼ˆ,ï¼‰åˆ†éš”é”®å€¼å¯¹\n",
    "\n",
    "### åºåˆ—ç±»å‹æ“ä½œ\n",
    "\n",
    "å­—ç¬¦ä¸²ã€åˆ—è¡¨å’Œå…ƒç»„éƒ½æ˜¯**åºåˆ—ç±»å‹**ï¼Œå¯ä»¥ä½¿ç”¨ `+`ã€`*`ã€`+=` å’Œ `*=` æ“ä½œç¬¦è¿›è¡Œè¿æ¥å’Œé‡å¤æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "2Cn_xfYVU265"
   },
   "outputs": [],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„å®¹å™¨ç±»å‹ç¤ºä¾‹\n",
    "# è¿™äº›å®¹å™¨ç±»å‹åœ¨å¤§æ¨¡å‹åº”ç”¨ä¸­ç”¨äºå­˜å‚¨å’Œç®¡ç†å„ç§æ•°æ®\n",
    "\n",
    "list1 = [3, 5, 6, 3, 'dog', 'cat', False]  # åˆ—è¡¨ï¼šå¯å˜ï¼Œæœ‰åºï¼Œå¯é‡å¤ - ç”¨äºå­˜å‚¨å¯¹è¯å†å²ã€é…ç½®åˆ—è¡¨ç­‰\n",
    "tuple1 = (3, 5, 6, 3, 'dog', 'cat', False)  # å…ƒç»„ï¼šä¸å¯å˜ï¼Œæœ‰åºï¼Œå¯é‡å¤ - ç”¨äºå­˜å‚¨å›ºå®šé…ç½®ã€åæ ‡ç­‰\n",
    "set1 = {3, 5, 6, 3, 'dog', 'cat', False}  # é›†åˆï¼šå¯å˜ï¼Œæ— åºï¼Œä¸é‡å¤ - ç”¨äºå»é‡ã€é›†åˆè¿ç®—ç­‰\n",
    "dict1 = {'name': 'Jane', 'age': 23, 'fav_foods': ['pizza', 'fruit', 'fish']}  # å­—å…¸ï¼šé”®å€¼å¯¹ - ç”¨äºå­˜å‚¨APIå“åº”ã€é…ç½®å‚æ•°ç­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "KYrUH7RhU266",
    "outputId": "fd0a1367-faf4-4f19-8d70-b4eb06a88898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 6, 3, 'dog', 'cat', False]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åˆ—è¡¨å¯¹è±¡ä¸­çš„é¡¹ç›®æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œåˆ—è¡¨çš„é¡ºåºå¾ˆé‡è¦ï¼Œå¸¸ç”¨äºä¿æŒå¯¹è¯å†å²çš„æ—¶åºæ€§\n",
    "list1  # æ˜¾ç¤ºåˆ—è¡¨å†…å®¹ï¼š[3, 5, 6, 3, 'dog', 'cat', False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "FNGRXIx3U267",
    "outputId": "936996da-7490-4003-b9f8-698f875269f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 6, 3, 'dog', 'cat', False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å…ƒç»„å¯¹è±¡ä¸­çš„é¡¹ç›®æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå…ƒç»„å¸¸ç”¨äºå­˜å‚¨ä¸å¯å˜çš„é…ç½®ä¿¡æ¯\n",
    "tuple1  # æ˜¾ç¤ºå…ƒç»„å†…å®¹ï¼š(3, 5, 6, 3, 'dog', 'cat', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "4iREXXYqU267",
    "outputId": "6449e0ce-076b-404d-9fe2-64fbed1cae34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 5, 6, False, 'cat', 'dog'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é›†åˆå¯¹è±¡ä¸­çš„é¡¹ç›®ä¸æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "# å¦å¤–ï¼Œæ³¨æ„å€¼3åœ¨è¿™ä¸ªé›†åˆå¯¹è±¡ä¸­åªå‡ºç°ä¸€æ¬¡ï¼ˆé›†åˆä¸åŒ…å«é‡å¤é¡¹ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œé›†åˆå¸¸ç”¨äºå»é‡ã€å¿«é€ŸæŸ¥æ‰¾ç­‰æ“ä½œ\n",
    "set1  # æ˜¾ç¤ºé›†åˆå†…å®¹ï¼š{False, 3, 5, 6, 'dog', 'cat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "7f0_10_sU268",
    "outputId": "420c34eb-735f-4d44-e78c-538e497155a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Jane', 'age': 23, 'fav_foods': ['pizza', 'fruit', 'fish']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—å…¸å¯¹è±¡ä¸­çš„é¡¹ç›®ä¸æŒ‰æ·»åŠ é¡ºåºå­˜å‚¨\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå­—å…¸æ˜¯æœ€å¸¸ç”¨çš„æ•°æ®ç»“æ„ï¼Œç”¨äºå­˜å‚¨APIå“åº”ã€é…ç½®å‚æ•°ç­‰\n",
    "dict1  # æ˜¾ç¤ºå­—å…¸å†…å®¹ï¼š{'name': 'Jane', 'age': 23, 'fav_foods': ['pizza', 'fruit', 'fish']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "AlWkrQjnU269",
    "outputId": "f76b2eb8-947c-47fb-ca72-fb3ed584bcf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 6, 3, 'dog', 'cat', False, 5, 'grapes']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åˆ—è¡¨è¿æ¥å¹¶é‡æ–°èµ‹å€¼ç¤ºä¾‹\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºæ·»åŠ æ–°çš„å¯¹è¯æ¶ˆæ¯ã€æ‰©å±•é…ç½®åˆ—è¡¨ç­‰\n",
    "list1 += [5, 'grapes']  # åœ¨åˆ—è¡¨æœ«å°¾æ·»åŠ æ–°å…ƒç´ \n",
    "list1  # æ˜¾ç¤ºæ›´æ–°åçš„åˆ—è¡¨ï¼š[3, 5, 6, 3, 'dog', 'cat', False, 5, 'grapes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "fZOuiMP1U26-",
    "outputId": "e40d9158-9d67-490a-9675-b8541a22695d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 6, 3, 'dog', 'cat', False, 5, 'grapes')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å…ƒç»„è¿æ¥å¹¶é‡æ–°èµ‹å€¼ç¤ºä¾‹\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œä¼šåˆ›å»ºæ–°çš„å…ƒç»„ï¼ˆå› ä¸ºå…ƒç»„ä¸å¯å˜ï¼‰\n",
    "tuple1 += (5, 'grapes')  # åˆ›å»ºæ–°çš„å…ƒç»„ï¼ˆå…ƒç»„ä¸å¯å˜ï¼‰\n",
    "tuple1  # æ˜¾ç¤ºæ›´æ–°åçš„å…ƒç»„ï¼š(3, 5, 6, 3, 'dog', 'cat', False, 5, 'grapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEAKE5xSLKJG",
    "outputId": "c2dbc8a6-b24e-4fbd-fc75-30b5d2a06758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…ƒç»„æ“ä½œé”™è¯¯: 'tuple' object does not support item assignment\n",
      "ä¿®æ”¹åçš„åˆ—è¡¨: [5, 20, 30]\n"
     ]
    }
   ],
   "source": [
    "# å…ƒç»„ (ä¸å¯å˜)\n",
    "my_tuple = (10, 20, 30)\n",
    "try:\n",
    "    my_tuple[0] = 5  # å°è¯•ä¿®æ”¹ç¬¬ä¸€ä¸ªå…ƒç´ \n",
    "except TypeError as e:\n",
    "    print(f\"å…ƒç»„æ“ä½œé”™è¯¯: {e}\")\n",
    "# è¾“å‡º: å…ƒç»„æ“ä½œé”™è¯¯: 'tuple' object does not support item assignment\n",
    "\n",
    "# åˆ—è¡¨ (å¯å˜)\n",
    "my_list = [10, 20, 30]\n",
    "my_list[0] = 5  # æˆåŠŸä¿®æ”¹\n",
    "print(f\"ä¿®æ”¹åçš„åˆ—è¡¨: {my_list}\")\n",
    "# è¾“å‡º: ä¿®æ”¹åçš„åˆ—è¡¨: [5, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "h2fGEnpxU26_",
    "outputId": "c9e6aa1e-889b-48e4-ac13-75c7d9e830b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åˆ—è¡¨é‡å¤ç¤ºä¾‹ï¼ˆä½¿ç”¨ä¹˜æ³•æ“ä½œç¬¦ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºç”Ÿæˆæµ‹è¯•æ•°æ®ã€åˆ›å»ºé‡å¤æ¨¡å¼ç­‰\n",
    "[1, 2, 3, 4] * 2  # å°†åˆ—è¡¨é‡å¤2æ¬¡ï¼š[1, 2, 3, 4, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "exVWY0ruU27H",
    "outputId": "359f96da-d5f6-4955-a411-c5c44c132dfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å…ƒç»„é‡å¤ç¤ºä¾‹ï¼ˆä½¿ç”¨ä¹˜æ³•æ“ä½œç¬¦ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºç”Ÿæˆå›ºå®šæ¨¡å¼çš„é…ç½®æ•°æ®\n",
    "(1, 2, 3, 4) * 3  # å°†å…ƒç»„é‡å¤3æ¬¡ï¼š(1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZeKbR1JKl4-"
   },
   "source": [
    "åœ¨ Python ä¸­ï¼Œè¯´ **ä¸å¯å˜** æŒ‡çš„æ˜¯ï¼Œä¸€æ—¦ä½ åˆ›å»ºäº†ä¸€ä¸ªå…ƒç»„ï¼Œå°±**æ— æ³•å†å¯¹å®ƒè¿›è¡Œä»»ä½•ä¿®æ”¹**ã€‚\n",
    "\n",
    "å…·ä½“æ¥è¯´ï¼Œè¿™æ„å‘³ç€ä½ ä¸èƒ½åšä»¥ä¸‹æ“ä½œï¼š\n",
    "\n",
    "  * **ä¿®æ”¹**å…ƒç»„ä¸­çš„ä»»ä½•å…ƒç´ ã€‚\n",
    "  * **æ·»åŠ **æ–°çš„å…ƒç´ åˆ°å…ƒç»„ä¸­ã€‚\n",
    "  * **åˆ é™¤**å…ƒç»„ä¸­çš„ä»»ä½•å…ƒç´ ã€‚\n",
    "\n",
    "å¦‚æœä½ å°è¯•è¿›è¡Œè¿™äº›æ“ä½œï¼ŒPython è§£é‡Šå™¨ä¼šæŠ›å‡ºä¸€ä¸ª `TypeError` é”™è¯¯ï¼Œå‘Šè¯‰ä½ å…ƒç»„å¯¹è±¡ä¸æ”¯æŒè¿™äº›æ“ä½œã€‚\n",
    "\n",
    "-----\n",
    "\n",
    "### ä¸åˆ—è¡¨ï¼ˆlistï¼‰çš„å¯¹æ¯”\n",
    "\n",
    "ç†è§£å…ƒç»„çš„ä¸å¯å˜æ€§ï¼Œæœ€å¥½çš„æ–¹å¼å°±æ˜¯å°†å®ƒä¸ **å¯å˜** çš„åˆ—è¡¨è¿›è¡Œå¯¹æ¯”ã€‚åˆ—è¡¨å…è®¸ä½ éšæ„ä¿®æ”¹å…¶å†…å®¹ã€‚\n",
    "\n",
    "**1. å°è¯•ä¿®æ”¹ä¸€ä¸ªå…ƒç´ **\n",
    "\n",
    "```python\n",
    "# å…ƒç»„ (ä¸å¯å˜)\n",
    "my_tuple = (10, 20, 30)\n",
    "try:\n",
    "    my_tuple[0] = 5  # å°è¯•ä¿®æ”¹ç¬¬ä¸€ä¸ªå…ƒç´ \n",
    "except TypeError as e:\n",
    "    print(f\"å…ƒç»„æ“ä½œé”™è¯¯: {e}\")\n",
    "# è¾“å‡º: å…ƒç»„æ“ä½œé”™è¯¯: 'tuple' object does not support item assignment\n",
    "\n",
    "# åˆ—è¡¨ (å¯å˜)\n",
    "my_list = [10, 20, 30]\n",
    "my_list[0] = 5  # æˆåŠŸä¿®æ”¹\n",
    "print(f\"ä¿®æ”¹åçš„åˆ—è¡¨: {my_list}\")\n",
    "# è¾“å‡º: ä¿®æ”¹åçš„åˆ—è¡¨: [5, 20, 30]\n",
    "```\n",
    "\n",
    "**2. å°è¯•æ·»åŠ æˆ–åˆ é™¤å…ƒç´ **\n",
    "\n",
    "```python\n",
    "# å…ƒç»„ (ä¸å¯å˜)\n",
    "another_tuple = (1, 2)\n",
    "try:\n",
    "    another_tuple.append(3) # å°è¯•æ·»åŠ å…ƒç´ \n",
    "except AttributeError as e:\n",
    "    print(f\"å…ƒç»„æ“ä½œé”™è¯¯: {e}\")\n",
    "# è¾“å‡º: å…ƒç»„æ“ä½œé”™è¯¯: 'tuple' object has no attribute 'append'\n",
    "\n",
    "# åˆ—è¡¨ (å¯å˜)\n",
    "another_list = [1, 2]\n",
    "another_list.append(3)  # æˆåŠŸæ·»åŠ å…ƒç´ \n",
    "del another_list[0]     # æˆåŠŸåˆ é™¤ç¬¬ä¸€ä¸ªå…ƒç´ \n",
    "print(f\"ä¿®æ”¹åçš„åˆ—è¡¨: {another_list}\")\n",
    "# è¾“å‡º: ä¿®æ”¹åçš„åˆ—è¡¨: [2, 3]\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### ç‰¹æ®Šæƒ…å†µï¼šå…ƒç»„ä¸­åŒ…å«å¯å˜å¯¹è±¡\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„æ··æ·†ç‚¹ã€‚è™½ç„¶å…ƒç»„æœ¬èº«æ˜¯ä¸å¯å˜çš„ï¼Œä½†å¦‚æœå…ƒç»„ä¸­åŒ…å«äº†ä¸€ä¸ª**å¯å˜å¯¹è±¡**ï¼ˆæ¯”å¦‚ä¸€ä¸ªåˆ—è¡¨ï¼‰ï¼Œä½ **å¯ä»¥ä¿®æ”¹è¿™ä¸ªå¯å˜å¯¹è±¡çš„å†…å®¹**ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "\n",
    "```python\n",
    "my_tuple = (1, 2, [3, 4]) # å…ƒç»„ä¸­çš„ç¬¬ä¸‰ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåˆ—è¡¨\n",
    "\n",
    "# æˆ‘ä»¬ä¸èƒ½ä¿®æ”¹å…ƒç»„æœ¬èº«\n",
    "try:\n",
    "    my_tuple[0] = 5\n",
    "except TypeError as e:\n",
    "    print(f\"å°è¯•ä¿®æ”¹å…ƒç»„å…ƒç´ : {e}\")\n",
    "\n",
    "# ä½†æˆ‘ä»¬å¯ä»¥ä¿®æ”¹å…ƒç»„ä¸­åˆ—è¡¨çš„å†…å®¹\n",
    "my_tuple[2].append(5)\n",
    "print(f\"ä¿®æ”¹åçš„å…ƒç»„: {my_tuple}\")\n",
    "# è¾“å‡º: ä¿®æ”¹åçš„å…ƒç»„: (1, 2, [3, 4, 5])\n",
    "```\n",
    "\n",
    "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ`my_tuple` è¿™ä¸ªå…ƒç»„æœ¬èº«æ²¡æœ‰å˜ï¼ˆå®ƒä»ç„¶åŒ…å«ä¸‰ä¸ªå…ƒç´ ï¼‰ï¼Œä½†å®ƒæ‰€å¼•ç”¨çš„é‚£ä¸ªåˆ—è¡¨ï¼ˆ`[3, 4]`ï¼‰å†…éƒ¨çš„å†…å®¹å‘ç”Ÿäº†æ”¹å˜ã€‚\n",
    "\n",
    "### æ€»ç»“\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼Œ**â€œå…ƒç»„ä¸å¯å˜â€** æŒ‡çš„æ˜¯å…ƒç»„çš„**ç»“æ„å’Œå†…å®¹æ— æ³•åœ¨åŸåœ°æ”¹å˜**ï¼Œä»»ä½•å°è¯•éƒ½ä¼šå¤±è´¥ã€‚è¿™ä½¿å¾—å…ƒç»„éå¸¸é€‚åˆç”¨ä½œå­—å…¸çš„é”®ã€æˆ–åœ¨éœ€è¦ç¡®ä¿æ•°æ®ä¸è¢«æ„å¤–ä¿®æ”¹çš„åœºæ™¯ä¸­ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9AiBMwALf2N",
    "outputId": "ce3aa719-e56b-424e-a657-d8b0954a58c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°è¯•ä¿®æ”¹å…ƒç»„å…ƒç´ : 'tuple' object does not support item assignment\n",
      "ä¿®æ”¹åçš„å…ƒç»„: (1, 2, [3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "## ç‰¹æ®Šæƒ…å†µï¼šå…ƒç»„ä¸­åŒ…å«å¯å˜å¯¹è±¡\n",
    "my_tuple = (1, 2, [3, 4]) # å…ƒç»„ä¸­çš„ç¬¬ä¸‰ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåˆ—è¡¨\n",
    "\n",
    "# æˆ‘ä»¬ä¸èƒ½ä¿®æ”¹å…ƒç»„æœ¬èº«\n",
    "try:\n",
    "    my_tuple[0] = 5\n",
    "except TypeError as e:\n",
    "    print(f\"å°è¯•ä¿®æ”¹å…ƒç»„å…ƒç´ : {e}\")\n",
    "\n",
    "# ä½†æˆ‘ä»¬å¯ä»¥ä¿®æ”¹å…ƒç»„ä¸­åˆ—è¡¨çš„å†…å®¹\n",
    "my_tuple[2].append(5)\n",
    "print(f\"ä¿®æ”¹åçš„å…ƒç»„: {my_tuple}\")\n",
    "# è¾“å‡º: ä¿®æ”¹åçš„å…ƒç»„: (1, 2, [3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "xvrMsyQcU27I"
   },
   "source": [
    "## è®¿é—®å®¹å™¨ä¸­çš„æ•°æ®\n",
    "\n",
    "> **æ ¸å¿ƒæŠ€èƒ½**ï¼šåœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œæ­£ç¡®è®¿é—®å®¹å™¨æ•°æ®æ˜¯å¤„ç†APIå“åº”ã€è§£æé…ç½®ã€æå–ä¿¡æ¯çš„åŸºç¡€æŠ€èƒ½ã€‚\n",
    "\n",
    "### ä¸‹æ ‡è¡¨ç¤ºæ³•ï¼ˆæ–¹æ‹¬å·ï¼‰\n",
    "\n",
    "å¯¹äºå­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å…ƒç»„å’Œå­—å…¸ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨**ä¸‹æ ‡è¡¨ç¤ºæ³•**ï¼ˆæ–¹æ‹¬å·ï¼‰æ¥è®¿é—®ç´¢å¼•å¤„çš„æ•°æ®ã€‚\n",
    "\n",
    "#### åºåˆ—ç±»å‹ç´¢å¼•ï¼ˆå­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å…ƒç»„ï¼‰\n",
    "- é€šè¿‡æ•´æ•°ç´¢å¼•è®¿é—®ï¼Œ**ä»0å¼€å§‹**ä½œä¸ºç¬¬ä¸€é¡¹\n",
    "- æ”¯æŒè®¿é—®é¡¹ç›®èŒƒå›´ï¼Œç§°ä¸º**åˆ‡ç‰‡**\n",
    "- ä½¿ç”¨**è´Ÿç´¢å¼•**ä»åºåˆ—çš„åé¢å¼€å§‹\n",
    "\n",
    "#### å­—å…¸ç´¢å¼•\n",
    "- é€šè¿‡å…¶é”®è¿›è¡Œç´¢å¼•\n",
    "- é”®å¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€æ•°å­—ã€å…ƒç»„ç­‰ä¸å¯å˜ç±»å‹\n",
    "\n",
    "#### é›†åˆé™åˆ¶\n",
    "> **é‡è¦æé†’**ï¼šé›†åˆæ²¡æœ‰ç´¢å¼•ï¼Œå› æ­¤æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨ä¸‹æ ‡è¡¨ç¤ºæ³•æ¥è®¿é—®æ•°æ®å…ƒç´ ã€‚é›†åˆä¸»è¦ç”¨äºå»é‡å’Œé›†åˆè¿ç®—ã€‚\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„å®é™…åº”ç”¨\n",
    "- **APIå“åº”è§£æ**ï¼šä»JSONå“åº”ä¸­æå–ç‰¹å®šå­—æ®µ\n",
    "- **æ–‡æœ¬å¤„ç†**ï¼šä»å­—ç¬¦ä¸²ä¸­æå–å­å­—ç¬¦ä¸²\n",
    "- **é…ç½®ç®¡ç†**ï¼šä»é…ç½®å­—å…¸ä¸­è·å–å‚æ•°å€¼\n",
    "- **æ•°æ®æ¸…æ´—**ï¼šä»åˆ—è¡¨ä¸­ç­›é€‰å’Œå¤„ç†æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "EY_UwM7rU27J",
    "outputId": "4d68cd1d-03ed-44f4-efe2-0260c85ba8ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¿é—®åºåˆ—ä¸­çš„ç¬¬ä¸€ä¸ªé¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºè·å–åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ ã€å­—ç¬¦ä¸²çš„ç¬¬ä¸€ä¸ªå­—ç¬¦ç­‰\n",
    "list1[0]  # è·å–ç´¢å¼•0å¤„çš„å…ƒç´ ï¼ˆç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰ï¼š3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "g3L7rm-VU27J",
    "outputId": "0c9d76a6-12f4-4ac1-a163-85928ed1392c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grapes'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¿é—®åºåˆ—ä¸­çš„æœ€åä¸€ä¸ªé¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºè·å–æœ€æ–°çš„æ¶ˆæ¯ã€æœ€åçš„ç»“æœç­‰\n",
    "tuple1[-1]  # ä½¿ç”¨è´Ÿç´¢å¼•è·å–æœ€åä¸€ä¸ªå…ƒç´ ï¼š'grapes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "B1yMUfnkU27K",
    "outputId": "fe34beea-3eaa-47d7-acf3-136f8a1024f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'examp'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¿é—®åºåˆ—ä¸­ä¸€å®šèŒƒå›´çš„é¡¹ç›®ï¼ˆåˆ‡ç‰‡ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œåˆ‡ç‰‡å¸¸ç”¨äºæå–æ–‡æœ¬ç‰‡æ®µã€è·å–å­åˆ—è¡¨ç­‰\n",
    "simple_string1[3:8]  # è·å–ä»ç´¢å¼•3åˆ°7çš„å­—ç¬¦ï¼ˆä¸åŒ…å«ç´¢å¼•8ï¼‰ï¼š'examp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "Fs70C7pnU27K",
    "outputId": "a69c2703-6490-4619-d4ba-9e8d86847639"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 6, 3, 'dog', 'cat')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¿é—®åºåˆ—ä¸­ä¸€å®šèŒƒå›´çš„é¡¹ç›®ï¼ˆåˆ‡ç‰‡ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºæ’é™¤æœ€åå‡ ä¸ªå…ƒç´ ã€è·å–å‰é¢çš„æ•°æ®ç­‰\n",
    "tuple1[:-3]  # è·å–é™¤æœ€å3ä¸ªå…ƒç´ å¤–çš„æ‰€æœ‰å…ƒç´ ï¼š(3, 5, 6, 3, 'dog', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "za9QmBS3U27K",
    "outputId": "fd8d27df-2322-4aef-9c1d-c3c4bc0b67c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'cat', False, 5, 'grapes']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¿é—®åºåˆ—ä¸­ä¸€å®šèŒƒå›´çš„é¡¹ç›®ï¼ˆåˆ‡ç‰‡ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºè·å–ä»æŸä¸ªä½ç½®å¼€å§‹çš„æ‰€æœ‰æ•°æ®\n",
    "list1[4:]  # è·å–ä»ç´¢å¼•4å¼€å§‹åˆ°æœ«å°¾çš„æ‰€æœ‰å…ƒç´ ï¼š['dog', 'cat', False, 5, 'grapes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "uGwutJ35U27L",
    "outputId": "30085d8a-c8ec-4d51-963d-5a1bc8baa2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jane'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¿é—®å­—å…¸ä¸­çš„é¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºä»APIå“åº”ä¸­æå–ç‰¹å®šå­—æ®µ\n",
    "dict1['name']  # é€šè¿‡é”®'name'è·å–å¯¹åº”çš„å€¼ï¼š'Jane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "LNsz-HOPU27L",
    "outputId": "5a47c190-250c-4d62-ab35-eb0eeb6b7ec0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fish'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¿é—®å­—å…¸ä¸­åºåˆ—çš„å…ƒç´ ï¼ˆåµŒå¥—è®¿é—®ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºå¤„ç†å¤æ‚çš„åµŒå¥—æ•°æ®ç»“æ„\n",
    "dict1['fav_foods'][2]  # å…ˆè·å–'fav_foods'é”®çš„å€¼ï¼ˆåˆ—è¡¨ï¼‰ï¼Œå†è·å–ç´¢å¼•2å¤„çš„å…ƒç´ ï¼š'fish'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "7rvLP3MiU27L"
   },
   "source": [
    "## Python å†…ç½®å‡½æ•°å’Œå¯è°ƒç”¨å¯¹è±¡\n",
    "\n",
    "> **æ ¸å¿ƒæ¦‚å¿µ**ï¼šå‡½æ•°æ˜¯Pythonä¸­å¯ä»¥\"è°ƒç”¨\"æ¥æ‰§è¡Œæ“ä½œæˆ–è®¡ç®—å¹¶è¿”å›å¦ä¸€ä¸ªå¯¹è±¡çš„å¯¹è±¡ã€‚åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œå‡½æ•°æ˜¯æ„å»ºå¤æ‚åº”ç”¨çš„åŸºç¡€ã€‚\n",
    "\n",
    "### å‡½æ•°è°ƒç”¨åŸºç¡€\n",
    "\n",
    "**å‡½æ•°**æ˜¯ä½ å¯ä»¥\"è°ƒç”¨\"æ¥**æ‰§è¡Œæ“ä½œ**æˆ–è®¡ç®—å¹¶**è¿”å›å¦ä¸€ä¸ªå¯¹è±¡**çš„ Python å¯¹è±¡ã€‚ä½ é€šè¿‡åœ¨å‡½æ•°åå³ä¾§æ”¾ç½®æ‹¬å·æ¥è°ƒç”¨å‡½æ•°ã€‚æŸäº›å‡½æ•°å…è®¸ä½ åœ¨æ‹¬å·å†…ä¼ é€’**å‚æ•°**ï¼ˆç”¨é€—å·åˆ†éš”å¤šä¸ªå‚æ•°ï¼‰ã€‚åœ¨å‡½æ•°å†…éƒ¨ï¼Œè¿™äº›å‚æ•°è¢«è§†ä¸ºå˜é‡ã€‚\n",
    "\n",
    "### å¸¸ç”¨å†…ç½®å‡½æ•°\n",
    "\n",
    "Python æœ‰å‡ ä¸ªæœ‰ç”¨çš„å†…ç½®å‡½æ•°æ¥å¸®åŠ©ä½ å¤„ç†ä¸åŒçš„å¯¹è±¡å’Œç¯å¢ƒã€‚ä»¥ä¸‹æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­å¸¸ç”¨çš„å‡½æ•°ï¼š\n",
    "\n",
    "#### ç±»å‹å’Œæ£€æŸ¥å‡½æ•°\n",
    "- **`type(obj)`** - ç¡®å®šå¯¹è±¡çš„ç±»å‹ï¼Œç”¨äºè°ƒè¯•å’Œç±»å‹æ£€æŸ¥\n",
    "- **`len(container)`** - ç¡®å®šå®¹å™¨ä¸­æœ‰å¤šå°‘é¡¹ç›®ï¼Œå¸¸ç”¨äºæ£€æŸ¥æ•°æ®é•¿åº¦\n",
    "- **`callable(obj)`** - ç¡®å®šå¯¹è±¡æ˜¯å¦å¯è°ƒç”¨ï¼Œç”¨äºæ£€æŸ¥å‡½æ•°å’Œæ–¹æ³•\n",
    "\n",
    "#### æ•°æ®å¤„ç†å‡½æ•°\n",
    "- **`sorted(container)`** - ä»å®¹å™¨è¿”å›ä¸€ä¸ªæ–°åˆ—è¡¨ï¼Œé¡¹ç›®å·²æ’åº\n",
    "- **`sum(container)`** - è®¡ç®—æ•°å­—å®¹å™¨çš„æ€»å’Œï¼Œå¸¸ç”¨äºç»Ÿè®¡è®¡ç®—\n",
    "- **`min(container)`** - ç¡®å®šå®¹å™¨ä¸­çš„æœ€å°é¡¹ç›®\n",
    "- **`max(container)`** - ç¡®å®šå®¹å™¨ä¸­çš„æœ€å¤§é¡¹ç›®\n",
    "- **`abs(number)`** - ç¡®å®šæ•°å­—çš„ç»å¯¹å€¼\n",
    "\n",
    "#### è¡¨ç¤ºå‡½æ•°\n",
    "- **`repr(obj)`** - è¿”å›å¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œç”¨äºè°ƒè¯•å’Œæ—¥å¿—è®°å½•\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "\n",
    "- **æ•°æ®éªŒè¯**ï¼šä½¿ç”¨ `type()` å’Œ `len()` éªŒè¯APIå“åº”æ ¼å¼\n",
    "- **ç»Ÿè®¡åˆ†æ**ï¼šä½¿ç”¨ `sum()`ã€`min()`ã€`max()` åˆ†ææ¨¡å‹æ€§èƒ½æŒ‡æ ‡\n",
    "- **æ•°æ®å¤„ç†**ï¼šä½¿ç”¨ `sorted()` å¯¹ç»“æœè¿›è¡Œæ’åº\n",
    "- **è°ƒè¯•æ”¯æŒ**ï¼šä½¿ç”¨ `repr()` è¾“å‡ºè°ƒè¯•ä¿¡æ¯\n",
    "\n",
    "> å®Œæ•´çš„å†…ç½®å‡½æ•°åˆ—è¡¨ï¼š[Pythonå®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/library/functions.html)\n",
    "\n",
    "è¿˜æœ‰å®šä¹‰ä½ è‡ªå·±çš„å‡½æ•°å’Œå¯è°ƒç”¨å¯¹è±¡çš„ä¸åŒæ–¹æ³•ï¼Œæˆ‘ä»¬ç¨åå°†æ¢è®¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "1jYmdXSnU27M",
    "outputId": "f97dfb1e-fe2d-471d-9fb2-f0289e743289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ type() å‡½æ•°ç¡®å®šå¯¹è±¡çš„ç±»å‹\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œtype()å¸¸ç”¨äºéªŒè¯APIå“åº”çš„æ•°æ®ç±»å‹\n",
    "type(simple_string1)  # è¿”å›å­—ç¬¦ä¸²å¯¹è±¡çš„ç±»å‹ï¼š<class 'str'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "K2XEuZygU27M",
    "outputId": "64b84eb9-c94c-4297-817d-fb3d069b0026"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ len() å‡½æ•°ç¡®å®šå®¹å™¨ä¸­æœ‰å¤šå°‘é¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œlen()å¸¸ç”¨äºæ£€æŸ¥æ•°æ®é•¿åº¦ã€éªŒè¯è¾“å…¥ç­‰\n",
    "len(dict1)  # è¿”å›å­—å…¸ä¸­é”®å€¼å¯¹çš„æ•°é‡ï¼š3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "CUh5qRUZU27M",
    "outputId": "2da3192d-53a9-4c47-8de9-670c76447cb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ len() å‡½æ•°ç¡®å®šå®¹å™¨ä¸­æœ‰å¤šå°‘é¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œlen()å¸¸ç”¨äºæ£€æŸ¥æ–‡æœ¬é•¿åº¦ã€è®¡ç®—tokenæ•°é‡ç­‰\n",
    "len(simple_string2)  # è¿”å›å­—ç¬¦ä¸²ä¸­å­—ç¬¦çš„æ•°é‡ï¼š24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "InzA1HSKU27N",
    "outputId": "ba416f93-c6df-4dbb-8f36-d0e6b916fa8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ callable() å‡½æ•°ç¡®å®šå¯¹è±¡æ˜¯å¦å¯è°ƒç”¨\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œcallable()å¸¸ç”¨äºæ£€æŸ¥APIæ–¹æ³•ã€éªŒè¯å‡½æ•°ç­‰\n",
    "callable(len)  # æ£€æŸ¥ len å‡½æ•°æ˜¯å¦å¯è°ƒç”¨ï¼šTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "kVTxXNiXU27O",
    "outputId": "0e7d9a74-5d64-4e05-e876-2d37b8bff0cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ callable() å‡½æ•°ç¡®å®šå¯¹è±¡æ˜¯å¦å¯è°ƒç”¨\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œcallable()å¸¸ç”¨äºæ£€æŸ¥å¯¹è±¡æ˜¯å¦ä¸ºå‡½æ•°æˆ–æ–¹æ³•\n",
    "callable(dict1)  # æ£€æŸ¥å­—å…¸å¯¹è±¡æ˜¯å¦å¯è°ƒç”¨ï¼šFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "5yBWcuesU27O",
    "outputId": "931a91b6-a2c1-401b-9e14-b913704dbc98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3, 1, 2, 3.6, 5, 7, 10]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ sorted() å‡½æ•°ä»å®¹å™¨è¿”å›ä¸€ä¸ªæ–°åˆ—è¡¨ï¼Œé¡¹ç›®å·²æ’åº\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œsorted()å¸¸ç”¨äºå¯¹ç»“æœè¿›è¡Œæ’åºã€åˆ†ææ•°æ®åˆ†å¸ƒç­‰\n",
    "sorted([10, 1, 3.6, 7, 5, 2, -3])  # å¯¹æ•°å­—åˆ—è¡¨è¿›è¡Œæ’åºï¼š[-3, 1, 2, 3.6, 5, 7, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "9l1EB4MRU27O",
    "outputId": "ae3561c9-ebd7-4d8e-d42b-6c8adc78a47b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['California', 'Chicago', 'ants', 'cats', 'dogs', 'mice', 'zebras']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ sorted() å‡½æ•°ä»å®¹å™¨è¿”å›ä¸€ä¸ªæ–°åˆ—è¡¨ï¼Œé¡¹ç›®å·²æ’åº\n",
    "# - æ³¨æ„å¤§å†™å­—ç¬¦ä¸²æ’åœ¨å‰é¢ï¼ˆASCIIç é¡ºåºï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œsorted()å¸¸ç”¨äºå¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œæ’åºã€ç»„ç»‡ç»“æœç­‰\n",
    "sorted(['dogs', 'cats', 'zebras', 'Chicago', 'California', 'ants', 'mice'])  # å¯¹å­—ç¬¦ä¸²åˆ—è¡¨è¿›è¡Œæ’åºï¼š['California', 'Chicago', 'ants', 'cats', 'dogs', 'mice', 'zebras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "VmWSr4qtU27P",
    "outputId": "f29a7119-276f-48b5-b3c5-339b0bdeea3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ sum() å‡½æ•°è®¡ç®—æ•°å­—å®¹å™¨çš„æ€»å’Œ\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œsum()å¸¸ç”¨äºè®¡ç®—æ€»tokenæ•°ã€ç»Ÿè®¡æŒ‡æ ‡ç­‰\n",
    "sum([10, 1, 3.6, 7, 5, 2, -3])  # è®¡ç®—åˆ—è¡¨ä¸­æ‰€æœ‰æ•°å­—çš„æ€»å’Œï¼š25.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "z2dlPGI0U27P",
    "outputId": "42c843a2-f787-430e-802f-b2beb240b2f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ min() å‡½æ•°ç¡®å®šå®¹å™¨ä¸­çš„æœ€å°é¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œmin()å¸¸ç”¨äºæ‰¾åˆ°æœ€å°å€¼ã€åˆ†ææ•°æ®èŒƒå›´ç­‰\n",
    "min([10, 1, 3.6, 7, 5, 2, -3])  # æ‰¾åˆ°åˆ—è¡¨ä¸­çš„æœ€å°å€¼ï¼š-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "yFre0KasU27Q",
    "outputId": "298092b5-3af1-49f5-8046-c02b1ff4b4aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ min() å‡½æ•°ç¡®å®šå®¹å™¨ä¸­çš„æœ€å°é¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œmin()å¸¸ç”¨äºå­—ç¬¦ä¸²æ¯”è¾ƒã€æ‰¾åˆ°æœ€å°/æœ€å¤§æ–‡æœ¬ç­‰\n",
    "min(['g', 'z', 'a', 'y'])  # æ‰¾åˆ°å­—ç¬¦ä¸²åˆ—è¡¨ä¸­çš„æœ€å°å­—ç¬¦ï¼ˆæŒ‰å­—æ¯é¡ºåºï¼‰ï¼š'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "LGZKNOzBU27Q",
    "outputId": "1cc7f7b9-a525-4b48-c66c-99c9bb73eb98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ max() å‡½æ•°ç¡®å®šå®¹å™¨ä¸­çš„æœ€å¤§é¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œmax()å¸¸ç”¨äºæ‰¾åˆ°æœ€å¤§å€¼ã€åˆ†ææ•°æ®èŒƒå›´ç­‰\n",
    "max([10, 1, 3.6, 7, 5, 2, -3])  # æ‰¾åˆ°åˆ—è¡¨ä¸­çš„æœ€å¤§å€¼ï¼š10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "s4YXs6aFU27Q",
    "outputId": "1014a632-4588-4f9c-e034-64ae0765b989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ max() å‡½æ•°ç¡®å®šå®¹å™¨ä¸­çš„æœ€å¤§é¡¹ç›®\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œmax()å¸¸ç”¨äºå­—ç¬¦ä¸²æ¯”è¾ƒã€æ‰¾åˆ°æœ€å¤§å­—ç¬¦ç­‰\n",
    "max('gibberish')  # æ‰¾åˆ°å­—ç¬¦ä¸²ä¸­çš„æœ€å¤§å­—ç¬¦ï¼ˆæŒ‰å­—æ¯é¡ºåºï¼‰ï¼š's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "V3Bzso3rU27R",
    "outputId": "fa416607-3764-4154-b63f-d6a96bc53699"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ abs() å‡½æ•°ç¡®å®šæ•°å­—çš„ç»å¯¹å€¼\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œabs()å¸¸ç”¨äºè®¡ç®—è·ç¦»ã€å¤„ç†è´Ÿæ•°ç­‰\n",
    "abs(10)  # æ­£æ•°çš„ç»å¯¹å€¼æ˜¯å®ƒæœ¬èº«ï¼š10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "vquqrSTXU27R",
    "outputId": "cfe3053f-d3c2-4888-8e04-d674f57da4f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ abs() å‡½æ•°ç¡®å®šæ•°å­—çš„ç»å¯¹å€¼\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œabs()å¸¸ç”¨äºè®¡ç®—è¯¯å·®ã€å¤„ç†è´Ÿæ•°ç­‰\n",
    "abs(-12)  # è´Ÿæ•°çš„ç»å¯¹å€¼æ˜¯å®ƒçš„ç›¸åæ•°ï¼š12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "zNEBR8jcU27S",
    "outputId": "4f154f91-2473-4b46-ad2b-3fac75259fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'cat', False, 3, 5, 6, 'dog'}\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ repr() å‡½æ•°è¿”å›å¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤º\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œrepr()å¸¸ç”¨äºè°ƒè¯•ã€æ—¥å¿—è®°å½•ç­‰\n",
    "repr(set1)  # è¿”å›é›†åˆçš„å®˜æ–¹å­—ç¬¦ä¸²è¡¨ç¤ºï¼š\"{False, 3, 5, 6, 'dog', 'cat'}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "4n98LeCOSy2E",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## strï¼ˆå­—ç¬¦ä¸²ï¼‰å¯¹è±¡çš„ä¸€äº›æ–¹æ³•\n",
    "\n",
    "> **é‡è¦æŠ€èƒ½**ï¼šå­—ç¬¦ä¸²æ–¹æ³•æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­æœ€å¸¸ç”¨çš„å·¥å…·ï¼Œç”¨äºæ–‡æœ¬å¤„ç†ã€æ•°æ®æ¸…æ´—ã€æ ¼å¼è½¬æ¢ç­‰ã€‚\n",
    "\n",
    "### å¤§å°å†™è½¬æ¢æ–¹æ³•\n",
    "- **`.capitalize()`** - è¿”å›å­—ç¬¦ä¸²çš„å¤§å†™ç‰ˆæœ¬ï¼ˆåªæœ‰ç¬¬ä¸€ä¸ªå­—ç¬¦å¤§å†™ï¼‰\n",
    "- **`.upper()`** - è¿”å›å­—ç¬¦ä¸²çš„å¤§å†™ç‰ˆæœ¬ï¼ˆæ‰€æœ‰å­—ç¬¦å¤§å†™ï¼‰\n",
    "- **`.lower()`** - è¿”å›å­—ç¬¦ä¸²çš„å°å†™ç‰ˆæœ¬ï¼ˆæ‰€æœ‰å­—ç¬¦å°å†™ï¼‰\n",
    "\n",
    "### æ–‡æœ¬åˆ†ææ–¹æ³•\n",
    "- **`.count(substring)`** - è¿”å›å­å­—ç¬¦ä¸²åœ¨å­—ç¬¦ä¸²ä¸­å‡ºç°çš„æ¬¡æ•°\n",
    "- **`.startswith(substring)`** - ç¡®å®šå­—ç¬¦ä¸²æ˜¯å¦ä»¥å­å­—ç¬¦ä¸²å¼€å¤´\n",
    "- **`.endswith(substring)`** - ç¡®å®šå­—ç¬¦ä¸²æ˜¯å¦ä»¥å­å­—ç¬¦ä¸²ç»“å°¾\n",
    "\n",
    "### æ–‡æœ¬æ›¿æ¢æ–¹æ³•\n",
    "- **`.replace(old, new)`** - è¿”å›å­—ç¬¦ä¸²çš„å‰¯æœ¬ï¼Œå…¶ä¸­\"old\"çš„å‡ºç°è¢«\"new\"æ›¿æ¢\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **æ–‡æœ¬é¢„å¤„ç†**ï¼šä½¿ç”¨ `.lower()` å’Œ `.strip()` æ ‡å‡†åŒ–è¾“å…¥æ–‡æœ¬\n",
    "- **æ•°æ®éªŒè¯**ï¼šä½¿ç”¨ `.startswith()` å’Œ `.endswith()` éªŒè¯æ–‡æœ¬æ ¼å¼\n",
    "- **å†…å®¹æ›¿æ¢**ï¼šä½¿ç”¨ `.replace()` æ¸…ç†å’Œè½¬æ¢æ–‡æœ¬å†…å®¹\n",
    "- **ç»Ÿè®¡åˆ†æ**ï¼šä½¿ç”¨ `.count()` åˆ†ææ–‡æœ¬ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "-ep5WQirSy2F"
   },
   "outputs": [],
   "source": [
    "# å°†å­—ç¬¦ä¸²èµ‹å€¼ç»™å˜é‡\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ··åˆå¤§å°å†™çš„å­—ç¬¦ä¸²å¸¸ç”¨äºæµ‹è¯•æ–‡æœ¬å¤„ç†åŠŸèƒ½\n",
    "a_string = 'tHis is a sTriNg'  # åŒ…å«å¤§å°å†™æ··åˆçš„å­—ç¬¦ä¸²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "N0wcyJnHSy2F",
    "outputId": "7252f1c4-6679-4e73-cbed-03daea00da62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a string'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿”å›å­—ç¬¦ä¸²çš„å¤§å†™ç‰ˆæœ¬ï¼ˆåªæœ‰ç¬¬ä¸€ä¸ªå­—ç¬¦å¤§å†™ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œcapitalize()å¸¸ç”¨äºæ ¼å¼åŒ–ç”¨æˆ·è¾“å…¥ã€æ ‡é¢˜ç­‰\n",
    "a_string.capitalize()  # å°†ç¬¬ä¸€ä¸ªå­—ç¬¦å¤§å†™ï¼Œå…¶ä½™å°å†™ï¼š'This is a string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "8LMtoCfySy2F",
    "outputId": "97da69af-3a27-4dc1-f7d3-4378c2d3c51b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THIS IS A STRING'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿”å›å­—ç¬¦ä¸²çš„å¤§å†™ç‰ˆæœ¬ï¼ˆæ‰€æœ‰å­—ç¬¦å¤§å†™ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œupper()å¸¸ç”¨äºæ ‡å‡†åŒ–æ–‡æœ¬ã€æ¯”è¾ƒç­‰\n",
    "a_string.upper()  # å°†æ‰€æœ‰å­—ç¬¦è½¬æ¢ä¸ºå¤§å†™ï¼š'THIS IS A STRING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "ggZ_UmI2Sy2F",
    "outputId": "4db74b05-4ae8-454b-83e8-2b091dde7d84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a string'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿”å›å­—ç¬¦ä¸²çš„å°å†™ç‰ˆæœ¬ï¼ˆæ‰€æœ‰å­—ç¬¦å°å†™ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œlower()å¸¸ç”¨äºæ–‡æœ¬æ ‡å‡†åŒ–ã€é¢„å¤„ç†ç­‰\n",
    "a_string.lower()  # å°†æ‰€æœ‰å­—ç¬¦è½¬æ¢ä¸ºå°å†™ï¼š'this is a string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "7Q168B72Sy2G",
    "outputId": "4c6ae19e-3580-499a-b9c6-cbadceecfd73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tHis is a sTriNg'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é‡è¦æ¦‚å¿µï¼šè°ƒç”¨çš„æ–¹æ³•å®é™…ä¸Šæ²¡æœ‰ä¿®æ”¹åŸå­—ç¬¦ä¸²ï¼ˆå­—ç¬¦ä¸²æ˜¯ä¸å¯å˜çš„ï¼‰\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œç†è§£å­—ç¬¦ä¸²ä¸å¯å˜æ€§å¾ˆé‡è¦ï¼Œæ¯æ¬¡æ“ä½œéƒ½ä¼šåˆ›å»ºæ–°å­—ç¬¦ä¸²\n",
    "a_string  # åŸå­—ç¬¦ä¸²ä¿æŒä¸å˜ï¼š'tHis is a sTriNg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "tOTILSrbSy2G",
    "outputId": "57b36ee1-b493-4e57-cc30-f1da8170ae3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¡ç®—å­å­—ç¬¦ä¸²åœ¨å­—ç¬¦ä¸²ä¸­å‡ºç°çš„æ¬¡æ•°\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œcount()å¸¸ç”¨äºæ–‡æœ¬åˆ†æã€ç»Ÿè®¡å­—ç¬¦ç­‰\n",
    "a_string.count('i')  # è®¡ç®—å­—ç¬¦'i'åœ¨å­—ç¬¦ä¸²ä¸­å‡ºç°çš„æ¬¡æ•°ï¼š3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "P6XwQxLYSy2G",
    "outputId": "14972dac-e5d1-4a86-ca8e-aab6b59c3dbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¡ç®—å­å­—ç¬¦ä¸²åœ¨å­—ç¬¦ä¸²ä¸­æŸä¸ªä½ç½®ä¹‹åå‡ºç°çš„æ¬¡æ•°\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºåˆ†ææ–‡æœ¬çš„ç‰¹å®šéƒ¨åˆ†\n",
    "a_string.count('i', 7)  # ä»ç´¢å¼•7å¼€å§‹è®¡ç®—å­—ç¬¦'i'çš„å‡ºç°æ¬¡æ•°ï¼š1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "r5JxhDSoSy2G",
    "outputId": "2bf8e4d1-d0d8-4449-e167-ff5088c986cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¡ç®—å­å­—ç¬¦ä¸²åœ¨å­—ç¬¦ä¸²ä¸­å‡ºç°çš„æ¬¡æ•°\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§æ“ä½œå¸¸ç”¨äºåˆ†æå…³é”®è¯ã€çŸ­è¯­ç­‰\n",
    "a_string.count('is')  # è®¡ç®—å­å­—ç¬¦ä¸²'is'åœ¨å­—ç¬¦ä¸²ä¸­å‡ºç°çš„æ¬¡æ•°ï¼š2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "jungZpUKSy2G",
    "outputId": "2c8d755f-1dc2-4d5a-a503-345694c61298"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²æ˜¯å¦ä»¥'this'å¼€å¤´ï¼Ÿ\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œstartswith()å¸¸ç”¨äºéªŒè¯è¾“å…¥æ ¼å¼ã€æ£€æŸ¥å‰ç¼€ç­‰\n",
    "a_string.startswith('this')  # æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä»¥'this'å¼€å¤´ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼šFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "0ClvSWBXSy2G",
    "outputId": "5078c7f3-f9f3-4c84-f128-e342abfaecb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°å†™å­—ç¬¦ä¸²æ˜¯å¦ä»¥'this'å¼€å¤´ï¼Ÿ\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§é“¾å¼è°ƒç”¨å¸¸ç”¨äºæ–‡æœ¬é¢„å¤„ç†å’ŒéªŒè¯\n",
    "a_string.lower().startswith('this')  # å…ˆè½¬æ¢ä¸ºå°å†™ï¼Œå†æ£€æŸ¥æ˜¯å¦ä»¥'this'å¼€å¤´ï¼šTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "GwbBdl2iSy2G",
    "outputId": "437df042-ba03-4dd3-b8b4-193947ae4b57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²æ˜¯å¦ä»¥'Ng'ç»“å°¾ï¼Ÿ\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œendswith()å¸¸ç”¨äºéªŒè¯æ–‡ä»¶æ ¼å¼ã€æ£€æŸ¥åç¼€ç­‰\n",
    "a_string.endswith('Ng')  # æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä»¥'Ng'ç»“å°¾ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼šTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "1zGDFHBBSy2H",
    "outputId": "dfb362d8-588b-4539-ac8b-33099ce3ad0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tHXYZ XYZ a sTriNg'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿”å›å­—ç¬¦ä¸²çš„ç‰ˆæœ¬ï¼Œå…¶ä¸­å­å­—ç¬¦ä¸²è¢«å…¶ä»–å†…å®¹æ›¿æ¢\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œreplace()å¸¸ç”¨äºæ–‡æœ¬æ¸…ç†ã€å†…å®¹æ›¿æ¢ç­‰\n",
    "a_string.replace('is', 'XYZ')  # å°†æ‰€æœ‰'is'æ›¿æ¢ä¸º'XYZ'ï¼š'tHXYZ XYZ a sTriNg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "1RaqrXmLSy2H",
    "outputId": "363c0b1d-9b53-4acb-f090-4713acbc066c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tH!s !s a sTr!Ng'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿”å›å­—ç¬¦ä¸²çš„ç‰ˆæœ¬ï¼Œå…¶ä¸­å­å­—ç¬¦ä¸²è¢«å…¶ä»–å†…å®¹æ›¿æ¢\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œreplace()å¸¸ç”¨äºå­—ç¬¦æ›¿æ¢ã€æ–‡æœ¬è½¬æ¢ç­‰\n",
    "a_string.replace('i', '!')  # å°†æ‰€æœ‰'i'æ›¿æ¢ä¸º'!'ï¼š'tH!s !s a sTr!Ng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "deletable": true,
    "editable": true,
    "id": "4KV4KgiVSy2H",
    "outputId": "0488e08e-0df5-4eee-a3af-fbda0b23d481"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tH!s !s a sTriNg'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿”å›å­—ç¬¦ä¸²çš„ç‰ˆæœ¬ï¼Œå…¶ä¸­å‰2ä¸ªå‡ºç°çš„å­å­—ç¬¦ä¸²è¢«å…¶ä»–å†…å®¹æ›¿æ¢\n",
    "# åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œè¿™ç§é™åˆ¶æ›¿æ¢æ¬¡æ•°å¸¸ç”¨äºç²¾ç¡®æ§åˆ¶æ–‡æœ¬ä¿®æ”¹\n",
    "a_string.replace('i', '!', 2)  # åªæ›¿æ¢å‰2ä¸ª'i'ä¸º'!'ï¼š'tH!s !s a sTriNg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "jXdBbBm4U27k",
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## listï¼ˆåˆ—è¡¨ï¼‰å¯¹è±¡çš„ä¸€äº›æ–¹æ³•\n",
    "\n",
    "> **é‡è¦æŠ€èƒ½**ï¼šåˆ—è¡¨æ–¹æ³•æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­å¤„ç†æ•°æ®é›†åˆçš„æ ¸å¿ƒå·¥å…·ï¼Œç”¨äºç®¡ç†å¯¹è¯å†å²ã€é…ç½®å‚æ•°ã€å¤„ç†ç»“æœç­‰ã€‚\n",
    "\n",
    "### æ·»åŠ å…ƒç´ æ–¹æ³•\n",
    "- **`.append(item)`** - åœ¨åˆ—è¡¨æœ«å°¾æ·»åŠ å•ä¸ªå…ƒç´ \n",
    "- **`.extend([item1, item2, ...])`** - åœ¨åˆ—è¡¨æœ«å°¾æ·»åŠ å¤šä¸ªå…ƒç´ \n",
    "\n",
    "### åˆ é™¤å…ƒç´ æ–¹æ³•\n",
    "- **`.remove(item)`** - åˆ é™¤åˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªåŒ¹é…çš„å…ƒç´ \n",
    "- **`.pop()`** - åˆ é™¤å¹¶è¿”å›åˆ—è¡¨æœ«å°¾çš„å…ƒç´ \n",
    "- **`.pop(index)`** - åˆ é™¤å¹¶è¿”å›æŒ‡å®šç´¢å¼•ä½ç½®çš„å…ƒç´ \n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **å¯¹è¯ç®¡ç†**ï¼šä½¿ç”¨ `append()` æ·»åŠ æ–°çš„å¯¹è¯æ¶ˆæ¯\n",
    "- **æ•°æ®å¤„ç†**ï¼šä½¿ç”¨ `extend()` æ‰¹é‡æ·»åŠ å¤„ç†ç»“æœ\n",
    "- **å†å²æ¸…ç†**ï¼šä½¿ç”¨ `pop()` å’Œ `remove()` ç®¡ç†å¯¹è¯å†å²é•¿åº¦\n",
    "- **é…ç½®ç®¡ç†**ï¼šåŠ¨æ€æ·»åŠ å’Œåˆ é™¤é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "kJ6ZUlveU27k",
    "outputId": "d389a206-ab30-4c86-efc5-559174a00165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ·»åŠ æ¶ˆæ¯åçš„å¯¹è¯å†å²:\n",
      "1. user: ä½ å¥½\n",
      "2. assistant: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "æ‰¹é‡æ·»åŠ åçš„å¯¹è¯å†å²:\n",
      "1. user: ä½ å¥½\n",
      "2. assistant: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "3. user: è¯·ä»‹ç»ä¸€ä¸‹Python\n",
      "4. assistant: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...\n",
      "5. user: è°¢è°¢\n",
      "\n",
      "åˆ é™¤çš„æœ€åä¸€æ¡æ¶ˆæ¯: è°¢è°¢\n",
      "\n",
      "åˆ é™¤ç‰¹å®šæ¶ˆæ¯åçš„å¯¹è¯å†å²:\n",
      "1. user: ä½ å¥½\n",
      "2. assistant: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "3. assistant: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...\n",
      "\n",
      "åˆ é™¤çš„ç¬¬ä¸€æ¡æ¶ˆæ¯: ä½ å¥½\n",
      "\n",
      "æœ€ç»ˆå¯¹è¯å†å²é•¿åº¦: 2\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„åˆ—è¡¨æ–¹æ³•ç¤ºä¾‹\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªå¯¹è¯å†å²åˆ—è¡¨\n",
    "conversation_history = []\n",
    "\n",
    "# ä½¿ç”¨ append() æ·»åŠ å•ä¸ªæ¶ˆæ¯\n",
    "conversation_history.append({\"role\": \"user\", \"content\": \"ä½ å¥½\"})\n",
    "conversation_history.append({\"role\": \"assistant\", \"content\": \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\"})\n",
    "\n",
    "print(\"æ·»åŠ æ¶ˆæ¯åçš„å¯¹è¯å†å²:\")\n",
    "for i, msg in enumerate(conversation_history):\n",
    "    print(f\"{i+1}. {msg['role']}: {msg['content']}\")\n",
    "\n",
    "# ä½¿ç”¨ extend() æ‰¹é‡æ·»åŠ æ¶ˆæ¯\n",
    "new_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"è¯·ä»‹ç»ä¸€ä¸‹Python\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...\"},\n",
    "    {\"role\": \"user\", \"content\": \"è°¢è°¢\"}\n",
    "]\n",
    "conversation_history.extend(new_messages)\n",
    "\n",
    "print(\"\\næ‰¹é‡æ·»åŠ åçš„å¯¹è¯å†å²:\")\n",
    "for i, msg in enumerate(conversation_history):\n",
    "    print(f\"{i+1}. {msg['role']}: {msg['content']}\")\n",
    "\n",
    "# ä½¿ç”¨ pop() åˆ é™¤æœ€åä¸€æ¡æ¶ˆæ¯\n",
    "last_message = conversation_history.pop()\n",
    "print(f\"\\nåˆ é™¤çš„æœ€åä¸€æ¡æ¶ˆæ¯: {last_message['content']}\")\n",
    "\n",
    "# ä½¿ç”¨ remove() åˆ é™¤ç‰¹å®šæ¶ˆæ¯\n",
    "conversation_history.remove({\"role\": \"user\", \"content\": \"è¯·ä»‹ç»ä¸€ä¸‹Python\"})\n",
    "print(\"\\nåˆ é™¤ç‰¹å®šæ¶ˆæ¯åçš„å¯¹è¯å†å²:\")\n",
    "for i, msg in enumerate(conversation_history):\n",
    "    print(f\"{i+1}. {msg['role']}: {msg['content']}\")\n",
    "\n",
    "# ä½¿ç”¨ pop(index) åˆ é™¤æŒ‡å®šä½ç½®çš„æ¶ˆæ¯\n",
    "if len(conversation_history) > 0:\n",
    "    first_message = conversation_history.pop(0)\n",
    "    print(f\"\\nåˆ é™¤çš„ç¬¬ä¸€æ¡æ¶ˆæ¯: {first_message['content']}\")\n",
    "\n",
    "print(f\"\\næœ€ç»ˆå¯¹è¯å†å²é•¿åº¦: {len(conversation_history)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfcmqqsTU27l",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## setï¼ˆé›†åˆï¼‰å¯¹è±¡çš„ä¸€äº›æ–¹æ³•\n",
    "\n",
    "> **é‡è¦æŠ€èƒ½**ï¼šé›†åˆæ–¹æ³•åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºå»é‡ã€é›†åˆè¿ç®—ã€æ•°æ®æ¯”è¾ƒç­‰æ“ä½œï¼Œç‰¹åˆ«é€‚åˆå¤„ç†å”¯ä¸€å€¼é›†åˆã€‚\n",
    "\n",
    "### æ·»åŠ å…ƒç´ æ–¹æ³•\n",
    "- **`.add(item)`** - å‘é›†åˆæ·»åŠ å•ä¸ªå…ƒç´ \n",
    "- **`.update([item1, item2, ...])`** - å‘é›†åˆæ·»åŠ å¤šä¸ªå…ƒç´ \n",
    "- **`.update(set2, set3, ...)`** - å°†å¤šä¸ªé›†åˆçš„å…ƒç´ æ·»åŠ åˆ°å½“å‰é›†åˆ\n",
    "\n",
    "### åˆ é™¤å…ƒç´ æ–¹æ³•\n",
    "- **`.remove(item)`** - ä»é›†åˆä¸­åˆ é™¤æŒ‡å®šå…ƒç´ \n",
    "- **`.pop()`** - åˆ é™¤å¹¶è¿”å›é›†åˆä¸­çš„éšæœºå…ƒç´ \n",
    "\n",
    "### é›†åˆè¿ç®—æ–¹æ³•\n",
    "- **`.difference(set2)`** - è¿”å›åœ¨å½“å‰é›†åˆä¸­ä½†ä¸åœ¨å¦ä¸€ä¸ªé›†åˆä¸­çš„å…ƒç´ \n",
    "- **`.intersection(set2)`** - è¿”å›ä¸¤ä¸ªé›†åˆçš„äº¤é›†\n",
    "- **`.union(set2)`** - è¿”å›ä¸¤ä¸ªé›†åˆçš„å¹¶é›†\n",
    "- **`.symmetric_difference(set2)`** - è¿”å›åªåœ¨å…¶ä¸­ä¸€ä¸ªé›†åˆä¸­çš„å…ƒç´ \n",
    "\n",
    "### é›†åˆå…³ç³»æ–¹æ³•\n",
    "- **`.issuperset(set2)`** - æ£€æŸ¥å½“å‰é›†åˆæ˜¯å¦åŒ…å«å¦ä¸€ä¸ªé›†åˆçš„æ‰€æœ‰å…ƒç´ \n",
    "- **`.issubset(set2)`** - æ£€æŸ¥å½“å‰é›†åˆæ˜¯å¦è¢«å¦ä¸€ä¸ªé›†åˆåŒ…å«\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **å»é‡å¤„ç†**ï¼šä½¿ç”¨ `add()` å’Œ `update()` å»é‡æ–‡æœ¬ã€æ ‡ç­¾ç­‰\n",
    "- **æ•°æ®æ¯”è¾ƒ**ï¼šä½¿ç”¨é›†åˆè¿ç®—æ¯”è¾ƒä¸åŒæ•°æ®é›†\n",
    "- **æƒé™ç®¡ç†**ï¼šä½¿ç”¨é›†åˆå…³ç³»æ–¹æ³•æ£€æŸ¥ç”¨æˆ·æƒé™\n",
    "- **ç‰¹å¾æå–**ï¼šä½¿ç”¨äº¤é›†å’Œå·®é›†åˆ†ææ–‡æœ¬ç‰¹å¾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEvlWBPIU27l",
    "outputId": "38cc56d5-7ffa-4d4f-fa6c-ff2b89d8c4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·å…³é”®è¯: {'machine learning', 'ai', 'python'}\n",
      "æ¨¡å‹å…³é”®è¯: {'neural network', 'deep learning', 'ai', 'python'}\n",
      "\n",
      "æ·»åŠ æ–°å…³é”®è¯å: {'machine learning', 'ai', 'python', 'natural language processing'}\n",
      "æ‰¹é‡æ·»åŠ å: {'machine learning', 'attention', 'gpt', 'natural language processing', 'transformer', 'ai', 'python'}\n",
      "\n",
      "å…±åŒå…³é”®è¯: {'ai', 'python'}\n",
      "ç”¨æˆ·ç‹¬æœ‰å…³é”®è¯: {'machine learning', 'attention', 'gpt', 'natural language processing', 'transformer'}\n",
      "æ‰€æœ‰å…³é”®è¯: {'machine learning', 'attention', 'neural network', 'gpt', 'natural language processing', 'transformer', 'ai', 'deep learning', 'python'}\n",
      "éå…±åŒå…³é”®è¯: {'machine learning', 'neural network', 'attention', 'gpt', 'natural language processing', 'transformer', 'deep learning'}\n",
      "\n",
      "åˆ é™¤'gpt'å: {'machine learning', 'attention', 'natural language processing', 'transformer', 'ai', 'python'}\n",
      "éšæœºåˆ é™¤çš„å…³é”®è¯: machine learning\n",
      "å‰©ä½™å…³é”®è¯: {'attention', 'natural language processing', 'transformer', 'ai', 'python'}\n",
      "\n",
      "æ¨¡å‹å…³é”®è¯æ˜¯å¦åŒ…å«ç”¨æˆ·å…³é”®è¯çš„å­é›†: False\n",
      "ç”¨æˆ·å…³é”®è¯æ˜¯å¦æ˜¯æ¨¡å‹å…³é”®è¯çš„å­é›†: False\n",
      "\n",
      "æœ€ç»ˆç”¨æˆ·å…³é”®è¯æ•°é‡: 5\n",
      "æœ€ç»ˆæ¨¡å‹å…³é”®è¯æ•°é‡: 4\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„é›†åˆæ–¹æ³•ç¤ºä¾‹\n",
    "\n",
    "# åˆ›å»ºç”¨äºå»é‡å’Œåˆ†æçš„é›†åˆ\n",
    "user_keywords = {'python', 'ai', 'machine learning'}\n",
    "model_keywords = {'ai', 'deep learning', 'neural network', 'python'}\n",
    "\n",
    "print(\"ç”¨æˆ·å…³é”®è¯:\", user_keywords)\n",
    "print(\"æ¨¡å‹å…³é”®è¯:\", model_keywords)\n",
    "\n",
    "# ä½¿ç”¨ add() æ·»åŠ æ–°å…³é”®è¯\n",
    "user_keywords.add('natural language processing')\n",
    "print(\"\\næ·»åŠ æ–°å…³é”®è¯å:\", user_keywords)\n",
    "\n",
    "# ä½¿ç”¨ update() æ‰¹é‡æ·»åŠ å…³é”®è¯\n",
    "new_keywords = ['transformer', 'attention', 'gpt']\n",
    "user_keywords.update(new_keywords)\n",
    "print(\"æ‰¹é‡æ·»åŠ å:\", user_keywords)\n",
    "\n",
    "# é›†åˆè¿ç®— - æ‰¾åˆ°å…±åŒå…´è¶£\n",
    "common_interests = user_keywords.intersection(model_keywords)\n",
    "print(\"\\nå…±åŒå…³é”®è¯:\", common_interests)\n",
    "\n",
    "# é›†åˆè¿ç®— - æ‰¾åˆ°ç”¨æˆ·ç‹¬æœ‰çš„å…³é”®è¯\n",
    "user_only = user_keywords.difference(model_keywords)\n",
    "print(\"ç”¨æˆ·ç‹¬æœ‰å…³é”®è¯:\", user_only)\n",
    "\n",
    "# é›†åˆè¿ç®— - åˆå¹¶æ‰€æœ‰å…³é”®è¯\n",
    "all_keywords = user_keywords.union(model_keywords)\n",
    "print(\"æ‰€æœ‰å…³é”®è¯:\", all_keywords)\n",
    "\n",
    "# é›†åˆè¿ç®— - æ‰¾åˆ°ä¸é‡å¤çš„å…³é”®è¯\n",
    "unique_keywords = user_keywords.symmetric_difference(model_keywords)\n",
    "print(\"éå…±åŒå…³é”®è¯:\", unique_keywords)\n",
    "\n",
    "# ä½¿ç”¨ remove() åˆ é™¤ç‰¹å®šå…³é”®è¯\n",
    "if 'gpt' in user_keywords:\n",
    "    user_keywords.remove('gpt')\n",
    "    print(\"\\nåˆ é™¤'gpt'å:\", user_keywords)\n",
    "\n",
    "# ä½¿ç”¨ pop() éšæœºåˆ é™¤ä¸€ä¸ªå…³é”®è¯\n",
    "if user_keywords:\n",
    "    removed_keyword = user_keywords.pop()\n",
    "    print(f\"éšæœºåˆ é™¤çš„å…³é”®è¯: {removed_keyword}\")\n",
    "    print(\"å‰©ä½™å…³é”®è¯:\", user_keywords)\n",
    "\n",
    "# æ£€æŸ¥é›†åˆå…³ç³»\n",
    "print(f\"\\næ¨¡å‹å…³é”®è¯æ˜¯å¦åŒ…å«ç”¨æˆ·å…³é”®è¯çš„å­é›†: {model_keywords.issuperset(user_keywords)}\")\n",
    "print(f\"ç”¨æˆ·å…³é”®è¯æ˜¯å¦æ˜¯æ¨¡å‹å…³é”®è¯çš„å­é›†: {user_keywords.issubset(model_keywords)}\")\n",
    "\n",
    "print(f\"\\næœ€ç»ˆç”¨æˆ·å…³é”®è¯æ•°é‡: {len(user_keywords)}\")\n",
    "print(f\"æœ€ç»ˆæ¨¡å‹å…³é”®è¯æ•°é‡: {len(model_keywords)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0eXxOTLU27l"
   },
   "source": [
    "## dictï¼ˆå­—å…¸ï¼‰å¯¹è±¡çš„ä¸€äº›æ–¹æ³•\n",
    "\n",
    "> **æ ¸å¿ƒæŠ€èƒ½**ï¼šå­—å…¸æ–¹æ³•æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­æœ€é‡è¦çš„æŠ€èƒ½ä¹‹ä¸€ï¼Œç”¨äºå¤„ç†APIå“åº”ã€é…ç½®ç®¡ç†ã€æ•°æ®ç»“æ„ç­‰ã€‚\n",
    "\n",
    "### æ›´æ–°å’Œæ·»åŠ æ–¹æ³•\n",
    "- **`.update([(key1, val1), (key2, val2), ...])`** - é€šè¿‡é”®å€¼å¯¹åˆ—è¡¨æ›´æ–°å­—å…¸\n",
    "- **`.update(dict2)`** - å°†å¦ä¸€ä¸ªå­—å…¸çš„æ‰€æœ‰é”®å€¼å¯¹æ·»åŠ åˆ°å½“å‰å­—å…¸\n",
    "\n",
    "### è·å–å’Œåˆ é™¤æ–¹æ³•\n",
    "- **`.pop(key)`** - åˆ é™¤æŒ‡å®šé”®å¹¶è¿”å›å…¶å€¼ï¼ˆå¦‚æœé”®ä¸å­˜åœ¨åˆ™æŠ¥é”™ï¼‰\n",
    "- **`.pop(key, default_val)`** - åˆ é™¤æŒ‡å®šé”®å¹¶è¿”å›å…¶å€¼ï¼ˆå¦‚æœé”®ä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼ï¼‰\n",
    "- **`.get(key)`** - è¿”å›æŒ‡å®šé”®çš„å€¼ï¼ˆå¦‚æœé”®ä¸å­˜åœ¨åˆ™è¿”å›Noneï¼‰\n",
    "- **`.get(key, default_val)`** - è¿”å›æŒ‡å®šé”®çš„å€¼ï¼ˆå¦‚æœé”®ä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼ï¼‰\n",
    "\n",
    "### è®¿é—®æ–¹æ³•\n",
    "- **`.keys()`** - è¿”å›å­—å…¸ä¸­æ‰€æœ‰é”®çš„è§†å›¾\n",
    "- **`.values()`** - è¿”å›å­—å…¸ä¸­æ‰€æœ‰å€¼çš„è§†å›¾\n",
    "- **`.items()`** - è¿”å›å­—å…¸ä¸­æ‰€æœ‰é”®å€¼å¯¹ï¼ˆå…ƒç»„ï¼‰çš„è§†å›¾\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **APIå“åº”å¤„ç†**ï¼šä½¿ç”¨ `get()` å®‰å…¨è·å–APIè¿”å›çš„å­—æ®µ\n",
    "- **é…ç½®ç®¡ç†**ï¼šä½¿ç”¨ `update()` åˆå¹¶ä¸åŒçš„é…ç½®æ–‡ä»¶\n",
    "- **æ•°æ®è½¬æ¢**ï¼šä½¿ç”¨ `items()` éå†å’Œè½¬æ¢æ•°æ®\n",
    "- **é”™è¯¯å¤„ç†**ï¼šä½¿ç”¨ `pop()` å’Œé»˜è®¤å€¼é¿å…KeyError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_IPWPT0U27m",
    "outputId": "784024c1-7898-464e-8712-5aaa56019dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå§‹APIé…ç½®: {'model': 'gpt-3.5-turbo', 'temperature': 0.7, 'max_tokens': 1000}\n",
      "\n",
      "åˆå¹¶é…ç½®å: {'model': 'gpt-3.5-turbo', 'temperature': 0.7, 'max_tokens': 1000, 'top_p': 0.9, 'presence_penalty': 0.1, 'frequency_penalty': 0.1}\n",
      "\n",
      "æ·»åŠ æµå¼é…ç½®å: {'model': 'gpt-3.5-turbo', 'temperature': 0.7, 'max_tokens': 1000, 'top_p': 0.9, 'presence_penalty': 0.1, 'frequency_penalty': 0.1, 'stream': True, 'stop': ['\\\\n', '###']}\n",
      "\n",
      "æ¨¡å‹åç§°: gpt-3.5-turbo\n",
      "è¶…æ—¶æ—¶é—´: 30 ç§’\n",
      "\n",
      "APIå“åº”å†…å®¹: ä½ å¥½ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹\n",
      "ä½¿ç”¨çš„tokenæ•°: 25\n",
      "ä½¿ç”¨çš„æ¨¡å‹: gpt-3.5-turbo-0613\n",
      "\n",
      "åˆ é™¤çš„presence_penaltyå€¼: 0.1\n",
      "è°ƒè¯•æ¨¡å¼ï¼ˆé»˜è®¤å€¼ï¼‰: False\n",
      "\n",
      "æ‰€æœ‰é…ç½®é”®: ['model', 'temperature', 'max_tokens', 'top_p', 'frequency_penalty', 'stream', 'stop']\n",
      "æ‰€æœ‰é…ç½®å€¼: ['gpt-3.5-turbo', 0.7, 1000, 0.9, 0.1, True, ['\\\\n', '###']]\n",
      "\n",
      "å®Œæ•´é…ç½®é¡¹:\n",
      "  model: gpt-3.5-turbo\n",
      "  temperature: 0.7\n",
      "  max_tokens: 1000\n",
      "  top_p: 0.9\n",
      "  frequency_penalty: 0.1\n",
      "  stream: True\n",
      "  stop: ['\\\\n', '###']\n",
      "\n",
      "æ•°å€¼å‹é…ç½®æ•°é‡: 5\n",
      "å­—ç¬¦ä¸²å‹é…ç½®æ•°é‡: 1\n",
      "æ€»é…ç½®é¡¹æ•°é‡: 7\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„å­—å…¸æ–¹æ³•ç¤ºä¾‹\n",
    "\n",
    "# æ¨¡æ‹ŸAPIé…ç½®\n",
    "api_config = {\n",
    "    'model': 'gpt-3.5-turbo',\n",
    "    'temperature': 0.7,\n",
    "    'max_tokens': 1000\n",
    "}\n",
    "\n",
    "print(\"åˆå§‹APIé…ç½®:\", api_config)\n",
    "\n",
    "# ä½¿ç”¨ update() åˆå¹¶æ–°é…ç½®\n",
    "additional_config = {\n",
    "    'top_p': 0.9,\n",
    "    'presence_penalty': 0.1,\n",
    "    'frequency_penalty': 0.1\n",
    "}\n",
    "api_config.update(additional_config)\n",
    "print(\"\\nåˆå¹¶é…ç½®å:\", api_config)\n",
    "\n",
    "# ä½¿ç”¨ update() é€šè¿‡é”®å€¼å¯¹åˆ—è¡¨æ›´æ–°\n",
    "streaming_config = [('stream', True), ('stop', ['\\\\n', '###'])]\n",
    "api_config.update(streaming_config)\n",
    "print(\"\\næ·»åŠ æµå¼é…ç½®å:\", api_config)\n",
    "\n",
    "# ä½¿ç”¨ get() å®‰å…¨è·å–é…ç½®å€¼\n",
    "model_name = api_config.get('model', 'default-model')\n",
    "timeout = api_config.get('timeout', 30)  # ä½¿ç”¨é»˜è®¤å€¼\n",
    "\n",
    "print(f\"\\næ¨¡å‹åç§°: {model_name}\")\n",
    "print(f\"è¶…æ—¶æ—¶é—´: {timeout} ç§’\")\n",
    "\n",
    "# æ¨¡æ‹ŸAPIå“åº”å¤„ç†\n",
    "api_response = {\n",
    "    'choices': [{'message': {'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹'}}],\n",
    "    'usage': {'total_tokens': 25},\n",
    "    'model': 'gpt-3.5-turbo-0613'\n",
    "}\n",
    "\n",
    "# å®‰å…¨åœ°æå–å“åº”å†…å®¹\n",
    "content = api_response.get('choices', [{}])[0].get('message', {}).get('content', 'æ— å“åº”')\n",
    "tokens_used = api_response.get('usage', {}).get('total_tokens', 0)\n",
    "model_used = api_response.get('model', 'æœªçŸ¥æ¨¡å‹')\n",
    "\n",
    "print(f\"\\nAPIå“åº”å†…å®¹: {content}\")\n",
    "print(f\"ä½¿ç”¨çš„tokenæ•°: {tokens_used}\")\n",
    "print(f\"ä½¿ç”¨çš„æ¨¡å‹: {model_used}\")\n",
    "\n",
    "# ä½¿ç”¨ pop() åˆ é™¤å¹¶è·å–é…ç½®é¡¹\n",
    "removed_penalty = api_config.pop('presence_penalty', 0)\n",
    "print(f\"\\nåˆ é™¤çš„presence_penaltyå€¼: {removed_penalty}\")\n",
    "\n",
    "# å°è¯•åˆ é™¤ä¸å­˜åœ¨çš„é”®ï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰\n",
    "debug_mode = api_config.pop('debug', False)\n",
    "print(f\"è°ƒè¯•æ¨¡å¼ï¼ˆé»˜è®¤å€¼ï¼‰: {debug_mode}\")\n",
    "\n",
    "# ä½¿ç”¨ keys(), values(), items() éå†é…ç½®\n",
    "print(\"\\næ‰€æœ‰é…ç½®é”®:\", list(api_config.keys()))\n",
    "print(\"æ‰€æœ‰é…ç½®å€¼:\", list(api_config.values()))\n",
    "\n",
    "print(\"\\nå®Œæ•´é…ç½®é¡¹:\")\n",
    "for key, value in api_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# ç»Ÿè®¡é…ç½®ä¿¡æ¯\n",
    "numeric_configs = {k: v for k, v in api_config.items() if isinstance(v, (int, float))}\n",
    "string_configs = {k: v for k, v in api_config.items() if isinstance(v, str)}\n",
    "\n",
    "print(f\"\\næ•°å€¼å‹é…ç½®æ•°é‡: {len(numeric_configs)}\")\n",
    "print(f\"å­—ç¬¦ä¸²å‹é…ç½®æ•°é‡: {len(string_configs)}\")\n",
    "print(f\"æ€»é…ç½®é¡¹æ•°é‡: {len(api_config)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9lV-PCtU27m",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°\n",
    "\n",
    "> **é‡è¦æ¦‚å¿µ**ï¼šç†è§£å‚æ•°ä¼ é€’æ–¹å¼å¯¹äºè°ƒç”¨å¤§æ¨¡å‹APIã€ä½¿ç”¨Pythonåº“å‡½æ•°è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "ä½ å¯ä»¥ç”¨å¤šç§ä¸åŒçš„æ–¹å¼è°ƒç”¨å‡½æ•°/æ–¹æ³•ï¼š\n",
    "\n",
    "### åŸºæœ¬è°ƒç”¨æ–¹å¼\n",
    "- `func()` - ä¸å¸¦å‚æ•°è°ƒç”¨å‡½æ•°\n",
    "- `func(arg)` - ä¼ é€’ä¸€ä¸ªä½ç½®å‚æ•°\n",
    "- `func(arg1, arg2)` - ä¼ é€’ä¸¤ä¸ªä½ç½®å‚æ•°\n",
    "- `func(arg1, arg2, ..., argn)` - ä¼ é€’å¤šä¸ªä½ç½®å‚æ•°\n",
    "\n",
    "### å…³é”®å­—å‚æ•°è°ƒç”¨\n",
    "- `func(kwarg=value)` - ä¼ é€’ä¸€ä¸ªå…³é”®å­—å‚æ•°\n",
    "- `func(kwarg1=value1, kwarg2=value2)` - ä¼ é€’ä¸¤ä¸ªå…³é”®å­—å‚æ•°\n",
    "- `func(kwarg1=value1, kwarg2=value2, ..., kwargn=valuen)` - ä¼ é€’å¤šä¸ªå…³é”®å­—å‚æ•°\n",
    "\n",
    "### æ··åˆè°ƒç”¨\n",
    "- `func(arg1, arg2, kwarg1=value1, kwarg2=value2)` - æ··åˆä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°\n",
    "- `obj.method()` - å¯¹è±¡æ–¹æ³•è°ƒç”¨ï¼ˆä¸å‡½æ•°è°ƒç”¨è§„åˆ™ç›¸åŒï¼‰\n",
    "\n",
    "### é‡è¦è§„åˆ™\n",
    "\n",
    "**ä½ç½®å‚æ•°ä½¿ç”¨æ—¶**ï¼šå¿…é¡»æŒ‰ç…§å‡½æ•°å®šä¹‰çš„é¡ºåºæä¾›å‚æ•°ï¼ˆå‡½æ•°çš„**ç­¾å**ï¼‰\n",
    "\n",
    "**å…³é”®å­—å‚æ•°ä½¿ç”¨æ—¶**ï¼šå¯ä»¥æä¾›ä»»æ„é¡ºåºçš„å‚æ•°ï¼Œä½†å¿…é¡»æŒ‡å®šæ¯ä¸ªå‚æ•°çš„åç§°\n",
    "\n",
    "**æ··åˆä½¿ç”¨æ—¶**ï¼šä½ç½®å‚æ•°å¿…é¡»åœ¨å…³é”®å­—å‚æ•°ä¹‹å‰\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨\n",
    "- **APIè°ƒç”¨**ï¼š`openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages, temperature=0.7)`\n",
    "- **å‡½æ•°è°ƒç”¨**ï¼šä½¿ç”¨å…³é”®å­—å‚æ•°æé«˜ä»£ç å¯è¯»æ€§\n",
    "- **é…ç½®ä¼ é€’**ï¼šé€šè¿‡å…³é”®å­—å‚æ•°ä¼ é€’å¤æ‚é…ç½®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkGgupOoU27m",
    "outputId": "35c0890f-7d2c-4474-d207-ef4726d25278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. åªä½¿ç”¨ä½ç½®å‚æ•°:\n",
      "   æ¨¡å‹: gpt-3.5-turbo\n",
      "   æ¸©åº¦: 0.7\n",
      "\n",
      "2. æ··åˆä½¿ç”¨ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°:\n",
      "   æ¨¡å‹: gpt-4\n",
      "   æ¸©åº¦: 0.9\n",
      "   æœ€å¤§tokens: 500\n",
      "\n",
      "3. ä½¿ç”¨å…³é”®å­—å‚æ•°ï¼ˆä»»æ„é¡ºåºï¼‰:\n",
      "   æ¨¡å‹: claude-3\n",
      "   æ‰€æœ‰å‚æ•°: {'temperature': 0.5, 'max_tokens': 800, 'top_p': 0.9}\n",
      "\n",
      "4. çµæ´»çš„APIé…ç½®:\n",
      "   é»˜è®¤é…ç½®: gpt-3.5-turbo, æ¸©åº¦: 0.7\n",
      "   è‡ªå®šä¹‰é…ç½®: gpt-4, æ¸©åº¦: 0.3\n",
      "   æµå¼è¾“å‡º: True\n",
      "\n",
      "5. å­—ç¬¦ä¸²æ ¼å¼åŒ–ç¤ºä¾‹:\n",
      "   ä½ç½®å‚æ•°: ç”¨æˆ· Alice ä½¿ç”¨æ¨¡å‹ GPT-4 æ¶ˆè€—äº† 150 ä¸ªtoken\n",
      "   å…³é”®å­—å‚æ•°: ç”¨æˆ· Alice ä½¿ç”¨æ¨¡å‹ GPT-4 æ¶ˆè€—äº† 150 ä¸ªtoken\n",
      "   f-string: ç”¨æˆ· Alice ä½¿ç”¨æ¨¡å‹ GPT-4 æ¶ˆè€—äº† 150 ä¸ªtoken\n"
     ]
    }
   ],
   "source": [
    "# ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°ç¤ºä¾‹\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªæ¨¡æ‹Ÿå¤§æ¨¡å‹APIè°ƒç”¨çš„å‡½æ•°\n",
    "def call_llm_api(model, prompt, temperature=0.7, max_tokens=1000, top_p=1.0):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿå¤§æ¨¡å‹APIè°ƒç”¨å‡½æ•°\n",
    "    å‚æ•°ï¼š\n",
    "    - model: æ¨¡å‹åç§°ï¼ˆå¿…éœ€ä½ç½®å‚æ•°ï¼‰\n",
    "    - prompt: æç¤ºè¯ï¼ˆå¿…éœ€ä½ç½®å‚æ•°ï¼‰\n",
    "    - temperature: æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰å…³é”®å­—å‚æ•°ï¼Œé»˜è®¤0.7ï¼‰\n",
    "    - max_tokens: æœ€å¤§tokenæ•°ï¼ˆå¯é€‰å…³é”®å­—å‚æ•°ï¼Œé»˜è®¤1000ï¼‰\n",
    "    - top_p: Top-på‚æ•°ï¼ˆå¯é€‰å…³é”®å­—å‚æ•°ï¼Œé»˜è®¤1.0ï¼‰\n",
    "    \"\"\"\n",
    "    response = {\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'parameters': {\n",
    "            'temperature': temperature,\n",
    "            'max_tokens': max_tokens,\n",
    "            'top_p': top_p\n",
    "        },\n",
    "        'response': f\"ä½¿ç”¨{model}æ¨¡å‹ç”Ÿæˆçš„å›å¤...\"\n",
    "    }\n",
    "    return response\n",
    "\n",
    "# 1. åªä½¿ç”¨ä½ç½®å‚æ•°\n",
    "print(\"1. åªä½¿ç”¨ä½ç½®å‚æ•°:\")\n",
    "result1 = call_llm_api(\"gpt-3.5-turbo\", \"ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹Python\")\n",
    "print(f\"   æ¨¡å‹: {result1['model']}\")\n",
    "print(f\"   æ¸©åº¦: {result1['parameters']['temperature']}\")\n",
    "print()\n",
    "\n",
    "# 2. æ··åˆä½¿ç”¨ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°\n",
    "print(\"2. æ··åˆä½¿ç”¨ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°:\")\n",
    "result2 = call_llm_api(\"gpt-4\", \"è¯·å†™ä¸€é¦–å…³äºAIçš„è¯—\", temperature=0.9, max_tokens=500)\n",
    "print(f\"   æ¨¡å‹: {result2['model']}\")\n",
    "print(f\"   æ¸©åº¦: {result2['parameters']['temperature']}\")\n",
    "print(f\"   æœ€å¤§tokens: {result2['parameters']['max_tokens']}\")\n",
    "print()\n",
    "\n",
    "# 3. ä½¿ç”¨å…³é”®å­—å‚æ•°ï¼ˆå¯ä»¥ä»»æ„é¡ºåºï¼‰\n",
    "print(\"3. ä½¿ç”¨å…³é”®å­—å‚æ•°ï¼ˆä»»æ„é¡ºåºï¼‰:\")\n",
    "result3 = call_llm_api(\n",
    "    max_tokens=800,\n",
    "    model=\"claude-3\",\n",
    "    top_p=0.9,\n",
    "    prompt=\"è§£é‡Šé‡å­è®¡ç®—çš„åŸç†\",\n",
    "    temperature=0.5\n",
    ")\n",
    "print(f\"   æ¨¡å‹: {result3['model']}\")\n",
    "print(f\"   æ‰€æœ‰å‚æ•°: {result3['parameters']}\")\n",
    "print()\n",
    "\n",
    "# 4. å®é™…çš„å¤§æ¨¡å‹å¼€å‘åœºæ™¯ - é…ç½®ç®¡ç†\n",
    "def create_chat_completion(messages, **kwargs):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºèŠå¤©å®Œæˆè¯·æ±‚ï¼ˆæ¨¡æ‹ŸOpenAI APIï¼‰\n",
    "    ä½¿ç”¨**kwargsæ¥æ”¶ä»»æ„å…³é”®å­—å‚æ•°\n",
    "    \"\"\"\n",
    "    default_config = {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'temperature': 0.7,\n",
    "        'max_tokens': 1000,\n",
    "        'top_p': 1.0,\n",
    "        'frequency_penalty': 0,\n",
    "        'presence_penalty': 0\n",
    "    }\n",
    "\n",
    "    # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æ›´æ–°é»˜è®¤é…ç½®\n",
    "    config = {**default_config, **kwargs}\n",
    "\n",
    "    return {\n",
    "        'messages': messages,\n",
    "        'config': config,\n",
    "        'status': 'success'\n",
    "    }\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "messages = [\n",
    "    {'role': 'user', 'content': 'è¯·è§£é‡Šæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ'}\n",
    "]\n",
    "\n",
    "print(\"4. çµæ´»çš„APIé…ç½®:\")\n",
    "# ä½¿ç”¨é»˜è®¤é…ç½®\n",
    "basic_request = create_chat_completion(messages)\n",
    "print(f\"   é»˜è®¤é…ç½®: {basic_request['config']['model']}, æ¸©åº¦: {basic_request['config']['temperature']}\")\n",
    "\n",
    "# è‡ªå®šä¹‰é…ç½®\n",
    "custom_request = create_chat_completion(\n",
    "    messages,\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=2000,\n",
    "    stream=True\n",
    ")\n",
    "print(f\"   è‡ªå®šä¹‰é…ç½®: {custom_request['config']['model']}, æ¸©åº¦: {custom_request['config']['temperature']}\")\n",
    "print(f\"   æµå¼è¾“å‡º: {custom_request['config'].get('stream', False)}\")\n",
    "\n",
    "# 5. å­—ç¬¦ä¸²æ ¼å¼åŒ–ä¸­çš„ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°\n",
    "print(\"\\n5. å­—ç¬¦ä¸²æ ¼å¼åŒ–ç¤ºä¾‹:\")\n",
    "user_name = \"Alice\"\n",
    "model_name = \"GPT-4\"\n",
    "token_count = 150\n",
    "\n",
    "# ä½ç½®å‚æ•°æ ¼å¼åŒ–\n",
    "message1 = \"ç”¨æˆ· {} ä½¿ç”¨æ¨¡å‹ {} æ¶ˆè€—äº† {} ä¸ªtoken\".format(user_name, model_name, token_count)\n",
    "print(f\"   ä½ç½®å‚æ•°: {message1}\")\n",
    "\n",
    "# å…³é”®å­—å‚æ•°æ ¼å¼åŒ–\n",
    "message2 = \"ç”¨æˆ· {name} ä½¿ç”¨æ¨¡å‹ {model} æ¶ˆè€—äº† {tokens} ä¸ªtoken\".format(\n",
    "    name=user_name,\n",
    "    model=model_name,\n",
    "    tokens=token_count\n",
    ")\n",
    "print(f\"   å…³é”®å­—å‚æ•°: {message2}\")\n",
    "\n",
    "# f-stringæ ¼å¼åŒ–ï¼ˆæ¨èæ–¹å¼ï¼‰\n",
    "message3 = f\"ç”¨æˆ· {user_name} ä½¿ç”¨æ¨¡å‹ {model_name} æ¶ˆè€—äº† {token_count} ä¸ªtoken\"\n",
    "print(f\"   f-string: {message3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZyRtAWeU27n",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## å­—ç¬¦ä¸²æ ¼å¼åŒ–å’Œå ä½ç¬¦\n",
    "\n",
    "> **æ ¸å¿ƒæŠ€èƒ½**ï¼šå­—ç¬¦ä¸²æ ¼å¼åŒ–åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºæ„å»ºåŠ¨æ€æç¤ºè¯ã€å¤„ç†APIå“åº”ã€ç”ŸæˆæŠ¥å‘Šç­‰ï¼Œæ˜¯æœ€å¸¸ç”¨çš„æŠ€èƒ½ä¹‹ä¸€ã€‚\n",
    "\n",
    "Pythonæä¾›å¤šç§å­—ç¬¦ä¸²æ ¼å¼åŒ–æ–¹æ³•ï¼Œæ¯ç§éƒ½æœ‰å…¶ç‰¹å®šçš„ç”¨é€”ï¼š\n",
    "\n",
    "### 1. f-stringæ ¼å¼åŒ–ï¼ˆæ¨èæ–¹å¼ï¼ŒPython 3.6+ï¼‰\n",
    "- **è¯­æ³•**ï¼š`f\"æ–‡æœ¬ {variable} æ›´å¤šæ–‡æœ¬\"`\n",
    "- **ä¼˜åŠ¿**ï¼šç®€æ´ã€é«˜æ•ˆã€å¯è¯»æ€§å¼º\n",
    "- **åº”ç”¨**ï¼šæ„å»ºæç¤ºè¯æ¨¡æ¿ã€æ—¥å¿—è¾“å‡º\n",
    "\n",
    "### 2. .format()æ–¹æ³•\n",
    "- **ä½ç½®å‚æ•°**ï¼š`\"æ–‡æœ¬ {} {}\".format(value1, value2)`\n",
    "- **å…³é”®å­—å‚æ•°**ï¼š`\"æ–‡æœ¬ {name} {age}\".format(name=\"å¼ ä¸‰\", age=25)`\n",
    "- **ç´¢å¼•å‚æ•°**ï¼š`\"æ–‡æœ¬ {0} {1}\".format(value1, value2)`\n",
    "\n",
    "### 3. %æ ¼å¼åŒ–ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰\n",
    "- **è¯­æ³•**ï¼š`\"æ–‡æœ¬ %s %d\" % (string_value, int_value)`\n",
    "- **åº”ç”¨**ï¼šå…¼å®¹æ—§ä»£ç ã€ç‰¹å®šæ ¼å¼éœ€æ±‚\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **æç¤ºè¯æ¨¡æ¿**ï¼šåŠ¨æ€æ„å»ºä¸ªæ€§åŒ–æç¤ºè¯\n",
    "- **APIå“åº”å¤„ç†**ï¼šæ ¼å¼åŒ–è¾“å‡ºç»“æœ\n",
    "- **æ—¥å¿—è®°å½•**ï¼šè®°å½•è°ƒç”¨ä¿¡æ¯å’Œé”™è¯¯\n",
    "- **æŠ¥å‘Šç”Ÿæˆ**ï¼šç”Ÿæˆç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š\n",
    "- **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ„å»ºæœ¬åœ°åŒ–æ–‡æœ¬æ¨¡æ¿\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzBd-MbzU27n",
    "outputId": "64958bec-7560-4f23-ad29-2fb618a8b313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. f-stringæ ¼å¼åŒ–ï¼ˆæ¨èæ–¹å¼ï¼‰ ===\n",
      "åŸºæœ¬ç”¨æ³•: ç”¨æˆ·å¼ ä¸‰ä½¿ç”¨GPT-4æ¨¡å‹\n",
      "è¡¨è¾¾å¼è®¡ç®—: æ€»æˆæœ¬: $0.0150\n",
      "æ•°å­—æ ¼å¼åŒ–: è¾“å…¥tokens: 120, è¾“å‡ºtokens: 380\n",
      "\n",
      "=== 2. æ„å»ºåŠ¨æ€æç¤ºè¯æ¨¡æ¿ ===\n",
      "ä¸ªæ€§åŒ–æç¤ºè¯:\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸ºæ•°æ®ç§‘å­¦å®¶ æåšå£«æä¾›å¸®åŠ©ã€‚\n",
      "\n",
      "ç”¨æˆ·èƒŒæ™¯: æ•°æ®ç§‘å­¦å®¶\n",
      "è®¨è®ºä¸»é¢˜: æ·±åº¦å­¦ä¹ ä¼˜åŒ–æŠ€æœ¯\n",
      "å›ç­”é£æ ¼: æŠ€æœ¯æ€§\n",
      "\n",
      "è¯·ä»¥æŠ€æœ¯æ€§çš„é£æ ¼ï¼Œä¸ºæåšå£«è¯¦ç»†è§£é‡Šæ·±åº¦å­¦ä¹ ä¼˜åŒ–æŠ€æœ¯çš„ç›¸å…³å†…å®¹ã€‚\n",
      "è¯·ç¡®ä¿å†…å®¹å‡†ç¡®ã€æ˜“æ‡‚ï¼Œå¹¶é€‚åˆæ•°æ®ç§‘å­¦å®¶çš„ä¸“ä¸šæ°´å¹³ã€‚...\n",
      "\n",
      "=== 3. .format()æ–¹æ³•åº”ç”¨ ===\n",
      "ä½ç½®å‚æ•°: æ¨¡å‹GPT-4åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º92.34%\n",
      "å…³é”®å­—å‚æ•°: \n",
      "APIè°ƒç”¨æŠ¥å‘Š:\n",
      "- ç”¨æˆ·: å¼ ä¸‰\n",
      "- æ¨¡å‹: GPT-4\n",
      "- è¾“å…¥tokens: 120\n",
      "- è¾“å‡ºtokens: 380\n",
      "- æ€»tokens: 500\n",
      "- æ¸©åº¦å‚æ•°: 0.7\n",
      "- æ€»æˆæœ¬: $0.0150\n",
      "\n",
      "\n",
      "=== 4. å®é™…åº”ç”¨åœºæ™¯ ===\n",
      "æˆåŠŸæ—¥å¿—: [2025-10-09 10:14:10] SUCCESS - ç”¨æˆ·:å¼ ä¸‰, æ¨¡å‹:GPT-4, tokens:500, çŠ¶æ€:completed\n",
      "é”™è¯¯æ—¥å¿—: [2025-10-09 10:14:10] ERROR - ç”¨æˆ·:å¼ ä¸‰, æ¨¡å‹:GPT-4, é”™è¯¯:API rate limit exceeded\n",
      "\n",
      "ä¸­æ–‡æç¤ºè¯: è¯·ç”¨ä¸­æ–‡æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼šäººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹\n",
      "è‹±æ–‡æç¤ºè¯: Please summarize the following content in English: the development of artificial intelligence\n",
      "\n",
      "=== æ€§èƒ½ç›‘æ§æŠ¥å‘Š ===\n",
      "\n",
      "ğŸ¤– æ¨¡å‹æ€§èƒ½æŠ¥å‘Š\n",
      "\n",
      "ğŸ“Š åŸºç¡€æŒ‡æ ‡:\n",
      "   â€¢ æ¨¡å‹åç§°: GPT-4 Turbo\n",
      "   â€¢ å¤„ç†è¯·æ±‚: 15,847 æ¬¡\n",
      "   â€¢ å¹³å‡å“åº”æ—¶é—´: 1234.50ms\n",
      "   â€¢ æˆåŠŸç‡: 98.8%\n",
      "\n",
      "ğŸ’° æˆæœ¬åˆ†æ:\n",
      "   â€¢ æ€»tokens: 2,450,000\n",
      "   â€¢ å¹³å‡æ¯è¯·æ±‚tokens: 155\n",
      "   â€¢ æ€»æˆæœ¬: $73.50\n",
      "   â€¢ å¹³å‡æ¯è¯·æ±‚æˆæœ¬: $0.0046\n",
      "\n",
      "ğŸ”¥ çƒ­é—¨åŠŸèƒ½:\n",
      "   â€¢ æœ€å¸¸ç”¨åŠŸèƒ½: ä»£ç ç”Ÿæˆ\n",
      "   â€¢ ä½¿ç”¨æ¬¡æ•°: 3,421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²æ ¼å¼åŒ–åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨ç¤ºä¾‹\n",
    "\n",
    "# åŸºç¡€æ•°æ®\n",
    "user_name = \"å¼ ä¸‰\"\n",
    "model_name = \"GPT-4\"\n",
    "input_tokens = 120\n",
    "output_tokens = 380\n",
    "total_tokens = input_tokens + output_tokens\n",
    "cost_per_token = 0.00003\n",
    "temperature = 0.7\n",
    "\n",
    "print(\"=== 1. f-stringæ ¼å¼åŒ–ï¼ˆæ¨èæ–¹å¼ï¼‰ ===\")\n",
    "\n",
    "# åŸºæœ¬f-stringç”¨æ³•\n",
    "basic_message = f\"ç”¨æˆ·{user_name}ä½¿ç”¨{model_name}æ¨¡å‹\"\n",
    "print(f\"åŸºæœ¬ç”¨æ³•: {basic_message}\")\n",
    "\n",
    "# è¡¨è¾¾å¼è®¡ç®—\n",
    "cost_calculation = f\"æ€»æˆæœ¬: ${total_tokens * cost_per_token:.4f}\"\n",
    "print(f\"è¡¨è¾¾å¼è®¡ç®—: {cost_calculation}\")\n",
    "\n",
    "# æ ¼å¼åŒ–æ•°å­—\n",
    "formatted_numbers = f\"è¾“å…¥tokens: {input_tokens:,}, è¾“å‡ºtokens: {output_tokens:,}\"\n",
    "print(f\"æ•°å­—æ ¼å¼åŒ–: {formatted_numbers}\")\n",
    "\n",
    "print(\"\\n=== 2. æ„å»ºåŠ¨æ€æç¤ºè¯æ¨¡æ¿ ===\")\n",
    "\n",
    "# ä¸ªæ€§åŒ–æç¤ºè¯æ¨¡æ¿\n",
    "def create_personalized_prompt(user_name, user_role, topic, style=\"professional\"):\n",
    "    \"\"\"åˆ›å»ºä¸ªæ€§åŒ–æç¤ºè¯\"\"\"\n",
    "    prompt_template = f\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸º{user_role} {user_name}æä¾›å¸®åŠ©ã€‚\n",
    "\n",
    "ç”¨æˆ·èƒŒæ™¯: {user_role}\n",
    "è®¨è®ºä¸»é¢˜: {topic}\n",
    "å›ç­”é£æ ¼: {style}\n",
    "\n",
    "è¯·ä»¥{style}çš„é£æ ¼ï¼Œä¸º{user_name}è¯¦ç»†è§£é‡Š{topic}çš„ç›¸å…³å†…å®¹ã€‚\n",
    "è¯·ç¡®ä¿å†…å®¹å‡†ç¡®ã€æ˜“æ‡‚ï¼Œå¹¶é€‚åˆ{user_role}çš„ä¸“ä¸šæ°´å¹³ã€‚\n",
    "\"\"\"\n",
    "    return prompt_template.strip()\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "prompt1 = create_personalized_prompt(\"æåšå£«\", \"æ•°æ®ç§‘å­¦å®¶\", \"æ·±åº¦å­¦ä¹ ä¼˜åŒ–æŠ€æœ¯\", \"æŠ€æœ¯æ€§\")\n",
    "print(\"ä¸ªæ€§åŒ–æç¤ºè¯:\")\n",
    "print(prompt1[:150] + \"...\")\n",
    "\n",
    "print(\"\\n=== 3. .format()æ–¹æ³•åº”ç”¨ ===\")\n",
    "\n",
    "# ä½ç½®å‚æ•°\n",
    "status_report = \"æ¨¡å‹{}åœ¨{}æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º{:.2%}\".format(model_name, \"æµ‹è¯•\", 0.9234)\n",
    "print(f\"ä½ç½®å‚æ•°: {status_report}\")\n",
    "\n",
    "# å…³é”®å­—å‚æ•°\n",
    "detailed_report = \"\"\"\n",
    "APIè°ƒç”¨æŠ¥å‘Š:\n",
    "- ç”¨æˆ·: {user}\n",
    "- æ¨¡å‹: {model}\n",
    "- è¾“å…¥tokens: {input_tokens:,}\n",
    "- è¾“å‡ºtokens: {output_tokens:,}\n",
    "- æ€»tokens: {total_tokens:,}\n",
    "- æ¸©åº¦å‚æ•°: {temp}\n",
    "- æ€»æˆæœ¬: ${cost:.4f}\n",
    "\"\"\".format(\n",
    "    user=user_name,\n",
    "    model=model_name,\n",
    "    input_tokens=input_tokens,\n",
    "    output_tokens=output_tokens,\n",
    "    total_tokens=total_tokens,\n",
    "    temp=temperature,\n",
    "    cost=total_tokens * cost_per_token\n",
    ")\n",
    "print(\"å…³é”®å­—å‚æ•°:\", detailed_report)\n",
    "\n",
    "print(\"\\n=== 4. å®é™…åº”ç”¨åœºæ™¯ ===\")\n",
    "\n",
    "# åœºæ™¯1: APIæ—¥å¿—è®°å½•\n",
    "import datetime\n",
    "\n",
    "def log_api_call(user, model, tokens, status, error=None):\n",
    "    \"\"\"è®°å½•APIè°ƒç”¨æ—¥å¿—\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    if error:\n",
    "        log_message = f\"[{timestamp}] ERROR - ç”¨æˆ·:{user}, æ¨¡å‹:{model}, é”™è¯¯:{error}\"\n",
    "    else:\n",
    "        log_message = f\"[{timestamp}] SUCCESS - ç”¨æˆ·:{user}, æ¨¡å‹:{model}, tokens:{tokens}, çŠ¶æ€:{status}\"\n",
    "\n",
    "    return log_message\n",
    "\n",
    "# æˆåŠŸè°ƒç”¨æ—¥å¿—\n",
    "success_log = log_api_call(user_name, model_name, total_tokens, \"completed\")\n",
    "print(\"æˆåŠŸæ—¥å¿—:\", success_log)\n",
    "\n",
    "# é”™è¯¯è°ƒç”¨æ—¥å¿—\n",
    "error_log = log_api_call(user_name, model_name, 0, \"failed\", \"API rate limit exceeded\")\n",
    "print(\"é”™è¯¯æ—¥å¿—:\", error_log)\n",
    "\n",
    "# åœºæ™¯2: å¤šè¯­è¨€æç¤ºè¯æ¨¡æ¿\n",
    "def create_multilingual_prompt(language, task, context):\n",
    "    \"\"\"åˆ›å»ºå¤šè¯­è¨€æç¤ºè¯æ¨¡æ¿\"\"\"\n",
    "    templates = {\n",
    "        'chinese': f\"è¯·ç”¨ä¸­æ–‡{task}ä»¥ä¸‹å†…å®¹ï¼š{context}\",\n",
    "        'english': f\"Please {task} the following content in English: {context}\",\n",
    "        'japanese': f\"ä»¥ä¸‹ã®å†…å®¹ã‚’æ—¥æœ¬èªã§{task}ã—ã¦ãã ã•ã„ï¼š{context}\"\n",
    "    }\n",
    "    return templates.get(language, templates['chinese'])\n",
    "\n",
    "# å¤šè¯­è¨€ç¤ºä¾‹\n",
    "chinese_prompt = create_multilingual_prompt('chinese', 'æ€»ç»“', 'äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹')\n",
    "english_prompt = create_multilingual_prompt('english', 'summarize', 'the development of artificial intelligence')\n",
    "\n",
    "print(f\"\\nä¸­æ–‡æç¤ºè¯: {chinese_prompt}\")\n",
    "print(f\"è‹±æ–‡æç¤ºè¯: {english_prompt}\")\n",
    "\n",
    "# åœºæ™¯3: æ€§èƒ½ç›‘æ§æŠ¥å‘Š\n",
    "def generate_performance_report(model_stats):\n",
    "    \"\"\"ç”Ÿæˆæ€§èƒ½ç›‘æ§æŠ¥å‘Š\"\"\"\n",
    "    report = f\"\"\"\n",
    "ğŸ¤– æ¨¡å‹æ€§èƒ½æŠ¥å‘Š\n",
    "\n",
    "ğŸ“Š åŸºç¡€æŒ‡æ ‡:\n",
    "   â€¢ æ¨¡å‹åç§°: {model_stats['name']}\n",
    "   â€¢ å¤„ç†è¯·æ±‚: {model_stats['requests']:,} æ¬¡\n",
    "   â€¢ å¹³å‡å“åº”æ—¶é—´: {model_stats['avg_response_time']:.2f}ms\n",
    "   â€¢ æˆåŠŸç‡: {model_stats['success_rate']:.1%}\n",
    "\n",
    "ğŸ’° æˆæœ¬åˆ†æ:\n",
    "   â€¢ æ€»tokens: {model_stats['total_tokens']:,}\n",
    "   â€¢ å¹³å‡æ¯è¯·æ±‚tokens: {model_stats['avg_tokens_per_request']:.0f}\n",
    "   â€¢ æ€»æˆæœ¬: ${model_stats['total_cost']:.2f}\n",
    "   â€¢ å¹³å‡æ¯è¯·æ±‚æˆæœ¬: ${model_stats['avg_cost_per_request']:.4f}\n",
    "\n",
    "ğŸ”¥ çƒ­é—¨åŠŸèƒ½:\n",
    "   â€¢ æœ€å¸¸ç”¨åŠŸèƒ½: {model_stats['top_feature']}\n",
    "   â€¢ ä½¿ç”¨æ¬¡æ•°: {model_stats['top_feature_count']:,}\n",
    "\"\"\"\n",
    "    return report\n",
    "\n",
    "# æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®\n",
    "performance_data = {\n",
    "    'name': 'GPT-4 Turbo',\n",
    "    'requests': 15847,\n",
    "    'avg_response_time': 1234.5,\n",
    "    'success_rate': 0.9876,\n",
    "    'total_tokens': 2450000,\n",
    "    'avg_tokens_per_request': 154.6,\n",
    "    'total_cost': 73.5,\n",
    "    'avg_cost_per_request': 0.00464,\n",
    "    'top_feature': 'ä»£ç ç”Ÿæˆ',\n",
    "    'top_feature_count': 3421\n",
    "}\n",
    "\n",
    "performance_report = generate_performance_report(performance_data)\n",
    "print(\"\\n=== æ€§èƒ½ç›‘æ§æŠ¥å‘Š ===\")\n",
    "print(performance_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsZCwjq6U27q",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Python \"forå¾ªç¯\"\n",
    "\n",
    "> **æ ¸å¿ƒæ¦‚å¿µ**ï¼šforå¾ªç¯æ˜¯Pythonä¸­ç”¨äºéå†æ•°æ®é›†åˆçš„å¼ºå¤§å·¥å…·ï¼Œåœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºå¤„ç†å¯¹è¯å†å²ã€æ‰¹é‡å¤„ç†æ•°æ®ã€åˆ†æç»“æœç­‰ã€‚\n",
    "\n",
    "ä½¿ç”¨**forå¾ªç¯**å¯ä»¥è½»æ¾åœ°**è¿­ä»£**ä¸€ä¸ªé¡¹ç›®é›†åˆã€‚æˆ‘ä»¬å®šä¹‰çš„å­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å…ƒç»„ã€é›†åˆå’Œå­—å…¸éƒ½æ˜¯**å¯è¿­ä»£**çš„å®¹å™¨ã€‚\n",
    "\n",
    "### åŸºæœ¬è¯­æ³•\n",
    "```python\n",
    "for item in container:\n",
    "    # å¤„ç†æ¯ä¸ªé¡¹ç›®\n",
    "    pass\n",
    "```\n",
    "\n",
    "### å·¥ä½œåŸç†\n",
    "forå¾ªç¯ä¼šéå†æŒ‡å®šçš„å®¹å™¨ï¼Œä¸€æ¬¡ä¸€ä¸ªé¡¹ç›®ï¼Œå¹¶ä¸ºå½“å‰é¡¹ç›®æä¾›ä¸€ä¸ªä¸´æ—¶å˜é‡ã€‚ä½ å¯ä»¥åƒä½¿ç”¨æ™®é€šå˜é‡ä¸€æ ·ä½¿ç”¨è¿™ä¸ªä¸´æ—¶å˜é‡ã€‚\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **å¤„ç†å¯¹è¯å†å²**ï¼šéå†æ¶ˆæ¯åˆ—è¡¨ï¼Œåˆ†æå¯¹è¯æ¨¡å¼\n",
    "- **æ‰¹é‡å¤„ç†**ï¼šå¯¹å¤šä¸ªæ–‡æ¡£æˆ–æ–‡æœ¬è¿›è¡Œç›¸åŒçš„å¤„ç†\n",
    "- **æ•°æ®åˆ†æ**ï¼šç»Ÿè®¡å’Œåˆ†ææ¨¡å‹è¾“å‡ºç»“æœ\n",
    "- **é…ç½®ç®¡ç†**ï¼šéå†é…ç½®é¡¹è¿›è¡ŒéªŒè¯å’Œè®¾ç½®\n",
    "- **APIå“åº”å¤„ç†**ï¼šå¤„ç†æ‰¹é‡APIè°ƒç”¨çš„ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPR_LxqfU27r",
    "outputId": "bbdb5971-3cc0-4ea7-cea5-03cab6b7ebfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. åŸºæœ¬forå¾ªç¯ç”¨æ³• ===\n",
      "æ¨¡å‹åç§° 'GPT-4' çš„æ¯ä¸ªå­—ç¬¦:\n",
      "  å­—ç¬¦: G\n",
      "  å­—ç¬¦: P\n",
      "  å­—ç¬¦: T\n",
      "  å­—ç¬¦: -\n",
      "  å­—ç¬¦: 4\n",
      "\n",
      "æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨:\n",
      "  âœ“ gpt-3.5-turbo\n",
      "  âœ“ gpt-4\n",
      "  âœ“ claude-3\n",
      "  âœ“ gemini-pro\n",
      "\n",
      "=== 2. å¤„ç†å¯¹è¯å†å² ===\n",
      "å¯¹è¯å†å²åˆ†æ:\n",
      "[2024-01-01 10:00:00] user: ä½ å¥½...\n",
      "[2024-01-01 10:00:01] assistant: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ...\n",
      "[2024-01-01 10:00:30] user: è¯·ä»‹ç»ä¸€ä¸‹Python...\n",
      "[2024-01-01 10:00:32] assistant: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€......\n",
      "\n",
      "å¯¹è¯ç»Ÿè®¡:\n",
      "  ç”¨æˆ·æ¶ˆæ¯: 2 æ¡\n",
      "  åŠ©æ‰‹æ¶ˆæ¯: 2 æ¡\n",
      "  æ€»å­—ç¬¦æ•°: 45 ä¸ª\n",
      "\n",
      "=== 3. æ‰¹é‡å¤„ç†æ–‡æœ¬æ•°æ® ===\n",
      "æ–‡æœ¬å¤„ç†ç»“æœ:\n",
      "  æ–‡æœ¬1: 12å­—ç¬¦, 1è¯, æƒ…æ„Ÿåˆ†æ•°:2\n",
      "  æ–‡æœ¬2: 12å­—ç¬¦, 1è¯, æƒ…æ„Ÿåˆ†æ•°:1\n",
      "  æ–‡æœ¬3: 14å­—ç¬¦, 1è¯, æƒ…æ„Ÿåˆ†æ•°:1\n",
      "  æ–‡æœ¬4: 15å­—ç¬¦, 1è¯, æƒ…æ„Ÿåˆ†æ•°:0\n",
      "\n",
      "=== 4. éå†å­—å…¸é…ç½® ===\n",
      "æ¨¡å‹é…ç½®æ¯”è¾ƒ:\n",
      "\n",
      "ğŸ“‹ gpt-3.5-turbo:\n",
      "    max_tokens: 4096\n",
      "    temperature: 0.7\n",
      "    cost_per_token: $0.000002\n",
      "    speed: fast\n",
      "\n",
      "ğŸ“‹ gpt-4:\n",
      "    max_tokens: 8192\n",
      "    temperature: 0.7\n",
      "    cost_per_token: $0.000030\n",
      "    speed: medium\n",
      "\n",
      "ğŸ“‹ claude-3:\n",
      "    max_tokens: 100000\n",
      "    temperature: 0.7\n",
      "    cost_per_token: $0.000008\n",
      "    speed: fast\n",
      "\n",
      "=== 5. ä½¿ç”¨enumerate()è·å–ç´¢å¼• ===\n",
      "APIè°ƒç”¨ç»“æœåˆ†æ:\n",
      "  è°ƒç”¨1: âœ… success - tokens:150, æ—¶é—´:1.2s\n",
      "  è°ƒç”¨2: âœ… success - tokens:220, æ—¶é—´:1.8s\n",
      "  è°ƒç”¨3: âŒ error - tokens:0, æ—¶é—´:0.5s\n",
      "  è°ƒç”¨4: âœ… success - tokens:180, æ—¶é—´:1.5s\n",
      "\n",
      "æ€»ç»“:\n",
      "  æˆåŠŸç‡: 3/4 (75.0%)\n",
      "  å¹³å‡tokens: 183\n",
      "  æ€»è€—æ—¶: 5.0s\n",
      "\n",
      "=== 6. ä½¿ç”¨range()ç”Ÿæˆæ•°å­—åºåˆ— ===\n",
      "æ‰¹é‡ç”Ÿæˆä¸ªæ€§åŒ–æç¤ºè¯:\n",
      "  æç¤ºè¯1 (å­¦ç”Ÿ): ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸ºå­¦ç”Ÿæä¾›å¸®åŠ©ã€‚è¯·ä»¥é€‚åˆå­¦ç”Ÿçš„æ–¹å¼å›ç­”é—®é¢˜ã€‚...\n",
      "  æç¤ºè¯2 (æ•™å¸ˆ): ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸ºæ•™å¸ˆæä¾›å¸®åŠ©ã€‚è¯·ä»¥é€‚åˆæ•™å¸ˆçš„æ–¹å¼å›ç­”é—®é¢˜ã€‚...\n",
      "  æç¤ºè¯3 (ç ”ç©¶å‘˜): ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸ºç ”ç©¶å‘˜æä¾›å¸®åŠ©ã€‚è¯·ä»¥é€‚åˆç ”ç©¶å‘˜çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚...\n",
      "  æç¤ºè¯4 (å·¥ç¨‹å¸ˆ): ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸ºå·¥ç¨‹å¸ˆæä¾›å¸®åŠ©ã€‚è¯·ä»¥é€‚åˆå·¥ç¨‹å¸ˆçš„æ–¹å¼å›ç­”é—®é¢˜ã€‚...\n",
      "  æç¤ºè¯5 (äº§å“ç»ç†): ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸ºäº§å“ç»ç†æä¾›å¸®åŠ©ã€‚è¯·ä»¥é€‚åˆäº§å“ç»ç†çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚...\n",
      "\n",
      "=== 7. åµŒå¥—å¾ªç¯å¤„ç†å¤æ‚æ•°æ® ===\n",
      "æ¨¡å‹æ€§èƒ½å¯¹æ¯”:\n",
      "\n",
      "ğŸ¤– gpt-3.5-turbo:\n",
      "    ğŸ“ æ–‡æœ¬ç”Ÿæˆ:\n",
      "        å‡†ç¡®ç‡: 85.0%\n",
      "        é€Ÿåº¦: 2.1s\n",
      "    ğŸ“ ä»£ç ç”Ÿæˆ:\n",
      "        å‡†ç¡®ç‡: 78.0%\n",
      "        é€Ÿåº¦: 2.3s\n",
      "    ğŸ“ ç¿»è¯‘:\n",
      "        å‡†ç¡®ç‡: 92.0%\n",
      "        é€Ÿåº¦: 1.8s\n",
      "\n",
      "ğŸ¤– gpt-4:\n",
      "    ğŸ“ æ–‡æœ¬ç”Ÿæˆ:\n",
      "        å‡†ç¡®ç‡: 92.0%\n",
      "        é€Ÿåº¦: 3.2s\n",
      "    ğŸ“ ä»£ç ç”Ÿæˆ:\n",
      "        å‡†ç¡®ç‡: 89.0%\n",
      "        é€Ÿåº¦: 3.5s\n",
      "    ğŸ“ ç¿»è¯‘:\n",
      "        å‡†ç¡®ç‡: 95.0%\n",
      "        é€Ÿåº¦: 2.9s\n"
     ]
    }
   ],
   "source": [
    "# forå¾ªç¯åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨ç¤ºä¾‹\n",
    "\n",
    "print(\"=== 1. åŸºæœ¬forå¾ªç¯ç”¨æ³• ===\")\n",
    "\n",
    "# éå†å­—ç¬¦ä¸²\n",
    "model_name = \"GPT-4\"\n",
    "print(f\"æ¨¡å‹åç§° '{model_name}' çš„æ¯ä¸ªå­—ç¬¦:\")\n",
    "for char in model_name:\n",
    "    print(f\"  å­—ç¬¦: {char}\")\n",
    "\n",
    "# éå†åˆ—è¡¨\n",
    "supported_models = [\"gpt-3.5-turbo\", \"gpt-4\", \"claude-3\", \"gemini-pro\"]\n",
    "print(f\"\\næ”¯æŒçš„æ¨¡å‹åˆ—è¡¨:\")\n",
    "for model in supported_models:\n",
    "    print(f\"  âœ“ {model}\")\n",
    "\n",
    "print(\"\\n=== 2. å¤„ç†å¯¹è¯å†å² ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿå¯¹è¯å†å²\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"ä½ å¥½\", \"timestamp\": \"2024-01-01 10:00:00\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\", \"timestamp\": \"2024-01-01 10:00:01\"},\n",
    "    {\"role\": \"user\", \"content\": \"è¯·ä»‹ç»ä¸€ä¸‹Python\", \"timestamp\": \"2024-01-01 10:00:30\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...\", \"timestamp\": \"2024-01-01 10:00:32\"}\n",
    "]\n",
    "\n",
    "print(\"å¯¹è¯å†å²åˆ†æ:\")\n",
    "user_messages = 0\n",
    "assistant_messages = 0\n",
    "total_characters = 0\n",
    "\n",
    "for message in conversation:\n",
    "    print(f\"[{message['timestamp']}] {message['role']}: {message['content'][:30]}...\")\n",
    "\n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    if message['role'] == 'user':\n",
    "        user_messages += 1\n",
    "    elif message['role'] == 'assistant':\n",
    "        assistant_messages += 1\n",
    "\n",
    "    total_characters += len(message['content'])\n",
    "\n",
    "print(f\"\\nå¯¹è¯ç»Ÿè®¡:\")\n",
    "print(f\"  ç”¨æˆ·æ¶ˆæ¯: {user_messages} æ¡\")\n",
    "print(f\"  åŠ©æ‰‹æ¶ˆæ¯: {assistant_messages} æ¡\")\n",
    "print(f\"  æ€»å­—ç¬¦æ•°: {total_characters} ä¸ª\")\n",
    "\n",
    "print(\"\\n=== 3. æ‰¹é‡å¤„ç†æ–‡æœ¬æ•°æ® ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿè¦å¤„ç†çš„æ–‡æœ¬åˆ—è¡¨\n",
    "texts_to_process = [\n",
    "    \"äººå·¥æ™ºèƒ½æ˜¯æœªæ¥ç§‘æŠ€çš„æ ¸å¿ƒ\",\n",
    "    \"æœºå™¨å­¦ä¹ æ­£åœ¨æ”¹å˜å„ä¸ªè¡Œä¸š\",\n",
    "    \"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ä¸­è¡¨ç°ä¼˜å¼‚\",\n",
    "    \"è‡ªç„¶è¯­è¨€å¤„ç†è®©æœºå™¨ç†è§£äººç±»è¯­è¨€\"\n",
    "]\n",
    "\n",
    "print(\"æ–‡æœ¬å¤„ç†ç»“æœ:\")\n",
    "processed_results = []\n",
    "\n",
    "for i, text in enumerate(texts_to_process, 1):\n",
    "    # æ¨¡æ‹Ÿæ–‡æœ¬å¤„ç†ï¼ˆè®¡ç®—é•¿åº¦ã€å•è¯æ•°ç­‰ï¼‰\n",
    "    char_count = len(text)\n",
    "    word_count = len(text.split())\n",
    "\n",
    "    # ç®€å•çš„æƒ…æ„Ÿåˆ†æï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "    positive_keywords = ['ä¼˜å¼‚', 'æ”¹å˜', 'æ ¸å¿ƒ', 'æœªæ¥']\n",
    "    sentiment_score = sum(1 for keyword in positive_keywords if keyword in text)\n",
    "\n",
    "    result = {\n",
    "        'id': i,\n",
    "        'text': text,\n",
    "        'char_count': char_count,\n",
    "        'word_count': word_count,\n",
    "        'sentiment_score': sentiment_score\n",
    "    }\n",
    "\n",
    "    processed_results.append(result)\n",
    "    print(f\"  æ–‡æœ¬{i}: {char_count}å­—ç¬¦, {word_count}è¯, æƒ…æ„Ÿåˆ†æ•°:{sentiment_score}\")\n",
    "\n",
    "print(\"\\n=== 4. éå†å­—å…¸é…ç½® ===\")\n",
    "\n",
    "# APIé…ç½®å­—å…¸\n",
    "api_configs = {\n",
    "    'gpt-3.5-turbo': {\n",
    "        'max_tokens': 4096,\n",
    "        'temperature': 0.7,\n",
    "        'cost_per_token': 0.0000015,\n",
    "        'speed': 'fast'\n",
    "    },\n",
    "    'gpt-4': {\n",
    "        'max_tokens': 8192,\n",
    "        'temperature': 0.7,\n",
    "        'cost_per_token': 0.00003,\n",
    "        'speed': 'medium'\n",
    "    },\n",
    "    'claude-3': {\n",
    "        'max_tokens': 100000,\n",
    "        'temperature': 0.7,\n",
    "        'cost_per_token': 0.000008,\n",
    "        'speed': 'fast'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"æ¨¡å‹é…ç½®æ¯”è¾ƒ:\")\n",
    "for model_name, config in api_configs.items():\n",
    "    print(f\"\\nğŸ“‹ {model_name}:\")\n",
    "    for key, value in config.items():\n",
    "        if key == 'cost_per_token':\n",
    "            print(f\"    {key}: ${value:.6f}\")\n",
    "        else:\n",
    "            print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"\\n=== 5. ä½¿ç”¨enumerate()è·å–ç´¢å¼• ===\")\n",
    "\n",
    "# å¤„ç†APIå“åº”åˆ—è¡¨\n",
    "api_responses = [\n",
    "    {\"status\": \"success\", \"tokens\": 150, \"response_time\": 1.2},\n",
    "    {\"status\": \"success\", \"tokens\": 220, \"response_time\": 1.8},\n",
    "    {\"status\": \"error\", \"tokens\": 0, \"response_time\": 0.5},\n",
    "    {\"status\": \"success\", \"tokens\": 180, \"response_time\": 1.5}\n",
    "]\n",
    "\n",
    "print(\"APIè°ƒç”¨ç»“æœåˆ†æ:\")\n",
    "successful_calls = 0\n",
    "total_tokens = 0\n",
    "total_time = 0\n",
    "\n",
    "for index, response in enumerate(api_responses, 1):\n",
    "    status_emoji = \"âœ…\" if response[\"status\"] == \"success\" else \"âŒ\"\n",
    "    print(f\"  è°ƒç”¨{index}: {status_emoji} {response['status']} - \"\n",
    "          f\"tokens:{response['tokens']}, æ—¶é—´:{response['response_time']}s\")\n",
    "\n",
    "    if response[\"status\"] == \"success\":\n",
    "        successful_calls += 1\n",
    "        total_tokens += response[\"tokens\"]\n",
    "\n",
    "    total_time += response[\"response_time\"]\n",
    "\n",
    "print(f\"\\næ€»ç»“:\")\n",
    "print(f\"  æˆåŠŸç‡: {successful_calls}/{len(api_responses)} ({successful_calls/len(api_responses)*100:.1f}%)\")\n",
    "print(f\"  å¹³å‡tokens: {total_tokens/successful_calls:.0f}\")\n",
    "print(f\"  æ€»è€—æ—¶: {total_time:.1f}s\")\n",
    "\n",
    "print(\"\\n=== 6. ä½¿ç”¨range()ç”Ÿæˆæ•°å­—åºåˆ— ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿæ‰¹é‡ç”Ÿæˆæç¤ºè¯\n",
    "print(\"æ‰¹é‡ç”Ÿæˆä¸ªæ€§åŒ–æç¤ºè¯:\")\n",
    "user_types = [\"å­¦ç”Ÿ\", \"æ•™å¸ˆ\", \"ç ”ç©¶å‘˜\", \"å·¥ç¨‹å¸ˆ\", \"äº§å“ç»ç†\"]\n",
    "\n",
    "for i in range(5):\n",
    "    user_type = user_types[i]\n",
    "    prompt = f\"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä¸º{user_type}æä¾›å¸®åŠ©ã€‚è¯·ä»¥é€‚åˆ{user_type}çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚\"\n",
    "    print(f\"  æç¤ºè¯{i+1} ({user_type}): {prompt[:40]}...\")\n",
    "\n",
    "print(\"\\n=== 7. åµŒå¥—å¾ªç¯å¤„ç†å¤æ‚æ•°æ® ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿå¤šæ¨¡å‹ã€å¤šä»»åŠ¡çš„æµ‹è¯•ç»“æœ\n",
    "test_results = {\n",
    "    \"gpt-3.5-turbo\": {\n",
    "        \"æ–‡æœ¬ç”Ÿæˆ\": {\"accuracy\": 0.85, \"speed\": 2.1},\n",
    "        \"ä»£ç ç”Ÿæˆ\": {\"accuracy\": 0.78, \"speed\": 2.3},\n",
    "        \"ç¿»è¯‘\": {\"accuracy\": 0.92, \"speed\": 1.8}\n",
    "    },\n",
    "    \"gpt-4\": {\n",
    "        \"æ–‡æœ¬ç”Ÿæˆ\": {\"accuracy\": 0.92, \"speed\": 3.2},\n",
    "        \"ä»£ç ç”Ÿæˆ\": {\"accuracy\": 0.89, \"speed\": 3.5},\n",
    "        \"ç¿»è¯‘\": {\"accuracy\": 0.95, \"speed\": 2.9}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"æ¨¡å‹æ€§èƒ½å¯¹æ¯”:\")\n",
    "for model, tasks in test_results.items():\n",
    "    print(f\"\\nğŸ¤– {model}:\")\n",
    "    for task, metrics in tasks.items():\n",
    "        print(f\"    ğŸ“ {task}:\")\n",
    "        print(f\"        å‡†ç¡®ç‡: {metrics['accuracy']:.1%}\")\n",
    "        print(f\"        é€Ÿåº¦: {metrics['speed']:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "wjqaJSy9U27s",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "uvcIGanUU279",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Python \"ifè¯­å¥\"å’Œ\"whileå¾ªç¯\"\n",
    "\n",
    "> **æ ¸å¿ƒæ¦‚å¿µ**ï¼šæ¡ä»¶è¯­å¥å’Œå¾ªç¯æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­æ§åˆ¶ç¨‹åºæµç¨‹çš„åŸºç¡€å·¥å…·ï¼Œç”¨äºæ¡ä»¶åˆ¤æ–­ã€é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶ç­‰ã€‚\n",
    "\n",
    "æ¡ä»¶è¡¨è¾¾å¼å¯ä»¥ä¸è¿™ä¸¤ç§**æ¡ä»¶è¯­å¥**ä¸€èµ·ä½¿ç”¨ã€‚\n",
    "\n",
    "### ifè¯­å¥\n",
    "**ifè¯­å¥**å…è®¸ä½ æµ‹è¯•æ¡ä»¶ï¼Œå¦‚æœæ¡ä»¶è¯„ä¼°ä¸º`True`åˆ™æ‰§è¡ŒæŸäº›æ“ä½œã€‚ä½ è¿˜å¯ä»¥ä¸ºifè¯­å¥æä¾›`elif`å’Œ/æˆ–`else`å­å¥ï¼Œä»¥ä¾¿åœ¨æ¡ä»¶è¯„ä¼°ä¸º`False`æ—¶é‡‡å–æ›¿ä»£æ“ä½œã€‚\n",
    "\n",
    "### whileå¾ªç¯\n",
    "**whileå¾ªç¯**å°†ä¸€ç›´å¾ªç¯ï¼Œç›´åˆ°å…¶æ¡ä»¶è¡¨è¾¾å¼è¯„ä¼°ä¸º`False`ã€‚\n",
    "\n",
    "> **æ³¨æ„**ï¼šå½“ä½¿ç”¨whileå¾ªç¯ä¸”æ¡ä»¶è¡¨è¾¾å¼æ°¸è¿œä¸ä¼šè¯„ä¼°ä¸º`False`æ—¶ï¼Œå¯èƒ½ä¼š\"æ°¸è¿œå¾ªç¯\"ã€‚\n",
    ">\n",
    "> **æ³¨æ„**ï¼šç”±äº**forå¾ªç¯**ä¼šéå†å®¹å™¨ä¸­çš„é¡¹ç›®ç›´åˆ°æ²¡æœ‰æ›´å¤šé¡¹ç›®ï¼Œå› æ­¤æ— éœ€æŒ‡å®š\"åœæ­¢å¾ªç¯\"æ¡ä»¶ã€‚\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **æ¡ä»¶åˆ¤æ–­**ï¼šæ ¹æ®APIå“åº”çŠ¶æ€æ‰§è¡Œä¸åŒæ“ä½œ\n",
    "- **é”™è¯¯å¤„ç†**ï¼šä½¿ç”¨ifè¯­å¥å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ\n",
    "- **é‡è¯•æœºåˆ¶**ï¼šä½¿ç”¨whileå¾ªç¯å®ç°APIè°ƒç”¨é‡è¯•\n",
    "- **æ•°æ®éªŒè¯**ï¼šä½¿ç”¨æ¡ä»¶è¯­å¥éªŒè¯è¾“å…¥æ•°æ®\n",
    "- **æµç¨‹æ§åˆ¶**ï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥æˆ–ç³»ç»ŸçŠ¶æ€æ§åˆ¶ç¨‹åºæµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvtmIeC2U27-",
    "outputId": "bed009f6-4d41-4002-9f36-863c8c7c3edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. ifè¯­å¥åœ¨APIè°ƒç”¨ä¸­çš„åº”ç”¨ ===\n",
      "âœ… APIè°ƒç”¨æˆåŠŸ\n",
      "å¤„ç†ç»“æœ: {'message': 'æˆåŠŸè·å–æ•°æ®'}\n",
      "----------------------------------------\n",
      "âŒ è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥\n",
      "å¤„ç†ç»“æœ: None\n",
      "----------------------------------------\n",
      "âš ï¸ è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œéœ€è¦ç­‰å¾…\n",
      "å¤„ç†ç»“æœ: None\n",
      "----------------------------------------\n",
      "ğŸ”¥ æœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•\n",
      "å¤„ç†ç»“æœ: None\n",
      "----------------------------------------\n",
      "â“ æœªçŸ¥é”™è¯¯ï¼ŒçŠ¶æ€ç : 404\n",
      "å¤„ç†ç»“æœ: None\n",
      "----------------------------------------\n",
      "\n",
      "=== 2. whileå¾ªç¯å®ç°APIé‡è¯•æœºåˆ¶ ===\n",
      "\n",
      "å¤„ç†æç¤ºè¯: 'è¯·ä»‹ç»ä¸€ä¸‹Python'\n",
      "âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• 1)\n",
      "â³ ç­‰å¾… 1 ç§’åé‡è¯•...\n",
      "âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• 2)\n",
      "â³ ç­‰å¾… 2 ç§’åé‡è¯•...\n",
      "âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• 3)\n",
      "ğŸ’¥ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° (3)ï¼Œè°ƒç”¨å¤±è´¥\n",
      "==================================================\n",
      "\n",
      "å¤„ç†æç¤ºè¯: 'è§£é‡Šæœºå™¨å­¦ä¹ '\n",
      "âœ… APIè°ƒç”¨æˆåŠŸ (å°è¯• 1)\n",
      "æœ€ç»ˆç»“æœ: AIå›å¤: è§£é‡Šæœºå™¨å­¦ä¹ ...\n",
      "==================================================\n",
      "\n",
      "å¤„ç†æç¤ºè¯: 'å†™ä¸€é¦–è¯—'\n",
      "âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• 1)\n",
      "â³ ç­‰å¾… 1 ç§’åé‡è¯•...\n",
      "âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• 2)\n",
      "â³ ç­‰å¾… 2 ç§’åé‡è¯•...\n",
      "âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• 3)\n",
      "ğŸ’¥ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° (3)ï¼Œè°ƒç”¨å¤±è´¥\n",
      "==================================================\n",
      "\n",
      "=== 3. å¤æ‚æ¡ä»¶åˆ¤æ–­ - æ¨¡å‹é€‰æ‹©é€»è¾‘ ===\n",
      "æ¨¡å‹é€‰æ‹©æµ‹è¯•:\n",
      "ä»»åŠ¡: ä»£ç ç”Ÿæˆ     | é•¿åº¦:  500 | é¢„ç®—: high   | æ¨èæ¨¡å‹: gpt-3.5-turbo\n",
      "ä»»åŠ¡: ä»£ç ç”Ÿæˆ     | é•¿åº¦: 2000 | é¢„ç®—: low    | æ¨èæ¨¡å‹: gpt-3.5-turbo\n",
      "ä»»åŠ¡: æ–‡æœ¬æ‘˜è¦     | é•¿åº¦: 3000 | é¢„ç®—: medium | æ¨èæ¨¡å‹: gpt-3.5-turbo\n",
      "ä»»åŠ¡: æ–‡æœ¬æ‘˜è¦     | é•¿åº¦: 8000 | é¢„ç®—: high   | æ¨èæ¨¡å‹: claude-3\n",
      "ä»»åŠ¡: ç¿»è¯‘       | é•¿åº¦: 1000 | é¢„ç®—: low    | æ¨èæ¨¡å‹: gpt-3.5-turbo\n",
      "ä»»åŠ¡: åˆ›æ„å†™ä½œ     | é•¿åº¦:  500 | é¢„ç®—: high   | æ¨èæ¨¡å‹: gpt-4\n",
      "ä»»åŠ¡: æœªçŸ¥ä»»åŠ¡     | é•¿åº¦: 1000 | é¢„ç®—: medium | æ¨èæ¨¡å‹: gpt-3.5-turbo\n",
      "\n",
      "=== 4. æ•°æ®éªŒè¯å’Œé”™è¯¯å¤„ç† ===\n",
      "è¾“å…¥éªŒè¯æµ‹è¯•:\n",
      "âŒ æ— æ•ˆ | ç±»å‹: text   | è¾“å…¥: ''\n",
      "    é”™è¯¯: è¾“å…¥ä¸èƒ½ä¸ºç©º\n",
      "------------------------------------------------------------\n",
      "âœ… æœ‰æ•ˆ | ç±»å‹: email  | è¾“å…¥: 'hello@example.com'\n",
      "------------------------------------------------------------\n",
      "âŒ æ— æ•ˆ | ç±»å‹: email  | è¾“å…¥: 'invalid-email'\n",
      "    é”™è¯¯: è¯·è¾“å…¥æœ‰æ•ˆçš„é‚®ç®±åœ°å€\n",
      "------------------------------------------------------------\n",
      "âœ… æœ‰æ•ˆ | ç±»å‹: number | è¾“å…¥: '123.45'\n",
      "------------------------------------------------------------\n",
      "âŒ æ— æ•ˆ | ç±»å‹: number | è¾“å…¥: 'not-a-number'\n",
      "    é”™è¯¯: è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—\n",
      "------------------------------------------------------------\n",
      "âœ… æœ‰æ•ˆ | ç±»å‹: code   | è¾“å…¥: 'def hello(): print('world')'\n",
      "------------------------------------------------------------\n",
      "âŒ æ— æ•ˆ | ç±»å‹: code   | è¾“å…¥: 'just text'\n",
      "    é”™è¯¯: è¯·è¾“å…¥æœ‰æ•ˆçš„ä»£ç \n",
      "------------------------------------------------------------\n",
      "âŒ æ— æ•ˆ | ç±»å‹: text   | è¾“å…¥: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...'\n",
      "    é”™è¯¯: è¾“å…¥è¿‡é•¿ï¼Œè¯·æ§åˆ¶åœ¨10000å­—ç¬¦ä»¥å†…\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„ifè¯­å¥å’Œwhileå¾ªç¯ç¤ºä¾‹\n",
    "\n",
    "print(\"=== 1. ifè¯­å¥åœ¨APIè°ƒç”¨ä¸­çš„åº”ç”¨ ===\")\n",
    "\n",
    "def process_api_response(response):\n",
    "    \"\"\"å¤„ç†APIå“åº”ï¼Œæ ¹æ®çŠ¶æ€ç æ‰§è¡Œä¸åŒæ“ä½œ\"\"\"\n",
    "    status_code = response.get('status_code', 0)\n",
    "\n",
    "    if status_code == 200:\n",
    "        print(\"âœ… APIè°ƒç”¨æˆåŠŸ\")\n",
    "        return response.get('data', {})\n",
    "    elif status_code == 401:\n",
    "        print(\"âŒ è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥\")\n",
    "        return None\n",
    "    elif status_code == 429:\n",
    "        print(\"âš ï¸ è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œéœ€è¦ç­‰å¾…\")\n",
    "        return None\n",
    "    elif status_code >= 500:\n",
    "        print(\"ğŸ”¥ æœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"â“ æœªçŸ¥é”™è¯¯ï¼ŒçŠ¶æ€ç : {status_code}\")\n",
    "        return None\n",
    "\n",
    "# æ¨¡æ‹Ÿä¸åŒçš„APIå“åº”\n",
    "test_responses = [\n",
    "    {'status_code': 200, 'data': {'message': 'æˆåŠŸè·å–æ•°æ®'}},\n",
    "    {'status_code': 401, 'error': 'Invalid API key'},\n",
    "    {'status_code': 429, 'error': 'Rate limit exceeded'},\n",
    "    {'status_code': 500, 'error': 'Internal server error'},\n",
    "    {'status_code': 404, 'error': 'Not found'}\n",
    "]\n",
    "\n",
    "for response in test_responses:\n",
    "    result = process_api_response(response)\n",
    "    print(f\"å¤„ç†ç»“æœ: {result}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n=== 2. whileå¾ªç¯å®ç°APIé‡è¯•æœºåˆ¶ ===\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "def call_llm_api_with_retry(prompt, max_retries=3, delay=1):\n",
    "    \"\"\"å¸¦é‡è¯•æœºåˆ¶çš„LLM APIè°ƒç”¨\"\"\"\n",
    "    retry_count = 0\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            # æ¨¡æ‹ŸAPIè°ƒç”¨ï¼ˆéšæœºæˆåŠŸ/å¤±è´¥ï¼‰\n",
    "            success = random.choice([True, False, False])  # 33%æˆåŠŸç‡\n",
    "\n",
    "            if success:\n",
    "                print(f\"âœ… APIè°ƒç”¨æˆåŠŸ (å°è¯• {retry_count + 1})\")\n",
    "                return f\"AIå›å¤: {prompt[:20]}...\"\n",
    "            else:\n",
    "                print(f\"âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• {retry_count + 1})\")\n",
    "                retry_count += 1\n",
    "\n",
    "                if retry_count < max_retries:\n",
    "                    print(f\"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...\")\n",
    "                    time.sleep(delay)\n",
    "                    delay *= 2  # æŒ‡æ•°é€€é¿\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ”¥ å¼‚å¸¸: {e}\")\n",
    "            retry_count += 1\n",
    "\n",
    "    print(f\"ğŸ’¥ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œè°ƒç”¨å¤±è´¥\")\n",
    "    return None\n",
    "\n",
    "# æµ‹è¯•é‡è¯•æœºåˆ¶\n",
    "test_prompts = [\"è¯·ä»‹ç»ä¸€ä¸‹Python\", \"è§£é‡Šæœºå™¨å­¦ä¹ \", \"å†™ä¸€é¦–è¯—\"]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nå¤„ç†æç¤ºè¯: '{prompt}'\")\n",
    "    result = call_llm_api_with_retry(prompt)\n",
    "    if result:\n",
    "        print(f\"æœ€ç»ˆç»“æœ: {result}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n=== 3. å¤æ‚æ¡ä»¶åˆ¤æ–­ - æ¨¡å‹é€‰æ‹©é€»è¾‘ ===\")\n",
    "\n",
    "def select_optimal_model(task_type, text_length, budget_level):\n",
    "    \"\"\"æ ¹æ®ä»»åŠ¡ç±»å‹ã€æ–‡æœ¬é•¿åº¦å’Œé¢„ç®—é€‰æ‹©æœ€ä¼˜æ¨¡å‹\"\"\"\n",
    "\n",
    "    # åŸºç¡€æ¡ä»¶åˆ¤æ–­\n",
    "    if task_type == \"ä»£ç ç”Ÿæˆ\":\n",
    "        if text_length > 1000:\n",
    "            return \"gpt-4\" if budget_level == \"high\" else \"gpt-3.5-turbo\"\n",
    "        else:\n",
    "            return \"gpt-3.5-turbo\"\n",
    "\n",
    "    elif task_type == \"æ–‡æœ¬æ‘˜è¦\":\n",
    "        if text_length > 5000:\n",
    "            return \"claude-3\" if budget_level == \"high\" else \"gpt-3.5-turbo\"\n",
    "        else:\n",
    "            return \"gpt-3.5-turbo\"\n",
    "\n",
    "    elif task_type == \"ç¿»è¯‘\":\n",
    "        return \"gpt-3.5-turbo\"  # ç¿»è¯‘ä»»åŠ¡é€šå¸¸ç”¨è¾ƒä¾¿å®œçš„æ¨¡å‹\n",
    "\n",
    "    elif task_type == \"åˆ›æ„å†™ä½œ\":\n",
    "        return \"gpt-4\" if budget_level == \"high\" else \"gpt-3.5-turbo\"\n",
    "\n",
    "    else:\n",
    "        return \"gpt-3.5-turbo\"  # é»˜è®¤é€‰æ‹©\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹é€‰æ‹©\n",
    "test_cases = [\n",
    "    (\"ä»£ç ç”Ÿæˆ\", 500, \"high\"),\n",
    "    (\"ä»£ç ç”Ÿæˆ\", 2000, \"low\"),\n",
    "    (\"æ–‡æœ¬æ‘˜è¦\", 3000, \"medium\"),\n",
    "    (\"æ–‡æœ¬æ‘˜è¦\", 8000, \"high\"),\n",
    "    (\"ç¿»è¯‘\", 1000, \"low\"),\n",
    "    (\"åˆ›æ„å†™ä½œ\", 500, \"high\"),\n",
    "    (\"æœªçŸ¥ä»»åŠ¡\", 1000, \"medium\")\n",
    "]\n",
    "\n",
    "print(\"æ¨¡å‹é€‰æ‹©æµ‹è¯•:\")\n",
    "for task, length, budget in test_cases:\n",
    "    model = select_optimal_model(task, length, budget)\n",
    "    print(f\"ä»»åŠ¡: {task:8} | é•¿åº¦: {length:4} | é¢„ç®—: {budget:6} | æ¨èæ¨¡å‹: {model}\")\n",
    "\n",
    "print(\"\\n=== 4. æ•°æ®éªŒè¯å’Œé”™è¯¯å¤„ç† ===\")\n",
    "\n",
    "def validate_user_input(user_input, input_type=\"text\"):\n",
    "    \"\"\"éªŒè¯ç”¨æˆ·è¾“å…¥\"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º\n",
    "    if not user_input or not user_input.strip():\n",
    "        errors.append(\"è¾“å…¥ä¸èƒ½ä¸ºç©º\")\n",
    "\n",
    "    # æ£€æŸ¥è¾“å…¥é•¿åº¦\n",
    "    if len(user_input) > 10000:\n",
    "        errors.append(\"è¾“å…¥è¿‡é•¿ï¼Œè¯·æ§åˆ¶åœ¨10000å­—ç¬¦ä»¥å†…\")\n",
    "\n",
    "    # æ ¹æ®ç±»å‹è¿›è¡Œç‰¹å®šéªŒè¯\n",
    "    if input_type == \"email\":\n",
    "        if \"@\" not in user_input:\n",
    "            errors.append(\"è¯·è¾“å…¥æœ‰æ•ˆçš„é‚®ç®±åœ°å€\")\n",
    "\n",
    "    elif input_type == \"number\":\n",
    "        try:\n",
    "            float(user_input)\n",
    "        except ValueError:\n",
    "            errors.append(\"è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—\")\n",
    "\n",
    "    elif input_type == \"code\":\n",
    "        if not any(keyword in user_input.lower() for keyword in [\"def \", \"class \", \"import \", \"if \", \"for \"]):\n",
    "            errors.append(\"è¯·è¾“å…¥æœ‰æ•ˆçš„ä»£ç \")\n",
    "\n",
    "    return len(errors) == 0, errors\n",
    "\n",
    "# æµ‹è¯•è¾“å…¥éªŒè¯\n",
    "test_inputs = [\n",
    "    (\"\", \"text\"),\n",
    "    (\"hello@example.com\", \"email\"),\n",
    "    (\"invalid-email\", \"email\"),\n",
    "    (\"123.45\", \"number\"),\n",
    "    (\"not-a-number\", \"number\"),\n",
    "    (\"def hello(): print('world')\", \"code\"),\n",
    "    (\"just text\", \"code\"),\n",
    "    (\"a\" * 15000, \"text\")\n",
    "]\n",
    "\n",
    "print(\"è¾“å…¥éªŒè¯æµ‹è¯•:\")\n",
    "for user_input, input_type in test_inputs:\n",
    "    is_valid, errors = validate_user_input(user_input, input_type)\n",
    "    status = \"âœ… æœ‰æ•ˆ\" if is_valid else \"âŒ æ— æ•ˆ\"\n",
    "    print(f\"{status} | ç±»å‹: {input_type:6} | è¾“å…¥: '{user_input[:30]}{'...' if len(user_input) > 30 else ''}'\")\n",
    "    if errors:\n",
    "        for error in errors:\n",
    "            print(f\"    é”™è¯¯: {error}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "b4JHiRS4U28C",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## åˆ—è¡¨ã€é›†åˆå’Œå­—å…¸æ¨å¯¼å¼\n",
    "\n",
    "> **æ ¸å¿ƒæŠ€èƒ½**ï¼šæ¨å¯¼å¼æ˜¯Pythonä¸­åˆ›å»ºå®¹å™¨çš„ç®€æ´é«˜æ•ˆæ–¹å¼ï¼Œåœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ç”¨äºæ•°æ®å¤„ç†ã€è½¬æ¢ã€è¿‡æ»¤ç­‰æ“ä½œã€‚\n",
    "\n",
    "æ¨å¯¼å¼ï¼ˆComprehensionsï¼‰æ˜¯Pythonä¸­åˆ›å»ºåˆ—è¡¨ã€é›†åˆå’Œå­—å…¸çš„ç®€æ´æ–¹å¼ï¼Œå®ƒä»¬åŸºäºç°æœ‰çš„å¯è¿­ä»£å¯¹è±¡ç”Ÿæˆæ–°çš„å®¹å™¨ã€‚\n",
    "\n",
    "### åˆ—è¡¨æ¨å¯¼å¼\n",
    "- **è¯­æ³•**ï¼š`[expression for item in iterable if condition]`\n",
    "- **ç”¨é€”**ï¼šä»ç°æœ‰æ•°æ®åˆ›å»ºæ–°åˆ—è¡¨ï¼Œè¿›è¡Œæ•°æ®è½¬æ¢å’Œè¿‡æ»¤\n",
    "\n",
    "### é›†åˆæ¨å¯¼å¼\n",
    "- **è¯­æ³•**ï¼š`{expression for item in iterable if condition}`\n",
    "- **ç”¨é€”**ï¼šåˆ›å»ºå”¯ä¸€å€¼é›†åˆï¼Œå»é‡å¤„ç†\n",
    "\n",
    "### å­—å…¸æ¨å¯¼å¼\n",
    "- **è¯­æ³•**ï¼š`{key_expression: value_expression for item in iterable if condition}`\n",
    "- **ç”¨é€”**ï¼šåˆ›å»ºé”®å€¼å¯¹æ˜ å°„ï¼Œæ•°æ®è½¬æ¢\n",
    "\n",
    "å¦‚ä½•é˜…è¯»ï¼Ÿä¾‹å¦‚`[resp for resp in api_responses if resp[\"success\"]]`,ä»ä¸­é—´å¼€å§‹é˜…è¯»ï¼Œç„¶åå‘ä¸¤è¾¹çœ‹ï¼š\n",
    "\n",
    "å¯¹äº (for resp in api_responses)ï¼šapi_responses ä¸­çš„æ¯ä¸€ä¸ª respã€‚\n",
    "\n",
    "å¦‚æœ (if resp[\"success\"])ï¼šè¯¥ resp æ˜¯æˆåŠŸçš„ã€‚\n",
    "\n",
    "é‚£ä¹ˆ ([resp ... ])ï¼šæŠŠè¿™ä¸ª resp æ”¶é›† èµ·æ¥ï¼Œæ”¾åˆ°æ–°åˆ—è¡¨ successful_responses ä¸­ã€‚\n",
    "\n",
    "åˆ—è¡¨æ¨å¯¼å¼æ˜¯ Python çš„æ ¸å¿ƒç‰¹æ€§ä¹‹ä¸€ï¼Œç†Ÿç»ƒæŒæ¡å®ƒèƒ½è®©æ‚¨çš„ä»£ç æ›´ç®€æ´ã€æ›´é«˜æ•ˆï¼\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **æ•°æ®å¤„ç†**ï¼šå¿«é€Ÿè½¬æ¢å’Œè¿‡æ»¤APIå“åº”æ•°æ®\n",
    "- **æ–‡æœ¬å¤„ç†**ï¼šæ‰¹é‡å¤„ç†æ–‡æœ¬ï¼Œæå–ç‰¹å¾\n",
    "- **é…ç½®ç®¡ç†**ï¼šä»åŸå§‹æ•°æ®ç”Ÿæˆé…ç½®å­—å…¸\n",
    "- **æ•°æ®åˆ†æ**ï¼šç»Ÿè®¡å’Œèšåˆæ•°æ®\n",
    "- **æ€§èƒ½ä¼˜åŒ–**ï¼šæ¯”ä¼ ç»Ÿå¾ªç¯æ›´é«˜æ•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMLylr5CU28A",
    "outputId": "2c97702e-1519-4e9b-b3ae-ecf671feb969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. åˆ—è¡¨æ¨å¯¼å¼ - æ•°æ®å¤„ç†å’Œè½¬æ¢ ===\n",
      "æˆåŠŸçš„APIè°ƒç”¨:\n",
      "  æ¨¡å‹: gpt-3.5-turbo, tokens: 150, æˆæœ¬: $0.0003\n",
      "  æ¨¡å‹: gpt-4, tokens: 200, æˆæœ¬: $0.0060\n",
      "  æ¨¡å‹: gpt-3.5-turbo, tokens: 120, æˆæœ¬: $0.0002\n",
      "  æ¨¡å‹: gpt-4, tokens: 300, æˆæœ¬: $0.0090\n",
      "\n",
      "å„æ¨¡å‹æ€»æˆæœ¬: {'gpt-3.5-turbo': 0.00054, 'gpt-4': 0.015, 'claude-3': 0.00144}\n",
      "\n",
      "é«˜æˆæœ¬è°ƒç”¨æ•°é‡: 2\n",
      "\n",
      "=== 2. å­—å…¸æ¨å¯¼å¼ - æ•°æ®èšåˆå’Œç»Ÿè®¡ ===\n",
      "æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯:\n",
      "  gpt-3.5-turbo:\n",
      "    æ€»è°ƒç”¨: 2, æˆåŠŸç‡: 100.0%\n",
      "    æ€»tokens: 270, å¹³å‡tokens: 135\n",
      "    æ€»æˆæœ¬: $0.0005\n",
      "  gpt-4:\n",
      "    æ€»è°ƒç”¨: 2, æˆåŠŸç‡: 100.0%\n",
      "    æ€»tokens: 500, å¹³å‡tokens: 250\n",
      "    æ€»æˆæœ¬: $0.0150\n",
      "  claude-3:\n",
      "    æ€»è°ƒç”¨: 1, æˆåŠŸç‡: 0.0%\n",
      "    æ€»tokens: 180, å¹³å‡tokens: 180\n",
      "    æ€»æˆæœ¬: $0.0014\n",
      "\n",
      "æ€§èƒ½æŠ¥å‘Š: {'gpt-3.5-turbo': {'success_rate': 1.0, 'avg_tokens': 135.0, 'cost_per_token': 2e-06}, 'gpt-4': {'success_rate': 1.0, 'avg_tokens': 250.0, 'cost_per_token': 2.9999999999999997e-05}, 'claude-3': {'success_rate': 0.0, 'avg_tokens': 180.0, 'cost_per_token': 8.000000000000001e-06}}\n",
      "\n",
      "=== 3. é›†åˆæ¨å¯¼å¼ - å»é‡å’Œç‰¹å¾æå– ===\n",
      "æ‰€æœ‰å”¯ä¸€å•è¯ (26 ä¸ª): ['a', 'ai', 'and', 'are', 'artificial', 'data', 'development', 'essential', 'for', 'great', 'industries', 'intelligence', 'is', 'language', 'learning', 'machine', 'popular', 'programming', 'python', 'requires', 'science', 'skills', 'strong', 'transforming', 'very', 'with']\n",
      "\n",
      "AIç›¸å…³å…³é”®è¯: ['ai', 'learning', 'machine', 'programming', 'python']\n",
      "\n",
      "é•¿åº¦å¤§äº5çš„å•è¯: ['artificial', 'development', 'essential', 'industries', 'intelligence', 'language', 'learning', 'machine', 'popular', 'programming', 'python', 'requires', 'science', 'skills', 'strong', 'transforming']\n",
      "\n",
      "=== 4. åµŒå¥—æ¨å¯¼å¼ - å¤æ‚æ•°æ®å¤„ç† ===\n",
      "æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯çš„tokens: [5, 8, 10]\n",
      "æ¯ä¸ªå¯¹è¯çš„æ€»tokens: {1: 78, 2: 40}\n",
      "åŒ…å«'python'çš„æ¶ˆæ¯: ['è¯·ä»‹ç»ä¸€ä¸‹Python', 'Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...', 'å†™ä¸€ä¸ªPythonå‡½æ•°', 'å¥½çš„ï¼Œæˆ‘æ¥ä¸ºä½ å†™ä¸€ä¸ªPythonå‡½æ•°...']\n",
      "\n",
      "=== 5. æ¡ä»¶æ¨å¯¼å¼ - æ•°æ®è¿‡æ»¤å’Œè½¬æ¢ ===\n",
      "é«˜æ•ˆæ¨¡å‹ï¼ˆå‡†ç¡®ç‡>87%ä¸”æˆæœ¬<0.01ï¼‰:\n",
      "  claude-3: å‡†ç¡®ç‡=89.0%, æˆæœ¬=$0.0080\n",
      "\n",
      "å¿«é€Ÿæ¨¡å‹ (<3.0s): ['gpt-3.5-turbo', 'claude-3', 'gemini-pro']\n",
      "é«˜å‡†ç¡®ç‡æ¨¡å‹ (>90%): ['gpt-4']\n",
      "ä½æˆæœ¬æ¨¡å‹ (<$0.005): ['gpt-3.5-turbo', 'gemini-pro']\n",
      "\n",
      "æ¨¡å‹ç»¼åˆè¯„åˆ†æ’åº:\n",
      "  gpt-3.5-turbo: 133.901\n",
      "  gemini-pro: 100.555\n",
      "  claude-3: 25.552\n",
      "  gpt-4: 7.220\n",
      "\n",
      "=== 6. æ¨å¯¼å¼æ€§èƒ½å¯¹æ¯” ===\n",
      "ä¼ ç»Ÿå¾ªç¯è€—æ—¶: 0.000779ç§’\n",
      "åˆ—è¡¨æ¨å¯¼å¼è€—æ—¶: 0.000437ç§’\n",
      "æ€§èƒ½æå‡: 1.78å€\n",
      "ç»“æœä¸€è‡´æ€§: True\n",
      "\n",
      "æ¨å¯¼å¼åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„ä¼˜åŠ¿:\n",
      "1. ä»£ç æ›´ç®€æ´æ˜“è¯»\n",
      "2. æ€§èƒ½é€šå¸¸æ›´å¥½\n",
      "3. å‡å°‘ä¸­é—´å˜é‡\n",
      "4. æ˜“äºå¹¶è¡ŒåŒ–å¤„ç†\n",
      "5. ç¬¦åˆPythonçš„ä¼˜é›…é£æ ¼\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„æ¨å¯¼å¼åº”ç”¨ç¤ºä¾‹\n",
    "\n",
    "print(\"=== 1. åˆ—è¡¨æ¨å¯¼å¼ - æ•°æ®å¤„ç†å’Œè½¬æ¢ ===\")\n",
    "\n",
    "# æ¨¡æ‹ŸAPIå“åº”æ•°æ®\n",
    "api_responses = [\n",
    "    {\"model\": \"gpt-3.5-turbo\", \"tokens\": 150, \"cost\": 0.0003, \"success\": True},\n",
    "    {\"model\": \"gpt-4\", \"tokens\": 200, \"cost\": 0.006, \"success\": True},\n",
    "    {\"model\": \"claude-3\", \"tokens\": 180, \"cost\": 0.00144, \"success\": False},\n",
    "    {\"model\": \"gpt-3.5-turbo\", \"tokens\": 120, \"cost\": 0.00024, \"success\": True},\n",
    "    {\"model\": \"gpt-4\", \"tokens\": 300, \"cost\": 0.009, \"success\": True}\n",
    "]\n",
    "\n",
    "# æå–æ‰€æœ‰æˆåŠŸçš„å“åº”\n",
    "successful_responses = [resp for resp in api_responses if resp[\"success\"]]\n",
    "print(\"æˆåŠŸçš„APIè°ƒç”¨:\")\n",
    "for resp in successful_responses:\n",
    "    print(f\"  æ¨¡å‹: {resp['model']}, tokens: {resp['tokens']}, æˆæœ¬: ${resp['cost']:.4f}\")\n",
    "\n",
    "# è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„æ€»æˆæœ¬\n",
    "model_costs = {}\n",
    "for resp in api_responses:\n",
    "    model = resp[\"model\"]\n",
    "    if model not in model_costs:\n",
    "        model_costs[model] = 0\n",
    "    model_costs[model] += resp[\"cost\"]\n",
    "\n",
    "print(f\"\\nå„æ¨¡å‹æ€»æˆæœ¬: {model_costs}\")\n",
    "\n",
    "# æå–é«˜æˆæœ¬è°ƒç”¨ï¼ˆ> $0.005ï¼‰\n",
    "high_cost_calls = [resp for resp in api_responses if resp[\"cost\"] > 0.005]\n",
    "print(f\"\\né«˜æˆæœ¬è°ƒç”¨æ•°é‡: {len(high_cost_calls)}\")\n",
    "\n",
    "# æŒ‰æ¨¡å‹åˆ†ç»„ç»Ÿè®¡\n",
    "print(\"\\n=== 2. å­—å…¸æ¨å¯¼å¼ - æ•°æ®èšåˆå’Œç»Ÿè®¡ ===\")\n",
    "\n",
    "# æŒ‰æ¨¡å‹åˆ†ç»„ç»Ÿè®¡\n",
    "model_stats = {}\n",
    "for resp in api_responses:\n",
    "    model = resp[\"model\"]\n",
    "    if model not in model_stats:\n",
    "        model_stats[model] = {\"total_calls\": 0, \"successful_calls\": 0, \"total_tokens\": 0, \"total_cost\": 0}\n",
    "\n",
    "    model_stats[model][\"total_calls\"] += 1\n",
    "    if resp[\"success\"]:\n",
    "        model_stats[model][\"successful_calls\"] += 1\n",
    "    model_stats[model][\"total_tokens\"] += resp[\"tokens\"]\n",
    "    model_stats[model][\"total_cost\"] += resp[\"cost\"]\n",
    "\n",
    "print(\"æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "for model, stats in model_stats.items():\n",
    "    success_rate = stats[\"successful_calls\"] / stats[\"total_calls\"] * 100\n",
    "    avg_tokens = stats[\"total_tokens\"] / stats[\"total_calls\"]\n",
    "    print(f\"  {model}:\")\n",
    "    print(f\"    æ€»è°ƒç”¨: {stats['total_calls']}, æˆåŠŸç‡: {success_rate:.1f}%\")\n",
    "    print(f\"    æ€»tokens: {stats['total_tokens']}, å¹³å‡tokens: {avg_tokens:.0f}\")\n",
    "    print(f\"    æ€»æˆæœ¬: ${stats['total_cost']:.4f}\")\n",
    "\n",
    "# ä½¿ç”¨å­—å…¸æ¨å¯¼å¼åˆ›å»ºæ¨¡å‹æ€§èƒ½æŠ¥å‘Š\n",
    "performance_report = {\n",
    "    model: {\n",
    "        \"success_rate\": stats[\"successful_calls\"] / stats[\"total_calls\"],\n",
    "        \"avg_tokens\": stats[\"total_tokens\"] / stats[\"total_calls\"],\n",
    "        \"cost_per_token\": stats[\"total_cost\"] / stats[\"total_tokens\"] if stats[\"total_tokens\"] > 0 else 0\n",
    "    }\n",
    "    for model, stats in model_stats.items()\n",
    "}\n",
    "\n",
    "print(f\"\\næ€§èƒ½æŠ¥å‘Š: {performance_report}\")\n",
    "\n",
    "print(\"\\n=== 3. é›†åˆæ¨å¯¼å¼ - å»é‡å’Œç‰¹å¾æå– ===\")\n",
    "\n",
    "# ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯\n",
    "texts = [\n",
    "    \"Python is a great programming language for AI development\",\n",
    "    \"Machine learning with Python is very popular\",\n",
    "    \"AI and machine learning are transforming industries\",\n",
    "    \"Python programming is essential for data science\",\n",
    "    \"Artificial intelligence requires strong programming skills\"\n",
    "]\n",
    "\n",
    "# æå–æ‰€æœ‰å•è¯å¹¶è½¬æ¢ä¸ºå°å†™\n",
    "all_words = {word.lower().strip('.,!?') for text in texts for word in text.split()}\n",
    "print(f\"æ‰€æœ‰å”¯ä¸€å•è¯ ({len(all_words)} ä¸ª): {sorted(all_words)}\")\n",
    "\n",
    "# æå–AIç›¸å…³å…³é”®è¯\n",
    "ai_keywords = {word.lower() for text in texts for word in text.split()\n",
    "               if any(keyword in word.lower() for keyword in ['ai', 'python', 'machine', 'learning', 'programming'])}\n",
    "print(f\"\\nAIç›¸å…³å…³é”®è¯: {sorted(ai_keywords)}\")\n",
    "\n",
    "# æå–é•¿åº¦å¤§äº5çš„å•è¯\n",
    "long_words = {word for word in all_words if len(word) > 5}\n",
    "print(f\"\\né•¿åº¦å¤§äº5çš„å•è¯: {sorted(long_words)}\")\n",
    "\n",
    "print(\"\\n=== 4. åµŒå¥—æ¨å¯¼å¼ - å¤æ‚æ•°æ®å¤„ç† ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿå¤šè½®å¯¹è¯æ•°æ®\n",
    "conversations = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"ä½ å¥½\", \"tokens\": 5},\n",
    "            {\"role\": \"assistant\", \"content\": \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\", \"tokens\": 15},\n",
    "            {\"role\": \"user\", \"content\": \"è¯·ä»‹ç»ä¸€ä¸‹Python\", \"tokens\": 8},\n",
    "            {\"role\": \"assistant\", \"content\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...\", \"tokens\": 50}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"å†™ä¸€ä¸ªPythonå‡½æ•°\", \"tokens\": 10},\n",
    "            {\"role\": \"assistant\", \"content\": \"å¥½çš„ï¼Œæˆ‘æ¥ä¸ºä½ å†™ä¸€ä¸ªPythonå‡½æ•°...\", \"tokens\": 30}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# æå–æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯çš„tokens\n",
    "user_tokens = [msg[\"tokens\"] for conv in conversations for msg in conv[\"messages\"] if msg[\"role\"] == \"user\"]\n",
    "print(f\"æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯çš„tokens: {user_tokens}\")\n",
    "\n",
    "# è®¡ç®—æ¯ä¸ªå¯¹è¯çš„æ€»tokens\n",
    "conversation_totals = {\n",
    "    conv[\"id\"]: sum(msg[\"tokens\"] for msg in conv[\"messages\"])\n",
    "    for conv in conversations\n",
    "}\n",
    "print(f\"æ¯ä¸ªå¯¹è¯çš„æ€»tokens: {conversation_totals}\")\n",
    "\n",
    "# æå–åŒ…å«ç‰¹å®šå…³é”®è¯çš„æ¶ˆæ¯\n",
    "keyword_messages = [\n",
    "    msg[\"content\"] for conv in conversations\n",
    "    for msg in conv[\"messages\"]\n",
    "    if \"python\" in msg[\"content\"].lower()\n",
    "]\n",
    "print(f\"åŒ…å«'python'çš„æ¶ˆæ¯: {keyword_messages}\")\n",
    "\n",
    "print(\"\\n=== 5. æ¡ä»¶æ¨å¯¼å¼ - æ•°æ®è¿‡æ»¤å’Œè½¬æ¢ ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿæ¨¡å‹æ€§èƒ½æ•°æ®\n",
    "model_performance = [\n",
    "    {\"name\": \"gpt-3.5-turbo\", \"accuracy\": 0.85, \"speed\": 2.1, \"cost\": 0.0015},\n",
    "    {\"name\": \"gpt-4\", \"accuracy\": 0.92, \"speed\": 3.2, \"cost\": 0.03},\n",
    "    {\"name\": \"claude-3\", \"accuracy\": 0.89, \"speed\": 2.8, \"cost\": 0.008},\n",
    "    {\"name\": \"gemini-pro\", \"accuracy\": 0.87, \"speed\": 2.5, \"cost\": 0.002}\n",
    "]\n",
    "\n",
    "# æ‰¾å‡ºé«˜å‡†ç¡®ç‡ä¸”ä½æˆæœ¬æ¨¡å‹\n",
    "efficient_models = [\n",
    "    model for model in model_performance\n",
    "    if model[\"accuracy\"] > 0.87 and model[\"cost\"] < 0.01\n",
    "]\n",
    "print(\"é«˜æ•ˆæ¨¡å‹ï¼ˆå‡†ç¡®ç‡>87%ä¸”æˆæœ¬<0.01ï¼‰:\")\n",
    "for model in efficient_models:\n",
    "    print(f\"  {model['name']}: å‡†ç¡®ç‡={model['accuracy']:.1%}, æˆæœ¬=${model['cost']:.4f}\")\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹æ¨èåˆ—è¡¨ï¼ˆåŸºäºä¸åŒæ ‡å‡†ï¼‰\n",
    "fast_models = [model[\"name\"] for model in model_performance if model[\"speed\"] < 3.0]\n",
    "accurate_models = [model[\"name\"] for model in model_performance if model[\"accuracy\"] > 0.9]\n",
    "cheap_models = [model[\"name\"] for model in model_performance if model[\"cost\"] < 0.005]\n",
    "\n",
    "print(f\"\\nå¿«é€Ÿæ¨¡å‹ (<3.0s): {fast_models}\")\n",
    "print(f\"é«˜å‡†ç¡®ç‡æ¨¡å‹ (>90%): {accurate_models}\")\n",
    "print(f\"ä½æˆæœ¬æ¨¡å‹ (<$0.005): {cheap_models}\")\n",
    "\n",
    "# è®¡ç®—ç»¼åˆè¯„åˆ†\n",
    "scored_models = [\n",
    "    {\n",
    "        \"name\": model[\"name\"],\n",
    "        \"score\": (model[\"accuracy\"] * 0.5 + (1/model[\"speed\"]) * 0.3 + (1/model[\"cost\"]) * 0.2)\n",
    "    }\n",
    "    for model in model_performance\n",
    "]\n",
    "\n",
    "# æŒ‰è¯„åˆ†æ’åº\n",
    "scored_models.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "print(f\"\\næ¨¡å‹ç»¼åˆè¯„åˆ†æ’åº:\")\n",
    "for model in scored_models:\n",
    "    print(f\"  {model['name']}: {model['score']:.3f}\")\n",
    "\n",
    "print(\"\\n=== 6. æ¨å¯¼å¼æ€§èƒ½å¯¹æ¯” ===\")\n",
    "\n",
    "import time\n",
    "\n",
    "# å¤§é‡æ•°æ®æµ‹è¯•\n",
    "large_data = list(range(10000))\n",
    "\n",
    "# ä¼ ç»Ÿå¾ªç¯æ–¹å¼\n",
    "start_time = time.time()\n",
    "result1 = []\n",
    "for x in large_data:\n",
    "    if x % 2 == 0:\n",
    "        result1.append(x * 2)\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "# åˆ—è¡¨æ¨å¯¼å¼æ–¹å¼\n",
    "start_time = time.time()\n",
    "result2 = [x * 2 for x in large_data if x % 2 == 0]\n",
    "comprehension_time = time.time() - start_time\n",
    "\n",
    "print(f\"ä¼ ç»Ÿå¾ªç¯è€—æ—¶: {loop_time:.6f}ç§’\")\n",
    "print(f\"åˆ—è¡¨æ¨å¯¼å¼è€—æ—¶: {comprehension_time:.6f}ç§’\")\n",
    "print(f\"æ€§èƒ½æå‡: {loop_time/comprehension_time:.2f}å€\")\n",
    "print(f\"ç»“æœä¸€è‡´æ€§: {result1 == result2}\")\n",
    "\n",
    "print(f\"\\næ¨å¯¼å¼åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„ä¼˜åŠ¿:\")\n",
    "print(\"1. ä»£ç æ›´ç®€æ´æ˜“è¯»\")\n",
    "print(\"2. æ€§èƒ½é€šå¸¸æ›´å¥½\")\n",
    "print(\"3. å‡å°‘ä¸­é—´å˜é‡\")\n",
    "print(\"4. æ˜“äºå¹¶è¡ŒåŒ–å¤„ç†\")\n",
    "print(\"5. ç¬¦åˆPythonçš„ä¼˜é›…é£æ ¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "_h3BoNV7U28G",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "KQhKyOTvU28G"
   },
   "source": [
    "## ä»å‚æ•°æˆ–å…¶ä»–å¯¹è±¡åˆ›å»ºå¯¹è±¡\n",
    "\n",
    "> **é‡è¦æ¦‚å¿µ**ï¼šç±»å‹æ„é€ å‡½æ•°æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­æ•°æ®ç±»å‹è½¬æ¢çš„åŸºç¡€å·¥å…·ï¼Œç”¨äºå¤„ç†APIå“åº”ã€æ•°æ®æ¸…æ´—ã€æ ¼å¼è½¬æ¢ç­‰ã€‚\n",
    "\n",
    "åˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬ä½¿ç”¨çš„åŸºæœ¬ç±»å‹å’Œå®¹å™¨éƒ½æä¾›**ç±»å‹æ„é€ å‡½æ•°**ï¼š\n",
    "\n",
    "- `int()` - æ•´æ•°æ„é€ å‡½æ•°\n",
    "- `float()` - æµ®ç‚¹æ•°æ„é€ å‡½æ•°\n",
    "- `str()` - å­—ç¬¦ä¸²æ„é€ å‡½æ•°\n",
    "- `list()` - åˆ—è¡¨æ„é€ å‡½æ•°\n",
    "- `tuple()` - å…ƒç»„æ„é€ å‡½æ•°\n",
    "- `set()` - é›†åˆæ„é€ å‡½æ•°\n",
    "- `dict()` - å­—å…¸æ„é€ å‡½æ•°\n",
    "\n",
    "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨ä½¿ç”¨ä¸€äº›è¯­æ³•å¿«æ·æ–¹å¼æ¥å®šä¹‰è¿™äº›å†…ç½®ç±»å‹çš„å¯¹è±¡ï¼Œå› ä¸ºå®ƒä»¬éå¸¸å¸¸è§ã€‚\n",
    "\n",
    "æœ‰æ—¶ï¼Œä½ ä¼šæœ‰ä¸€ä¸ªç±»å‹çš„å¯¹è±¡éœ€è¦è½¬æ¢ä¸ºå¦ä¸€ç§ç±»å‹ã€‚ä½¿ç”¨ä½ æƒ³è¦çš„å¯¹è±¡ç±»å‹çš„**ç±»å‹æ„é€ å‡½æ•°**ï¼Œå¹¶ä¼ å…¥ä½ å½“å‰æ‹¥æœ‰çš„å¯¹è±¡ã€‚\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **APIå“åº”å¤„ç†**ï¼šå°†JSONå­—ç¬¦ä¸²è½¬æ¢ä¸ºPythonå¯¹è±¡\n",
    "- **æ•°æ®æ¸…æ´—**ï¼šè½¬æ¢æ•°æ®ç±»å‹ï¼Œç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®\n",
    "- **ç±»å‹è½¬æ¢**ï¼šåœ¨ä¸åŒæ•°æ®ç±»å‹ä¹‹é—´è¿›è¡Œå®‰å…¨è½¬æ¢\n",
    "- **é”™è¯¯å¤„ç†**ï¼šä½¿ç”¨æ„é€ å‡½æ•°è¿›è¡Œç±»å‹éªŒè¯\n",
    "- **æ•°æ®æ ‡å‡†åŒ–**ï¼šå°†ä¸åŒæ ¼å¼çš„æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Z4frKcZU28D",
    "outputId": "47972d35-f0cd-4616-f15d-248583536c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. åŸºæœ¬ç±»å‹è½¬æ¢ ===\n",
      "ç”¨æˆ·ID: 123 (ç±»å‹: <class 'int'>)\n",
      "Tokenå­—ç¬¦ä¸²: '1500' (ç±»å‹: <class 'str'>)\n",
      "ç½®ä¿¡åº¦: 0.85 (ç±»å‹: <class 'float'>)\n",
      "\n",
      "=== 2. å®¹å™¨ç±»å‹è½¬æ¢ ===\n",
      "ä¸»é¢˜åˆ—è¡¨: ['Python', 'AI', 'Machine Learning', 'Deep Learning']\n",
      "å»é‡åçš„æ ‡ç­¾: {'ai', 'machine learning', 'python'}\n",
      "é…ç½®å…ƒç»„: ('gpt-3.5-turbo', 0.7, 1000, True)\n",
      "é…ç½®é”®: ['model', 'temperature', 'max_tokens']\n",
      "\n",
      "=== 3. APIå“åº”æ•°æ®å¤„ç† ===\n",
      "è§£æåçš„å“åº”: {'choices': [{'message': {'content': 'Hello! How can I help you?'}}], 'usage': {'total_tokens': 25}}\n",
      "å†…å®¹: Hello! How can I help you?\n",
      "Tokenä½¿ç”¨é‡: 25\n",
      "\n",
      "=== 4. æ•°æ®éªŒè¯å’Œç±»å‹è½¬æ¢ ===\n",
      "å®‰å…¨ç±»å‹è½¬æ¢æµ‹è¯•:\n",
      "  123 -> int: 123\n",
      "  45.67 -> float: 45.67\n",
      "  hello -> str: hello\n",
      "  True -> bool: True\n",
      "  false -> bool: True\n",
      "è½¬æ¢å¤±è´¥:  -> int, é”™è¯¯: invalid literal for int() with base 10: ''\n",
      "   -> int: è½¬æ¢å¤±è´¥\n",
      "\n",
      "=== 5. æ‰¹é‡æ•°æ®å¤„ç† ===\n",
      "è§£æåçš„ç”¨æˆ·æ•°æ®:\n",
      "  ç”¨æˆ·: user_001, tokens: 150, ç½®ä¿¡åº¦: 0.85\n",
      "  ç”¨æˆ·: user_002, tokens: 200, ç½®ä¿¡åº¦: 0.92\n",
      "  ç”¨æˆ·: user_003, tokens: 175, ç½®ä¿¡åº¦: 0.78\n",
      "  ç”¨æˆ·: user_004, tokens: 300, ç½®ä¿¡åº¦: 0.95\n",
      "  ç”¨æˆ·: user_005, tokens: 125, ç½®ä¿¡åº¦: 0.88\n",
      "\n",
      "Tokenåˆ—è¡¨: [150, 200, 175, 300, 125]\n",
      "ç½®ä¿¡åº¦åˆ—è¡¨: [0.85, 0.92, 0.78, 0.95, 0.88]\n",
      "\n",
      "=== 6. é…ç½®ç®¡ç†ä¸­çš„ç±»å‹è½¬æ¢ ===\n",
      "è½¬æ¢åçš„é…ç½®:\n",
      "  model_name: gpt-3.5-turbo (ç±»å‹: str)\n",
      "  max_tokens: 1000 (ç±»å‹: int)\n",
      "  temperature: 0.7 (ç±»å‹: float)\n",
      "  enable_streaming: True (ç±»å‹: bool)\n",
      "  timeout: 30 (ç±»å‹: int)\n",
      "  retry_count: 3 (ç±»å‹: int)\n",
      "\n",
      "=== 7. é”™è¯¯å¤„ç†å’Œç±»å‹éªŒè¯ ===\n",
      "å‚æ•°è½¬æ¢ç»“æœ:\n",
      "âœ… æ‰€æœ‰å‚æ•°è½¬æ¢æˆåŠŸ\n",
      "  model: gpt-3.5-turbo (ç±»å‹: str)\n",
      "  max_tokens: 1000 (ç±»å‹: int)\n",
      "  temperature: 0.7 (ç±»å‹: float)\n",
      "  top_p: 0.9 (ç±»å‹: float)\n",
      "  stream: True (ç±»å‹: bool)\n",
      "\n",
      "=== 8. æ€§èƒ½ä¼˜åŒ– - æ‰¹é‡è½¬æ¢ ===\n",
      "é€ä¸ªè½¬æ¢è€—æ—¶: 0.006932ç§’\n",
      "åˆ—è¡¨æ¨å¯¼å¼è€—æ—¶: 0.003455ç§’\n",
      "æ€§èƒ½æå‡: 2.01å€\n",
      "ç»“æœä¸€è‡´æ€§: True\n",
      "\n",
      "ç±»å‹æ„é€ å‡½æ•°åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„é‡è¦æ€§:\n",
      "1. æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–\n",
      "2. APIå‚æ•°éªŒè¯å’Œè½¬æ¢\n",
      "3. é…ç½®æ–‡ä»¶è§£æ\n",
      "4. é”™è¯¯å¤„ç†å’Œå®¹é”™\n",
      "5. æ€§èƒ½ä¼˜åŒ–å’Œæ‰¹é‡å¤„ç†\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„ç±»å‹æ„é€ å‡½æ•°åº”ç”¨ç¤ºä¾‹\n",
    "\n",
    "print(\"=== 1. åŸºæœ¬ç±»å‹è½¬æ¢ ===\")\n",
    "\n",
    "# å­—ç¬¦ä¸²è½¬æ•°å­—\n",
    "user_input = \"123\"\n",
    "user_id = int(user_input)\n",
    "print(f\"ç”¨æˆ·ID: {user_id} (ç±»å‹: {type(user_id)})\")\n",
    "\n",
    "# æ•°å­—è½¬å­—ç¬¦ä¸²\n",
    "token_count = 1500\n",
    "token_str = str(token_count)\n",
    "print(f\"Tokenå­—ç¬¦ä¸²: '{token_str}' (ç±»å‹: {type(token_str)})\")\n",
    "\n",
    "# å­—ç¬¦ä¸²è½¬æµ®ç‚¹æ•°\n",
    "confidence_score = \"0.85\"\n",
    "confidence = float(confidence_score)\n",
    "print(f\"ç½®ä¿¡åº¦: {confidence} (ç±»å‹: {type(confidence)})\")\n",
    "\n",
    "print(\"\\n=== 2. å®¹å™¨ç±»å‹è½¬æ¢ ===\")\n",
    "\n",
    "# å­—ç¬¦ä¸²è½¬åˆ—è¡¨\n",
    "text = \"Python,AI,Machine Learning,Deep Learning\"\n",
    "topics = text.split(\",\")\n",
    "print(f\"ä¸»é¢˜åˆ—è¡¨: {topics}\")\n",
    "\n",
    "# åˆ—è¡¨è½¬é›†åˆï¼ˆå»é‡ï¼‰\n",
    "duplicate_tags = [\"python\", \"ai\", \"python\", \"machine learning\", \"ai\", \"python\"]\n",
    "unique_tags = set(duplicate_tags)\n",
    "print(f\"å»é‡åçš„æ ‡ç­¾: {unique_tags}\")\n",
    "\n",
    "# åˆ—è¡¨è½¬å…ƒç»„ï¼ˆä¸å¯å˜ï¼‰\n",
    "config_list = [\"gpt-3.5-turbo\", 0.7, 1000, True]\n",
    "config_tuple = tuple(config_list)\n",
    "print(f\"é…ç½®å…ƒç»„: {config_tuple}\")\n",
    "\n",
    "# å­—å…¸è½¬åˆ—è¡¨ï¼ˆé”®ï¼‰\n",
    "api_config = {\"model\": \"gpt-4\", \"temperature\": 0.7, \"max_tokens\": 2000}\n",
    "config_keys = list(api_config.keys())\n",
    "print(f\"é…ç½®é”®: {config_keys}\")\n",
    "\n",
    "print(\"\\n=== 3. APIå“åº”æ•°æ®å¤„ç† ===\")\n",
    "\n",
    "# æ¨¡æ‹ŸAPIå“åº”ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰\n",
    "json_response = '{\"choices\": [{\"message\": {\"content\": \"Hello! How can I help you?\"}}], \"usage\": {\"total_tokens\": 25}}'\n",
    "\n",
    "# å­—ç¬¦ä¸²è½¬å­—å…¸ï¼ˆå®é™…å¼€å‘ä¸­ä¼šä½¿ç”¨json.loads()ï¼‰\n",
    "# è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨è§£ææ¥æ¼”ç¤ºç±»å‹è½¬æ¢\n",
    "import json\n",
    "response_data = json.loads(json_response)\n",
    "print(f\"è§£æåçš„å“åº”: {response_data}\")\n",
    "\n",
    "# æå–ç‰¹å®šæ•°æ®å¹¶è½¬æ¢ç±»å‹\n",
    "content = str(response_data[\"choices\"][0][\"message\"][\"content\"])\n",
    "token_usage = int(response_data[\"usage\"][\"total_tokens\"])\n",
    "print(f\"å†…å®¹: {content}\")\n",
    "print(f\"Tokenä½¿ç”¨é‡: {token_usage}\")\n",
    "\n",
    "print(\"\\n=== 4. æ•°æ®éªŒè¯å’Œç±»å‹è½¬æ¢ ===\")\n",
    "\n",
    "def safe_convert(value, target_type, default=None):\n",
    "    \"\"\"å®‰å…¨åœ°è½¬æ¢æ•°æ®ç±»å‹\"\"\"\n",
    "    try:\n",
    "        return target_type(value)\n",
    "    except (ValueError, TypeError) as e:\n",
    "        print(f\"è½¬æ¢å¤±è´¥: {value} -> {target_type.__name__}, é”™è¯¯: {e}\")\n",
    "        return default\n",
    "\n",
    "# æµ‹è¯•å„ç§è½¬æ¢\n",
    "test_values = [\"123\", \"45.67\", \"hello\", \"True\", \"false\", \"\"]\n",
    "target_types = [int, float, str, bool, bool, int]\n",
    "\n",
    "print(\"å®‰å…¨ç±»å‹è½¬æ¢æµ‹è¯•:\")\n",
    "for value, target_type in zip(test_values, target_types):\n",
    "    result = safe_convert(value, target_type, \"è½¬æ¢å¤±è´¥\")\n",
    "    print(f\"  {value} -> {target_type.__name__}: {result}\")\n",
    "\n",
    "print(\"\\n=== 5. æ‰¹é‡æ•°æ®å¤„ç† ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿä»APIè·å–çš„åŸå§‹æ•°æ®\n",
    "raw_data = [\n",
    "    \"user_001,150,0.85\",\n",
    "    \"user_002,200,0.92\",\n",
    "    \"user_003,175,0.78\",\n",
    "    \"user_004,300,0.95\",\n",
    "    \"user_005,125,0.88\"\n",
    "]\n",
    "\n",
    "# è§£æCSVæ ¼å¼æ•°æ®\n",
    "parsed_data = []\n",
    "for line in raw_data:\n",
    "    parts = line.split(\",\")\n",
    "    user_data = {\n",
    "        \"user_id\": str(parts[0]),\n",
    "        \"tokens\": int(parts[1]),\n",
    "        \"confidence\": float(parts[2])\n",
    "    }\n",
    "    parsed_data.append(user_data)\n",
    "\n",
    "print(\"è§£æåçš„ç”¨æˆ·æ•°æ®:\")\n",
    "for data in parsed_data:\n",
    "    print(f\"  ç”¨æˆ·: {data['user_id']}, tokens: {data['tokens']}, ç½®ä¿¡åº¦: {data['confidence']:.2f}\")\n",
    "\n",
    "# æå–ç‰¹å®šå­—æ®µ\n",
    "token_list = [data[\"tokens\"] for data in parsed_data]\n",
    "confidence_list = [data[\"confidence\"] for data in parsed_data]\n",
    "\n",
    "print(f\"\\nTokenåˆ—è¡¨: {token_list}\")\n",
    "print(f\"ç½®ä¿¡åº¦åˆ—è¡¨: {confidence_list}\")\n",
    "\n",
    "print(\"\\n=== 6. é…ç½®ç®¡ç†ä¸­çš„ç±»å‹è½¬æ¢ ===\")\n",
    "\n",
    "# ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è¯»å–çš„å­—ç¬¦ä¸²é…ç½®\n",
    "env_config = {\n",
    "    \"MODEL_NAME\": \"gpt-3.5-turbo\",\n",
    "    \"MAX_TOKENS\": \"1000\",\n",
    "    \"TEMPERATURE\": \"0.7\",\n",
    "    \"ENABLE_STREAMING\": \"true\",\n",
    "    \"TIMEOUT\": \"30\",\n",
    "    \"RETRY_COUNT\": \"3\"\n",
    "}\n",
    "\n",
    "# è½¬æ¢ä¸ºé€‚å½“çš„æ•°æ®ç±»å‹\n",
    "config = {\n",
    "    \"model_name\": str(env_config[\"MODEL_NAME\"]),\n",
    "    \"max_tokens\": int(env_config[\"MAX_TOKENS\"]),\n",
    "    \"temperature\": float(env_config[\"TEMPERATURE\"]),\n",
    "    \"enable_streaming\": env_config[\"ENABLE_STREAMING\"].lower() == \"true\",\n",
    "    \"timeout\": int(env_config[\"TIMEOUT\"]),\n",
    "    \"retry_count\": int(env_config[\"RETRY_COUNT\"])\n",
    "}\n",
    "\n",
    "print(\"è½¬æ¢åçš„é…ç½®:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value} (ç±»å‹: {type(value).__name__})\")\n",
    "\n",
    "print(\"\\n=== 7. é”™è¯¯å¤„ç†å’Œç±»å‹éªŒè¯ ===\")\n",
    "\n",
    "def validate_and_convert_api_params(params):\n",
    "    \"\"\"éªŒè¯å¹¶è½¬æ¢APIå‚æ•°\"\"\"\n",
    "    converted_params = {}\n",
    "    errors = []\n",
    "\n",
    "    # å®šä¹‰æœŸæœ›çš„ç±»å‹\n",
    "    expected_types = {\n",
    "        \"model\": str,\n",
    "        \"max_tokens\": int,\n",
    "        \"temperature\": float,\n",
    "        \"top_p\": float,\n",
    "        \"stream\": bool\n",
    "    }\n",
    "\n",
    "    for key, expected_type in expected_types.items():\n",
    "        if key in params:\n",
    "            try:\n",
    "                if expected_type == bool:\n",
    "                    # å¸ƒå°”å€¼çš„ç‰¹æ®Šå¤„ç†\n",
    "                    value = str(params[key]).lower()\n",
    "                    converted_params[key] = value in [\"true\", \"1\", \"yes\", \"on\"]\n",
    "                else:\n",
    "                    converted_params[key] = expected_type(params[key])\n",
    "            except (ValueError, TypeError) as e:\n",
    "                errors.append(f\"å‚æ•° '{key}' è½¬æ¢å¤±è´¥: {e}\")\n",
    "        else:\n",
    "            errors.append(f\"ç¼ºå°‘å¿…éœ€å‚æ•°: {key}\")\n",
    "\n",
    "    return converted_params, errors\n",
    "\n",
    "# æµ‹è¯•å‚æ•°è½¬æ¢\n",
    "test_params = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"max_tokens\": \"1000\",  # å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ä¸ºint\n",
    "    \"temperature\": \"0.7\",  # å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ä¸ºfloat\n",
    "    \"top_p\": 0.9,          # å·²ç»æ˜¯float\n",
    "    \"stream\": \"true\"       # å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ä¸ºbool\n",
    "}\n",
    "\n",
    "converted_params, errors = validate_and_convert_api_params(test_params)\n",
    "\n",
    "print(\"å‚æ•°è½¬æ¢ç»“æœ:\")\n",
    "if errors:\n",
    "    print(\"é”™è¯¯:\")\n",
    "    for error in errors:\n",
    "        print(f\"  âŒ {error}\")\n",
    "else:\n",
    "    print(\"âœ… æ‰€æœ‰å‚æ•°è½¬æ¢æˆåŠŸ\")\n",
    "    for key, value in converted_params.items():\n",
    "        print(f\"  {key}: {value} (ç±»å‹: {type(value).__name__})\")\n",
    "\n",
    "print(\"\\n=== 8. æ€§èƒ½ä¼˜åŒ– - æ‰¹é‡è½¬æ¢ ===\")\n",
    "\n",
    "import time\n",
    "\n",
    "# å¤§é‡æ•°æ®è½¬æ¢æ€§èƒ½æµ‹è¯•\n",
    "large_string_list = [str(i) for i in range(10000)]\n",
    "\n",
    "# æ–¹æ³•1: é€ä¸ªè½¬æ¢\n",
    "start_time = time.time()\n",
    "int_list1 = []\n",
    "for s in large_string_list:\n",
    "    int_list1.append(int(s))\n",
    "method1_time = time.time() - start_time\n",
    "\n",
    "# æ–¹æ³•2: åˆ—è¡¨æ¨å¯¼å¼\n",
    "start_time = time.time()\n",
    "int_list2 = [int(s) for s in large_string_list]\n",
    "method2_time = time.time() - start_time\n",
    "\n",
    "print(f\"é€ä¸ªè½¬æ¢è€—æ—¶: {method1_time:.6f}ç§’\")\n",
    "print(f\"åˆ—è¡¨æ¨å¯¼å¼è€—æ—¶: {method2_time:.6f}ç§’\")\n",
    "print(f\"æ€§èƒ½æå‡: {method1_time/method2_time:.2f}å€\")\n",
    "print(f\"ç»“æœä¸€è‡´æ€§: {int_list1 == int_list2}\")\n",
    "\n",
    "print(f\"\\nç±»å‹æ„é€ å‡½æ•°åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„é‡è¦æ€§:\")\n",
    "print(\"1. æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–\")\n",
    "print(\"2. APIå‚æ•°éªŒè¯å’Œè½¬æ¢\")\n",
    "print(\"3. é…ç½®æ–‡ä»¶è§£æ\")\n",
    "print(\"4. é”™è¯¯å¤„ç†å’Œå®¹é”™\")\n",
    "print(\"5. æ€§èƒ½ä¼˜åŒ–å’Œæ‰¹é‡å¤„ç†\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "EDXEG8gfU28I"
   },
   "source": [
    "## å¯¼å…¥æ¨¡å—\n",
    "\n",
    "> **æ ¸å¿ƒæŠ€èƒ½**ï¼šæ¨¡å—å¯¼å…¥æ˜¯å¤§æ¨¡å‹å¼€å‘çš„åŸºç¡€ï¼Œç”¨äºä½¿ç”¨å„ç§åº“å’Œæ¡†æ¶ï¼Œå¦‚OpenAIã€LangChainã€Pandasç­‰ã€‚\n",
    "\n",
    "Pythonçš„æ¨¡å—ç³»ç»Ÿå…è®¸ä½ ç»„ç»‡å’Œé‡ç”¨ä»£ç ã€‚åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œä½ éœ€è¦å¯¼å…¥å„ç§åº“æ¥å¤„ç†ä¸åŒçš„ä»»åŠ¡ã€‚\n",
    "\n",
    "### åŸºæœ¬å¯¼å…¥æ–¹å¼\n",
    "- `import module_name` - å¯¼å…¥æ•´ä¸ªæ¨¡å—\n",
    "- `from module_name import function_name` - å¯¼å…¥ç‰¹å®šå‡½æ•°\n",
    "- `from module_name import *` - å¯¼å…¥æ¨¡å—ä¸­çš„æ‰€æœ‰å†…å®¹ï¼ˆä¸æ¨èï¼‰\n",
    "- `import module_name as alias` - ä½¿ç”¨åˆ«åå¯¼å…¥æ¨¡å—\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­å¸¸ç”¨çš„æ¨¡å—\n",
    "- **`openai`** - OpenAI APIå®¢æˆ·ç«¯\n",
    "- **`requests`** - HTTPè¯·æ±‚åº“\n",
    "- **`json`** - JSONæ•°æ®å¤„ç†\n",
    "- **`pandas`** - æ•°æ®åˆ†æ\n",
    "- **`numpy`** - æ•°å€¼è®¡ç®—\n",
    "- **`langchain`** - å¤§æ¨¡å‹åº”ç”¨æ¡†æ¶\n",
    "- **`transformers`** - Hugging Faceæ¨¡å‹åº“\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "- æŒ‰æ ‡å‡†åº“ã€ç¬¬ä¸‰æ–¹åº“ã€æœ¬åœ°æ¨¡å—çš„é¡ºåºå¯¼å…¥\n",
    "- ä½¿ç”¨å…·ä½“çš„å¯¼å…¥è€Œä¸æ˜¯é€šé…ç¬¦å¯¼å…¥\n",
    "- ä¸ºé•¿æ¨¡å—åä½¿ç”¨æœ‰æ„ä¹‰çš„åˆ«å\n",
    "- åœ¨æ–‡ä»¶é¡¶éƒ¨é›†ä¸­å¯¼å…¥æ‰€æœ‰æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "664efe3d",
    "outputId": "9130ff10-6e3b-4508-f468-9b29cd10e76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai æ¨¡å—å·²æˆåŠŸå¯¼å…¥\n",
      "LangChain æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·å°è¯• !pip install langchain\n",
      "transformers æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·å°è¯• !pip install transformers\n",
      "\n",
      "ä½¿ç”¨å¯¼å…¥çš„æ¨¡å—:\n",
      "è§£æçš„é…ç½®: {'model': 'gpt-3.5-turbo', 'temperature': 0.7}\n",
      "requestsæ¨¡å—ç±»å‹: <class 'module'>\n",
      "\n",
      "Pandas DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     3\n",
       "1     2     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\å½“å‰æ—¶é—´: 2025-10-09 10:14:17.599016\n",
      "\n",
      "æ¨¡å—å¯¼å…¥ç¤ºä¾‹ç»“æŸ\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¸¸ç”¨æ¨¡å—çš„ç¤ºä¾‹\n",
    "\n",
    "# å¯¼å…¥æ•´ä¸ªæ¨¡å—å¹¶ä½¿ç”¨åˆ«å (æ¨èæ–¹å¼)\n",
    "import json as js  # ç”¨äºå¤„ç†JSONæ•°æ®ï¼ŒAPIå“åº”å¸¸ç”¨\n",
    "import requests as req # ç”¨äºå‘é€HTTPè¯·æ±‚ï¼Œè°ƒç”¨API\n",
    "import pandas as pd # ç”¨äºæ•°æ®åˆ†æå’Œå¤„ç†\n",
    "\n",
    "# ä»æ¨¡å—ä¸­å¯¼å…¥ç‰¹å®šå‡½æ•°æˆ–ç±»\n",
    "from datetime import datetime, timedelta # ç”¨äºå¤„ç†æ—¥æœŸå’Œæ—¶é—´\n",
    "\n",
    "# å¯¼å…¥ç‰¹å®šçš„å¤§æ¨¡å‹ç›¸å…³åº“ï¼ˆå¯èƒ½éœ€è¦å®‰è£…ï¼‰\n",
    "# è¯·æ³¨æ„ï¼šè¿™äº›åº“å¯èƒ½éœ€è¦é€šè¿‡ !pip install å‘½ä»¤è¿›è¡Œå®‰è£…\n",
    "try:\n",
    "    import openai # OpenAI APIå®¢æˆ·ç«¯\n",
    "    print(\"openai æ¨¡å—å·²æˆåŠŸå¯¼å…¥\")\n",
    "except ImportError:\n",
    "    print(\"openai æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·å°è¯• !pip install openai\")\n",
    "\n",
    "try:\n",
    "    from langchain.prompts import PromptTemplate # LangChainæç¤ºè¯æ¨¡æ¿\n",
    "    print(\"LangChain.prompts æ¨¡å—å·²æˆåŠŸå¯¼å…¥\")\n",
    "except ImportError:\n",
    "    print(\"LangChain æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·å°è¯• !pip install langchain\")\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline # Hugging Face Transformersæ¨¡å‹ pipeline\n",
    "    print(\"transformers æ¨¡å—å·²æˆåŠŸå¯¼å…¥\")\n",
    "except ImportError:\n",
    "    print(\"transformers æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·å°è¯• !pip install transformers\")\n",
    "\n",
    "# å¯¼å…¥NumPyç”¨äºæ•°å€¼è®¡ç®—\n",
    "import numpy as np # ç”¨äºæ•°å€¼è®¡ç®—ï¼Œå¤„ç†å¼ é‡ç­‰\n",
    "\n",
    "# ä½¿ç”¨å¯¼å…¥çš„æ¨¡å—å’Œå¯¹è±¡\n",
    "print(\"\\nä½¿ç”¨å¯¼å…¥çš„æ¨¡å—:\")\n",
    "\n",
    "# ä½¿ç”¨jsonæ¨¡å—\n",
    "json_string = '{\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.7}'\n",
    "config = js.loads(json_string)\n",
    "print(\"è§£æçš„é…ç½®:\", config)\n",
    "\n",
    "# ä½¿ç”¨requestsæ¨¡å— (è¿™é‡Œåªæ‰“å°ç±»å‹ï¼Œä¸å®é™…å‘é€è¯·æ±‚)\n",
    "# response = req.get(\"https://api.example.com\")\n",
    "print(\"requestsæ¨¡å—ç±»å‹:\", type(req))\n",
    "\n",
    "# ä½¿ç”¨pandasæ¨¡å—\n",
    "data = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\nPandas DataFrame:\")\n",
    "display(df)\n",
    "\n",
    "# ä½¿ç”¨datetimeå¯¹è±¡\n",
    "now = datetime.now()\n",
    "print(\"\\å½“å‰æ—¶é—´:\", now)\n",
    "\n",
    "# ä½¿ç”¨PromptTemplate (å¦‚æœlangchainå¯¼å…¥æˆåŠŸ)\n",
    "if 'PromptTemplate' in locals():\n",
    "    template = \"è¯·ä»¥{style}çš„é£æ ¼ä»‹ç»{topic}\"\n",
    "    prompt_template = PromptTemplate(template=template, input_variables=[\"style\", \"topic\"])\n",
    "    formatted_prompt = prompt_template.format(style=\"å¹½é»˜\", topic=\"äººå·¥æ™ºèƒ½\")\n",
    "    print(\"\\næ ¼å¼åŒ–æç¤ºè¯:\", formatted_prompt)\n",
    "\n",
    "# ä½¿ç”¨pipeline (å¦‚æœtransformerså¯¼å…¥æˆåŠŸ)\n",
    "if 'pipeline' in locals():\n",
    "    # æ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½ä¼šæ¶ˆè€—æ—¶é—´å’Œèµ„æº\n",
    "    # text_generator = pipeline(\"text-generation\")\n",
    "    # generated_text = text_generator(\"Hello, I am\", max_length=10)\n",
    "    print(\"\\ntransformers.pipeline å·²å¯¼å…¥ï¼Œå¯ä»¥ä½¿ç”¨äº†ã€‚\")\n",
    "\n",
    "\n",
    "# å¯¼å…¥æœ¬åœ°è‡ªå®šä¹‰æ¨¡å—çš„ç¤ºä¾‹ï¼ˆå‡è®¾æœ‰ä¸€ä¸ªåä¸º my_utils.py çš„æ–‡ä»¶ï¼‰\n",
    "# try:\n",
    "#     from my_utils import process_text\n",
    "#     print(\"\\næœ¬åœ°æ¨¡å— my_utils å·²æˆåŠŸå¯¼å…¥\")\n",
    "# except ImportError:\n",
    "#     print(\"\\næœ¬åœ°æ¨¡å— my_utils æœªæ‰¾åˆ°\")\n",
    "\n",
    "print(\"\\næ¨¡å—å¯¼å…¥ç¤ºä¾‹ç»“æŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "NDBZz5s7U28M",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "XI8_VBhHU28M"
   },
   "source": [
    "## å¼‚å¸¸å¤„ç†\n",
    "\n",
    "> **æ ¸å¿ƒæŠ€èƒ½**ï¼šå¼‚å¸¸å¤„ç†æ˜¯å¤§æ¨¡å‹å¼€å‘ä¸­å¿…ä¸å¯å°‘çš„æŠ€èƒ½ï¼Œç”¨äºå¤„ç†APIè°ƒç”¨å¤±è´¥ã€ç½‘ç»œé”™è¯¯ã€æ•°æ®éªŒè¯ç­‰å„ç§å¼‚å¸¸æƒ…å†µã€‚\n",
    "\n",
    "å¼‚å¸¸æ˜¯Pythonä¸­å¤„ç†é”™è¯¯å’Œå¼‚å¸¸æƒ…å†µçš„æœºåˆ¶ã€‚åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œæ­£ç¡®å¤„ç†å¼‚å¸¸å¯¹äºæ„å»ºç¨³å®šçš„åº”ç”¨è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "### åŸºæœ¬å¼‚å¸¸å¤„ç†è¯­æ³•\n",
    "```python\n",
    "try:\n",
    "    # å¯èƒ½å‡ºé”™çš„ä»£ç \n",
    "    pass\n",
    "except ExceptionType as e:\n",
    "    # å¤„ç†ç‰¹å®šå¼‚å¸¸\n",
    "    pass\n",
    "except Exception as e:\n",
    "    # å¤„ç†æ‰€æœ‰å…¶ä»–å¼‚å¸¸\n",
    "    pass\n",
    "else:\n",
    "    # æ²¡æœ‰å¼‚å¸¸æ—¶æ‰§è¡Œ\n",
    "    pass\n",
    "finally:\n",
    "    # æ— è®ºæ˜¯å¦æœ‰å¼‚å¸¸éƒ½æ‰§è¡Œ\n",
    "    pass\n",
    "```\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­å¸¸è§çš„å¼‚å¸¸ç±»å‹\n",
    "- **`ConnectionError`** - ç½‘ç»œè¿æ¥é”™è¯¯\n",
    "- **`TimeoutError`** - è¯·æ±‚è¶…æ—¶\n",
    "- **`ValueError`** - å€¼é”™è¯¯ï¼ˆå¦‚æ— æ•ˆå‚æ•°ï¼‰\n",
    "- **`KeyError`** - å­—å…¸é”®ä¸å­˜åœ¨\n",
    "- **`JSONDecodeError`** - JSONè§£æé”™è¯¯\n",
    "- **`APIError`** - APIè°ƒç”¨é”™è¯¯\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "- æ•è·å…·ä½“çš„å¼‚å¸¸ç±»å‹è€Œä¸æ˜¯é€šç”¨çš„Exception\n",
    "- æä¾›æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯\n",
    "- å®ç°é‡è¯•æœºåˆ¶\n",
    "- è®°å½•é”™è¯¯æ—¥å¿—\n",
    "- ä¼˜é›…åœ°å¤„ç†å¤±è´¥æƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjZI-YHcU28J",
    "outputId": "922983e1-745a-45f2-bd61-1e8262e845c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. åŸºæœ¬å¼‚å¸¸å¤„ç† - APIè°ƒç”¨ ===\n",
      "\n",
      "æµ‹è¯•æç¤ºè¯: 'ä½ å¥½'\n",
      "ğŸ”‘ å‚æ•°é”™è¯¯: æ— æ•ˆçš„APIå¯†é’¥\n",
      "\n",
      "æµ‹è¯•æç¤ºè¯: 'è¯·ä»‹ç»ä¸€ä¸‹Python'\n",
      "â° è¶…æ—¶é”™è¯¯: è¯·æ±‚è¶…æ—¶\n",
      "\n",
      "æµ‹è¯•æç¤ºè¯: 'å†™ä¸€é¦–è¯—'\n",
      "ğŸ”¥ å…¶ä»–é”™è¯¯: æœåŠ¡å™¨å†…éƒ¨é”™è¯¯\n",
      "\n",
      "=== 2. é«˜çº§å¼‚å¸¸å¤„ç† - é‡è¯•æœºåˆ¶ ===\n",
      "æµ‹è¯•é‡è¯•æœºåˆ¶:\n",
      "\n",
      "--- æµ‹è¯• 1 ---\n",
      "ğŸ”‘ å‚æ•°é”™è¯¯ï¼Œæ— æ³•é‡è¯•: æ— æ•ˆçš„è¾“å…¥å‚æ•°\n",
      "\n",
      "--- æµ‹è¯• 2 ---\n",
      "ğŸ”„ ç½‘ç»œé”™è¯¯ï¼Œ1ç§’åé‡è¯• (å°è¯• 2/3)\n",
      "ğŸ”„ æœåŠ¡å™¨é”™è¯¯ï¼Œ2ç§’åé‡è¯• (å°è¯• 3/3)\n",
      "ğŸ’¥ æœåŠ¡å™¨é”™è¯¯ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: æœåŠ¡å™¨å†…éƒ¨é”™è¯¯\n",
      "\n",
      "--- æµ‹è¯• 3 ---\n",
      "ğŸ”„ ç½‘ç»œé”™è¯¯ï¼Œ1ç§’åé‡è¯• (å°è¯• 2/3)\n",
      "ğŸ”„ æœåŠ¡å™¨é”™è¯¯ï¼Œ2ç§’åé‡è¯• (å°è¯• 3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 10:14:23,647 - ERROR - APIè°ƒç”¨å¤±è´¥ - æç¤ºè¯: 'ä½ å¥½...', é”™è¯¯: æ— æ•ˆçš„APIå¯†é’¥\n",
      "2025-10-09 10:14:23,649 - ERROR - APIè°ƒç”¨å¤±è´¥ - æç¤ºè¯: 'è¯·ä»‹ç»ä¸€ä¸‹Python...', é”™è¯¯: APIè°ƒç”¨é¢‘ç‡è¿‡é«˜\n",
      "2025-10-09 10:14:23,649 - ERROR - APIè°ƒç”¨å¤±è´¥ - æç¤ºè¯: 'å†™ä¸€é¦–è¯—...', é”™è¯¯: ç½‘ç»œè¿æ¥å¤±è´¥\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¥ ç½‘ç»œé”™è¯¯ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "\n",
      "=== 3. å¼‚å¸¸å¤„ç† - æ•°æ®éªŒè¯ ===\n",
      "APIè¯·æ±‚éªŒè¯æµ‹è¯•:\n",
      "\n",
      "æµ‹è¯• 1: {'prompt': 'ä½ å¥½', 'max_tokens': 100, 'temperature': 0.7}\n",
      "âœ… éªŒè¯é€šè¿‡\n",
      "\n",
      "æµ‹è¯• 2: {'prompt': '', 'max_tokens': 100}\n",
      "âŒ éªŒè¯å¤±è´¥:\n",
      "   - promptä¸èƒ½ä¸ºç©º\n",
      "\n",
      "æµ‹è¯• 3: {'prompt': 'ä½ å¥½', 'max_tokens': 'invalid'}\n",
      "âŒ éªŒè¯å¤±è´¥:\n",
      "   - max_tokenså¿…é¡»æ˜¯æ•´æ•°\n",
      "\n",
      "æµ‹è¯• 4: {'prompt': 'ä½ å¥½', 'temperature': 3.0}\n",
      "âŒ éªŒè¯å¤±è´¥:\n",
      "   - temperatureå¿…é¡»åœ¨0-2ä¹‹é—´\n",
      "\n",
      "æµ‹è¯• 5: {'prompt': 'ä½ å¥½', 'model': 'invalid-model'}\n",
      "âŒ éªŒè¯å¤±è´¥:\n",
      "   - modelå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: gpt-3.5-turbo, gpt-4, claude-3, gemini-pro\n",
      "\n",
      "æµ‹è¯• 6: {'max_tokens': 100}\n",
      "âŒ éªŒè¯å¤±è´¥:\n",
      "   - ç¼ºå°‘å¿…éœ€å­—æ®µ: prompt\n",
      "\n",
      "æµ‹è¯• 7: {'prompt': 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'}\n",
      "âŒ éªŒè¯å¤±è´¥:\n",
      "   - prompté•¿åº¦ä¸èƒ½è¶…è¿‡10000å­—ç¬¦\n",
      "\n",
      "=== 4. å¼‚å¸¸å¤„ç† - èµ„æºç®¡ç† ===\n",
      "ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿›è¡ŒAPIè°ƒç”¨:\n",
      "ğŸ”— APIè¿æ¥å·²å»ºç«‹\n",
      "âŒ è¯·æ±‚ 1 å¤±è´¥: APIè°ƒç”¨é¢‘ç‡è¿‡é«˜\n",
      "âŒ è¯·æ±‚ 2 å¤±è´¥: ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "âŒ è¯·æ±‚ 3 å¤±è´¥: è¯·æ±‚è¶…æ—¶\n",
      "ğŸ”Œ APIè¿æ¥å·²æ–­å¼€\n",
      "\n",
      "=== 5. å¼‚å¸¸å¤„ç† - æ—¥å¿—è®°å½• ===\n",
      "æµ‹è¯•æ—¥å¿—è®°å½•:\n",
      "\n",
      "=== 6. è‡ªå®šä¹‰å¼‚å¸¸ç±» ===\n",
      "æµ‹è¯•è‡ªå®šä¹‰å¼‚å¸¸:\n",
      "ğŸ”¥ APIé”™è¯¯: æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ (é”™è¯¯ç : SERVER_ERROR)\n",
      "â° é¢‘ç‡é™åˆ¶: APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ (é‡è¯•æ—¶é—´: 60ç§’)\n",
      "â° é¢‘ç‡é™åˆ¶: APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ (é‡è¯•æ—¶é—´: 60ç§’)\n",
      "â° é¢‘ç‡é™åˆ¶: APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ (é‡è¯•æ—¶é—´: 60ç§’)\n",
      "âœ… è°ƒç”¨æˆåŠŸ: AIå›å¤: æµ‹è¯•...\n",
      "\n",
      "å¼‚å¸¸å¤„ç†åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„é‡è¦æ€§:\n",
      "1. æé«˜ç³»ç»Ÿç¨³å®šæ€§å’Œå¯é æ€§\n",
      "2. æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ\n",
      "3. ä¾¿äºé—®é¢˜è¯Šæ–­å’Œè°ƒè¯•\n",
      "4. å®ç°ä¼˜é›…çš„é”™è¯¯æ¢å¤\n",
      "5. ä¿æŠ¤ç³»ç»Ÿèµ„æº\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹å¼€å‘ä¸­çš„å¼‚å¸¸å¤„ç†ç¤ºä¾‹\n",
    "\n",
    "print(\"=== 1. åŸºæœ¬å¼‚å¸¸å¤„ç† - APIè°ƒç”¨ ===\")\n",
    "\n",
    "def call_llm_api(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"æ¨¡æ‹ŸLLM APIè°ƒç”¨ï¼Œå¯èƒ½æŠ›å‡ºå„ç§å¼‚å¸¸\"\"\"\n",
    "    import random\n",
    "\n",
    "    # æ¨¡æ‹Ÿä¸åŒçš„å¼‚å¸¸æƒ…å†µ\n",
    "    error_type = random.choice([\n",
    "        \"success\", \"connection_error\", \"timeout\", \"rate_limit\",\n",
    "        \"invalid_key\", \"server_error\", \"value_error\"\n",
    "    ])\n",
    "\n",
    "    if error_type == \"success\":\n",
    "        return {\"content\": f\"AIå›å¤: {prompt[:20]}...\", \"tokens\": 50}\n",
    "    elif error_type == \"connection_error\":\n",
    "        raise ConnectionError(\"ç½‘ç»œè¿æ¥å¤±è´¥\")\n",
    "    elif error_type == \"timeout\":\n",
    "        raise TimeoutError(\"è¯·æ±‚è¶…æ—¶\")\n",
    "    elif error_type == \"rate_limit\":\n",
    "        raise Exception(\"APIè°ƒç”¨é¢‘ç‡è¿‡é«˜\")\n",
    "    elif error_type == \"invalid_key\":\n",
    "        raise ValueError(\"æ— æ•ˆçš„APIå¯†é’¥\")\n",
    "    elif error_type == \"server_error\":\n",
    "        raise Exception(\"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯\")\n",
    "    elif error_type == \"value_error\":\n",
    "        raise ValueError(\"æ— æ•ˆçš„è¾“å…¥å‚æ•°\")\n",
    "\n",
    "# åŸºæœ¬å¼‚å¸¸å¤„ç†\n",
    "def safe_api_call(prompt):\n",
    "    \"\"\"å®‰å…¨çš„APIè°ƒç”¨ï¼ŒåŒ…å«åŸºæœ¬å¼‚å¸¸å¤„ç†\"\"\"\n",
    "    try:\n",
    "        result = call_llm_api(prompt)\n",
    "        print(f\"âœ… APIè°ƒç”¨æˆåŠŸ: {result['content']}\")\n",
    "        return result\n",
    "    except ConnectionError as e:\n",
    "        print(f\"âŒ è¿æ¥é”™è¯¯: {e}\")\n",
    "        return None\n",
    "    except TimeoutError as e:\n",
    "        print(f\"â° è¶…æ—¶é”™è¯¯: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"ğŸ”‘ å‚æ•°é”™è¯¯: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ”¥ å…¶ä»–é”™è¯¯: {e}\")\n",
    "        return None\n",
    "\n",
    "# æµ‹è¯•åŸºæœ¬å¼‚å¸¸å¤„ç†\n",
    "test_prompts = [\"ä½ å¥½\", \"è¯·ä»‹ç»ä¸€ä¸‹Python\", \"å†™ä¸€é¦–è¯—\"]\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\næµ‹è¯•æç¤ºè¯: '{prompt}'\")\n",
    "    result = safe_api_call(prompt)\n",
    "    if result:\n",
    "        print(f\"Tokenä½¿ç”¨é‡: {result['tokens']}\")\n",
    "\n",
    "print(\"\\n=== 2. é«˜çº§å¼‚å¸¸å¤„ç† - é‡è¯•æœºåˆ¶ ===\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "def call_llm_api_with_retry(prompt, max_retries=3, base_delay=1):\n",
    "    \"\"\"å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨\"\"\"\n",
    "    retry_count = 0\n",
    "    delay = base_delay\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            result = call_llm_api(prompt)\n",
    "            print(f\"âœ… APIè°ƒç”¨æˆåŠŸ (å°è¯• {retry_count + 1})\")\n",
    "            return result\n",
    "\n",
    "        except (ConnectionError, TimeoutError) as e:\n",
    "            retry_count += 1\n",
    "            if retry_count < max_retries:\n",
    "                print(f\"ğŸ”„ ç½‘ç»œé”™è¯¯ï¼Œ{delay}ç§’åé‡è¯• (å°è¯• {retry_count + 1}/{max_retries})\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # æŒ‡æ•°é€€é¿\n",
    "            else:\n",
    "                print(f\"ğŸ’¥ ç½‘ç»œé”™è¯¯ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}\")\n",
    "                return None\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"ğŸ”‘ å‚æ•°é”™è¯¯ï¼Œæ— æ³•é‡è¯•: {e}\")\n",
    "            return None\n",
    "\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            if retry_count < max_retries:\n",
    "                print(f\"ğŸ”„ æœåŠ¡å™¨é”™è¯¯ï¼Œ{delay}ç§’åé‡è¯• (å°è¯• {retry_count + 1}/{max_retries})\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2\n",
    "            else:\n",
    "                print(f\"ğŸ’¥ æœåŠ¡å™¨é”™è¯¯ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}\")\n",
    "                return None\n",
    "\n",
    "    return None\n",
    "\n",
    "# æµ‹è¯•é‡è¯•æœºåˆ¶\n",
    "print(\"æµ‹è¯•é‡è¯•æœºåˆ¶:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- æµ‹è¯• {i+1} ---\")\n",
    "    result = call_llm_api_with_retry(\"è¯·ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ \")\n",
    "\n",
    "print(\"\\n=== 3. å¼‚å¸¸å¤„ç† - æ•°æ®éªŒè¯ ===\")\n",
    "\n",
    "def validate_api_request(request_data):\n",
    "    \"\"\"éªŒè¯APIè¯·æ±‚æ•°æ®\"\"\"\n",
    "    errors = []\n",
    "\n",
    "    try:\n",
    "        # æ£€æŸ¥å¿…éœ€å­—æ®µ\n",
    "        if \"prompt\" not in request_data:\n",
    "            errors.append(\"ç¼ºå°‘å¿…éœ€å­—æ®µ: prompt\")\n",
    "        elif not isinstance(request_data[\"prompt\"], str):\n",
    "            errors.append(\"promptå¿…é¡»æ˜¯å­—ç¬¦ä¸²\")\n",
    "        elif len(request_data[\"prompt\"]) == 0:\n",
    "            errors.append(\"promptä¸èƒ½ä¸ºç©º\")\n",
    "        elif len(request_data[\"prompt\"]) > 10000:\n",
    "            errors.append(\"prompté•¿åº¦ä¸èƒ½è¶…è¿‡10000å­—ç¬¦\")\n",
    "\n",
    "        # æ£€æŸ¥å¯é€‰å­—æ®µ\n",
    "        if \"max_tokens\" in request_data:\n",
    "            try:\n",
    "                max_tokens = int(request_data[\"max_tokens\"])\n",
    "                if max_tokens <= 0:\n",
    "                    errors.append(\"max_tokenså¿…é¡»å¤§äº0\")\n",
    "                elif max_tokens > 4000:\n",
    "                    errors.append(\"max_tokensä¸èƒ½è¶…è¿‡4000\")\n",
    "            except (ValueError, TypeError):\n",
    "                errors.append(\"max_tokenså¿…é¡»æ˜¯æ•´æ•°\")\n",
    "\n",
    "        if \"temperature\" in request_data:\n",
    "            try:\n",
    "                temperature = float(request_data[\"temperature\"])\n",
    "                if temperature < 0 or temperature > 2:\n",
    "                    errors.append(\"temperatureå¿…é¡»åœ¨0-2ä¹‹é—´\")\n",
    "            except (ValueError, TypeError):\n",
    "                errors.append(\"temperatureå¿…é¡»æ˜¯æ•°å­—\")\n",
    "\n",
    "        if \"model\" in request_data:\n",
    "            valid_models = [\"gpt-3.5-turbo\", \"gpt-4\", \"claude-3\", \"gemini-pro\"]\n",
    "            if request_data[\"model\"] not in valid_models:\n",
    "                errors.append(f\"modelå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {', '.join(valid_models)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append(f\"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "\n",
    "    return len(errors) == 0, errors\n",
    "\n",
    "# æµ‹è¯•æ•°æ®éªŒè¯\n",
    "test_requests = [\n",
    "    {\"prompt\": \"ä½ å¥½\", \"max_tokens\": 100, \"temperature\": 0.7},\n",
    "    {\"prompt\": \"\", \"max_tokens\": 100},  # ç©ºæç¤ºè¯\n",
    "    {\"prompt\": \"ä½ å¥½\", \"max_tokens\": \"invalid\"},  # æ— æ•ˆçš„max_tokens\n",
    "    {\"prompt\": \"ä½ å¥½\", \"temperature\": 3.0},  # æ— æ•ˆçš„temperature\n",
    "    {\"prompt\": \"ä½ å¥½\", \"model\": \"invalid-model\"},  # æ— æ•ˆçš„æ¨¡å‹\n",
    "    {\"max_tokens\": 100},  # ç¼ºå°‘prompt\n",
    "    {\"prompt\": \"a\" * 15000}  # è¿‡é•¿çš„prompt\n",
    "]\n",
    "\n",
    "print(\"APIè¯·æ±‚éªŒè¯æµ‹è¯•:\")\n",
    "for i, request in enumerate(test_requests, 1):\n",
    "    print(f\"\\næµ‹è¯• {i}: {request}\")\n",
    "    is_valid, errors = validate_api_request(request)\n",
    "    if is_valid:\n",
    "        print(\"âœ… éªŒè¯é€šè¿‡\")\n",
    "    else:\n",
    "        print(\"âŒ éªŒè¯å¤±è´¥:\")\n",
    "        for error in errors:\n",
    "            print(f\"   - {error}\")\n",
    "\n",
    "print(\"\\n=== 4. å¼‚å¸¸å¤„ç† - èµ„æºç®¡ç† ===\")\n",
    "\n",
    "class APIClient:\n",
    "    \"\"\"APIå®¢æˆ·ç«¯ï¼Œæ¼”ç¤ºèµ„æºç®¡ç†\"\"\"\n",
    "\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.connection_open = False\n",
    "        self.request_count = 0\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"å»ºç«‹è¿æ¥\"\"\"\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"APIå¯†é’¥ä¸èƒ½ä¸ºç©º\")\n",
    "        self.connection_open = True\n",
    "        print(\"ğŸ”— APIè¿æ¥å·²å»ºç«‹\")\n",
    "\n",
    "    def disconnect(self):\n",
    "        \"\"\"æ–­å¼€è¿æ¥\"\"\"\n",
    "        self.connection_open = False\n",
    "        print(\"ğŸ”Œ APIè¿æ¥å·²æ–­å¼€\")\n",
    "\n",
    "    def make_request(self, prompt):\n",
    "        \"\"\"å‘é€è¯·æ±‚\"\"\"\n",
    "        if not self.connection_open:\n",
    "            raise ConnectionError(\"APIæœªè¿æ¥\")\n",
    "\n",
    "        self.request_count += 1\n",
    "        if self.request_count > 5:  # æ¨¡æ‹Ÿè¿æ¥é™åˆ¶\n",
    "            raise Exception(\"è¯·æ±‚æ¬¡æ•°è¶…é™\")\n",
    "\n",
    "        return call_llm_api(prompt)\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£\"\"\"\n",
    "        self.connect()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£\"\"\"\n",
    "        self.disconnect()\n",
    "        if exc_type:\n",
    "            print(f\"âš ï¸ å‘ç”Ÿå¼‚å¸¸: {exc_type.__name__}: {exc_val}\")\n",
    "        return False  # ä¸æŠ‘åˆ¶å¼‚å¸¸\n",
    "\n",
    "# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨\n",
    "print(\"ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿›è¡ŒAPIè°ƒç”¨:\")\n",
    "try:\n",
    "    with APIClient(\"your-api-key\") as client:\n",
    "        for i in range(3):\n",
    "            try:\n",
    "                result = client.make_request(f\"æµ‹è¯•è¯·æ±‚ {i+1}\")\n",
    "                print(f\"âœ… è¯·æ±‚ {i+1} æˆåŠŸ: {result['content']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯·æ±‚ {i+1} å¤±è´¥: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸ”¥ å®¢æˆ·ç«¯é”™è¯¯: {e}\")\n",
    "\n",
    "print(\"\\n=== 5. å¼‚å¸¸å¤„ç† - æ—¥å¿—è®°å½• ===\")\n",
    "\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# é…ç½®æ—¥å¿—\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('api_errors.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def log_api_call(prompt, success, error=None, tokens=0):\n",
    "    \"\"\"è®°å½•APIè°ƒç”¨æ—¥å¿—\"\"\"\n",
    "    if success:\n",
    "        logging.info(f\"APIè°ƒç”¨æˆåŠŸ - æç¤ºè¯: '{prompt[:50]}...', tokens: {tokens}\")\n",
    "    else:\n",
    "        logging.error(f\"APIè°ƒç”¨å¤±è´¥ - æç¤ºè¯: '{prompt[:50]}...', é”™è¯¯: {error}\")\n",
    "\n",
    "def monitored_api_call(prompt):\n",
    "    \"\"\"å¸¦ç›‘æ§çš„APIè°ƒç”¨\"\"\"\n",
    "    try:\n",
    "        result = call_llm_api(prompt)\n",
    "        log_api_call(prompt, True, tokens=result.get('tokens', 0))\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        log_api_call(prompt, False, error=str(e))\n",
    "        return None\n",
    "\n",
    "# æµ‹è¯•æ—¥å¿—è®°å½•\n",
    "print(\"æµ‹è¯•æ—¥å¿—è®°å½•:\")\n",
    "test_prompts = [\"ä½ å¥½\", \"è¯·ä»‹ç»ä¸€ä¸‹Python\", \"å†™ä¸€é¦–è¯—\"]\n",
    "for prompt in test_prompts:\n",
    "    result = monitored_api_call(prompt)\n",
    "\n",
    "print(\"\\n=== 6. è‡ªå®šä¹‰å¼‚å¸¸ç±» ===\")\n",
    "\n",
    "class LLMAPIError(Exception):\n",
    "    \"\"\"LLM APIåŸºç¡€å¼‚å¸¸\"\"\"\n",
    "    def __init__(self, message, error_code=None):\n",
    "        super().__init__(message)\n",
    "        self.error_code = error_code\n",
    "        self.timestamp = datetime.now()\n",
    "\n",
    "class RateLimitError(LLMAPIError):\n",
    "    \"\"\"é¢‘ç‡é™åˆ¶å¼‚å¸¸\"\"\"\n",
    "    def __init__(self, message=\"APIè°ƒç”¨é¢‘ç‡è¿‡é«˜\", retry_after=None):\n",
    "        super().__init__(message, \"RATE_LIMIT\")\n",
    "        self.retry_after = retry_after\n",
    "\n",
    "class AuthenticationError(LLMAPIError):\n",
    "    \"\"\"è®¤è¯å¼‚å¸¸\"\"\"\n",
    "    def __init__(self, message=\"APIå¯†é’¥æ— æ•ˆ\"):\n",
    "        super().__init__(message, \"AUTH_ERROR\")\n",
    "\n",
    "class ModelNotFoundError(LLMAPIError):\n",
    "    \"\"\"æ¨¡å‹ä¸å­˜åœ¨å¼‚å¸¸\"\"\"\n",
    "    def __init__(self, model_name, message=None):\n",
    "        if message is None:\n",
    "            message = f\"æ¨¡å‹ '{model_name}' ä¸å­˜åœ¨\"\n",
    "        super().__init__(message, \"MODEL_NOT_FOUND\")\n",
    "        self.model_name = model_name\n",
    "\n",
    "def call_llm_with_custom_exceptions(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"ä½¿ç”¨è‡ªå®šä¹‰å¼‚å¸¸çš„APIè°ƒç”¨\"\"\"\n",
    "    import random\n",
    "\n",
    "    error_type = random.choice([\n",
    "        \"success\", \"rate_limit\", \"auth_error\", \"model_not_found\", \"server_error\"\n",
    "    ])\n",
    "\n",
    "    if error_type == \"success\":\n",
    "        return {\"content\": f\"AIå›å¤: {prompt[:20]}...\", \"tokens\": 50}\n",
    "    elif error_type == \"rate_limit\":\n",
    "        raise RateLimitError(retry_after=60)\n",
    "    elif error_type == \"auth_error\":\n",
    "        raise AuthenticationError()\n",
    "    elif error_type == \"model_not_found\":\n",
    "        raise ModelNotFoundError(model)\n",
    "    else:\n",
    "        raise LLMAPIError(\"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯\", \"SERVER_ERROR\")\n",
    "\n",
    "# æµ‹è¯•è‡ªå®šä¹‰å¼‚å¸¸\n",
    "print(\"æµ‹è¯•è‡ªå®šä¹‰å¼‚å¸¸:\")\n",
    "for i in range(5):\n",
    "    try:\n",
    "        result = call_llm_with_custom_exceptions(\"æµ‹è¯•\")\n",
    "        print(f\"âœ… è°ƒç”¨æˆåŠŸ: {result['content']}\")\n",
    "    except RateLimitError as e:\n",
    "        print(f\"â° é¢‘ç‡é™åˆ¶: {e} (é‡è¯•æ—¶é—´: {e.retry_after}ç§’)\")\n",
    "    except AuthenticationError as e:\n",
    "        print(f\"ğŸ”‘ è®¤è¯é”™è¯¯: {e}\")\n",
    "    except ModelNotFoundError as e:\n",
    "        print(f\"ğŸ¤– æ¨¡å‹é”™è¯¯: {e} (æ¨¡å‹: {e.model_name})\")\n",
    "    except LLMAPIError as e:\n",
    "        print(f\"ğŸ”¥ APIé”™è¯¯: {e} (é”™è¯¯ç : {e.error_code})\")\n",
    "    except Exception as e:\n",
    "        print(f\"â“ æœªçŸ¥é”™è¯¯: {e}\")\n",
    "\n",
    "print(f\"\\nå¼‚å¸¸å¤„ç†åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„é‡è¦æ€§:\")\n",
    "print(\"1. æé«˜ç³»ç»Ÿç¨³å®šæ€§å’Œå¯é æ€§\")\n",
    "print(\"2. æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ\")\n",
    "print(\"3. ä¾¿äºé—®é¢˜è¯Šæ–­å’Œè°ƒè¯•\")\n",
    "print(\"4. å®ç°ä¼˜é›…çš„é”™è¯¯æ¢å¤\")\n",
    "print(\"5. ä¿æŠ¤ç³»ç»Ÿèµ„æº\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "mRuC_9CoU28P"
   },
   "source": [
    "## ç±»ï¼šåˆ›å»ºä½ è‡ªå·±çš„å¯¹è±¡\n",
    "\n",
    "> **æ ¸å¿ƒæ¦‚å¿µ**ï¼šé¢å‘å¯¹è±¡ç¼–ç¨‹æ˜¯å¤§æ¨¡å‹åº”ç”¨æ¶æ„è®¾è®¡çš„åŸºç¡€ï¼Œç”¨äºåˆ›å»ºå¯é‡ç”¨çš„ç»„ä»¶ã€å°è£…å¤æ‚é€»è¾‘ã€æ„å»ºæ¨¡å—åŒ–ç³»ç»Ÿã€‚\n",
    "\n",
    "ç±»æ˜¯Pythonä¸­é¢å‘å¯¹è±¡ç¼–ç¨‹çš„åŸºç¡€ã€‚åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­ï¼Œä½¿ç”¨ç±»å¯ä»¥åˆ›å»ºå¯é‡ç”¨çš„ç»„ä»¶ï¼Œå¦‚APIå®¢æˆ·ç«¯ã€æ•°æ®å¤„ç†å™¨ã€æ¨¡å‹åŒ…è£…å™¨ç­‰ã€‚\n",
    "\n",
    "### åŸºæœ¬ç±»å®šä¹‰\n",
    "```python\n",
    "class ClassName:\n",
    "    def __init__(self, parameter1, parameter2):\n",
    "        self.attribute1 = parameter1\n",
    "        self.attribute2 = parameter2\n",
    "    \n",
    "    def method1(self):\n",
    "        # æ–¹æ³•å®ç°\n",
    "        pass\n",
    "```\n",
    "\n",
    "### é¢å‘å¯¹è±¡ç¼–ç¨‹çš„æ ¸å¿ƒæ¦‚å¿µ\n",
    "- **å°è£…**ï¼šå°†æ•°æ®å’Œæ–¹æ³•ç»„ç»‡åœ¨ä¸€èµ·\n",
    "- **ç»§æ‰¿**ï¼šåˆ›å»ºåŸºäºç°æœ‰ç±»çš„æ–°ç±»\n",
    "- **å¤šæ€**ï¼šåŒä¸€æ¥å£çš„ä¸åŒå®ç°\n",
    "- **æŠ½è±¡**ï¼šéšè—å®ç°ç»†èŠ‚ï¼Œåªæš´éœ²å¿…è¦æ¥å£\n",
    "\n",
    "### å¤§æ¨¡å‹å¼€å‘ä¸­çš„åº”ç”¨åœºæ™¯\n",
    "- **APIå®¢æˆ·ç«¯ç±»**ï¼šå°è£…å¤§æ¨¡å‹APIè°ƒç”¨é€»è¾‘\n",
    "- **æ•°æ®å¤„ç†ç±»**ï¼šå¤„ç†æ–‡æœ¬ã€JSONç­‰æ•°æ®\n",
    "- **æ¨¡å‹åŒ…è£…ç±»**ï¼šç»Ÿä¸€ä¸åŒæ¨¡å‹çš„æ¥å£\n",
    "- **é…ç½®ç®¡ç†ç±»**ï¼šç®¡ç†åº”ç”¨é…ç½®å’Œå‚æ•°\n",
    "- **å·¥å…·ç±»**ï¼šæä¾›é€šç”¨çš„è¾…åŠ©åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "IZ_oJu43U28P"
   },
   "outputs": [],
   "source": [
    "# Define a new class called `Thing` that is derived from the base Python object\n",
    "class Thing(object):\n",
    "    my_property = 'I am a \"Thing\"'\n",
    "\n",
    "\n",
    "# Define a new class called `DictThing` that is derived from the `dict` type\n",
    "class DictThing(dict):\n",
    "    my_property = 'I am a \"DictThing\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "Q7nVDnDJU28Q",
    "outputId": "6a1ab9f6-646f-46b3-ad3a-7e1ada297de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Thing'>\n",
      "<class 'type'>\n",
      "<class '__main__.DictThing'>\n",
      "<class 'type'>\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(Thing)\n",
    "print(type(Thing))\n",
    "print(DictThing)\n",
    "print(type(DictThing))\n",
    "print(issubclass(DictThing, dict))\n",
    "print(issubclass(DictThing, object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "J42GL9LzU28R",
    "outputId": "a6b48d4c-6d0b-4e7b-f021-61afd140419b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Thing object at 0x7fe15c00ffd0>\n",
      "<class '__main__.Thing'>\n",
      "{}\n",
      "<class '__main__.DictThing'>\n"
     ]
    }
   ],
   "source": [
    "# Create \"instances\" of our new classes\n",
    "t = Thing()\n",
    "d = DictThing()\n",
    "print(t)\n",
    "print(type(t))\n",
    "print(d)\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "FONf3-PDU28S",
    "outputId": "cb9852de-e804-4901-c5d1-b1e459b27339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Sally'}\n"
     ]
    }
   ],
   "source": [
    "# Interact with a DictThing instance just as you would a normal dictionary\n",
    "d['name'] = 'Sally'\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "xN0nOhJEU28T",
    "outputId": "d38d0aa2-b3d5-45a3-b2f4-c272c416eb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Sally', 'age': 13, 'fav_foods': ['pizza', 'sushi', 'pad thai', 'waffles'], 'fav_color': 'green'}\n"
     ]
    }
   ],
   "source": [
    "d.update({\n",
    "        'age': 13,\n",
    "        'fav_foods': ['pizza', 'sushi', 'pad thai', 'waffles'],\n",
    "        'fav_color': 'green',\n",
    "    })\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": true,
    "editable": true,
    "id": "UldXgWrdU28U",
    "outputId": "0242f2cc-29dd-4e3a-e11c-cc1b7d8cb987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a \"DictThing\"\n"
     ]
    }
   ],
   "source": [
    "print(d.my_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZuLEQKMU27e"
   },
   "source": [
    "## å¤§æ¨¡å‹æŠ€æœ¯ä¸­çš„PythonåŸºç¡€çŸ¥è¯†\n",
    "\n",
    "> **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡å¤§æ¨¡å‹å¼€å‘ä¸­å¿…éœ€çš„PythonæŠ€èƒ½ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ã€APIè°ƒç”¨ã€æ–‡æœ¬å¤„ç†ç­‰æ ¸å¿ƒæ¦‚å¿µã€‚\n",
    "\n",
    "åœ¨å¤§æ¨¡å‹ï¼ˆLLMï¼‰å¼€å‘ä¸­ï¼ŒPythonæ˜¯æœ€ä¸»è¦çš„ç¼–ç¨‹è¯­è¨€ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¸å¤§æ¨¡å‹æŠ€æœ¯å¯†åˆ‡ç›¸å…³çš„Pythonæ¦‚å¿µï¼š\n",
    "\n",
    "### 1. æ•°æ®å¤„ç†å’Œç§‘å­¦è®¡ç®—\n",
    "- **NumPy**: æ•°å€¼è®¡ç®—åº“ï¼Œç”¨äºå¤„ç†å¤šç»´æ•°ç»„å’Œå¼ é‡è¿ç®—\n",
    "- **Pandas**: æ•°æ®åˆ†æåº“ï¼Œç”¨äºå¤„ç†ç»“æ„åŒ–æ•°æ®å’ŒCSVæ–‡ä»¶\n",
    "- **JSON**: å¤„ç†APIå“åº”å’Œé…ç½®æ–‡ä»¶ï¼Œå¤§æ¨¡å‹APIçš„ä¸»è¦æ•°æ®æ ¼å¼\n",
    "\n",
    "### 2. æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ \n",
    "- **PyTorch/TensorFlow**: æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒå’Œæ¨ç†\n",
    "- **Transformers**: Hugging Faceçš„é¢„è®­ç»ƒæ¨¡å‹åº“ï¼Œæä¾›å„ç§é¢„è®­ç»ƒæ¨¡å‹\n",
    "- **NumPy**: å¼ é‡æ“ä½œçš„åŸºç¡€ï¼Œæ‰€æœ‰æ·±åº¦å­¦ä¹ æ¡†æ¶çš„åº•å±‚\n",
    "\n",
    "### 3. æ–‡æœ¬å¤„ç†\n",
    "- **å­—ç¬¦ä¸²æ“ä½œ**: å¤„ç†æç¤ºè¯ã€å“åº”æ–‡æœ¬ã€æ•°æ®æ¸…æ´—\n",
    "- **æ­£åˆ™è¡¨è¾¾å¼**: æ–‡æœ¬æ¨¡å¼åŒ¹é…ã€æ•°æ®æå–\n",
    "- **ç¼–ç /è§£ç **: UTF-8ã€Base64ç­‰ï¼Œå¤„ç†å¤šè¯­è¨€æ–‡æœ¬\n",
    "\n",
    "### 4. APIå’Œç½‘ç»œè¯·æ±‚\n",
    "- **requests**: HTTPè¯·æ±‚åº“ï¼Œè°ƒç”¨å¤§æ¨¡å‹API\n",
    "- **aiohttp**: å¼‚æ­¥HTTPè¯·æ±‚ï¼Œæé«˜å¹¶å‘æ€§èƒ½\n",
    "- **WebSocket**: å®æ—¶é€šä¿¡ï¼Œæµå¼å“åº”\n",
    "\n",
    "### 5. å¼‚æ­¥ç¼–ç¨‹\n",
    "- **async/await**: å¤„ç†å¹¶å‘è¯·æ±‚ï¼Œæé«˜æ•ˆç‡\n",
    "- **asyncio**: å¼‚æ­¥IOæ“ä½œï¼Œç®¡ç†å¼‚æ­¥ä»»åŠ¡\n",
    "\n",
    "### 6. å¤§æ¨¡å‹å¼€å‘æ¡†æ¶\n",
    "- **LangChain**: æ„å»ºå¤§æ¨¡å‹åº”ç”¨çš„ç»¼åˆæ¡†æ¶\n",
    "- **FastAPI**: æ„å»ºAPIæœåŠ¡çš„ç°ä»£æ¡†æ¶\n",
    "- **Streamlit**: å¿«é€Ÿæ„å»ºå¤§æ¨¡å‹åº”ç”¨ç•Œé¢\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPjkF4CwU27e",
    "outputId": "8705bd49-ac61-4a8e-d294-25861bce40cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIå›å¤: ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚\n",
      "ä½¿ç”¨çš„tokenæ•°: 25\n"
     ]
    }
   ],
   "source": [
    "# å¤§æ¨¡å‹æŠ€æœ¯ä¸­çš„PythonåŸºç¡€ç¤ºä¾‹\n",
    "\n",
    "# 1. å¤„ç†APIå“åº”æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰\n",
    "import json\n",
    "\n",
    "# æ¨¡æ‹ŸLLM APIå“åº”\n",
    "api_response = {\n",
    "    \"choices\": [\n",
    "        {\n",
    "            \"message\": {\n",
    "                \"content\": \"ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚\",\n",
    "                \"role\": \"assistant\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "        \"prompt_tokens\": 10,\n",
    "        \"completion_tokens\": 15,\n",
    "        \"total_tokens\": 25\n",
    "    }\n",
    "}\n",
    "\n",
    "# è§£æJSONæ•°æ®\n",
    "response_data = json.loads(json.dumps(api_response))  # æ¨¡æ‹Ÿä»APIè·å–çš„æ•°æ®\n",
    "print(\"AIå›å¤:\", response_data[\"choices\"][0][\"message\"][\"content\"])\n",
    "print(\"ä½¿ç”¨çš„tokenæ•°:\", response_data[\"usage\"][\"total_tokens\"])\n",
    "\n",
    "# åœ¨å®é™…å¼€å‘ä¸­ï¼Œä½ ä¼šè¿™æ ·è°ƒç”¨APIï¼š\n",
    "# import requests\n",
    "# response = requests.post(\"https://api.openai.com/v1/chat/completions\",\n",
    "#                        headers={\"Authorization\": \"Bearer YOUR_API_KEY\"},\n",
    "#                        json={\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½\"}]})\n",
    "# data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7of-4txU27g",
    "outputId": "c4e15894-a06c-4533-c329-adbeb14e7cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆçš„æç¤ºè¯:\n",
      "ç³»ç»Ÿæ¶ˆæ¯: ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚\n",
      "\n",
      "ç”¨æˆ·è¾“å…¥: è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\n",
      "\n",
      "è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 2. æ–‡æœ¬å¤„ç†å’Œæç¤ºè¯å·¥ç¨‹\n",
    "def create_prompt(user_input, system_message=\"ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚\"):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºç»“æ„åŒ–çš„æç¤ºè¯\n",
    "    è¿™æ˜¯å¤§æ¨¡å‹åº”ç”¨ä¸­çš„æ ¸å¿ƒæŠ€èƒ½\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "ç³»ç»Ÿæ¶ˆæ¯: {system_message}\n",
    "\n",
    "ç”¨æˆ·è¾“å…¥: {user_input}\n",
    "\n",
    "è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯æä¾›å¸®åŠ©ã€‚\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "user_question = \"è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\"\n",
    "prompt = create_prompt(user_question)\n",
    "print(\"ç”Ÿæˆçš„æç¤ºè¯:\")\n",
    "print(prompt)\n",
    "\n",
    "# æç¤ºè¯å·¥ç¨‹çš„æœ€ä½³å®è·µï¼š\n",
    "# 1. æ˜ç¡®è§’è‰²å’Œä»»åŠ¡\n",
    "# 2. æä¾›å…·ä½“çš„æŒ‡ä»¤\n",
    "# 3. åŒ…å«ç¤ºä¾‹ï¼ˆfew-shot learningï¼‰\n",
    "# 4. è®¾ç½®è¾“å‡ºæ ¼å¼è¦æ±‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32MeTJ3tU27g",
    "outputId": "5ec6756f-005d-409d-84e1-6263317c8abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·æ¶ˆæ¯: ['ä½ å¥½', 'è¯·ä»‹ç»ä¸€ä¸‹Python']\n",
      "æ¶ˆæ¯é•¿åº¦: [2, 14, 11, 18]\n",
      "æŒ‰è§’è‰²åˆ†ç»„çš„æ¶ˆæ¯: {'user': ['ä½ å¥½', 'è¯·ä»‹ç»ä¸€ä¸‹Python'], 'assistant': ['ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ', 'Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...']}\n"
     ]
    }
   ],
   "source": [
    "# 3. åˆ—è¡¨æ¨å¯¼å¼å’Œæ•°æ®å¤„ç†ï¼ˆå¤§æ¨¡å‹æ•°æ®å¤„ç†å¸¸ç”¨ï¼‰\n",
    "# å¤„ç†å¤šä¸ªå¯¹è¯å†å²\n",
    "conversation_history = [\n",
    "    {\"role\": \"user\", \"content\": \"ä½ å¥½\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\"},\n",
    "    {\"role\": \"user\", \"content\": \"è¯·ä»‹ç»ä¸€ä¸‹Python\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...\"}\n",
    "]\n",
    "\n",
    "# ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æå–æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯\n",
    "user_messages = [msg[\"content\"] for msg in conversation_history if msg[\"role\"] == \"user\"]\n",
    "print(\"ç”¨æˆ·æ¶ˆæ¯:\", user_messages)\n",
    "\n",
    "# ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„é•¿åº¦\n",
    "message_lengths = [len(msg[\"content\"]) for msg in conversation_history]\n",
    "print(\"æ¶ˆæ¯é•¿åº¦:\", message_lengths)\n",
    "\n",
    "# ä½¿ç”¨å­—å…¸æ¨å¯¼å¼åˆ›å»ºè§’è‰²åˆ°æ¶ˆæ¯çš„æ˜ å°„\n",
    "role_messages = {msg[\"role\"]: [m[\"content\"] for m in conversation_history if m[\"role\"] == msg[\"role\"]]\n",
    "                 for msg in conversation_history}\n",
    "print(\"æŒ‰è§’è‰²åˆ†ç»„çš„æ¶ˆæ¯:\", role_messages)\n",
    "\n",
    "# åˆ—è¡¨æ¨å¯¼å¼åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„ä¼˜åŠ¿ï¼š\n",
    "# 1. ä»£ç ç®€æ´æ˜“è¯»\n",
    "# 2. æ€§èƒ½ä¼˜äºä¼ ç»Ÿå¾ªç¯\n",
    "# 3. é€‚åˆå¤„ç†å¤§é‡æ•°æ®\n",
    "# 4. æ˜“äºå¹¶è¡ŒåŒ–å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NHDLq7LU27h",
    "outputId": "5136e90a-d679-4b25-d229-8e1ac3c4161d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æç¤ºè¯: 'ä½ å¥½...'\n",
      "ç»“æœ: {'success': True, 'data': 'AIå›å¤: ä½ å¥½...', 'error': None}\n",
      "----------------------------------------\n",
      "æç¤ºè¯: '...'\n",
      "ç»“æœ: {'success': False, 'data': None, 'error': 'å€¼é”™è¯¯: æç¤ºè¯ä¸èƒ½ä¸ºç©º'}\n",
      "----------------------------------------\n",
      "æç¤ºè¯: 'å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿...'\n",
      "ç»“æœ: {'success': True, 'data': 'AIå›å¤: å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿çš„æç¤ºè¯å¾ˆé•¿...', 'error': None}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. é”™è¯¯å¤„ç†å’Œå¼‚å¸¸å¤„ç†ï¼ˆå¤§æ¨¡å‹APIè°ƒç”¨å¿…å¤‡ï¼‰\n",
    "def safe_api_call(api_function, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    å®‰å…¨åœ°è°ƒç”¨APIå‡½æ•°ï¼ŒåŒ…å«é”™è¯¯å¤„ç†\n",
    "    è¿™æ˜¯å¤§æ¨¡å‹åº”ç”¨ä¸­çš„æœ€ä½³å®è·µ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = api_function(*args, **kwargs)\n",
    "        return {\"success\": True, \"data\": result, \"error\": None}\n",
    "    except ConnectionError as e:\n",
    "        return {\"success\": False, \"data\": None, \"error\": f\"è¿æ¥é”™è¯¯: {e}\"}\n",
    "    except ValueError as e:\n",
    "        return {\"success\": False, \"data\": None, \"error\": f\"å€¼é”™è¯¯: {e}\"}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"data\": None, \"error\": f\"æœªçŸ¥é”™è¯¯: {e}\"}\n",
    "\n",
    "# æ¨¡æ‹ŸAPIè°ƒç”¨å‡½æ•°\n",
    "def mock_llm_api_call(prompt):\n",
    "    \"\"\"æ¨¡æ‹ŸLLM APIè°ƒç”¨\"\"\"\n",
    "    if not prompt:\n",
    "        raise ValueError(\"æç¤ºè¯ä¸èƒ½ä¸ºç©º\")\n",
    "    if len(prompt) > 1000:\n",
    "        raise ConnectionError(\"æç¤ºè¯è¿‡é•¿ï¼Œè¿æ¥è¶…æ—¶\")\n",
    "    return f\"AIå›å¤: {prompt[:50]}...\"\n",
    "\n",
    "# æµ‹è¯•å®‰å…¨APIè°ƒç”¨\n",
    "test_prompts = [\"ä½ å¥½\", \"\", \"å¾ˆé•¿çš„æç¤ºè¯\" * 100]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    result = safe_api_call(mock_llm_api_call, prompt)\n",
    "    print(f\"æç¤ºè¯: '{prompt[:20]}...'\")\n",
    "    print(f\"ç»“æœ: {result}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# é”™è¯¯å¤„ç†åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„é‡è¦æ€§ï¼š\n",
    "# 1. APIè°ƒç”¨å¯èƒ½å¤±è´¥ï¼ˆç½‘ç»œé—®é¢˜ã€é…é¢é™åˆ¶ç­‰ï¼‰\n",
    "# 2. è¾“å…¥æ•°æ®å¯èƒ½æ— æ•ˆ\n",
    "# 3. æ¨¡å‹å¯èƒ½è¿”å›æ„å¤–ç»“æœ\n",
    "# 4. éœ€è¦ä¼˜é›…åœ°å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Qw7dBHCU27i",
    "outputId": "2898544d-11a8-480e-8781-6d6c7459d9a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å®¢æˆ·ç«¯ä¿¡æ¯: LLMClient(model=gpt-4, messages=3)\n",
      "å¯¹è¯ä¸Šä¸‹æ–‡: [{'role': 'user', 'content': 'ä½ å¥½'}, {'role': 'assistant', 'content': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}, {'role': 'user', 'content': 'è¯·ä»‹ç»ä¸€ä¸‹Python'}]\n"
     ]
    }
   ],
   "source": [
    "# 5. ç±»å’Œå¯¹è±¡ï¼ˆå¤§æ¨¡å‹åº”ç”¨æ¶æ„è®¾è®¡ï¼‰\n",
    "class LLMClient:\n",
    "    \"\"\"\n",
    "    å¤§è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯ç±»\n",
    "    å±•ç¤ºé¢å‘å¯¹è±¡ç¼–ç¨‹åœ¨å¤§æ¨¡å‹åº”ç”¨ä¸­çš„åº”ç”¨\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo\", api_key=None):\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        \"\"\"æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²\"\"\"\n",
    "        self.conversation_history.append({\n",
    "            \"role\": role,\n",
    "            \"content\": content\n",
    "        })\n",
    "\n",
    "    def get_conversation_context(self, max_messages=10):\n",
    "        \"\"\"è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘çš„æ¶ˆæ¯ï¼‰\"\"\"\n",
    "        return self.conversation_history[-max_messages:]\n",
    "\n",
    "    def clear_history(self):\n",
    "        \"\"\"æ¸…ç©ºå¯¹è¯å†å²\"\"\"\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"LLMClient(model={self.model_name}, messages={len(self.conversation_history)})\"\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "client = LLMClient(\"gpt-4\", \"your-api-key\")\n",
    "client.add_message(\"user\", \"ä½ å¥½\")\n",
    "client.add_message(\"assistant\", \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\")\n",
    "client.add_message(\"user\", \"è¯·ä»‹ç»ä¸€ä¸‹Python\")\n",
    "\n",
    "print(\"å®¢æˆ·ç«¯ä¿¡æ¯:\", client)\n",
    "print(\"å¯¹è¯ä¸Šä¸‹æ–‡:\", client.get_conversation_context())\n",
    "\n",
    "# é¢å‘å¯¹è±¡ç¼–ç¨‹åœ¨å¤§æ¨¡å‹å¼€å‘ä¸­çš„ä¼˜åŠ¿ï¼š\n",
    "# 1. å°è£…ï¼šå°†ç›¸å…³åŠŸèƒ½ç»„ç»‡åœ¨ä¸€èµ·\n",
    "# 2. ç»§æ‰¿ï¼šåˆ›å»ºä¸åŒç±»å‹çš„æ¨¡å‹å®¢æˆ·ç«¯\n",
    "# 3. å¤šæ€ï¼šæ”¯æŒä¸åŒçš„æ¨¡å‹æ¥å£\n",
    "# 4. ç»´æŠ¤æ€§ï¼šä»£ç ç»“æ„æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJN3lY28U28X"
   },
   "source": [
    "## å®è·µä½œä¸š - å¤§æ¨¡å‹åº”ç”¨å¼€å‘\n",
    "\n",
    "> **ç›®æ ‡**ï¼šé€šè¿‡å®é™…é¡¹ç›®ç»ƒä¹ ï¼Œå·©å›ºPythonåŸºç¡€çŸ¥è¯†ï¼Œå¹¶æŒæ¡å¤§æ¨¡å‹å¼€å‘çš„æ ¸å¿ƒæŠ€èƒ½ã€‚\n",
    "\n",
    "### ä½œä¸š1ï¼šæ„å»ºç®€å•çš„èŠå¤©æœºå™¨äºº\n",
    "\n",
    "**ä»»åŠ¡æè¿°**ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººï¼Œèƒ½å¤Ÿå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤ã€‚\n",
    "\n",
    "**è¦æ±‚**ï¼š\n",
    "1. ä½¿ç”¨å­—å…¸å­˜å‚¨å¯¹è¯å†å²\n",
    "2. å®ç°åŸºæœ¬çš„è¾“å…¥éªŒè¯\n",
    "3. æ·»åŠ é”™è¯¯å¤„ç†æœºåˆ¶\n",
    "4. æ”¯æŒå¤šç§å›å¤æ¨¡å¼\n",
    "\n",
    "**æç¤º**ï¼š\n",
    "```python\n",
    "# åŸºç¡€æ¡†æ¶\n",
    "class SimpleChatBot:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.responses = {\n",
    "            \"ä½ å¥½\": \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\",\n",
    "            \"å†è§\": \"å†è§ï¼ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼\",\n",
    "            \"å¸®åŠ©\": \"æˆ‘å¯ä»¥å›ç­”ä½ çš„é—®é¢˜ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³äº†è§£ä»€ä¹ˆã€‚\"\n",
    "        }\n",
    "    \n",
    "    def chat(self, user_input):\n",
    "        # å®ç°èŠå¤©é€»è¾‘\n",
    "        pass\n",
    "```\n",
    "\n",
    "### ä½œä¸š2ï¼šAPIå“åº”æ•°æ®å¤„ç†å™¨\n",
    "\n",
    "**ä»»åŠ¡æè¿°**ï¼šåˆ›å»ºä¸€ä¸ªæ•°æ®å¤„ç†ç³»ç»Ÿï¼Œç”¨äºå¤„ç†å¤§æ¨¡å‹APIçš„å“åº”æ•°æ®ã€‚\n",
    "\n",
    "**è¦æ±‚**ï¼š\n",
    "1. è§£æJSONæ ¼å¼çš„APIå“åº”\n",
    "2. æå–å…³é”®ä¿¡æ¯ï¼ˆå†…å®¹ã€tokensã€æˆæœ¬ç­‰ï¼‰\n",
    "3. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ€»tokensã€å¹³å‡æˆæœ¬ç­‰ï¼‰\n",
    "4. ç”Ÿæˆæ•°æ®æŠ¥å‘Š\n",
    "\n",
    "**æç¤º**ï¼š\n",
    "```python\n",
    "# ç¤ºä¾‹APIå“åº”\n",
    "api_response = {\n",
    "    \"choices\": [{\"message\": {\"content\": \"AIå›å¤å†…å®¹\"}}],\n",
    "    \"usage\": {\"total_tokens\": 150, \"prompt_tokens\": 50, \"completion_tokens\": 100},\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "## ä½œä¸šè¯„åˆ†æ ‡å‡†\n",
    "\n",
    "### åŸºç¡€è¦æ±‚ï¼ˆä¸€èˆ¬ï¼‰\n",
    "- ä»£ç èƒ½å¤Ÿæ­£å¸¸è¿è¡Œ\n",
    "- å®ç°åŸºæœ¬åŠŸèƒ½\n",
    "- ä»£ç ç»“æ„æ¸…æ™°\n",
    "\n",
    "### è¿›é˜¶è¦æ±‚ï¼ˆè‰¯å¥½ï¼‰\n",
    "- æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†\n",
    "- ä»£ç æ³¨é‡Šå®Œæ•´\n",
    "- æ€§èƒ½ä¼˜åŒ–åˆç†\n",
    "\n",
    "### é«˜çº§è¦æ±‚ï¼ˆä¼˜ç§€ï¼‰\n",
    "- ä»£ç è®¾è®¡ä¼˜é›…\n",
    "- åŠŸèƒ½å®Œæ•´ä¸”å®ç”¨\n",
    "- åŒ…å«æµ‹è¯•ç”¨ä¾‹\n",
    "- æ–‡æ¡£è¯´æ˜è¯¦ç»†\n",
    "\n",
    "## æäº¤è¦æ±‚\n",
    "\n",
    "1. **ä»£ç æ–‡ä»¶**ï¼šå°†ç»ƒä¹ ä»£ç ä¿å­˜ä¸º.pyæ–‡ä»¶\n",
    "2. **è¿è¡Œæˆªå›¾**ï¼šå±•ç¤ºç¨‹åºè¿è¡Œç»“æœ\n",
    "3. **è¯´æ˜æ–‡æ¡£**ï¼šç®€è¦è¯´æ˜å®ç°æ€è·¯å’ŒåŠŸèƒ½ç‰¹ç‚¹\n",
    "4. **é—®é¢˜è®°å½•**ï¼šè®°å½•é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "## å­¦ä¹ èµ„æº\n",
    "\n",
    "- [Pythonå®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/)\n",
    "- [Jupyter Notebookæ•™ç¨‹](https://jupyter-notebook.readthedocs.io/)\n",
    "- [å¤§æ¨¡å‹å¼€å‘æœ€ä½³å®è·µ](https://platform.openai.com/docs)\n",
    "- [Pythonä»£ç è§„èŒƒ](https://pep8.org/)\n",
    "\n",
    "---\n",
    "\n",
    "**å¼€å§‹ä½ çš„å®è·µä¹‹æ—…å§ï¼** è®°ä½ï¼Œç¼–ç¨‹æ˜¯ä¸€é—¨å®è·µæ€§å¾ˆå¼ºçš„æŠ€èƒ½ï¼Œå¤šåŠ¨æ‰‹ç»ƒä¹ æ‰èƒ½çœŸæ­£æŒæ¡ã€‚ğŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjCnQPCvgcrf"
   },
   "source": [
    "## å®è·µä½œä¸šå‚è€ƒå®ç°\n",
    "ä»¥ä¸‹æ˜¯ä¸¤ä¸ªå®è·µä½œä¸šçš„å‚è€ƒå®ç°ä»£ç ã€‚ä½ å¯ä»¥è¿è¡Œè¿™äº›ä»£ç ï¼Œè§‚å¯Ÿè¾“å‡ºç»“æœï¼Œå¹¶å°è¯•ç†è§£ä»£ç é€»è¾‘ã€‚è¿™äº›å®ç°åŒ…å«äº†åŸºç¡€åŠŸèƒ½ã€è¾“å…¥éªŒè¯å’Œé”™è¯¯å¤„ç†ç­‰ï¼Œå¯ä»¥ä½œä¸ºä½ å®Œæˆä½œä¸šçš„èµ·ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b0fe2d0",
    "outputId": "407149f9-1d63-47a2-e6f1-c2d99f139f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ç®€å•çš„èŠå¤©æœºå™¨äººç¤ºä¾‹ ---\n",
      "ç”¨æˆ·: ä½ å¥½\n",
      "æœºå™¨äºº: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "ç”¨æˆ·: è¯·ä»‹ç»ä¸€ä¸‹Python\n",
      "æœºå™¨äºº: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´æ˜“è¯»çš„è¯­æ³•è€Œé—»åï¼Œå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚\n",
      "\n",
      "ç”¨æˆ·: ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ\n",
      "æœºå™¨äºº: æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£ä½ çš„æ„æ€ã€‚ä½ å¯ä»¥é—®æˆ‘â€˜ä½ å¥½â€™ã€â€˜å†è§â€™æˆ–â€˜å¸®åŠ©â€™ã€‚\n",
      "\n",
      "ç”¨æˆ·: \n",
      "é”™è¯¯ï¼šç”¨æˆ·è¾“å…¥å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ã€‚\n",
      "æœºå™¨äºº: è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æœ¬ã€‚\n",
      "\n",
      "ç”¨æˆ·: å†è§\n",
      "æœºå™¨äºº: å†è§ï¼ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼\n",
      "\n",
      "--- å¯¹è¯å†å² ---\n",
      "user: ä½ å¥½\n",
      "assistant: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "user: è¯·ä»‹ç»ä¸€ä¸‹Python\n",
      "assistant: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´æ˜“è¯»çš„è¯­æ³•è€Œé—»åï¼Œå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚\n",
      "user: ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ\n",
      "assistant: æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£ä½ çš„æ„æ€ã€‚ä½ å¯ä»¥é—®æˆ‘â€˜ä½ å¥½â€™ã€â€˜å†è§â€™æˆ–â€˜å¸®åŠ©â€™ã€‚\n",
      "user: \n",
      "assistant: å†è§ï¼ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼\n",
      "user: å†è§\n"
     ]
    }
   ],
   "source": [
    "# ä½œä¸š 1ï¼šæ„å»ºç®€å•çš„èŠå¤©æœºå™¨äººå®ç°\n",
    "\n",
    "class SimpleChatBot:\n",
    "    def __init__(self):\n",
    "        # ä½¿ç”¨å­—å…¸å­˜å‚¨å¯¹è¯å†å²ï¼Œé”®ä¸ºè§’è‰²ï¼Œå€¼ä¸ºæ¶ˆæ¯åˆ—è¡¨\n",
    "        self.conversation_history = {\n",
    "            \"user\": [],\n",
    "            \"assistant\": []\n",
    "        }\n",
    "        # é¢„è®¾å›å¤å­—å…¸\n",
    "        self.responses = {\n",
    "            \"ä½ å¥½\": \"ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\",\n",
    "            \"å†è§\": \"å†è§ï¼ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼\",\n",
    "            \"å¸®åŠ©\": \"æˆ‘å¯ä»¥å›ç­”ä½ çš„é—®é¢˜ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³äº†è§£ä»€ä¹ˆã€‚\",\n",
    "            \"è¯·ä»‹ç»ä¸€ä¸‹python\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´æ˜“è¯»çš„è¯­æ³•è€Œé—»åï¼Œå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚\",\n",
    "            \"é»˜è®¤\": \"æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£ä½ çš„æ„æ€ã€‚ä½ å¯ä»¥é—®æˆ‘â€˜ä½ å¥½â€™ã€â€˜å†è§â€™æˆ–â€˜å¸®åŠ©â€™ã€‚\"\n",
    "        }\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        \"\"\"\n",
    "        å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤\n",
    "        \"\"\"\n",
    "        # 1. å®ç°åŸºæœ¬çš„è¾“å…¥éªŒè¯\n",
    "        if not isinstance(user_input, str) or not user_input.strip():\n",
    "            print(\"é”™è¯¯ï¼šç”¨æˆ·è¾“å…¥å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ã€‚\")\n",
    "            self.conversation_history[\"user\"].append({\"content\": user_input, \"status\": \"invalid\"})\n",
    "            return \"è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æœ¬ã€‚\"\n",
    "\n",
    "        cleaned_input = user_input.strip().lower()\n",
    "        self.conversation_history[\"user\"].append({\"content\": user_input, \"status\": \"valid\"})\n",
    "\n",
    "        # 2. æ·»åŠ é”™è¯¯å¤„ç†æœºåˆ¶ï¼ˆè¿™é‡Œæ¨¡æ‹Ÿç®€å•çš„æŸ¥æ‰¾é”™è¯¯ï¼‰\n",
    "        try:\n",
    "            # 3. æ”¯æŒå¤šç§å›å¤æ¨¡å¼\n",
    "            # å°è¯•åœ¨é¢„è®¾å›å¤ä¸­æŸ¥æ‰¾åŒ¹é…\n",
    "            response_content = self.responses.get(cleaned_input, self.responses[\"é»˜è®¤\"])\n",
    "            response_status = \"success\"\n",
    "\n",
    "        except Exception as e:\n",
    "            response_content = f\"å¤„ç†å›å¤æ—¶å‘ç”Ÿé”™è¯¯: {e}\"\n",
    "            response_status = \"error\"\n",
    "            print(f\"å†…éƒ¨é”™è¯¯: {e}\") # è®°å½•å†…éƒ¨é”™è¯¯æ—¥å¿—\n",
    "\n",
    "        self.conversation_history[\"assistant\"].append({\"content\": response_content, \"status\": response_status})\n",
    "        return response_content\n",
    "\n",
    "    def get_history(self):\n",
    "        \"\"\"\n",
    "        è·å–å®Œæ•´çš„å¯¹è¯å†å²\n",
    "        \"\"\"\n",
    "        # å°†ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯æŒ‰æ—¶é—´é¡ºåºåˆå¹¶ï¼ˆç®€å•åˆå¹¶ï¼Œå®é™…åº”ç”¨éœ€è¦æ—¶é—´æˆ³ï¼‰\n",
    "        history = []\n",
    "        user_msgs = self.conversation_history[\"user\"]\n",
    "        assistant_msgs = self.conversation_history[\"assistant\"]\n",
    "        min_len = min(len(user_msgs), len(assistant_msgs))\n",
    "\n",
    "        for i in range(min_len):\n",
    "            history.append({\"role\": \"user\", \"content\": user_msgs[i][\"content\"]})\n",
    "            history.append({\"role\": \"assistant\", \"content\": assistant_msgs[i][\"content\"]})\n",
    "\n",
    "        # æ·»åŠ å‰©ä½™çš„æ¶ˆæ¯\n",
    "        if len(user_msgs) > len(assistant_msgs):\n",
    "            for i in range(min_len, len(user_msgs)):\n",
    "                 history.append({\"role\": \"user\", \"content\": user_msgs[i][\"content\"]})\n",
    "        elif len(assistant_msgs) > len(user_msgs):\n",
    "             for i in range(min_len, len(assistant_msgs)):\n",
    "                 history.append({\"role\": \"assistant\", \"content\": assistant_msgs[i][\"content\"]})\n",
    "\n",
    "        return history\n",
    "\n",
    "\n",
    "# --- è¿è¡Œç¤ºä¾‹ ---\n",
    "print(\"--- ç®€å•çš„èŠå¤©æœºå™¨äººç¤ºä¾‹ ---\")\n",
    "bot = SimpleChatBot()\n",
    "\n",
    "# è¿›è¡Œä¸€äº›å¯¹è¯\n",
    "print(\"ç”¨æˆ·: ä½ å¥½\")\n",
    "print(\"æœºå™¨äºº:\", bot.chat(\"ä½ å¥½\"))\n",
    "\n",
    "print(\"\\nç”¨æˆ·: è¯·ä»‹ç»ä¸€ä¸‹Python\")\n",
    "print(\"æœºå™¨äºº:\", bot.chat(\"è¯·ä»‹ç»ä¸€ä¸‹Python\"))\n",
    "\n",
    "print(\"\\nç”¨æˆ·: ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ\")\n",
    "print(\"æœºå™¨äºº:\", bot.chat(\"ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ\"))\n",
    "\n",
    "print(\"\\nç”¨æˆ·: \") # æµ‹è¯•ç©ºè¾“å…¥\n",
    "print(\"æœºå™¨äºº:\", bot.chat(\"\"))\n",
    "\n",
    "print(\"\\nç”¨æˆ·: å†è§\")\n",
    "print(\"æœºå™¨äºº:\", bot.chat(\"å†è§\"))\n",
    "\n",
    "# æŸ¥çœ‹å¯¹è¯å†å²\n",
    "print(\"\\n--- å¯¹è¯å†å² ---\")\n",
    "full_history = bot.get_history()\n",
    "for msg in full_history:\n",
    "    print(f\"{msg['role']}: {msg['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12b553d9",
    "outputId": "3d692ed5-fef5-46a3-d8bb-16555dad6efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- API å“åº”æ•°æ®å¤„ç†å™¨ç¤ºä¾‹ ---\n",
      "--- å¼€å§‹å¤„ç†APIå“åº” ---\n",
      "âœ… æˆåŠŸå¤„ç†å“åº” 1\n",
      "âœ… æˆåŠŸå¤„ç†å“åº” 2\n",
      "âœ… æˆåŠŸå¤„ç†å“åº” 3\n",
      "âœ… æˆåŠŸå¤„ç†å“åº” 4\n",
      "âœ… æˆåŠŸå¤„ç†å“åº” 5\n",
      "--- APIå“åº”å¤„ç†å®Œæˆ ---\n",
      "\n",
      "--- API å“åº”å¤„ç†æŠ¥å‘Š ---\n",
      "\n",
      "æ€»å“åº”æ•°: 5\n",
      "æˆåŠŸå¤„ç†æ•°: 5\n",
      "å¤±è´¥å¤„ç†æ•°: 0\n",
      "\n",
      "æ€» Token ä½¿ç”¨é‡: 470\n",
      "å¹³å‡æ¯æ¬¡æˆåŠŸè°ƒç”¨ Token æ•°: 94\n",
      "\n",
      "æ€»é¢„ä¼°æˆæœ¬: $0.0123\n",
      "å¹³å‡æ¯æ¬¡æˆåŠŸè°ƒç”¨æˆæœ¬: $0.0025\n",
      "\n",
      "ä½¿ç”¨çš„æ¨¡å‹: gpt-4, Unknown, gpt-3.5-turbo, claude-3\n",
      "\n",
      "--- è¯¦ç»†å¤„ç†ç»“æœ ---\n",
      "\n",
      "æˆåŠŸå“åº”è¯¦æƒ…:\n",
      "|   response_id | model         | content   |   total_tokens |   prompt_tokens |   completion_tokens |   estimated_cost | status   | error_message   |\n",
      "|--------------:|:--------------|:----------|---------------:|----------------:|--------------------:|-----------------:|:---------|:----------------|\n",
      "|             1 | gpt-3.5-turbo | AI å›å¤ 1 |            100 |              30 |                  70 |          0.00255 | Success  |                 |\n",
      "|             2 | gpt-4         | AI å›å¤ 2 |            250 |              50 |                 200 |          0.00675 | Success  |                 |\n",
      "|             3 | Unknown       | N/A       |              0 |               0 |                   0 |          0       | Success  |                 |\n",
      "|             4 | gpt-3.5-turbo | AI å›å¤ 3 |            120 |              40 |                  80 |          0.003   | Success  |                 |\n",
      "|             5 | claude-3      | AI å›å¤ 4 |              0 |               0 |                   0 |          0       | Success  |                 |\n",
      "æ— å¤±è´¥å“åº”è¯¦æƒ…ã€‚\n",
      "\n",
      "--- è¿›ä¸€æ­¥åˆ†æ ---\n",
      "æŒ‰æ¨¡å‹åˆ†ç»„çš„æ€»tokens:\n",
      "model\n",
      "Unknown            0\n",
      "claude-3           0\n",
      "gpt-3.5-turbo    220\n",
      "gpt-4            250\n",
      "Name: total_tokens, dtype: int64\n",
      "\n",
      "æŒ‰æ¨¡å‹åˆ†ç»„çš„æ€»æˆæœ¬:\n",
      "model\n",
      "Unknown          $0.0000\n",
      "claude-3         $0.0000\n",
      "gpt-3.5-turbo    $0.0055\n",
      "gpt-4            $0.0067\n",
      "Name: estimated_cost, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ä½œä¸š 2ï¼šAPI å“åº”æ•°æ®å¤„ç†å™¨å®ç°\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class APIResponseProcessor:\n",
    "    def __init__(self, api_responses):\n",
    "        # å­˜å‚¨åŸå§‹APIå“åº”åˆ—è¡¨\n",
    "        self.api_responses = api_responses\n",
    "        # å­˜å‚¨å¤„ç†åçš„æ•°æ®åˆ—è¡¨\n",
    "        self.processed_data = []\n",
    "        # å­˜å‚¨é”™è¯¯ä¿¡æ¯\n",
    "        self.errors = []\n",
    "\n",
    "    def process_responses(self):\n",
    "        \"\"\"\n",
    "        è§£æJSONæ ¼å¼çš„APIå“åº”ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œå¹¶å¤„ç†é”™è¯¯\n",
    "        \"\"\"\n",
    "        print(\"--- å¼€å§‹å¤„ç†APIå“åº” ---\")\n",
    "        for i, raw_response in enumerate(self.api_responses):\n",
    "            try:\n",
    "                # 1. è§£æJSONæ ¼å¼çš„APIå“åº”\n",
    "                # å‡è®¾åŸå§‹å“åº”å·²ç»æ˜¯Pythonå­—å…¸ï¼Œå¦‚æœä¸æ˜¯JSONå­—ç¬¦ä¸²ï¼Œéœ€è¦json.loads()\n",
    "                # response_data = json.loads(raw_response)\n",
    "                response_data = raw_response # å‡è®¾raw_responseå·²ç»æ˜¯å­—å…¸\n",
    "\n",
    "                # 2. æå–å…³é”®ä¿¡æ¯ï¼ˆå†…å®¹ã€tokensã€æˆæœ¬ç­‰ï¼‰\n",
    "                # ä½¿ç”¨.get()æ–¹æ³•å®‰å…¨è®¿é—®åµŒå¥—å­—å…¸ï¼Œé¿å…KeyError\n",
    "                content = response_data.get('choices', [{}])[0].get('message', {}).get('content', 'N/A')\n",
    "                usage = response_data.get('usage', {})\n",
    "                total_tokens = usage.get('total_tokens', 0)\n",
    "                prompt_tokens = usage.get('prompt_tokens', 0)\n",
    "                completion_tokens = usage.get('completion_tokens', 0)\n",
    "                model_name = response_data.get('model', 'Unknown')\n",
    "                # å‡è®¾æˆæœ¬ä¿¡æ¯å¯ä»¥ç›´æ¥ä»å“åº”ä¸­è·å–æˆ–æ ¹æ®tokensè®¡ç®—\n",
    "                # è¿™é‡Œæ¨¡æ‹Ÿä¸€ä¸ªæˆæœ¬è®¡ç®—ï¼šå‡è®¾æ¯å®Œæˆtokenæˆæœ¬ä¸º0.00003ç¾å…ƒ\n",
    "                cost = completion_tokens * 0.00003 + prompt_tokens * 0.000015 # ç¤ºä¾‹æˆæœ¬è®¡ç®—\n",
    "\n",
    "                processed_item = {\n",
    "                    \"response_id\": i + 1,\n",
    "                    \"model\": model_name,\n",
    "                    \"content\": content,\n",
    "                    \"total_tokens\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"estimated_cost\": cost,\n",
    "                    \"status\": \"Success\",\n",
    "                    \"error_message\": None\n",
    "                }\n",
    "                self.processed_data.append(processed_item)\n",
    "                print(f\"âœ… æˆåŠŸå¤„ç†å“åº” {i+1}\")\n",
    "\n",
    "            except (json.JSONDecodeError, KeyError, IndexError, Exception) as e:\n",
    "                error_info = {\n",
    "                    \"response_id\": i + 1,\n",
    "                    \"status\": \"Failed\",\n",
    "                    \"error_message\": str(e),\n",
    "                    \"raw_response\": raw_response\n",
    "                }\n",
    "                self.errors.append(error_info)\n",
    "                print(f\"âŒ å¤„ç†å“åº” {i+1} å¤±è´¥: {e}\")\n",
    "\n",
    "        print(\"--- APIå“åº”å¤„ç†å®Œæˆ ---\")\n",
    "        return self.processed_data, self.errors\n",
    "\n",
    "    def calculate_statistics(self):\n",
    "        \"\"\"\n",
    "        è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ€» tokensã€å¹³å‡æˆæœ¬ç­‰ï¼‰\n",
    "        \"\"\"\n",
    "        if not self.processed_data:\n",
    "            return {\n",
    "                \"total_responses\": 0,\n",
    "                \"successful_responses\": 0,\n",
    "                \"failed_responses\": len(self.errors),\n",
    "                \"total_tokens_used\": 0,\n",
    "                \"average_tokens_per_success\": 0,\n",
    "                \"total_estimated_cost\": 0,\n",
    "                \"average_cost_per_success\": 0,\n",
    "                \"models_used\": []\n",
    "            }\n",
    "\n",
    "        successful_count = len(self.processed_data)\n",
    "        total_tokens_used = sum(item['total_tokens'] for item in self.processed_data)\n",
    "        total_estimated_cost = sum(item['estimated_cost'] for item in self.processed_data)\n",
    "        models_used = list(set(item['model'] for item in self.processed_data))\n",
    "\n",
    "        average_tokens_per_success = total_tokens_used / successful_count if successful_count > 0 else 0\n",
    "        average_cost_per_success = total_estimated_cost / successful_count if successful_count > 0 else 0\n",
    "\n",
    "\n",
    "        stats = {\n",
    "            \"total_responses\": len(self.api_responses),\n",
    "            \"successful_responses\": successful_count,\n",
    "            \"failed_responses\": len(self.errors),\n",
    "            \"total_tokens_used\": total_tokens_used,\n",
    "            \"average_tokens_per_success\": average_tokens_per_success,\n",
    "            \"total_estimated_cost\": total_estimated_cost,\n",
    "            \"average_cost_per_success\": average_cost_per_success,\n",
    "            \"models_used\": models_used\n",
    "        }\n",
    "        return stats\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆæ•°æ®æŠ¥å‘Š\n",
    "        \"\"\"\n",
    "        stats = self.calculate_statistics()\n",
    "        report = f\"\"\"\n",
    "--- API å“åº”å¤„ç†æŠ¥å‘Š ---\n",
    "\n",
    "æ€»å“åº”æ•°: {stats['total_responses']}\n",
    "æˆåŠŸå¤„ç†æ•°: {stats['successful_responses']}\n",
    "å¤±è´¥å¤„ç†æ•°: {stats['failed_responses']}\n",
    "\n",
    "æ€» Token ä½¿ç”¨é‡: {stats['total_tokens_used']:,}\n",
    "å¹³å‡æ¯æ¬¡æˆåŠŸè°ƒç”¨ Token æ•°: {stats['average_tokens_per_success']:.0f}\n",
    "\n",
    "æ€»é¢„ä¼°æˆæœ¬: ${stats['total_estimated_cost']:.4f}\n",
    "å¹³å‡æ¯æ¬¡æˆåŠŸè°ƒç”¨æˆæœ¬: ${stats['average_cost_per_success']:.4f}\n",
    "\n",
    "ä½¿ç”¨çš„æ¨¡å‹: {', '.join(stats['models_used'])}\n",
    "\n",
    "--- è¯¦ç»†å¤„ç†ç»“æœ ---\n",
    "\"\"\"\n",
    "        # å°†å¤„ç†ç»“æœè½¬æ¢ä¸ºDataFrameä»¥ä¾¿å±•ç¤º\n",
    "        if self.processed_data:\n",
    "            df = pd.DataFrame(self.processed_data)\n",
    "            report += \"\\næˆåŠŸå“åº”è¯¦æƒ…:\\n\"\n",
    "            report += df.to_markdown(index=False)\n",
    "        else:\n",
    "            report += \"\\næ— æˆåŠŸå“åº”è¯¦æƒ…ã€‚\"\n",
    "\n",
    "        if self.errors:\n",
    "            error_df = pd.DataFrame(self.errors)\n",
    "            report += \"\\n\\nå¤±è´¥å“åº”è¯¦æƒ…:\\n\"\n",
    "            report += error_df.to_markdown(index=False)\n",
    "        else:\n",
    "             report += \"\\næ— å¤±è´¥å“åº”è¯¦æƒ…ã€‚\"\n",
    "\n",
    "\n",
    "        return report\n",
    "\n",
    "# --- è¿è¡Œç¤ºä¾‹ ---\n",
    "print(\"--- API å“åº”æ•°æ®å¤„ç†å™¨ç¤ºä¾‹ ---\")\n",
    "\n",
    "# æ¨¡æ‹Ÿä¸€æ‰¹APIå“åº”æ•°æ®\n",
    "mock_api_responses = [\n",
    "    {\n",
    "        \"choices\": [{\"message\": {\"content\": \"AI å›å¤ 1\"}}],\n",
    "        \"usage\": {\"total_tokens\": 100, \"prompt_tokens\": 30, \"completion_tokens\": 70},\n",
    "        \"model\": \"gpt-3.5-turbo\"\n",
    "    },\n",
    "    {\n",
    "        \"choices\": [{\"message\": {\"content\": \"AI å›å¤ 2\"}}],\n",
    "        \"usage\": {\"total_tokens\": 250, \"prompt_tokens\": 50, \"completion_tokens\": 200},\n",
    "        \"model\": \"gpt-4\"\n",
    "    },\n",
    "    # æ¨¡æ‹Ÿä¸€ä¸ªæ ¼å¼é”™è¯¯çš„å“åº”\n",
    "    {\"invalid_field\": \"this is wrong\"},\n",
    "    {\n",
    "        \"choices\": [{\"message\": {\"content\": \"AI å›å¤ 3\"}}],\n",
    "        \"usage\": {\"total_tokens\": 120, \"prompt_tokens\": 40, \"completion_tokens\": 80},\n",
    "        \"model\": \"gpt-3.5-turbo\"\n",
    "    },\n",
    "     # æ¨¡æ‹Ÿä¸€ä¸ªç¼ºå°‘usageå­—æ®µçš„å“åº”\n",
    "    {\n",
    "        \"choices\": [{\"message\": {\"content\": \"AI å›å¤ 4\"}}],\n",
    "        \"model\": \"claude-3\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# åˆ›å»ºå¤„ç†å™¨å®ä¾‹å¹¶å¤„ç†å“åº”\n",
    "processor = APIResponseProcessor(mock_api_responses)\n",
    "processed_data, errors = processor.process_responses()\n",
    "\n",
    "# ç”Ÿæˆå¹¶æ‰“å°æŠ¥å‘Š\n",
    "report = processor.generate_report()\n",
    "print(report)\n",
    "\n",
    "# è¿›ä¸€æ­¥åˆ†æå¤„ç†åçš„æ•°æ®\n",
    "if processed_data:\n",
    "    print(\"\\n--- è¿›ä¸€æ­¥åˆ†æ ---\")\n",
    "    df_results = pd.DataFrame(processed_data)\n",
    "    print(\"æŒ‰æ¨¡å‹åˆ†ç»„çš„æ€»tokens:\")\n",
    "    print(df_results.groupby('model')['total_tokens'].sum())\n",
    "\n",
    "    print(\"\\næŒ‰æ¨¡å‹åˆ†ç»„çš„æ€»æˆæœ¬:\")\n",
    "    print(df_results.groupby('model')['estimated_cost'].sum().apply(lambda x: f\"${x:.4f}\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
