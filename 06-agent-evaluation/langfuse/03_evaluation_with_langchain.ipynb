{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/evaluation_with_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWL354n0DECo"
   },
   "source": [
    "---\n",
    "åœ¨ Langfuse ä¸Šè¿è¡Œ LangChain è¯„æµ‹\n",
    "\n",
    "æœ¬æŒ‡å—æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨åŸºäºæ¨¡å‹çš„è¯„æµ‹ï¼Œè‡ªåŠ¨åŒ–è¯„ä¼° Langfuse ä¸­çº¿ä¸Šäº§å‡ºçš„ LLM å®Œæˆç»“æœã€‚ç¤ºä¾‹ä½¿ç”¨ LangChainï¼Œäº¦å¯è¿ç§»åˆ°å…¶ä»–åº“ï¼›æœ€ä½³é€‰æ‹©å–å†³äºå…·ä½“åœºæ™¯ã€‚\n",
    "\n",
    "æœ¬æŒ‡å—åˆ†ä¸‰æ­¥ï¼š\n",
    "1. ä» Langfuse è·å–çº¿ä¸Šå­˜å‚¨çš„ `generations`\n",
    "2. ä½¿ç”¨ LangChain å¯¹è¿™äº› `generations` è¿›è¡Œè¯„æµ‹\n",
    "3. å°†ç»“æœä½œä¸º `scores` å›çŒåˆ° Langfuse\n",
    "\n",
    "\n",
    "----\n",
    "è¿˜æœªä½¿ç”¨ Langfuseï¼Ÿé€šè¿‡é‡‡é›† LLM äº‹ä»¶ï¼Œ[ç«‹å³å¼€å§‹](https://langfuse.com/docs/get-started)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbfTYaTkEu3G"
   },
   "source": [
    "### ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "å…ˆç”¨ pip å®‰è£… Langfuse ä¸ LangChainï¼Œç„¶åè®¾ç½®ç¯å¢ƒå˜é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Qclwxd9LRPAL",
    "outputId": "4562f107-0c7d-4f1b-da00-55d40bd587e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse==3.3.0 in /usr/local/lib/python3.12/dist-packages (3.3.0)\n",
      "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai==0.3.31 in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§° å®‰è£…ç¤ºä¾‹æ‰€éœ€çš„æ ¸å¿ƒä¾èµ–åŒ…\n",
    "# ä½¿ç”¨ IPython çš„ %pip é­”æ³•å‘½ä»¤å¯ä»¥åœ¨ notebook å†…ç›´æ¥å®‰è£…ä¾èµ–ï¼Œæ•ˆæœç­‰åŒäºåœ¨ç»ˆç«¯æ‰§è¡Œ `pip install`\n",
    "# - langfuse: Langfuse å¹³å°çš„ Python SDKï¼Œç”¨äºè®°å½•ä¸è¯„æµ‹ LLM åº”ç”¨\n",
    "# - langchain: æ„å»ºå¤§æ¨¡å‹åº”ç”¨çš„ä¸»æ¡†æ¶ï¼Œæä¾›é“¾ã€ä»£ç†ã€å·¥å…·ç­‰æŠ½è±¡\n",
    "# - langchain-openai: LangChain å¯¹ OpenAI ç³»åˆ—æ¨¡å‹çš„å°è£…ï¼Œä¾¿äºç»Ÿä¸€è°ƒç”¨æ¥å£\n",
    "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRKSP2mWFUL4",
    "outputId": "45080dd4-0d5d-44df-97ec-9782ff2297d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGFUSE_PUBLIC_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_SECRET_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_HOST: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒå˜é‡é…ç½®ï¼šå°†æ•æ„Ÿå‡­æ®å®‰å…¨åœ°æ³¨å…¥è¿è¡Œç¯å¢ƒ\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"æç¤ºç”¨æˆ·è¾“å…¥ç¼ºå¤±çš„ç¯å¢ƒå˜é‡ï¼Œé¿å…æŠŠå¯†é’¥ç¡¬ç¼–ç åˆ°ç¬”è®°æœ¬ä¸­ã€‚\"\"\"\n",
    "    # å½“ç¯å¢ƒå˜é‡å°šæœªé…ç½®æ—¶ï¼Œæç¤ºç”¨æˆ·åœ¨æ§åˆ¶å°è¾“å…¥ï¼›getpass ä¼šéšè—è¾“å…¥å†…å®¹ã€‚\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# ğŸ—ï¸ OpenAI API é…ç½® â€”â€” è¯„æµ‹é˜¶æ®µéœ€è¦è°ƒç”¨ä¸€ä¸ªè¯„ä¼°ç”¨çš„ LLM\n",
    "# è¯·åœ¨ https://platform.openai.com/api-keys ç”³è¯·å¯†é’¥åï¼Œåœ¨æ­¤è¾“å…¥ã€‚\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ğŸŒ OpenAI ä»£ç†åœ°å€ï¼ˆå¯é€‰ï¼‰â€”â€” å¦‚æœä½ æ‰€åœ¨ç½‘ç»œæ— æ³•ç›´æ¥è®¿é—® OpenAIï¼Œå¯åœ¨æ­¤å¡«å†™ä»£ç†ç½‘å…³\n",
    "# å¸¸è§æ ¼å¼å¦‚ https://api.xxx.com/v1ï¼›è‹¥æ— éœ€ä»£ç†å¯ç›´æ¥å›è½¦è·³è¿‡ã€‚\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# ğŸ›°ï¸ Langfuse å¹³å°é…ç½® â€”â€” ç”¨äºæ‰˜ç®¡ä¸å›æ”¾è¯„æµ‹æ•°æ®\n",
    "# æ‰€æœ‰å¯†é’¥å‡å¯åœ¨ https://cloud.langfuse.com çš„é¡¹ç›®è®¾ç½®é¡µé¢æ‰¾åˆ°ã€‚\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")   # å…¬é’¥ï¼šæ ‡è¯†é¡¹ç›®èº«ä»½\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")   # ç§é’¥ï¼šç”¨äºèº«ä»½è®¤è¯ï¼Œè¯·å‹¿æ³„éœ²\n",
    "_set_env(\"LANGFUSE_HOST\")         # æœåŠ¡åœ°å€ï¼šEU åŒºåŸŸ https://cloud.langfuse.comï¼›US åŒºåŸŸ https://us.cloud.langfuse.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQhmQQpLRa1K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# âš™ï¸ æŒ‡å®šåœ¨è¯„æµ‹é˜¶æ®µè¦ä½¿ç”¨çš„ LLM åç§°\n",
    "# è¿™é‡Œé»˜è®¤é‡‡ç”¨ \"gpt-3.5-turbo-instruct\"ï¼Œä½ ä¹Ÿå¯ä»¥æŒ‰éœ€åˆ‡æ¢ä¸º gpt-4 ç­‰æ›´å¼ºæ¨¡å‹ï¼ˆæˆæœ¬æ›´é«˜ï¼‰ã€‚\n",
    "os.environ[\"EVAL_MODEL\"] = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "# ğŸ—‚ï¸ é…ç½® LangChain å†…ç½®çš„å¤šç»´åº¦è¯„æµ‹å¼€å…³\n",
    "# å°†è¦å¯ç”¨çš„è¯„æµ‹ç»´åº¦è®¾ç½®ä¸º Trueï¼›False è¡¨ç¤ºè·³è¿‡è¯¥æŒ‡æ ‡ã€‚\n",
    "EVAL_TYPES = {\n",
    "    \"hallucination\": True,   # å¹»è§‰ï¼šè¾“å‡ºæ˜¯å¦åŒ…å«è¾“å…¥æˆ–å‚è€ƒä¸­ä¸å­˜åœ¨çš„è™šå‡ä¿¡æ¯\n",
    "    \"conciseness\": True,     # ç®€æ´æ€§ï¼šå›ç­”æ˜¯å¦è¨€ç®€æ„èµ…ã€é¿å…å†—ä½™\n",
    "    \"relevance\": True,       # ç›¸å…³æ€§ï¼šå›ç­”æ˜¯å¦ç´§æ‰£æé—®æˆ–ä»»åŠ¡\n",
    "    \"coherence\": True,       # è¿è´¯æ€§ï¼šæ®µè½ç»„ç»‡æ˜¯å¦é¡ºç•…ã€é€»è¾‘æ˜¯å¦è‡ªæ´½\n",
    "    \"harmfulness\": True,     # æœ‰å®³æ€§ï¼šæ˜¯å¦å‡ºç°å±é™©ã€ä¼¤å®³æˆ–ä¸å½“å†…å®¹\n",
    "    \"maliciousness\": True,   # æ¶æ„æ€§ï¼šæ˜¯å¦æœ‰æ¶æ„æ„å›¾ï¼Œä¾‹å¦‚ç…½åŠ¨æ”»å‡»\n",
    "    \"helpfulness\": True,     # æœ‰ç”¨æ€§ï¼šå›ç­”æ˜¯å¦æä¾›å®è´¨æ€§å¸®åŠ©\n",
    "    \"controversiality\": True,# äº‰è®®æ€§ï¼šæ˜¯å¦åŒ…å«æ˜“å¼•å‘äº‰è®®æˆ–æç«¯è§‚ç‚¹\n",
    "    \"misogyny\": True,        # æ€§åˆ«æ­§è§†ï¼šæ˜¯å¦å…·æœ‰æ­§è§†å¥³æ€§çš„è¨€è®º\n",
    "    \"criminality\": True,     # çŠ¯ç½ªæ€§ï¼šæ˜¯å¦é¼“åŠ±æˆ–æè¿°çŠ¯ç½ªè¡Œä¸º\n",
    "    \"insensitivity\": True    # ä¸æ•æ„Ÿæ€§ï¼šæ˜¯å¦å¯¹æ•æ„Ÿç¾¤ä½“ã€äº‹ä»¶ç¼ºä¹å°Šé‡\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yiwrz1-mavJ4"
   },
   "source": [
    "åˆå§‹åŒ– Langfuse Python SDKï¼Œæ›´å¤šä¿¡æ¯è§[æ­¤å¤„](https://langfuse.com/docs/sdk/python#1-installation)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8viV4KT5RMjA",
    "outputId": "36dba82a-2a90-4f07-abe9-2b0b2371cea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse å®¢æˆ·ç«¯å·²é€šè¿‡è®¤è¯ï¼Œå‡†å¤‡å°±ç»ªï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¡ è¿æ¥ Langfuse å¹³å°ä»¥è¯»å–è¯„æµ‹æ ·æœ¬\n",
    "from langfuse import get_client\n",
    "\n",
    "# Langfuse å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨è¯»å–åˆšæ‰è®¾ç½®çš„ç¯å¢ƒå˜é‡å®Œæˆè®¤è¯\n",
    "langfuse = get_client()\n",
    "\n",
    "# âœ… å¿«é€Ÿå¥åº·æ£€æŸ¥ï¼šç¡®ä¿å¯†é’¥ä¸ç½‘ç»œé…ç½®æ­£ç¡®\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse å®¢æˆ·ç«¯å·²é€šè¿‡è®¤è¯ï¼Œå‡†å¤‡å°±ç»ªï¼\")\n",
    "    print(\"ç°åœ¨å¯ä»¥å¼€å§‹ä» Langfuse è·å–æ•°æ®å¹¶è¿›è¡Œè¯„æµ‹\")\n",
    "else:\n",
    "    print(\"è®¤è¯å¤±è´¥ã€‚è¯·æ£€æŸ¥ä»¥ä¸‹è®¾ç½®ï¼š\")\n",
    "    print(\"- LANGFUSE_PUBLIC_KEY / LANGFUSE_SECRET_KEY æ˜¯å¦å¡«å†™æ­£ç¡®\")\n",
    "    print(\"- LANGFUSE_HOST æ˜¯å¦æŒ‡å‘æ­£ç¡®çš„åŒºåŸŸ (EU / US)\")\n",
    "    print(\"- å½“å‰ç½‘ç»œæ˜¯å¦å¯ä»¥è®¿é—®å¯¹åº”çš„ Langfuse æœåŠ¡\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjMZ1VLhF2Vv"
   },
   "source": [
    "### æ‹‰å–æ•°æ®\n",
    "\n",
    "æ ¹æ® `name` ä» Langfuse è½½å…¥æ‰€æœ‰ `generations`ï¼Œæ­¤å¤„ç¤ºä¾‹ä¸º `OpenAI`ã€‚åœ¨ Langfuse ä¸­ï¼Œ`name` ç”¨äºæ ‡è¯†åº”ç”¨å†…ä¸åŒç±»å‹çš„ç”Ÿæˆã€‚å°†å…¶æ›¿æ¢ä¸ºä½ éœ€è¦è¯„æµ‹çš„åç§°ã€‚\n",
    "\n",
    "å…³äºåœ¨å†™å…¥ LLM Generation æ—¶å¦‚ä½•è®¾ç½® `name`ï¼Œå‚è§[æ–‡æ¡£](https://langfuse.com/docs/sdk/python#generation)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r3jOEX0RvXi"
   },
   "outputs": [],
   "source": [
    "def fetch_all_pages(name=None, user_id=None, limit=50):\n",
    "    \"\"\"ä» Langfuse åˆ†é¡µæ‹‰å– trace æ•°æ®ï¼Œç›´åˆ°æ‹¿é½æ‰€æœ‰ç»“æœã€‚\"\"\"\n",
    "    page = 1            # Langfuse API çš„é¡µç ä» 1 èµ·æ­¥\n",
    "    all_data = []       # ç”¨åˆ—è¡¨æ”¶é›†æ¯ä¸€é¡µè¿”å›çš„æ•°æ®\n",
    "\n",
    "    while True:\n",
    "        # é€šè¿‡ SDK è°ƒç”¨åç«¯æ¥å£ã€‚å¯ä»¥é™„åŠ  name / user_id è¿‡æ»¤æ¡ä»¶ï¼Œlimit æ§åˆ¶å•é¡µå¤§å°ã€‚\n",
    "        response = langfuse.api.trace.list(name=name, limit=limit, user_id=user_id, page=page)\n",
    "\n",
    "        # å½“æŸä¸€é¡µæ²¡æœ‰æ•°æ®æ—¶ï¼Œè¯´æ˜éå†å®Œæ¯•ï¼Œè·³å‡ºå¾ªç¯ã€‚\n",
    "        if not response.data:\n",
    "            break\n",
    "\n",
    "        # å°†å½“å‰é¡µçš„æ‰€æœ‰ trace è¿½åŠ åˆ°ç»“æœåˆ—è¡¨ä¸­\n",
    "        all_data.extend(response.data)\n",
    "        page += 1  # è‡ªå¢é¡µç ï¼Œç»§ç»­è¯·æ±‚ä¸‹ä¸€é¡µ\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAnLShvjBDBU"
   },
   "outputs": [],
   "source": [
    "# ğŸ“¥ è°ƒç”¨è‡ªå®šä¹‰å·¥å…·ï¼Œæ‹‰å–æŒ‡å®šç”¨æˆ·çš„å…¨éƒ¨ trace\n",
    "# è¿™é‡Œä»¥ user_id='user_123' ä¸ºä¾‹ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±ä¸šåŠ¡é‡Œè®°å½•çš„ç”¨æˆ·æ ‡è¯†ã€‚\n",
    "generations = fetch_all_pages(user_id='user_123')\n",
    "\n",
    "print(f\"æˆåŠŸè·å–åˆ° {len(generations)} æ¡ trace æ•°æ®\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTS1P1O2dm3I",
    "outputId": "3c131bed-36bf-4db9-e2e0-541bb9864f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” å¿«é€Ÿæµè§ˆæ‹‰å–åˆ°çš„åŸå§‹æ•°æ®ç»“æ„ï¼Œå¸®åŠ©ç†è§£åç»­å­—æ®µçš„æ¥æº\n",
    "def _print_generations_preview(items):\n",
    "    if not items:\n",
    "        print()  # åˆ†éš”æç¤ºä¿¡æ¯\n",
    "        print(\"âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• trace æ•°æ®ï¼è¯·æ£€æŸ¥ä¸‹åˆ—äº‹é¡¹ï¼š\")\n",
    "        print(\"1. user_id æ˜¯å¦å¡«å†™æ­£ç¡®\")\n",
    "        print(\"2. Langfuse é¡¹ç›®ä¸­æ˜¯å¦å·²æœ‰ç”Ÿæˆè®°å½•\")\n",
    "        print(\"3. å½“å‰ç½‘ç»œèƒ½å¦è®¿é—® Langfuse\")\n",
    "        return\n",
    "\n",
    "    print(\"è·å–åˆ°çš„ trace æ•°æ®ç¤ºä¾‹ (ä»…å±•ç¤ºå‰ 3 æ¡)ï¼š\")\n",
    "    for item in items[:3]:\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"trace_id: {item.id}\")\n",
    "        print(f\"input: {item.input}\")\n",
    "        print(f\"output: {item.output}\")\n",
    "        print(f\"timestamp: {item.timestamp}\")\n",
    "\n",
    "_print_generations_preview(generations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "jmiO90n_QjiS",
    "outputId": "4f2e6e2f-0c72-4660-e436-ce4230b8c8b4"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4056371054.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ğŸ†” ç¤ºä¾‹ï¼šæŸ¥çœ‹ç¬¬ä¸€æ¡ trace çš„å”¯ä¸€ IDï¼Œå¯åœ¨ Langfuse å‰ç«¯ç”¨å®ƒå®šä½è®°å½•\n",
    "# ä»…å½“æˆåŠŸæ‹‰å–åˆ°æ•°æ®åå†è®¿é—®åˆ—è¡¨å…ƒç´ ï¼Œé¿å… IndexErrorã€‚\n",
    "if generations:\n",
    "    generations[0].id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYM6UG_dGbb6"
   },
   "source": [
    "### å®šä¹‰è¯„æµ‹å‡½æ•°\n",
    "\n",
    "æœ¬èŠ‚åŸºäº `EVAL_TYPES` å®šä¹‰ LangChain è¯„æµ‹å™¨ï¼›å…¶ä¸­â€œå¹»è§‰â€ï¼ˆhallucinationï¼‰éœ€è¦å•ç‹¬å‡½æ•°ã€‚å…³äº LangChain è¯„æµ‹çš„æ›´å¤šä¿¡æ¯è§[æ­¤å¤„](https://python.langchain.com/docs/guides/evaluation/string/criteria_eval_chain)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NijTmslvyK8"
   },
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ å¯¼å…¥ LangChain è¯„æµ‹å·¥å…·ä¸ OpenAI æ¨¡å‹å°è£…\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain.evaluation.criteria import LabeledCriteriaEvalChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "def get_evaluator_for_key(key: str):\n",
    "    \"\"\"ä¸ºæŒ‡å®šçš„è¯„æµ‹ç»´åº¦åŠ è½½ LangChain å†…ç½®è¯„æµ‹å™¨ã€‚\"\"\"\n",
    "    # temperature è®¾ä¸º 0 ä»¥è·å¾—ç¡®å®šæ€§æ›´é«˜çš„è¯„æµ‹ç»“æœã€‚\n",
    "    llm = OpenAI(temperature=0, model=os.environ.get(\"EVAL_MODEL\"))\n",
    "    # load_evaluator ä¼šè¿”å›ä¸€ä¸ªå¯ç›´æ¥è°ƒç”¨çš„è¯„æµ‹é“¾å¯¹è±¡ã€‚\n",
    "    return load_evaluator(\"criteria\", criteria=key, llm=llm)\n",
    "\n",
    "\n",
    "def get_hallucination_eval():\n",
    "    \"\"\"å•ç‹¬æ„å»ºâ€œå¹»è§‰â€ç»´åº¦çš„è¯„æµ‹é“¾ï¼ˆHallucination éœ€è¦å‚è€ƒæ–‡æœ¬ï¼‰ã€‚\"\"\"\n",
    "    criteria = {\n",
    "        \"hallucination\": (\n",
    "            \"Does this submission contain information not present in the input or reference?\"\n",
    "        )\n",
    "    }\n",
    "    llm = OpenAI(temperature=0, model=os.environ.get(\"EVAL_MODEL\"))\n",
    "    return LabeledCriteriaEvalChain.from_llm(llm=llm, criteria=criteria)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzZZfztGdrIQ"
   },
   "source": [
    "### æ‰§è¡Œè¯„æµ‹\n",
    "\n",
    "ä¸‹é¢å°†å¯¹ä¸Šé¢è½½å…¥çš„æ¯ä¸ª `Generation` æ‰§è¡Œè¯„æµ‹ã€‚æ¯ä¸ªå¾—åˆ†å°†é€šè¿‡ [`langfuse.score()`](https://langfuse.com/docs/scores) å†™å› Langfuseã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMa2OEtqvyGg"
   },
   "outputs": [],
   "source": [
    "def execute_eval_and_score():\n",
    "    \"\"\"éå†æ‰€æœ‰ traceï¼Œé’ˆå¯¹å¼€å¯çš„è¯„æµ‹ç»´åº¦é€é¡¹æ‰“åˆ†ã€‚\"\"\"\n",
    "\n",
    "    for generation in generations:\n",
    "        # è¿‡æ»¤å‡ºæ‰€æœ‰å¼€å¯çš„è¯„æµ‹ç»´åº¦ï¼ˆé™¤ hallucination å¤–ï¼Œåè€…å•ç‹¬å¤„ç†ï¼‰\n",
    "        criteria = [key for key, enabled in EVAL_TYPES.items() if enabled and key != \"hallucination\"]\n",
    "\n",
    "        for criterion in criteria:\n",
    "            # evaluate_strings ä¼šè¿”å›ä¸€ä¸ªåŒ…å« score ä¸ reasoning çš„å­—å…¸\n",
    "            eval_result = get_evaluator_for_key(criterion).evaluate_strings(\n",
    "                prediction=generation.output,\n",
    "                input=generation.input,\n",
    "            )\n",
    "            print(eval_result)\n",
    "\n",
    "            # å°†è¯„æµ‹å¾—åˆ†å†™å› Langfuseï¼Œtrace_id / observation_id å¯ç”¨äºåç»­å›æ”¾\n",
    "            langfuse.create_score(\n",
    "                name=criterion,\n",
    "                trace_id=generation.id,\n",
    "                observation_id=generation.id,\n",
    "                value=eval_result[\"score\"],\n",
    "                comment=eval_result[\"reasoning\"],\n",
    "            )\n",
    "\n",
    "\n",
    "execute_eval_and_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcTF-z8eeL0a"
   },
   "outputs": [],
   "source": [
    "# ğŸ¯ å¹»è§‰ï¼ˆhallucinationï¼‰è¯„æµ‹éœ€è¦é¢å¤–ä¼ å…¥å‚è€ƒæ–‡æœ¬ï¼Œè¿™é‡Œå•ç‹¬å¤„ç†\n",
    "\n",
    "def eval_hallucination():\n",
    "    chain = get_hallucination_eval()\n",
    "\n",
    "    for generation in generations:\n",
    "        eval_result = chain.evaluate_strings(\n",
    "            prediction=generation.output,\n",
    "            input=generation.input,\n",
    "            reference=generation.input,  # ç®€å•ç¤ºä¾‹ï¼šä»¥åŸå§‹è¾“å…¥ä½œä¸ºå‚è€ƒæ–‡æœ¬\n",
    "        )\n",
    "        print(eval_result)\n",
    "\n",
    "        if (\n",
    "            eval_result is not None\n",
    "            and eval_result.get(\"score\") is not None\n",
    "            and eval_result.get(\"reasoning\") is not None\n",
    "        ):\n",
    "            langfuse.create_score(\n",
    "                name=\"hallucination\",\n",
    "                trace_id=generation.id,\n",
    "                observation_id=generation.id,\n",
    "                value=eval_result[\"score\"],\n",
    "                comment=eval_result[\"reasoning\"],\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4zeFEKlfjQ-"
   },
   "outputs": [],
   "source": [
    "# âœ… æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ‰§è¡Œå¹»è§‰è¯„æµ‹\n",
    "if EVAL_TYPES.get(\"hallucination\"):\n",
    "    eval_hallucination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ROOd8d8rdl6"
   },
   "outputs": [],
   "source": [
    "# ğŸ“¤ Langfuse Python SDK å†…éƒ¨ä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—å‘é€æ•°æ®ï¼Œè¿™é‡Œæ‰‹åŠ¨ flush ä»¥ç¡®ä¿æ‰€æœ‰æ‰“åˆ†å·²å†™å…¥æœåŠ¡ç«¯\n",
    "langfuse.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsKpVyYdavJ5"
   },
   "source": [
    "### åœ¨ Langfuse ä¸­æŸ¥çœ‹åˆ†æ•°\n",
    "\n",
    "åœ¨ Langfuse ç•Œé¢ä¸­ï¼Œä½ å¯ä»¥æŒ‰ `Scores` è¿‡æ»¤ Tracesï¼Œå¹¶æŸ¥çœ‹æ¯æ¡çš„è¯¦ç»†ä¿¡æ¯ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ Langfuse Analytics åˆ†ææ–°æç¤ºè¯ç‰ˆæœ¬æˆ–åº”ç”¨å‘å¸ƒå¯¹è¿™äº›åˆ†æ•°çš„å½±å“ã€‚\n",
    "\n",
    "![Trace ç¤ºä¾‹](https://langfuse.com/images/docs/trace-conciseness-score.jpg)\n",
    "_åŒ…å«ç®€æ´æ€§ï¼ˆconcisenessï¼‰åˆ†æ•°çš„ç¤ºä¾‹ Trace_\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}