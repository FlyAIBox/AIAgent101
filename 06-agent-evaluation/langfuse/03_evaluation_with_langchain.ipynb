{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/evaluation_with_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWL354n0DECo"
   },
   "source": [
    "---\n",
    "在 Langfuse 上运行 LangChain 评测\n",
    "\n",
    "本指南演示如何使用基于模型的评测，自动化评估 Langfuse 中线上产出的 LLM 完成结果。示例使用 LangChain，亦可迁移到其他库；最佳选择取决于具体场景。\n",
    "\n",
    "本指南分三步：\n",
    "1. 从 Langfuse 获取线上存储的 `generations`\n",
    "2. 使用 LangChain 对这些 `generations` 进行评测\n",
    "3. 将结果作为 `scores` 回灌到 Langfuse\n",
    "\n",
    "\n",
    "----\n",
    "还未使用 Langfuse？通过采集 LLM 事件，[立即开始](https://langfuse.com/docs/get-started)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbfTYaTkEu3G"
   },
   "source": [
    "### 环境准备\n",
    "\n",
    "先用 pip 安装 Langfuse 与 LangChain，然后设置环境变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Qclwxd9LRPAL",
    "outputId": "4562f107-0c7d-4f1b-da00-55d40bd587e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse==3.3.0 in /usr/local/lib/python3.12/dist-packages (3.3.0)\n",
      "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai==0.3.31 in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# 🧰 安装示例所需的核心依赖包\n",
    "# 使用 IPython 的 %pip 魔法命令可以在 notebook 内直接安装依赖，效果等同于在终端执行 `pip install`\n",
    "# - langfuse: Langfuse 平台的 Python SDK，用于记录与评测 LLM 应用\n",
    "# - langchain: 构建大模型应用的主框架，提供链、代理、工具等抽象\n",
    "# - langchain-openai: LangChain 对 OpenAI 系列模型的封装，便于统一调用接口\n",
    "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRKSP2mWFUL4",
    "outputId": "45080dd4-0d5d-44df-97ec-9782ff2297d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGFUSE_PUBLIC_KEY: ··········\n",
      "LANGFUSE_SECRET_KEY: ··········\n",
      "LANGFUSE_HOST: ··········\n"
     ]
    }
   ],
   "source": [
    "# 🔐 环境变量配置：将敏感凭据安全地注入运行环境\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"提示用户输入缺失的环境变量，避免把密钥硬编码到笔记本中。\"\"\"\n",
    "    # 当环境变量尚未配置时，提示用户在控制台输入；getpass 会隐藏输入内容。\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# 🗝️ OpenAI API 配置 —— 评测阶段需要调用一个评估用的 LLM\n",
    "# 请在 https://platform.openai.com/api-keys 申请密钥后，在此输入。\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 🌐 OpenAI 代理地址（可选）—— 如果你所在网络无法直接访问 OpenAI，可在此填写代理网关\n",
    "# 常见格式如 https://api.xxx.com/v1；若无需代理可直接回车跳过。\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 🛰️ Langfuse 平台配置 —— 用于托管与回放评测数据\n",
    "# 所有密钥均可在 https://cloud.langfuse.com 的项目设置页面找到。\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")   # 公钥：标识项目身份\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")   # 私钥：用于身份认证，请勿泄露\n",
    "_set_env(\"LANGFUSE_HOST\")         # 服务地址：EU 区域 https://cloud.langfuse.com；US 区域 https://us.cloud.langfuse.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQhmQQpLRa1K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ⚙️ 指定在评测阶段要使用的 LLM 名称\n",
    "# 这里默认采用 \"gpt-3.5-turbo-instruct\"，你也可以按需切换为 gpt-4 等更强模型（成本更高）。\n",
    "os.environ[\"EVAL_MODEL\"] = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "# 🗂️ 配置 LangChain 内置的多维度评测开关\n",
    "# 将要启用的评测维度设置为 True；False 表示跳过该指标。\n",
    "EVAL_TYPES = {\n",
    "    \"hallucination\": True,   # 幻觉：输出是否包含输入或参考中不存在的虚假信息\n",
    "    \"conciseness\": True,     # 简洁性：回答是否言简意赅、避免冗余\n",
    "    \"relevance\": True,       # 相关性：回答是否紧扣提问或任务\n",
    "    \"coherence\": True,       # 连贯性：段落组织是否顺畅、逻辑是否自洽\n",
    "    \"harmfulness\": True,     # 有害性：是否出现危险、伤害或不当内容\n",
    "    \"maliciousness\": True,   # 恶意性：是否有恶意意图，例如煽动攻击\n",
    "    \"helpfulness\": True,     # 有用性：回答是否提供实质性帮助\n",
    "    \"controversiality\": True,# 争议性：是否包含易引发争议或极端观点\n",
    "    \"misogyny\": True,        # 性别歧视：是否具有歧视女性的言论\n",
    "    \"criminality\": True,     # 犯罪性：是否鼓励或描述犯罪行为\n",
    "    \"insensitivity\": True    # 不敏感性：是否对敏感群体、事件缺乏尊重\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yiwrz1-mavJ4"
   },
   "source": [
    "初始化 Langfuse Python SDK，更多信息见[此处](https://langfuse.com/docs/sdk/python#1-installation)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8viV4KT5RMjA",
    "outputId": "36dba82a-2a90-4f07-abe9-2b0b2371cea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse 客户端已通过认证，准备就绪！\n"
     ]
    }
   ],
   "source": [
    "# 📡 连接 Langfuse 平台以读取评测样本\n",
    "from langfuse import get_client\n",
    "\n",
    "# Langfuse 客户端会自动读取刚才设置的环境变量完成认证\n",
    "langfuse = get_client()\n",
    "\n",
    "# ✅ 快速健康检查：确保密钥与网络配置正确\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse 客户端已通过认证，准备就绪！\")\n",
    "    print(\"现在可以开始从 Langfuse 获取数据并进行评测\")\n",
    "else:\n",
    "    print(\"认证失败。请检查以下设置：\")\n",
    "    print(\"- LANGFUSE_PUBLIC_KEY / LANGFUSE_SECRET_KEY 是否填写正确\")\n",
    "    print(\"- LANGFUSE_HOST 是否指向正确的区域 (EU / US)\")\n",
    "    print(\"- 当前网络是否可以访问对应的 Langfuse 服务\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjMZ1VLhF2Vv"
   },
   "source": [
    "### 拉取数据\n",
    "\n",
    "根据 `name` 从 Langfuse 载入所有 `generations`，此处示例为 `OpenAI`。在 Langfuse 中，`name` 用于标识应用内不同类型的生成。将其替换为你需要评测的名称。\n",
    "\n",
    "关于在写入 LLM Generation 时如何设置 `name`，参见[文档](https://langfuse.com/docs/sdk/python#generation)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r3jOEX0RvXi"
   },
   "outputs": [],
   "source": [
    "def fetch_all_pages(name=None, user_id=None, limit=50):\n",
    "    \"\"\"从 Langfuse 分页拉取 trace 数据，直到拿齐所有结果。\"\"\"\n",
    "    page = 1            # Langfuse API 的页码从 1 起步\n",
    "    all_data = []       # 用列表收集每一页返回的数据\n",
    "\n",
    "    while True:\n",
    "        # 通过 SDK 调用后端接口。可以附加 name / user_id 过滤条件，limit 控制单页大小。\n",
    "        response = langfuse.api.trace.list(name=name, limit=limit, user_id=user_id, page=page)\n",
    "\n",
    "        # 当某一页没有数据时，说明遍历完毕，跳出循环。\n",
    "        if not response.data:\n",
    "            break\n",
    "\n",
    "        # 将当前页的所有 trace 追加到结果列表中\n",
    "        all_data.extend(response.data)\n",
    "        page += 1  # 自增页码，继续请求下一页\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAnLShvjBDBU"
   },
   "outputs": [],
   "source": [
    "# 📥 调用自定义工具，拉取指定用户的全部 trace\n",
    "# 这里以 user_id='user_123' 为例，实际使用时请替换为你自己业务里记录的用户标识。\n",
    "generations = fetch_all_pages(user_id='user_123')\n",
    "\n",
    "print(f\"成功获取到 {len(generations)} 条 trace 数据\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTS1P1O2dm3I",
    "outputId": "3c131bed-36bf-4db9-e2e0-541bb9864f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 🔎 快速浏览拉取到的原始数据结构，帮助理解后续字段的来源\n",
    "def _print_generations_preview(items):\n",
    "    if not items:\n",
    "        print()  # 分隔提示信息\n",
    "        print(\"⚠️ 没有找到任何 trace 数据！请检查下列事项：\")\n",
    "        print(\"1. user_id 是否填写正确\")\n",
    "        print(\"2. Langfuse 项目中是否已有生成记录\")\n",
    "        print(\"3. 当前网络能否访问 Langfuse\")\n",
    "        return\n",
    "\n",
    "    print(\"获取到的 trace 数据示例 (仅展示前 3 条)：\")\n",
    "    for item in items[:3]:\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"trace_id: {item.id}\")\n",
    "        print(f\"input: {item.input}\")\n",
    "        print(f\"output: {item.output}\")\n",
    "        print(f\"timestamp: {item.timestamp}\")\n",
    "\n",
    "_print_generations_preview(generations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "jmiO90n_QjiS",
    "outputId": "4f2e6e2f-0c72-4660-e436-ce4230b8c8b4"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4056371054.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 🆔 示例：查看第一条 trace 的唯一 ID，可在 Langfuse 前端用它定位记录\n",
    "# 仅当成功拉取到数据后再访问列表元素，避免 IndexError。\n",
    "if generations:\n",
    "    generations[0].id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYM6UG_dGbb6"
   },
   "source": [
    "### 定义评测函数\n",
    "\n",
    "本节基于 `EVAL_TYPES` 定义 LangChain 评测器；其中“幻觉”（hallucination）需要单独函数。关于 LangChain 评测的更多信息见[此处](https://python.langchain.com/docs/guides/evaluation/string/criteria_eval_chain)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NijTmslvyK8"
   },
   "outputs": [],
   "source": [
    "# 🛠️ 导入 LangChain 评测工具与 OpenAI 模型封装\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain.evaluation.criteria import LabeledCriteriaEvalChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "def get_evaluator_for_key(key: str):\n",
    "    \"\"\"为指定的评测维度加载 LangChain 内置评测器。\"\"\"\n",
    "    # temperature 设为 0 以获得确定性更高的评测结果。\n",
    "    llm = OpenAI(temperature=0, model=os.environ.get(\"EVAL_MODEL\"))\n",
    "    # load_evaluator 会返回一个可直接调用的评测链对象。\n",
    "    return load_evaluator(\"criteria\", criteria=key, llm=llm)\n",
    "\n",
    "\n",
    "def get_hallucination_eval():\n",
    "    \"\"\"单独构建“幻觉”维度的评测链（Hallucination 需要参考文本）。\"\"\"\n",
    "    criteria = {\n",
    "        \"hallucination\": (\n",
    "            \"Does this submission contain information not present in the input or reference?\"\n",
    "        )\n",
    "    }\n",
    "    llm = OpenAI(temperature=0, model=os.environ.get(\"EVAL_MODEL\"))\n",
    "    return LabeledCriteriaEvalChain.from_llm(llm=llm, criteria=criteria)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzZZfztGdrIQ"
   },
   "source": [
    "### 执行评测\n",
    "\n",
    "下面将对上面载入的每个 `Generation` 执行评测。每个得分将通过 [`langfuse.score()`](https://langfuse.com/docs/scores) 写回 Langfuse。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMa2OEtqvyGg"
   },
   "outputs": [],
   "source": [
    "def execute_eval_and_score():\n",
    "    \"\"\"遍历所有 trace，针对开启的评测维度逐项打分。\"\"\"\n",
    "\n",
    "    for generation in generations:\n",
    "        # 过滤出所有开启的评测维度（除 hallucination 外，后者单独处理）\n",
    "        criteria = [key for key, enabled in EVAL_TYPES.items() if enabled and key != \"hallucination\"]\n",
    "\n",
    "        for criterion in criteria:\n",
    "            # evaluate_strings 会返回一个包含 score 与 reasoning 的字典\n",
    "            eval_result = get_evaluator_for_key(criterion).evaluate_strings(\n",
    "                prediction=generation.output,\n",
    "                input=generation.input,\n",
    "            )\n",
    "            print(eval_result)\n",
    "\n",
    "            # 将评测得分写回 Langfuse，trace_id / observation_id 可用于后续回放\n",
    "            langfuse.create_score(\n",
    "                name=criterion,\n",
    "                trace_id=generation.id,\n",
    "                observation_id=generation.id,\n",
    "                value=eval_result[\"score\"],\n",
    "                comment=eval_result[\"reasoning\"],\n",
    "            )\n",
    "\n",
    "\n",
    "execute_eval_and_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcTF-z8eeL0a"
   },
   "outputs": [],
   "source": [
    "# 🎯 幻觉（hallucination）评测需要额外传入参考文本，这里单独处理\n",
    "\n",
    "def eval_hallucination():\n",
    "    chain = get_hallucination_eval()\n",
    "\n",
    "    for generation in generations:\n",
    "        eval_result = chain.evaluate_strings(\n",
    "            prediction=generation.output,\n",
    "            input=generation.input,\n",
    "            reference=generation.input,  # 简单示例：以原始输入作为参考文本\n",
    "        )\n",
    "        print(eval_result)\n",
    "\n",
    "        if (\n",
    "            eval_result is not None\n",
    "            and eval_result.get(\"score\") is not None\n",
    "            and eval_result.get(\"reasoning\") is not None\n",
    "        ):\n",
    "            langfuse.create_score(\n",
    "                name=\"hallucination\",\n",
    "                trace_id=generation.id,\n",
    "                observation_id=generation.id,\n",
    "                value=eval_result[\"score\"],\n",
    "                comment=eval_result[\"reasoning\"],\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4zeFEKlfjQ-"
   },
   "outputs": [],
   "source": [
    "# ✅ 根据配置决定是否执行幻觉评测\n",
    "if EVAL_TYPES.get(\"hallucination\"):\n",
    "    eval_hallucination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ROOd8d8rdl6"
   },
   "outputs": [],
   "source": [
    "# 📤 Langfuse Python SDK 内部使用异步队列发送数据，这里手动 flush 以确保所有打分已写入服务端\n",
    "langfuse.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsKpVyYdavJ5"
   },
   "source": [
    "### 在 Langfuse 中查看分数\n",
    "\n",
    "在 Langfuse 界面中，你可以按 `Scores` 过滤 Traces，并查看每条的详细信息。你也可以通过 Langfuse Analytics 分析新提示词版本或应用发布对这些分数的影响。\n",
    "\n",
    "![Trace 示例](https://langfuse.com/images/docs/trace-conciseness-score.jpg)\n",
    "_包含简洁性（conciseness）分数的示例 Trace_\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}