{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/evaluation_with_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWL354n0DECo"
      },
      "source": [
        "---\n",
        "åœ¨ Langfuse ä¸Šè¿è¡Œ LangChain è¯„æµ‹\n",
        "\n",
        "æœ¬æŒ‡å—æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨åŸºäºæ¨¡å‹çš„è¯„æµ‹ï¼Œè‡ªåŠ¨åŒ–è¯„ä¼° Langfuse ä¸­çº¿ä¸Šäº§å‡ºçš„ LLM å®Œæˆç»“æœã€‚ç¤ºä¾‹ä½¿ç”¨ LangChainï¼Œäº¦å¯è¿ç§»åˆ°å…¶ä»–åº“ï¼›æœ€ä½³é€‰æ‹©å–å†³äºå…·ä½“åœºæ™¯ã€‚\n",
        "\n",
        "æœ¬æŒ‡å—åˆ†ä¸‰æ­¥ï¼š\n",
        "1. ä» Langfuse è·å–çº¿ä¸Šå­˜å‚¨çš„ `generations`\n",
        "2. ä½¿ç”¨ LangChain å¯¹è¿™äº› `generations` è¿›è¡Œè¯„æµ‹\n",
        "3. å°†ç»“æœä½œä¸º `scores` å›çŒåˆ° Langfuse\n",
        "\n",
        "\n",
        "----\n",
        "è¿˜æœªä½¿ç”¨ Langfuseï¼Ÿé€šè¿‡é‡‡é›† LLM äº‹ä»¶ï¼Œ[ç«‹å³å¼€å§‹](https://langfuse.com/docs/get-started)ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbfTYaTkEu3G"
      },
      "source": [
        "### ç¯å¢ƒå‡†å¤‡\n",
        "\n",
        "å…ˆç”¨ pip å®‰è£… Langfuse ä¸ LangChainï¼Œç„¶åè®¾ç½®ç¯å¢ƒå˜é‡ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qclwxd9LRPAL",
        "outputId": "4562f107-0c7d-4f1b-da00-55d40bd587e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langfuse==3.3.0 in /usr/local/lib/python3.12/dist-packages (3.3.0)\n",
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai==0.3.31 in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.2.1)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "# å®‰è£…å¿…è¦çš„PythonåŒ…\n",
        "# langfuse: ç”¨äºå¤§æ¨¡å‹åº”ç”¨çš„å¯è§‚æµ‹æ€§å¹³å°ï¼Œå¯ä»¥è¿½è¸ªã€è°ƒè¯•å’Œä¼˜åŒ–LLMåº”ç”¨\n",
        "# langchain: ç”¨äºæ„å»ºLLMåº”ç”¨çš„æ¡†æ¶ï¼Œæä¾›å„ç§å·¥å…·å’Œç»„ä»¶\n",
        "# langchain-openai: LangChainçš„OpenAIé›†æˆåŒ…ï¼Œç”¨äºè°ƒç”¨OpenAIçš„æ¨¡å‹\n",
        "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRKSP2mWFUL4",
        "outputId": "45080dd4-0d5d-44df-97ec-9782ff2297d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LANGFUSE_PUBLIC_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_SECRET_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_HOST: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "# ç¯å¢ƒå˜é‡é…ç½®\n",
        "# è®¾ç½®OpenAI APIå¯†é’¥ï¼Œè¿™æ˜¯ä½¿ç”¨OpenAIæ¨¡å‹æ‰€å¿…éœ€çš„\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
        "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
        "    è¿™æ ·å¯ä»¥é¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "# è®¾ç½®OpenAI APIå¯†é’¥\n",
        "# æ‚¨éœ€è¦ä» https://platform.openai.com/api-keys è·å–APIå¯†é’¥\n",
        "# è¿™æ˜¯è°ƒç”¨OpenAIæ¨¡å‹è¿›è¡Œè¯„æµ‹æ‰€å¿…éœ€çš„\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "\n",
        "# è®¾ç½® OpenAI APIä»£ç†åœ°å€ (ä¾‹å¦‚ï¼šhttps://api.apiyi.com/v1ï¼‰\n",
        "# å¦‚æœæ‚¨ä½¿ç”¨ä»£ç†æœåŠ¡è®¿é—®OpenAIï¼Œéœ€è¦è®¾ç½®è¿™ä¸ªå˜é‡\n",
        "_set_env(\"OPENAI_BASE_URL\")\n",
        "\n",
        "# Langfuseé…ç½®\n",
        "# åœ¨é¡¹ç›®è®¾ç½®é¡µè·å–å¯†é’¥ï¼šhttps://cloud.langfuse.com\n",
        "# è¿™äº›å¯†é’¥ç”¨äºè¿æ¥Langfuseå¹³å°ï¼Œå­˜å‚¨å’Œæ£€ç´¢è¯„æµ‹æ•°æ®\n",
        "# PUBLIC KEY - ç”¨äºæ ‡è¯†æ‚¨çš„é¡¹ç›®\n",
        "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
        "# SECRET KEY - ç”¨äºè®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡\n",
        "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
        "# é€‰æ‹©LangfuseæœåŠ¡å™¨åŒºåŸŸ\n",
        "# ğŸ‡ªğŸ‡º æ¬§ç›ŸåŒºåŸŸ(æ¨è) https://cloud.langfuse.com\n",
        "# ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸ https://us.cloud.langfuse.com\n",
        "_set_env(\"LANGFUSE_HOST\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQhmQQpLRa1K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# è®¾ç½®ç”¨äºè¯„ä¼°çš„LLMæ¨¡å‹åç§°\n",
        "# è¿™é‡Œä½¿ç”¨gpt-3.5-turbo-instructï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–æ¨¡å‹å¦‚gpt-4\n",
        "# è¯„æµ‹æ¨¡å‹çš„é€‰æ‹©ä¼šå½±å“è¯„æµ‹çš„å‡†ç¡®æ€§å’Œæˆæœ¬\n",
        "os.environ['EVAL_MODEL'] = \"gpt-3.5-turbo-instruct\"\n",
        "\n",
        "# LangChain è¯„æµ‹ç±»å‹é…ç½®\n",
        "# å®šä¹‰ä¸€ä¸ªå­—å…¸æ¥æŒ‡å®šè¦æ‰§è¡Œå“ªäº›LangChainè¯„æµ‹\n",
        "# æ¯ä¸ªè¯„æµ‹ç±»å‹éƒ½ä¼šå¯¹ç”Ÿæˆçš„å†…å®¹è¿›è¡Œç‰¹å®šç»´åº¦çš„è¯„ä¼°\n",
        "EVAL_TYPES={\n",
        "    \"hallucination\": True, # å¹»è§‰æ£€æµ‹ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦åŒ…å«è¾“å…¥æˆ–å‚è€ƒä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯\n",
        "    \"conciseness\": True, # ç®€æ´æ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦ç®€æ´æ˜äº†ï¼Œé¿å…å†—ä½™\n",
        "    \"relevance\": True, # ç›¸å…³æ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦ä¸è¾“å…¥é—®é¢˜ç›¸å…³\n",
        "    \"coherence\": True, # è¿è´¯æ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦é€»è¾‘è¿è´¯ï¼Œç»“æ„æ¸…æ™°\n",
        "    \"harmfulness\": True, # æœ‰å®³æ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦åŒ…å«æœ‰å®³ä¿¡æ¯\n",
        "    \"maliciousness\": True, # æ¶æ„æ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦åŒ…å«æ¶æ„ä¿¡æ¯\n",
        "    \"helpfulness\": True, # æœ‰ç”¨æ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦å¯¹ç”¨æˆ·æœ‰å¸®åŠ©\n",
        "    \"controversiality\": True, # äº‰è®®æ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦åŒ…å«äº‰è®®æ€§è§‚ç‚¹\n",
        "    \"misogyny\": True, # æ€§åˆ«æ­§è§†ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦åŒ…å«æ€§åˆ«æ­§è§†è§‚ç‚¹\n",
        "    \"criminality\": True, # çŠ¯ç½ªæ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦åŒ…å«é¼“åŠ±çŠ¯ç½ªçš„ä¿¡æ¯\n",
        "    \"insensitivity\": True # ä¸æ•æ„Ÿæ€§ï¼šè¯„ä¼°ç”Ÿæˆçš„å†…å®¹æ˜¯å¦åŒ…å«ä¸æ•æ„Ÿä¿¡æ¯\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yiwrz1-mavJ4"
      },
      "source": [
        "åˆå§‹åŒ– Langfuse Python SDKï¼Œæ›´å¤šä¿¡æ¯è§[æ­¤å¤„](https://langfuse.com/docs/sdk/python#1-installation)ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8viV4KT5RMjA",
        "outputId": "36dba82a-2a90-4f07-abe9-2b0b2371cea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Langfuse å®¢æˆ·ç«¯å·²é€šè¿‡è®¤è¯ï¼Œå‡†å¤‡å°±ç»ªï¼\n"
          ]
        }
      ],
      "source": [
        "# å¯¼å…¥Langfuseå®¢æˆ·ç«¯\n",
        "from langfuse import get_client\n",
        "\n",
        "# åˆå§‹åŒ–Langfuseå®¢æˆ·ç«¯\n",
        "# å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–é…ç½®ä¿¡æ¯\n",
        "langfuse = get_client()\n",
        "\n",
        "# éªŒè¯è¿æ¥\n",
        "# æ£€æŸ¥APIå¯†é’¥å’ŒæœåŠ¡å™¨è¿æ¥æ˜¯å¦æ­£å¸¸\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse å®¢æˆ·ç«¯å·²é€šè¿‡è®¤è¯ï¼Œå‡†å¤‡å°±ç»ªï¼\")\n",
        "    print(\"ç°åœ¨å¯ä»¥å¼€å§‹ä»Langfuseè·å–æ•°æ®å¹¶è¿›è¡Œè¯„æµ‹\")\n",
        "else:\n",
        "    print(\"è®¤è¯å¤±è´¥ã€‚è¯·æ£€æŸ¥å‡­æ®ä¸ä¸»æœºé…ç½®ã€‚\")\n",
        "    print(\"è¯·ç¡®ä¿å·²æ­£ç¡®è®¾ç½®LANGFUSE_PUBLIC_KEYã€LANGFUSE_SECRET_KEYå’ŒLANGFUSE_HOST\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjMZ1VLhF2Vv"
      },
      "source": [
        "### æ‹‰å–æ•°æ®\n",
        "\n",
        "æ ¹æ® `name` ä» Langfuse è½½å…¥æ‰€æœ‰ `generations`ï¼Œæ­¤å¤„ç¤ºä¾‹ä¸º `OpenAI`ã€‚åœ¨ Langfuse ä¸­ï¼Œ`name` ç”¨äºæ ‡è¯†åº”ç”¨å†…ä¸åŒç±»å‹çš„ç”Ÿæˆã€‚å°†å…¶æ›¿æ¢ä¸ºä½ éœ€è¦è¯„æµ‹çš„åç§°ã€‚\n",
        "\n",
        "å…³äºåœ¨å†™å…¥ LLM Generation æ—¶å¦‚ä½•è®¾ç½® `name`ï¼Œå‚è§[æ–‡æ¡£](https://langfuse.com/docs/sdk/python#generation)ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r3jOEX0RvXi"
      },
      "outputs": [],
      "source": [
        "def fetch_all_pages(name=None, user_id=None, limit=50):\n",
        "    \"\"\"\n",
        "    ä»Langfuseè·å–æ‰€æœ‰é¡µé¢çš„æ•°æ®\n",
        "    \n",
        "    å‚æ•°:\n",
        "    - name: å¯é€‰çš„traceåç§°è¿‡æ»¤å™¨ï¼Œç”¨äºç­›é€‰ç‰¹å®šç±»å‹çš„ç”Ÿæˆ\n",
        "    - user_id: å¯é€‰çš„ç”¨æˆ·IDè¿‡æ»¤å™¨ï¼Œç”¨äºç­›é€‰ç‰¹å®šç”¨æˆ·çš„æ•°æ®\n",
        "    - limit: æ¯é¡µè·å–çš„æ•°æ®æ¡æ•°ï¼Œé»˜è®¤50æ¡\n",
        "    \n",
        "    è¿”å›:\n",
        "    - all_data: åŒ…å«æ‰€æœ‰è·å–åˆ°çš„traceæ•°æ®çš„åˆ—è¡¨\n",
        "    \"\"\"\n",
        "    page = 1  # ä»ç¬¬ä¸€é¡µå¼€å§‹\n",
        "    all_data = []  # å­˜å‚¨æ‰€æœ‰æ•°æ®\n",
        "\n",
        "    # å¾ªç¯è·å–æ‰€æœ‰é¡µé¢çš„æ•°æ®\n",
        "    while True:\n",
        "        # è°ƒç”¨Langfuse APIè·å–æŒ‡å®šé¡µé¢çš„traceæ•°æ®\n",
        "        response = langfuse.api.trace.list(name=name, limit=limit, user_id=user_id, page=page)\n",
        "        \n",
        "        # å¦‚æœæ²¡æœ‰æ•°æ®äº†ï¼Œè·³å‡ºå¾ªç¯\n",
        "        if not response.data:\n",
        "            break\n",
        "\n",
        "        # å°†å½“å‰é¡µé¢çš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®åˆ—è¡¨ä¸­\n",
        "        all_data.extend(response.data)\n",
        "        page += 1  # å‡†å¤‡è·å–ä¸‹ä¸€é¡µ\n",
        "\n",
        "    return all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAnLShvjBDBU"
      },
      "outputs": [],
      "source": [
        "# ä»Langfuseè·å–æ‰€æœ‰traceæ•°æ®\n",
        "# è¿™é‡Œä½¿ç”¨user_id='user_123'ä½œä¸ºç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹\n",
        "# å¦‚æœæ‚¨çš„æ•°æ®æ²¡æœ‰è®¾ç½®user_idï¼Œå¯ä»¥å»æ‰è¿™ä¸ªå‚æ•°\n",
        "generations = fetch_all_pages(user_id='user_123')\n",
        "\n",
        "# æ‰“å°è·å–åˆ°çš„æ•°æ®æ¡æ•°\n",
        "print(f\"æˆåŠŸè·å–åˆ° {len(generations)} æ¡traceæ•°æ®\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTS1P1O2dm3I",
        "outputId": "3c131bed-36bf-4db9-e2e0-541bb9864f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# æŸ¥çœ‹è·å–åˆ°çš„æ•°æ®\n",
        "# è¿™å°†æ˜¾ç¤ºæ‰€æœ‰traceçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¾“å…¥ã€è¾“å‡ºã€æ—¶é—´æˆ³ç­‰\n",
        "print(\"è·å–åˆ°çš„traceæ•°æ®:\")\n",
        "print(generations)\n",
        "\n",
        "# å¦‚æœæ•°æ®ä¸ºç©ºï¼Œè¯´æ˜æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„trace\n",
        "if not generations:\n",
        "    print(\"\\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•traceæ•°æ®ï¼\")\n",
        "    print(\"è¯·æ£€æŸ¥ï¼š\")\n",
        "    print(\"1. user_idæ˜¯å¦æ­£ç¡®\")\n",
        "    print(\"2. æ˜¯å¦å·²ç»æœ‰æ•°æ®å†™å…¥åˆ°Langfuse\")\n",
        "    print(\"3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "jmiO90n_QjiS",
        "outputId": "4f2e6e2f-0c72-4660-e436-ce4230b8c8b4"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4056371054.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "generations[0].id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYM6UG_dGbb6"
      },
      "source": [
        "### å®šä¹‰è¯„æµ‹å‡½æ•°\n",
        "\n",
        "æœ¬èŠ‚åŸºäº `EVAL_TYPES` å®šä¹‰ LangChain è¯„æµ‹å™¨ï¼›å…¶ä¸­â€œå¹»è§‰â€ï¼ˆhallucinationï¼‰éœ€è¦å•ç‹¬å‡½æ•°ã€‚å…³äº LangChain è¯„æµ‹çš„æ›´å¤šä¿¡æ¯è§[æ­¤å¤„](https://python.langchain.com/docs/guides/evaluation/string/criteria_eval_chain)ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NijTmslvyK8"
      },
      "outputs": [],
      "source": [
        "# å¯¼å…¥ LangChain è¯„æµ‹å™¨å’Œ OpenAI æ¨¡å‹\n",
        "from langchain.evaluation import load_evaluator\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.evaluation.criteria import LabeledCriteriaEvalChain\n",
        "\n",
        "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œæ ¹æ®ç»™å®šçš„è¯„æµ‹æ ‡å‡†é”®ï¼ˆkeyï¼‰è·å–å¯¹åº”çš„ LangChain è¯„æµ‹å™¨\n",
        "def get_evaluator_for_key(key: str):\n",
        "  # åˆå§‹åŒ–ä¸€ä¸ª OpenAI æ¨¡å‹ï¼Œè®¾ç½® temperature=0 ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º\n",
        "  # ä½¿ç”¨ç¯å¢ƒå˜é‡ 'EVAL_MODEL' æŒ‡å®šæ¨¡å‹åç§°\n",
        "  llm = OpenAI(temperature=0, model=os.environ.get('EVAL_MODEL'))\n",
        "  # ä½¿ç”¨ load_evaluator å‡½æ•°åŠ è½½æŒ‡å®šæ ‡å‡†çš„è¯„æµ‹å™¨\n",
        "  return load_evaluator(\"criteria\", criteria=key, llm=llm)\n",
        "\n",
        "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè·å–ç”¨äºè¯„ä¼°â€œå¹»è§‰â€ï¼ˆhallucinationï¼‰çš„è¯„æµ‹å™¨\n",
        "def get_hallucination_eval():\n",
        "  # å®šä¹‰â€œå¹»è§‰â€çš„è¯„æµ‹æ ‡å‡†\n",
        "  criteria = {\n",
        "    \"hallucination\": (\n",
        "      \"Does this submission contain information\"\n",
        "      \" not present in the input or reference?\" # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«è¾“å…¥æˆ–å‚è€ƒä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯\n",
        "    ),\n",
        "  }\n",
        "  # åˆå§‹åŒ–ä¸€ä¸ª OpenAI æ¨¡å‹\n",
        "  llm = OpenAI(temperature=0, model=os.environ.get('EVAL_MODEL'))\n",
        "\n",
        "  # ä½¿ç”¨ LabeledCriteriaEvalChain.from_llm åˆ›å»ºä¸€ä¸ªåŸºäº LLM çš„è¯„æµ‹é“¾\n",
        "  return LabeledCriteriaEvalChain.from_llm(\n",
        "      llm=llm,\n",
        "      criteria=criteria, # ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„â€œå¹»è§‰â€æ ‡å‡†\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzZZfztGdrIQ"
      },
      "source": [
        "### æ‰§è¡Œè¯„æµ‹\n",
        "\n",
        "ä¸‹é¢å°†å¯¹ä¸Šé¢è½½å…¥çš„æ¯ä¸ª `Generation` æ‰§è¡Œè¯„æµ‹ã€‚æ¯ä¸ªå¾—åˆ†å°†é€šè¿‡ [`langfuse.score()`](https://langfuse.com/docs/scores) å†™å› Langfuseã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMa2OEtqvyGg"
      },
      "outputs": [],
      "source": [
        "def execute_eval_and_score():\n",
        "\n",
        "  for generation in generations:\n",
        "    criteria = [key for key, value in EVAL_TYPES.items() if value and key != \"hallucination\"]\n",
        "\n",
        "    for criterion in criteria:\n",
        "      eval_result = get_evaluator_for_key(criterion).evaluate_strings(\n",
        "          prediction=generation.output,\n",
        "          input=generation.input,\n",
        "      )\n",
        "      print(eval_result)\n",
        "\n",
        "      langfuse.create_score(name=criterion, trace_id=generation.id, observation_id=generation.id, value=eval_result[\"score\"], comment=eval_result['reasoning'])\n",
        "\n",
        "execute_eval_and_score()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcTF-z8eeL0a"
      },
      "outputs": [],
      "source": [
        "# å¹»è§‰ï¼ˆhallucinationï¼‰\n",
        "\n",
        "def eval_hallucination():\n",
        "\n",
        "  chain = get_hallucination_eval()\n",
        "\n",
        "  for generation in generations:\n",
        "    eval_result = chain.evaluate_strings(\n",
        "      prediction=generation.output,\n",
        "      input=generation.input,\n",
        "      reference=generation.input\n",
        "    )\n",
        "    print(eval_result)\n",
        "    if eval_result is not None and eval_result[\"score\"] is not None and eval_result[\"reasoning\"] is not None:\n",
        "      langfuse.create_score(name='hallucination', trace_id=generation.id, observation_id=generation.id, value=eval_result[\"score\"], comment=eval_result['reasoning'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4zeFEKlfjQ-"
      },
      "outputs": [],
      "source": [
        "if EVAL_TYPES.get(\"hallucination\") == True:\n",
        "  eval_hallucination()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ROOd8d8rdl6"
      },
      "outputs": [],
      "source": [
        "# SDK ä¸ºå¼‚æ­¥å®ç°ï¼Œè¯·ç¡®ä¿ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ\n",
        "langfuse.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsKpVyYdavJ5"
      },
      "source": [
        "### åœ¨ Langfuse ä¸­æŸ¥çœ‹åˆ†æ•°\n",
        "\n",
        "åœ¨ Langfuse ç•Œé¢ä¸­ï¼Œä½ å¯ä»¥æŒ‰ `Scores` è¿‡æ»¤ Tracesï¼Œå¹¶æŸ¥çœ‹æ¯æ¡çš„è¯¦ç»†ä¿¡æ¯ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ Langfuse Analytics åˆ†ææ–°æç¤ºè¯ç‰ˆæœ¬æˆ–åº”ç”¨å‘å¸ƒå¯¹è¿™äº›åˆ†æ•°çš„å½±å“ã€‚\n",
        "\n",
        "![Trace ç¤ºä¾‹](https://langfuse.com/images/docs/trace-conciseness-score.jpg)\n",
        "_åŒ…å«ç®€æ´æ€§ï¼ˆconcisenessï¼‰åˆ†æ•°çš„ç¤ºä¾‹ Trace_\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
