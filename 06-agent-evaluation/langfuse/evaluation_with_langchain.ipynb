{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/evaluation_with_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWL354n0DECo"
      },
      "source": [
        "---\n",
        "在 Langfuse 上运行 LangChain 评测\n",
        "\n",
        "本指南演示如何使用基于模型的评测，自动化评估 Langfuse 中线上产出的 LLM 完成结果。示例使用 LangChain，亦可迁移到其他库；最佳选择取决于具体场景。\n",
        "\n",
        "本指南分三步：\n",
        "1. 从 Langfuse 获取线上存储的 `generations`\n",
        "2. 使用 LangChain 对这些 `generations` 进行评测\n",
        "3. 将结果作为 `scores` 回灌到 Langfuse\n",
        "\n",
        "\n",
        "----\n",
        "还未使用 Langfuse？通过采集 LLM 事件，[立即开始](https://langfuse.com/docs/get-started)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbfTYaTkEu3G"
      },
      "source": [
        "### 环境准备\n",
        "\n",
        "先用 pip 安装 Langfuse 与 LangChain，然后设置环境变量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qclwxd9LRPAL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4562f107-0c7d-4f1b-da00-55d40bd587e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langfuse==3.3.0 in /usr/local/lib/python3.12/dist-packages (3.3.0)\n",
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai==0.3.31 in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.2.1)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 环境变量配置\n",
        "# 设置OpenAI API密钥，这是使用OpenAI模型所必需的\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    安全地设置环境变量\n",
        "    如果环境变量不存在，会提示用户输入\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "# 设置OpenAI API密钥\n",
        "# 您需要从 https://platform.openai.com/api-keys 获取API密钥\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
        "_set_env(\"OPENAI_BASE_URL\")\n",
        "\n",
        "\n",
        "# 在项目设置页获取密钥：https://cloud.langfuse.com,\n",
        "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-2cf6d992-461d-4b3c-a47e-96285c1e5526@FLYAIBOX\"\n",
        "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-55c2fa56-c913-44be-916b-85ba498dcb8a@FLYAIBOX\"\n",
        "# PUBLIC KEY\n",
        "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
        "# SECRET KEY\n",
        "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
        "# 🇪🇺 欧盟区域(推荐) https://cloud.langfuse.com\n",
        "# 🇺🇸 美国区域 https://us.cloud.langfuse.com\n",
        "_set_env(\"LANGFUSE_HOST\")"
      ],
      "metadata": {
        "id": "QRKSP2mWFUL4",
        "outputId": "45080dd4-0d5d-44df-97ec-9782ff2297d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LANGFUSE_PUBLIC_KEY: ··········\n",
            "LANGFUSE_SECRET_KEY: ··········\n",
            "LANGFUSE_HOST: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CQhmQQpLRa1K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 设置用于评估的LLM模型名称，这里使用gpt-3.5-turbo-instruct\n",
        "os.environ['EVAL_MODEL'] = \"gpt-3.5-turbo-instruct\"\n",
        "\n",
        "# LangChain 评测类型\n",
        "# 定义一个字典来指定要执行哪些LangChain评测\n",
        "EVAL_TYPES={\n",
        "    \"hallucination\": True, # 是否评估幻觉（生成的内容是否包含输入或参考中不存在的信息）\n",
        "    \"conciseness\": True, # 是否评估简洁性（生成的内容是否简洁明了）\n",
        "    \"relevance\": True, # 是否评估相关性（生成的内容是否与输入相关）\n",
        "    \"coherence\": True, # 是否评估连贯性（生成的内容是否逻辑连贯）\n",
        "    \"harmfulness\": True, # 是否评估有害性（生成的内容是否包含有害信息）\n",
        "    \"maliciousness\": True, # 是否评估恶意性（生成的内容是否包含恶意信息）\n",
        "    \"helpfulness\": True, # 是否评估有用性（生成的内容是否对用户有用）\n",
        "    \"controversiality\": True, # 是否评估争议性（生成的内容是否包含争议性观点）\n",
        "    \"misogyny\": True, # 是否评估性别歧视症（生成的内容是否包含性别歧视症观点）\n",
        "    \"criminality\": True, # 是否评估犯罪性（生成的内容是否包含鼓励犯罪的信息）\n",
        "    \"insensitivity\": True # 是否评估不敏感性（生成的内容是否包含不敏感信息）\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yiwrz1-mavJ4"
      },
      "source": [
        "初始化 Langfuse Python SDK，更多信息见[此处](https://langfuse.com/docs/sdk/python#1-installation)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8viV4KT5RMjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36dba82a-2a90-4f07-abe9-2b0b2371cea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langfuse 客户端已通过认证，准备就绪！\n"
          ]
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# 验证连接\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse 客户端已通过认证，准备就绪！\")\n",
        "else:\n",
        "    print(\"认证失败。请检查凭据与主机配置。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjMZ1VLhF2Vv"
      },
      "source": [
        "### 拉取数据\n",
        "\n",
        "根据 `name` 从 Langfuse 载入所有 `generations`，此处示例为 `OpenAI`。在 Langfuse 中，`name` 用于标识应用内不同类型的生成。将其替换为你需要评测的名称。\n",
        "\n",
        "关于在写入 LLM Generation 时如何设置 `name`，参见[文档](https://langfuse.com/docs/sdk/python#generation)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3r3jOEX0RvXi"
      },
      "outputs": [],
      "source": [
        "def fetch_all_pages(name=None, user_id = None, limit=50):\n",
        "    page = 1\n",
        "    all_data = []\n",
        "\n",
        "    while True:\n",
        "        response = langfuse.api.trace.list(name=name, limit=limit, user_id=user_id, page=page)\n",
        "        if not response.data:\n",
        "            break\n",
        "\n",
        "        all_data.extend(response.data)\n",
        "        page += 1\n",
        "\n",
        "    return all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cAnLShvjBDBU"
      },
      "outputs": [],
      "source": [
        "generations = fetch_all_pages(user_id='user_123')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generations)"
      ],
      "metadata": {
        "id": "xTS1P1O2dm3I",
        "outputId": "3c131bed-36bf-4db9-e2e0-541bb9864f2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "jmiO90n_QjiS",
        "outputId": "4f2e6e2f-0c72-4660-e436-ce4230b8c8b4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4056371054.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "generations[0].id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYM6UG_dGbb6"
      },
      "source": [
        "### 定义评测函数\n",
        "\n",
        "本节基于 `EVAL_TYPES` 定义 LangChain 评测器；其中“幻觉”（hallucination）需要单独函数。关于 LangChain 评测的更多信息见[此处](https://python.langchain.com/docs/guides/evaluation/string/criteria_eval_chain)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NijTmslvyK8"
      },
      "outputs": [],
      "source": [
        "# 导入 LangChain 评测器和 OpenAI 模型\n",
        "from langchain.evaluation import load_evaluator\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.evaluation.criteria import LabeledCriteriaEvalChain\n",
        "\n",
        "# 定义一个函数，根据给定的评测标准键（key）获取对应的 LangChain 评测器\n",
        "def get_evaluator_for_key(key: str):\n",
        "  # 初始化一个 OpenAI 模型，设置 temperature=0 以获得更稳定的输出\n",
        "  # 使用环境变量 'EVAL_MODEL' 指定模型名称\n",
        "  llm = OpenAI(temperature=0, model=os.environ.get('EVAL_MODEL'))\n",
        "  # 使用 load_evaluator 函数加载指定标准的评测器\n",
        "  return load_evaluator(\"criteria\", criteria=key, llm=llm)\n",
        "\n",
        "# 定义一个函数，获取用于评估“幻觉”（hallucination）的评测器\n",
        "def get_hallucination_eval():\n",
        "  # 定义“幻觉”的评测标准\n",
        "  criteria = {\n",
        "    \"hallucination\": (\n",
        "      \"Does this submission contain information\"\n",
        "      \" not present in the input or reference?\" # 检查输出是否包含输入或参考中不存在的信息\n",
        "    ),\n",
        "  }\n",
        "  # 初始化一个 OpenAI 模型\n",
        "  llm = OpenAI(temperature=0, model=os.environ.get('EVAL_MODEL'))\n",
        "\n",
        "  # 使用 LabeledCriteriaEvalChain.from_llm 创建一个基于 LLM 的评测链\n",
        "  return LabeledCriteriaEvalChain.from_llm(\n",
        "      llm=llm,\n",
        "      criteria=criteria, # 使用上面定义的“幻觉”标准\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzZZfztGdrIQ"
      },
      "source": [
        "### 执行评测\n",
        "\n",
        "下面将对上面载入的每个 `Generation` 执行评测。每个得分将通过 [`langfuse.score()`](https://langfuse.com/docs/scores) 写回 Langfuse。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMa2OEtqvyGg"
      },
      "outputs": [],
      "source": [
        "def execute_eval_and_score():\n",
        "\n",
        "  for generation in generations:\n",
        "    criteria = [key for key, value in EVAL_TYPES.items() if value and key != \"hallucination\"]\n",
        "\n",
        "    for criterion in criteria:\n",
        "      eval_result = get_evaluator_for_key(criterion).evaluate_strings(\n",
        "          prediction=generation.output,\n",
        "          input=generation.input,\n",
        "      )\n",
        "      print(eval_result)\n",
        "\n",
        "      langfuse.create_score(name=criterion, trace_id=generation.id, observation_id=generation.id, value=eval_result[\"score\"], comment=eval_result['reasoning'])\n",
        "\n",
        "execute_eval_and_score()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcTF-z8eeL0a"
      },
      "outputs": [],
      "source": [
        "# 幻觉（hallucination）\n",
        "\n",
        "def eval_hallucination():\n",
        "\n",
        "  chain = get_hallucination_eval()\n",
        "\n",
        "  for generation in generations:\n",
        "    eval_result = chain.evaluate_strings(\n",
        "      prediction=generation.output,\n",
        "      input=generation.input,\n",
        "      reference=generation.input\n",
        "    )\n",
        "    print(eval_result)\n",
        "    if eval_result is not None and eval_result[\"score\"] is not None and eval_result[\"reasoning\"] is not None:\n",
        "      langfuse.create_score(name='hallucination', trace_id=generation.id, observation_id=generation.id, value=eval_result[\"score\"], comment=eval_result['reasoning'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4zeFEKlfjQ-"
      },
      "outputs": [],
      "source": [
        "if EVAL_TYPES.get(\"hallucination\") == True:\n",
        "  eval_hallucination()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ROOd8d8rdl6"
      },
      "outputs": [],
      "source": [
        "# SDK 为异步实现，请确保等待所有请求完成\n",
        "langfuse.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsKpVyYdavJ5"
      },
      "source": [
        "### 在 Langfuse 中查看分数\n",
        "\n",
        "在 Langfuse 界面中，你可以按 `Scores` 过滤 Traces，并查看每条的详细信息。你也可以通过 Langfuse Analytics 分析新提示词版本或应用发布对这些分数的影响。\n",
        "\n",
        "![Trace 示例](https://langfuse.com/images/docs/trace-conciseness-score.jpg)\n",
        "_包含简洁性（conciseness）分数的示例 Trace_\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}