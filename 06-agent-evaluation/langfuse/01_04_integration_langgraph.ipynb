{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/01_04_integration_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlCI9KeX4Zn4"
      },
      "source": [
        "## 什么是 LangGraph？\n",
        "\n",
        "[LangGraph](https://langchain-ai.github.io/langgraph/) 是由 LangChain 团队开源的框架，用于基于大语言模型（LLM）构建复杂、有状态的多智能体应用。LangGraph 内置了持久化能力，可保存与恢复状态，从而支持错误恢复与包含“人机交互”（Human-in-the-loop, HITL）的工作流。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o8L1qPcaZeC"
      },
      "source": [
        "## 本实践手册的目标\n",
        "\n",
        "本手册演示如何借助 [Langfuse](https://langfuse.com/docs)，通过其与 [LangChain 的集成](https://langfuse.com/integrations/frameworks/langchain)，对你的 LangGraph 应用进行调试、分析与迭代优化。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPTaMtxH4eHV"
      },
      "source": [
        "**完成本手册后，你将能够：**\n",
        "\n",
        "- 自动通过 Langfuse 集成对 LangGraph 应用进行追踪（tracing）\n",
        "- 监控复杂的多智能体（multi-agent）方案\n",
        "- 添加评分（例如用户反馈）\n",
        "- 使用 Langfuse 管理 LangGraph 中使用的提示词（prompt）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sSIS88y9Ewm"
      },
      "source": [
        "## 初始化 Langfuse\n",
        "\n",
        "在 Langfuse 控制台项目设置页获取你的 [API 密钥](https://langfuse.com/faq/all/where-are-langfuse-api-keys)，并将其加入到运行环境变量中以初始化 Langfuse 客户端。\n",
        "\n",
        "<!-- CALLOUT_START type: \"info\" emoji: \"⚠️\" -->\n",
        "_**注意：** 本笔记使用 Langfuse Python SDK v3。_\n",
        "<!-- CALLOUT_END -->\n",
        "\n",
        "<!-- CALLOUT_START type: \"info\" emoji: \"ℹ️\" -->\n",
        "_**注意：** 需要至少 Python 3.11（参见 [GitHub Issue](https://github.com/langfuse/langfuse/issues/1926)）。_\n",
        "<!-- CALLOUT_END -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C85BK1vJ5yD3",
        "outputId": "618fb8cc-9395-45e0-ee15-549cf7ac3c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse==3.3.0\n",
            "  Downloading langfuse-3.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai==0.3.31\n",
            "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_community==0.3.27\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langgraph==0.6.7\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting backoff>=1.10.0 (from langfuse==3.3.0)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.3.27)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph==0.6.7)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph==0.6.7)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph==0.6.7)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langfuse-3.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: ormsgpack, opentelemetry-proto, mypy-extensions, marshmallow, backoff, typing-inspect, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, langgraph-sdk, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langfuse, langgraph, langchain_community\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.36.0\n",
            "    Uninstalling opentelemetry-api-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.36.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.36.0\n",
            "    Uninstalling opentelemetry-sdk-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
            "Successfully installed backoff-2.2.1 dataclasses-json-0.6.7 langchain-openai-0.3.31 langchain_community-0.3.27 langfuse-3.3.0 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 marshmallow-3.26.1 mypy-extensions-1.1.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 ormsgpack-1.10.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langchain_community==0.3.27 langgraph==0.6.7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 Langfuse 控制台的项目设置页获取 API Key，初始化 Langfuse 客户端，并将其设置到环境变量中。"
      ],
      "metadata": {
        "id": "sUbRmJ-Kh0rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔐 环境变量配置 - 安全存储敏感信息\n",
        "# 环境变量是存储API密钥等敏感信息的最佳实践\n",
        "# 避免在代码中硬编码密钥，防止泄露\n",
        "\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    安全地设置环境变量\n",
        "    如果环境变量不存在，会提示用户输入\n",
        "    使用getpass模块隐藏输入内容，防止密码泄露\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "# 🤖 OpenAI API 配置\n",
        "# OpenAI API密钥：从 https://platform.openai.com/api-keys 获取\n",
        "# 这是调用GPT模型必需的认证信息\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "\n",
        "# API代理地址：如果你使用第三方代理服务（如国内代理）\n",
        "# 示例：https://api.apiyi.com/v1\n",
        "# 如果直接使用OpenAI官方API，可以留空\n",
        "_set_env(\"OPENAI_BASE_URL\")\n",
        "\n",
        "# 🌐 Langfuse 配置\n",
        "# Langfuse是一个可观测性平台，需要注册账户获取密钥\n",
        "# 注册地址：https://cloud.langfuse.com\n",
        "\n",
        "# 公开密钥：用于标识你的项目\n",
        "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
        "\n",
        "# 秘密密钥：用于认证，请妥善保管\n",
        "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
        "\n",
        "# 服务器地址：选择离你最近的区域\n",
        "# 🇪🇺 欧盟区域(推荐) https://cloud.langfuse.com\n",
        "# 🇺🇸 美国区域（不推荐） https://us.cloud.langfuse.com\n",
        "_set_env(\"LANGFUSE_HOST\")\n",
        "\n",
        "# 💡 初学者提示：\n",
        "# 1. 环境变量存储在操作系统中，重启后需要重新设置\n",
        "# 2. 生产环境中建议使用.env文件或云服务配置\n",
        "# 3. 永远不要在代码中硬编码API密钥！\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vku6l5CLhwdC",
        "outputId": "2b08d8c8-36b9-496a-8bfd-247a64893f8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n",
            "OPENAI_BASE_URL: ··········\n",
            "LANGFUSE_PUBLIC_KEY: ··········\n",
            "LANGFUSE_SECRET_KEY: ··········\n",
            "LANGFUSE_HOST: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agy0r3Byg-Aw"
      },
      "source": [
        "在环境变量设置完成后，我们即可初始化 Langfuse 客户端。`get_client()` 会使用环境变量中提供的凭据来初始化 Langfuse 客户端。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVLs2A8g-Ax",
        "outputId": "4cf4f89d-2ff0-4e97-d627-2043009554eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Langfuse 客户端已通过身份验证，准备就绪！\n",
            "🔧 现在可以开始使用追踪功能了\n"
          ]
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "# 🚀 初始化 Langfuse 客户端\n",
        "# get_client() 会自动读取环境变量中的配置信息\n",
        "langfuse = get_client()\n",
        "\n",
        "# 🔍 验证客户端连接状态\n",
        "# 这个步骤非常重要，确保后续的追踪功能能够正常工作\n",
        "if langfuse.auth_check():\n",
        "    print(\"✅ Langfuse 客户端已通过身份验证，准备就绪！\")\n",
        "    print(\"🔧 现在可以开始使用追踪功能了\")\n",
        "else:\n",
        "    print(\"❌ 身份验证失败！\")\n",
        "    print(\"🔍 请检查以下配置项：\")\n",
        "    print(\"   - LANGFUSE_PUBLIC_KEY 是否正确\")\n",
        "    print(\"   - LANGFUSE_SECRET_KEY 是否正确\")\n",
        "    print(\"   - LANGFUSE_HOST 是否可访问\")\n",
        "    print(\"   - 网络连接是否正常\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqYMmi6n9Nh1"
      },
      "source": [
        "## 示例 1：使用 LangGraph 构建简单聊天应用\n",
        "\n",
        "**本节将完成：**\n",
        "\n",
        "- 在 LangGraph 中构建一个可回答常见问题的客服聊天机器人\n",
        "- 使用 Langfuse 对机器人的输入与输出进行追踪（tracing）\n",
        "\n",
        "我们先从一个基础机器人入手，随后在下一节扩展为更高级的多智能体（multi-agent）设置，并在过程中介绍关键的 LangGraph 概念。\n",
        "\n",
        "### 创建智能体（Agent）\n",
        "\n",
        "首先创建一个 `StateGraph`。`StateGraph` 定义了聊天机器人的状态机结构。我们会添加节点来表示 LLM 以及机器人可调用的函数，并通过边（edge）定义机器人在这些函数之间的状态流转。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aGIxgPww6VX6"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入 LangGraph 构建智能体所需的核心模块\n",
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI  # OpenAI 聊天模型\n",
        "from langchain_core.messages import HumanMessage  # 人类消息类型\n",
        "from typing_extensions import TypedDict  # 类型化字典\n",
        "from langgraph.graph import StateGraph  # LangGraph 状态图\n",
        "from langgraph.graph.message import add_messages  # 消息添加函数\n",
        "\n",
        "# 📋 定义智能体的状态结构\n",
        "# State 是一个类型化字典，定义了智能体在执行过程中需要维护的状态信息\n",
        "class State(TypedDict):\n",
        "    # 💬 消息列表：存储对话历史\n",
        "    # Annotated[list, add_messages] 的含义：\n",
        "    # - list: 消息的数据类型是列表\n",
        "    # - add_messages: 指定状态更新策略，新消息会追加到列表末尾而不是覆盖整个列表\n",
        "    # 这种设计确保了对话历史的完整保存\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# 🏗️ 创建状态图构建器\n",
        "# StateGraph 是 LangGraph 的核心组件，用于定义智能体的工作流程\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# 🤖 初始化语言模型\n",
        "# 选择 GPT-4o 模型，temperature=0.2 确保输出相对稳定但仍有一定创造性\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# 🔄 定义聊天机器人节点函数\n",
        "# 这是 LangGraph 节点函数的基本模式：接收当前状态，返回更新后的状态\n",
        "def chatbot(state: State):\n",
        "    \"\"\"\n",
        "    聊天机器人节点的核心逻辑\n",
        "\n",
        "    参数:\n",
        "        state (State): 当前的智能体状态，包含消息历史\n",
        "\n",
        "    返回:\n",
        "        dict: 包含新生成消息的状态更新\n",
        "\n",
        "    工作流程:\n",
        "    1. 获取当前的消息历史\n",
        "    2. 将消息历史发送给语言模型\n",
        "    3. 接收模型生成的回复\n",
        "    4. 将回复包装成状态更新返回\n",
        "    \"\"\"\n",
        "    # 调用语言模型处理当前对话历史，生成回复\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "\n",
        "    # 返回状态更新：将模型的回复添加到消息列表中\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# 🔗 向图中添加\"chatbot\"节点\n",
        "# 节点代表工作单元，通常是普通的 Python 函数\n",
        "# 每个节点负责特定的处理逻辑，如调用 LLM、处理工具、数据转换等\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# 🚀 设置图的入口点\n",
        "# 告诉图每次运行时从哪个节点开始执行\n",
        "# 在这个简单示例中，我们直接从 chatbot 节点开始\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "\n",
        "# 🏁 设置图的结束点\n",
        "# 指示图\"当这个节点运行完成后，可以退出执行\"\n",
        "# 对于简单的单轮对话，chatbot 节点执行完就可以结束\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "\n",
        "# ⚙️ 编译图形为可执行对象\n",
        "# compile() 方法将图构建器转换为 CompiledGraph\n",
        "# CompiledGraph 是可以实际运行的图形对象，支持 invoke、stream 等方法\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# 💡 理解 LangGraph 的核心概念：\n",
        "# 🏗️ StateGraph: 定义智能体的状态和工作流程\n",
        "# 🔄 Node: 执行具体任务的函数，如调用 LLM、使用工具等\n",
        "# 🔗 Edge: 连接节点，定义执行顺序和条件跳转\n",
        "# 📊 State: 智能体运行过程中维护的数据结构\n",
        "# ⚙️ CompiledGraph: 编译后的可执行图形对象"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW2SJcRgh7Xo"
      },
      "source": [
        "### 在调用时添加 Langfuse 回调\n",
        "\n",
        "现在，为了追踪应用执行过程，我们将添加 [面向 LangChain 的 Langfuse 回调处理器](https://langfuse.com/integrations/frameworks/langchain)：`config={\"callbacks\": [langfuse_handler]}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PxEc455-KYM",
        "outputId": "b4c73185-7d54-4e1d-b140-80685ea5b9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 智能体开始运行，正在处理问题……\n",
            "❓ 用户提问：什么是 Langfuse？\n",
            "📋 执行过程:\n",
            "📤 节点执行结果：{'chatbot': {'messages': [AIMessage(content='Langfuse 是一个专注于语言模型和自然语言处理（NLP）应用的工具或平台，旨在帮助开发者和企业更有效地构建、管理和优化基于语言模型的应用程序。虽然具体的功能和应用场景可能会因版本和具体实现而有所不同，但以下是一些可能的主要功能和典型应用场景：\\n\\n### 主要功能\\n\\n1. **模型管理**：\\n   - 提供对多种语言模型的支持，包括开源模型和商业模型。\\n   - 允许用户上传和管理自定义模型。\\n\\n2. **数据处理与分析**：\\n   - 提供数据预处理工具，以便更好地准备训练数据。\\n   - 提供分析工具来评估模型性能，包括准确性、召回率、F1分数等。\\n\\n3. **训练与优化**：\\n   - 支持模型训练和微调，帮助用户根据特定需求优化模型。\\n   - 提供超参数调优工具，以提高模型的效率和效果。\\n\\n4. **部署与集成**：\\n   - 提供简单的API接口，方便将模型集成到现有应用中。\\n   - 支持云端和本地部署，满足不同的业务需求。\\n\\n5. **监控与日志**：\\n   - 提供实时监控工具，帮助用户跟踪模型的使用情况和性能。\\n   - 提供日志记录功能，以便进行故障排查和性能分析。\\n\\n6. **安全与合规**：\\n   - 提供数据加密和访问控制，确保数据安全。\\n   - 确保平台符合相关法律法规，如GDPR等。\\n\\n### 典型应用场景\\n\\n1. **客服与聊天机器人**：\\n   - 使用Langfuse构建智能客服系统，能够理解和响应客户的自然语言查询。\\n   - 提供24/7的客户支持，提高客户满意度。\\n\\n2. **内容生成与编辑**：\\n   - 帮助内容创作者生成高质量的文本内容，如文章、报告等。\\n   - 提供自动化的文本校对和编辑功能。\\n\\n3. **翻译与语言转换**：\\n   - 提供高效的机器翻译服务，支持多语言转换。\\n   - 帮助企业实现全球化运营，支持多语言客户。\\n\\n4. **情感分析与市场调研**：\\n   - 分析社交媒体、客户反馈中的情感倾向，帮助企业了解市场动态。\\n   - 提供数据驱动的市场决策支持。\\n\\n5. **个性化推荐系统**：\\n   - 基于用户的历史行为和偏好，提供个性化的产品或内容推荐。\\n   - 提高用户参与度和转化率。\\n\\nLangfuse 作为一个综合性的平台，能够为各种需要自然语言处理的应用提供支持，从而帮助企业和开发者更高效地利用语言模型的强大功能。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 624, 'prompt_tokens': 26, 'total_tokens': 650, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-CIXdYUV27bcw2APXT9Ho5L9hZ9Hzb', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--94ba4345-2e2b-46ac-8d71-6f41ec1598de-0', usage_metadata={'input_tokens': 26, 'output_tokens': 624, 'total_tokens': 650, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "✅ 智能体执行完成！\n",
            "🔍 请前往 Langfuse 控制台查看完整的追踪记录。\n"
          ]
        }
      ],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 🛎️ 初始化 Langfuse 回调处理器\n",
        "# 该处理器会自动捕获 LangChain/LangGraph 的执行细节，用于：\n",
        "# - 🕒 记录每个节点的耗时与延迟\n",
        "# - 📝 保存输入、输出及中间状态\n",
        "# - 💰 统计 token 消耗和 API 调用成本\n",
        "# - 🐞 收集异常信息，便于排错\n",
        "# - 📈 在 Langfuse 中生成可视化调用链\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# 🚀 运行智能体并启用 Langfuse 追踪\n",
        "print(\"🤖 智能体开始运行，正在处理问题……\")\n",
        "print(\"❓ 用户提问：什么是 Langfuse？\")\n",
        "print(\"📋 执行过程:\")\n",
        "\n",
        "# 使用 stream 方法可以实时查看智能体的执行步骤\n",
        "for step_result in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"什么是 Langfuse？请详细介绍其主要功能和典型应用场景。\")]},\n",
        "    config={\"callbacks\": [langfuse_handler]}\n",
        "):\n",
        "    print(f\"📤 节点执行结果：{step_result}\")\n",
        "\n",
        "print(\n",
        "\"✅ 智能体执行完成！\")\n",
        "print(\"🔍 请前往 Langfuse 控制台查看完整的追踪记录。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdf3ZRnWGZ0N"
      },
      "source": [
        "### 在 Langfuse 中查看追踪结果\n",
        "\n",
        "示例追踪：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=cbc8503a9a111fc5eadb5e914be3fa7a&timestamp=2025-09-22T03%3A48%3A16.647Z&observation=47245ec86916a5d1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Aq7u6_LBR6"
      },
      "source": [
        "![在 Langfuse 中查看聊天应用的追踪](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509221150147.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3yyVtGKhMPU"
      },
      "source": [
        "### 可视化聊天应用\n",
        "\n",
        "你可以使用 `get_graph` 方法配合相应的 “draw” 方法对图进行可视化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "MKkM6mw47kIy",
        "outputId": "8eae221d-3838-4fbe-ac94-8fe2c1e18513"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAQAElEQVR4nOydCXwTZd7Hn5mcTZred0tpSylQwBYo18tR5ZJlYTnsviDHuwKuwnKzuIDgURDRRZRdRRERQaSgckgRuREQioK0HK1cPSk96ZkmTXPMzPtMpk0DTDKTTgNDM99+PunkeZ55kvnlOf7zHPMXEwQBBFqKGAhwQJCPE4J8nBDk44QgHycE+TjBVb78LN2djLrq+wa9DsNNABAAQQkCR8g4lEAAQuCNKQmE/CODxQRuMidACEA0pgTmU8zvESo9TAbzgacjCE4QKBWIiAFhavrsprPIM5CmYyoZCsgTza9m4D/UEotKELkCVXlL2nVUdP0fFeAA0jK77/Ip9fVz1ToNhmO4VCYSSYBYgpJfFyMsXxoRIaQe8NoR6g9BzJ8lkiGYnqASwPTk9YgQ3HwApQJN3wcVk/kQ1IU3/QYiCYIZmxKgCI5TZ8GsUMKEN1+VCH6T5vxJfa2uEoWJCcJkAvp6E44DuUIUGat8bqI/cByH5Us/WXP5VDWGEf6hst7D/MO7SMHTjKaSOJtaVpyjMxnxiK7uI/8v0KHTHZNvx5oCrRqL7ec1eLwPaFvcuKhN+7EcFvaZb0UiErZnOSDfp0uyA8PdXpgfCtoup/dUZF2oGTDGP/5ZTzbp2cr3yeLs5/43qGs/d+ACwIIyZXmkp6+IMSUr+Tb+M/uVd6IlbsB1+Hx5bu8hfj2He9hPhgImNi3NHTox2KW0g7y6NurC0fu19032kzHIt311gX+YrHMfJXA9+v3Jd9cHd+2nsSdf+slaaNm9MK8t9xV26DXUy80d3fvfIjtp7Mn3+8mqbv29gAuTNL9dSb7OTgKb8l09o8ZM+MBxbc2+cwilp0ihEu37xGYBtClfxulq/xA5eLwMHz68qKjI0bNycnJGjx4NnMMzA71KCxpsxdqUT6s29fmTH3iMlJSUVFdXA8f5448/gNNIGO4N75cLbtbTxtKPuNy5okVQJLyTDDgBaGnu2rXrxx9/LCgoiIyM7Nev3+zZszMyMmbNmgVjx44dm5iYuH79elim9uzZc+nSpeLi4qioqHHjxiUlJVE5DB069OWXXz516hQ8a9q0aTt27CCvMyFh0aJFU6ZMAa2NTIFmnlO376x4NIpevrxMrcQp0pHs3r1769atCxcuHDBgwOnTpzdu3KhUKqdPn75hwwYYeODAgdBQsq+HCkLhVqxYAUdq8vPz33///eDgYHgKjJJIJPv37+/Tpw8UsVevXjDBsWPH4O8BnIPKSwJH5Gij6OVTVxrhMA5wDunp6bGxsVRrNX78+N69e9fX01SNtWvXarXakJAQYC5ZqampaWlplHxQL09PzyVLloDHgqeftCjHkcpr0GMSqbPki4uL+/jjj1etWtWjR4/BgweHhYXRJoN1HJbT8+fPwzpOhVClkgL+AOBxIXdHjAaMNopePoK8E8aBc5g8eTKsrWfOnElOThaLxbC3nT9/vr//A6OVOI4vWLDAYDDMnTsXFj2VSjVz5kzrBFLp4xtnRMzQRtHLJ5WK9TqG270Wg6LoeDO5ubkXL17cvHmzRqP56KOPrNPcvHkzKyvr008/hQ0cFVJXVxcQEACeBDoNDke2aaPo5VN5i9XVRuAcYBvfpUuXDh06RJmBusB+4KE0NTU18NWiV64ZeAp4EsCeQCynt/DoQ9t1UjTUO6v0HTly5LXXXjt79mxtbe25c+eg/QFbQxgeEREBX48fP56ZmQllhfUaWiRqtRp2u+vWrYP2DTQMaTMMDw+vqKiAnbillWxd6qqNPn70hgi9fF37q2DTV1lC31tzZOXKlVCdxYsXQ/Nt9erV0MqD1gkMh33ImDFjNm3aBDuWoKCgd9555/r160OGDIHW3Jw5c6DRB2W1mH7WDBw4MD4+HnbER48eBU6gXmOK6UE/TmxzuHTLG3mB7eRjXgkGrs3Ni5oTu0vnfhhNG2vzpi2mh6rwtha4PBePVfoG27yFsDlNPniC37VzNRmnansMoZ80KS0tnTRpEm2Uu7s77Expo2C1hbccwDlsM0MbZZ5kpq9n0DaibRMoaisNr6yJthVrb67jREr5nSt1s/9N39+ZTKby8nLaqIaGBrmcfrQGdgjOsz/qzNBGwS7Iw4N+4gKGw9+bNirlvbs4BqauCAc2YJgq2rIyL7yTYsQ0xyaP2wZ3bzUc3HxvzvpoO2kY5jpeficy+6pGX+uKC3h/+rJ40HiGisI80zbsxcBt7+YBF+OrtwvCY5TPDGSYqGQ1z1tdbkp5v2DOBx0AAlyBz/6Vk/hCYGxf5jUBbFcZ5GXVH9pSHDfYe9B4X9B2uXtDd3h7SbsYxagZQWzSO7JECAOfv5ErFiOjXgoOjnrc0yCPgZR/F9beN/T/S0D8ILaL/hxeoHZoS8ndW/UyhahTvGpAmyiJV8/WXT9fDccFfIJkk5aEOXRuC5dH/rS1tChHZ2jAxFLUzV3k7iGRuiHAvDyyOWsUIczLF1HUvDgRQaxjYWLUvLz0wWWgABXBwb7G1YzUKkfzqebTzblZshWJyOWWON68IBOG4ASZIbXMkgpHRSgO/+HNlrNILDLpcY3apNNg8BLgYJRviDxpdghgvS6t+Rq57Cqqq8IvHa8su6tr0GIGcsFo0yJRKmsyb6Tx4s1DsMCq6yGX3YpIXWEwQr1Q4VZSkoJjBBwfBOYluwTxQLbkr0Kd3hxCHlgybHwlz4WCI5ZPge2PSILI3UTegZLuA7zDYlo+rcNJvsfA888/n5KS4uvL01aC7yvr4a0hvM8DfEWQjxOCfJzgu3xGoxFOigO+wmv5cNKEIWfmAF/htXw8r7lAkI8jvP5yPG/4gFD6OCLIxwlBPk4I8nGC7/IJXUfLEUofJwT5OCHIxwloNgvytRyh9HFCkI8TgnycEOTjhDDiwgmh9HFCJBKpVJyeMeVs+D5VVFtbC3gMv6uGWAzrL+AxgnycEOTjhCAfJwT5OMF3w0WQr+UIpY8TgnycEOTjhCAfJwT5OCHIxwlBPk4I8nFCkI8T/JePj7uKkpOTU1NTqS9G7rIyg6LopUuXAM/g46L12bNnR0REoGbgbS98hfLZetDak4WP8gUEBAwbNsw6BMo3duxYwD94umVi6tSp7du3t7wNDQ0dN24c4B88lQ9OsI0ZM8ayIWbEiBFeXnx8gjR/N+xMnjyZau9CQkImTJgAeIljPW/2FV1elqahvvHRfuTOb2q3N9q81RuCY3jjrmaznxwqltyOTO3oxh84xbJbGpgd7OCmxh3RsMMoLLx3J/t2aEhYx44dKdc6zc9SsvafY7VZmvpEix8e80Z28wc95G9HjJDf/MFrl8nFgeHyuEQPwBq28ul0IOXdfKMBk8hEBl3jdu/mnd/NXpcI8qtjjW6cGl0PIU0unMgN8k3OnyzXY/Hx1PR7ULvDqcxxMl/y0Y1Nn9W0Jf1B+QCwvCV/tGZ/SSj1JFHkIfkQkdkf1YOXLlWgmIFUfdD4oNg+CsACVmazQQe2vZUX29uz54i2/wz2vOvas/tKJeKgjj2ZFWRV+j5fmjv4hbCwTk+3VyeH2Lkm74XZEf6RDM/9Ye46jm0vl8rFLqUdxC9UfnRXIWMyZvnK7jV4+vN6lZgzaB+r1NZhjMmY5YMdBe4iz66yQiRGMSPzk6uZuw4MI3B+D3s4A5zAMYy5VxBcfHJCkI8TLORDCVtPbG/jIK1SeXG+P6jJGSAAQVh0mELlpYcArMqMIB8n2Mjnio/NJb1Zg9YxXFyx30Co1o8JofLSQwBWtY5ZPjiEactXStuGTZvFLB8c/m30oO5KkCO8LAR8rHMdf534py1fbgQcGDt+6Nc7tgDnYx6fZq5zLORDwZO96UheteynwwcAB/b/8N3a998CToCFfDh4sjcdt25xdUHZghxYFhjmtg9BHbZcMAz7fs/O7V9vhsexXbq/9LdXu3ePb/w8sWTf/m83fb5BKpV26xa/fNkqTw/SncqFC7+c+vnotesZanVtl87dpk17uUd8Agx/bij5uu6D1Z9t+ujggdNUJrA0HTmSWlRc2LNHn8WLXvfy8qbCYb0+euzHiorygICg+LheixYuhzPFCxe/cvVqOoy9fi0jZWcqy0tgWWDYtH2Eo/pt/uLjAwe+X5X8wcrX1/j7By5dPu/u3Xwq6szZE1qt5v33Pn5tyZuZmVe++uozYHaPsmbtSr1ev2xp8rtrNoSHR6xYuaiqqhJGHfnpPHx9bckbFu0OHz5QXV05a9bCFcvfuXLl9082fkCFf7Vt0w8Hvpv96sI93x+dOeMfp88chz8hDN/w4eYuXbqNGPFn9toBsvTB1q81hksJcsgAsKdWXfvd998sXLCsd0I/+LZv3wH19drKqgooCnyrUCinTW3093c+7QwsbvBALpdv2bzbzc3N05NcSgBL34HUPdczryQOHvpo/m4KxfSXZlGDQKNHT9izN8VgMOgN+l27t8+etWjgwGdh+LOJw3Jz73yz88sJ4ye1bD86OTvMomyxvGlzQL/8vBz42rlz18YPEItXJa+zxHbvFm859vTwMuj11DGUeMuXn1y5ermysoIKqamh99Wb0KufZQAtNra7cbexovI+TGw0GmEpsySLiemi0WiKigojIqJAi2BT5ZgFphYOANZoNKS3ILnMpq+i5pybsi0rK12w6GV4/W+sePfYkQvHj/5qO3uy/FqO3dzIqdja2pqqqoqHPpSK0unqQUtpHbPZUZRK0ksILE3sT4HtFKyAsOGD9RfYLncUDQ3NvtZhMwpfYZWnAnVWUdQX8PFpoYNrluWFufQRjtVdEB3dCRaxq9fSm04nlr2+4OhRe76HYW+rUnlQ2gGyezlpJ3F29i3LMbRIYA/u7xfQoUOMSCTKyrpqibpxI1PlrvL3b6lXLrOjAMZULHpewiH1SCdtw4eNgj3v4SOpGVd+//iTdZcv/2bdKj1KVFRH2OSlHtxrMpl+u5iWnn4RFqjy8lIYJZPJoAS///4rzIpa55yXnwO7Jmgb3b5zE5opgwcNgZ2Dh8oDfug3O7empZ1V16mPHTu0/4dvk5KmUEvcQkPbQTWzsq4B1pC+GJ7UaPOC+Us3/Oe99R+ugRcZ3SFm1dvrqG7XFkOHPF9QkPv1ji8+2rAW9tdL//X27m+/Ttm1ra5ODc26KZNnQKPk4qW0XSk/mkzGFyf9DQrx2aYNSqWyd0L/uXMafUTP+cc/oVir17wOVQ4JCZv84nSYkooa8+cJt2/fePe9N3fu+AG0KszzGF+syPPyl4yczselxc7j9mV12sHyeR9F20/Gwu4DrgjLq2Zx0wb4vAbVaRCgdQbrCbzZ+40LgbRW14ESLjjW3HojLi45VQTYKShMFdFDtNZNG+GCSzRYw6L0uWLTZ665rbJECHnScx1PBPM8b2v0vKTV4oKGS6t1HSjhimZz6433IS5648YCNssjBfVswiyfxA2RSl2u9iIoKpG2xlSR0l1cr3G58ldVomcjH3OKuEG+dVUNI1lI/gAACJtJREFUwMW4d7suOMKNMRmzfJ16u3n4yfasZ97g1WY4/nUZbiJGzQxkTMl21fyJlPv5N7RB7d1Cot1xnHmzVyPEI+YTtVf3gYBH7FPEttVglSE8EUcbbw0QwspAaNo9bJ28OUvLhuAmn9KWbyASEZXFWOHtOlhtpy5vB1jgwKaD86lVt9PVBj1uaKAxoxGU3GD80IU3bod+8O2jaaj3hOWt1TZv882T1VukeeqKGsdt3PYMKB/bVhk2qfywS25Rowdwy3ej9rrDA7EUdpLi4Ej5qBnM5a7x+/B8QGDkyJE7d+4UnGu3EMG9MScE+TjBc29PQunjBK/lg90ajuMikQjwFcFbDCcE+TghuHrihFD6OCHIxwlBPk4IbR8nhNLHCUE+TgjycUKQjxOCfJwQ5OOEIB8nBPk4IZjNnBBKHycE+TjBd28x/v7+gMfwWj4Mw8rLywGPEXwVcUKQjxOCfJwQ5OOEIB8nBPk4wXf5oO0CeIxQ+jghyMcJvssHB10AjxFKHycE+TghyMcJQT5OCPJxQpCPE3zcVTRv3rxz585ZHs2JoiiO4/Dt5cuXAc/g4z7nBQsWhIWFoU0As4Lh4eGAf/BRvujo6IEDB1pXC1j0EhMTAf/gr3Ptdu2at4TC46SkJMA/eCpfaGjo0KGNz7yGDV9CQgLlKZpv8PcZD5MmTaK8u8PXiRMnAl7SmoZL3X289J7OqMdovKM8skEcRRCcodOXjej/95O6E3Gd4nTl/pnlantpbW1AtwoXo6TjTs9AaUBYqznL5Wq43MnQXj5RVVmmB2YX4IjZLQ/Owjlm08ZyBsxOu1lUEZot/XSpqE9FoI6Ip48kpqcqYYQ34EDL5Tu9t+rWxRqjEZcqJAovmW+Yp5vn0+EC2WTAqwrVmiqdXmskcDw0ym3s7BDQIloiX2WBYe9n96Al6xnsEdzZCzzN1BTVl+VU4hje41mvfqMc9rzusHzHdpTfSlf7hXkFx3Iq9ryipkRXfKPM008yZaljxrlj8p389v6dDE3nRD7eAHAn+0IRiuAzkiPYn+KAfPs2FpcWNMQ+1x60Xe6cLxKLiOnJbK+Rrd3301dl5ff0bVs7SMcBoYhItG1VAcv0rOTLy9TlZWk6D26bdfYhInoH6+vxw9vK2CRmJd/Rb0r8I57uHtYhOiWG517XsEnJLN9PW0sRBA3o4ELyQRSe8u2r7zImY5Yv/2a9f4e2Y6OwJLJ3kKbGUHufYYkIg3y/HqqCY20+oe6Al2i01Uve6Hvl+gngBODd1LGdJfbTMMh3O0MjUz4dt2KtjnewR2WJwX4aBvm0apNPmAdwSfwiPTCMqCq2V3/tDVjVlGGYCfcKVgDnoK6rPHh4Q37hNYOhoVPHfsMSZwT4k3ZlSVnO+k8mz39166mz2zNvnPH0CIjvPnzU8DnU44Qyrh07cvJznU4d23lQ4oApwJnAOZbMtOrBSTa9ldkrfbmZGsRpfqExDNu09R85+ekvjFn2z7kp7kqf/26eUVF5D0aJReRGrO8PrO3xzPPvvXVuclLymfM7r2aRDVxJWXbKnjcTeoxatnBvQvyfDxxaD5wJKkErSvX2EtiJU1canPew+ry7V8or8l9MSu4c099D5Ttm5HylwuuXC7stCeK6DonrNlQslnSI7OnrHXqv6CYMTPttr5dn0PBnZyoUHtFRvfomjANOBcHrtfYmmu1VXqPBiXPA+QVXRSJJx6gE6i3s36FMufkZlgRhIV0sx3K5StdA+m6sqCoMCmz2OdkuNBY4FThaa6/w2ZVPIked59lY16DBMCM0O6wD3ZXNBia01R89q75e7efbPAMnlTI/G5gLKCKSKexVUHvy+QXLnOdrQuXuCy9+xpQHGi9qUtwOsM4ajc0PkdbrHfCE2QIwDJcp7e2ItSdfTLzq9D5Wd84tIDQ4xmDQeXkF+vk0zkBWVhVZlz5avL2C/7j5C5y6pIT+49Y54EwwI+YXYs/stfdrS5XkY3or8uqAE+jYoXfnjv2//2FNdU2pRltz/rc9/9n00sX0g/bPius6DN5p/HBoPRymzM69nPbbHuBM4ORXrxH2HtrLMFGp8pLWltX5RaqAE5gx9cMLl/Z9893KgsLr/n7te8aNHNSfYT63U8e+o5+fd+Hivtfe7Ae74Cl/Td645VUneTIsu1UjkaFudltXhtHma7+oz6dWdBnSxkdJabl97l5AmGSc3Uk4hqb6mUEesAMsy64BroexwTSOaQKTeZVBp16qW5drA6Ppx/tgK/7m2uG0USaTAVp2tI65g/yj5r7yBWg9vtyxOO/uVdooo1EvkcgeDZdK5G/+6xCwQc5vxT6BzGMlrKaKNr+ep/RWhHajv/VTqytow/UGncyGXSYSiZXK1hx/1dbXYib6HSBwMtxNpqSJQBB4t0N/Sq0p99K9Oes7ACZYyWfQgS9WZncdFglcgxunC54Z4D3gL8yDxKzmOmAZ6vWc3x+n2M4/PdVkpxX5hcjYaAfYT1T2G+3V8znvrJP5oE1z4+cCn0DJXxeEskzv2CqDSydqLx2ujO4fKlW2Qd+gN0/f9Q6STFzkwDpMh9e4ZPxce/7gfaWXG5xMAW2F4htV1UXqdjHKv7zq2EW1cIHatuQCrdqo9HaL6PV0iwiFqy2tQ0Vg7N/DgqIcntVp+fq+Oxnas/vL6+tMYolYqhCr/BQege5yd957sNBhmgqd+n69TqPHDJhEhnTt6zVgrMNL0yg4b4vBwJFvygvvaA06nPLki4IHVt3SrJp91P8TXSB9KoJmCI1uZSlhy0UnPB2Og8jcxL5Bkr4jfYKj5IADrb+rSKchx8ma34tQgFm5hkKt/K0iaLPXeDgAhVuOEYBbdGry7GQJhME40ewDCjW/Ek05UPkjZp1gMnMgYV5IDUTAzU0EWtV7Bd9dPfGcNmh/PE4E+TghyMcJQT5OCPJxQpCPE/8PAAD//y1DB2UAAAAGSURBVAMAX/51wSR9VdUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY0HW5xISntw"
      },
      "source": [
        "```mermaid\n",
        "graph TD;\n",
        "\t__start__([__start__]):::first\n",
        "\tchatbot(chatbot)\n",
        "\t__end__([__end__]):::last\n",
        "\t__start__ --> chatbot;\n",
        "\tchatbot --> __end__;\n",
        "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
        "\tclassDef first fill-opacity:0\n",
        "\tclassDef last fill:#bfb6fc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F4Tt_E4g-A0"
      },
      "source": [
        "### 在 LangGraph Server 中使用 Langfuse\n",
        "\n",
        "#### 🖥️ LangGraph Server 简介\n",
        "\n",
        "[LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) 是 LangGraph 提供的服务器部署方案，用于将本地构建的图工作流发布为可扩展的在线服务，具备以下能力：\n",
        "\n",
        "- 🌐 **HTTP API 接口**：将 LangGraph 智能体封装为 REST API，便于与业务系统集成\n",
        "- 🚀 **生产级运行**：支持高并发、负载均衡与容器化交付\n",
        "- 🔧 **运维友好**：自动处理请求路由、状态恢复与错误重试\n",
        "- 📊 **监控集成**：兼容主流监控与追踪体系，便于观测运行状况\n",
        "- 🔒 **安全管控**：内置身份认证与授权机制，满足企业安全需求\n",
        "\n",
        "#### 💡 为什么要在 Server 环境接入 Langfuse？\n",
        "\n",
        "- 🏭 **生产可观测性**：实时查看线上请求的调用链与状态\n",
        "- 🐛 **远程调试**：无需复现场景即可还原问题细节\n",
        "- 📈 **性能洞察**：量化每个节点的耗时与成本\n",
        "- 💰 **费用治理**：准确统计第三方 API 的调用量与费用\n",
        "- 👥 **团队协作**：共享追踪记录，支持跨职能协同排查\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTW_X4rFg-A0"
      },
      "source": [
        "#### 🔧 配置方法说明\n",
        "\n",
        "使用 LangGraph Server 时，智能体图的调用由服务器自动处理，用户无法在每次请求时手动指定回调处理器。\n",
        "\n",
        "**关键差异：**\n",
        "- 🏠 **本地开发**：可以在每次调用时添加 `config={\"callbacks\": [langfuse_handler]}`\n",
        "- 🖥️ **服务器部署**：需要在图编译时预先配置回调处理器\n",
        "\n",
        "**解决方案：**\n",
        "在声明和编译图时就添加 Langfuse 回调，这样服务器上的所有请求都会自动启用追踪功能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J5UKXzbUg-A0"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入服务器部署所需的模块\n",
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 📋 定义与前文一致的智能体状态结构\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# 🏗️ 构建图形结构\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# 🤖 初始化语言模型\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# 🔄 定义聊天机器人节点\n",
        "def chatbot(state: State):\n",
        "    \"\"\"处理用户消息并生成回复。\"\"\"\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# 🔗 组装图形结构\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "\n",
        "# 🔄 初始化 Langfuse 回调处理器（服务器模式）\n",
        "# 在服务器环境中，此处理器会自动追踪所有请求的执行情况\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# ⚙️ 编译图形并预配置回调处理器\n",
        "# 🎯 核心方法：with_config()\n",
        "# - compile()：编译图形，生成可执行的 CompiledGraph\n",
        "# - with_config()：为编译后的图形设置默认配置（如回调处理器）\n",
        "#\n",
        "# 💡 工作流程：\n",
        "# 1. 编译图形得到 CompiledGraph 对象\n",
        "# 2. 调用 with_config() 注入 Langfuse 回调\n",
        "# 3. 返回一个已内置追踪能力的新图对象\n",
        "#\n",
        "# 🚀 优势：\n",
        "# - 无需在每次请求时手动添加回调配置\n",
        "# - 所有 API 请求都会自动写入 Langfuse 追踪\n",
        "# - 简化生产环境的部署与运维\n",
        "graph = graph_builder.compile().with_config({\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "# 💡 部署提示：\n",
        "# 在 LangGraph Server 中直接引用此 graph，即可立即获得完整的追踪数据\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2W94eY19TR1"
      },
      "source": [
        "## 示例 2：基于 LangGraph 的多智能体应用\n",
        "\n",
        "**本节将完成：**\n",
        "\n",
        "- 构建 2 个执行智能体：一个研究智能体使用 LangChain 的 WikipediaAPIWrapper 搜索维基百科，另一个使用自定义工具获取当前时间\n",
        "- 构建一个智能体监督者（supervisor），用于将用户问题分配给上述智能体\n",
        "- 添加 Langfuse 回调以追踪监督者与执行智能体的步骤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WfnrswDdjYTV",
        "outputId": "4da1756a-98bd-43a4-fdb0-c0314c1aaaaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langfuse==3.3.0 in /usr/local/lib/python3.12/dist-packages (3.3.0)\n",
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai==0.3.31 in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langgraph==0.6.7 in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Collecting langchain_experimental\n",
            "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.2.1)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (3.5.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_experimental) (0.3.27)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=a0cfe403b04fc6787680c1491497e5a56409f7981aeb7d862e3ef66fdcb371bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia, langchain_experimental\n",
            "Successfully installed langchain_experimental-0.3.4 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langgraph==0.6.7 langchain_experimental==0.3.4 pandas==2.2.2 wikipedia==1.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tciUQ62IEVec"
      },
      "source": [
        "### 创建工具\n",
        "\n",
        "在本示例中，我们将构建一个用于维基百科检索的智能体，以及一个用于告知当前时间的智能体。先定义它们将使用的工具："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cet0loyp9p-T"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入多智能体系统所需的工具和模块\n",
        "from typing import Annotated\n",
        "from langchain_community.tools import WikipediaQueryRun  # 维基百科查询工具\n",
        "from langchain_community.utilities import WikipediaAPIWrapper  # 维基百科 API 封装\n",
        "from datetime import datetime  # 时间处理模块\n",
        "from langchain.tools import Tool  # 通用工具定义类\n",
        "\n",
        "# 🔍 定义维基百科搜索工具\n",
        "# 功能：根据查询词在维基百科中搜索相关信息\n",
        "# 适用场景：回答百科知识、历史事件、人物传记等问题\n",
        "wikipedia_tool = WikipediaQueryRun(\n",
        "    api_wrapper=WikipediaAPIWrapper(\n",
        "        top_k_results=2,  # 返回最相关的2个搜索结果\n",
        "        doc_content_chars_max=1000  # 限制每个结果的字符数，避免信息过载\n",
        "    )\n",
        ")\n",
        "\n",
        "# ⏰ 定义当前时间查询工具\n",
        "# 功能：返回当前的日期和时间信息\n",
        "# 适用场景：回答\"现在几点\"、\"今天是什么日期\"等时间相关问题\n",
        "datetime_tool = Tool(\n",
        "    name=\"Datetime\",  # 工具名称，智能体会通过这个名称调用工具\n",
        "    func=lambda x: datetime.now().isoformat(),  # 工具函数：返回 ISO 格式的当前时间\n",
        "    description=\"返回当前的日期和时间信息（ISO 格式）\",  # 工具描述，帮助智能体理解何时使用此工具\n",
        ")\n",
        "\n",
        "# 💡 工具设计原则：\n",
        "# 1. 🎯 单一职责：每个工具只负责一个特定功能\n",
        "# 2. 📝 清晰描述：description 要准确描述工具的功能和使用场景\n",
        "# 3. 🔒 错误处理：生产环境中应该添加异常处理逻辑\n",
        "# 4. ⚡ 性能考虑：限制返回数据的大小，避免影响整体性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31uhDy_mEqr6"
      },
      "source": [
        "### 🛠️ 辅助工具函数\n",
        "\n",
        "#### 📝 功能说明\n",
        "下面定义的辅助函数用于简化添加新的智能体工作节点。这些函数封装了创建智能体和节点的通用逻辑，提高代码的可重用性和可维护性。\n",
        "\n",
        "#### 🎯 设计目标\n",
        "- **减少重复代码**：避免为每个智能体重复编写相同的初始化逻辑\n",
        "- **标准化接口**：确保所有智能体节点具有一致的输入输出格式\n",
        "- **简化扩展**：新增智能体时只需关注业务逻辑，无需处理框架细节"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "75atiExdqd4P"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入智能体构建所需的核心组件\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent  # 智能体执行器和创建函数\n",
        "from langchain_core.messages import BaseMessage, HumanMessage  # 消息基类和人类消息\n",
        "from langchain_openai import ChatOpenAI  # OpenAI 聊天模型\n",
        "\n",
        "def create_agent(llm: ChatOpenAI, system_prompt: str, tools: list):\n",
        "    \"\"\"\n",
        "    🏭 智能体工厂函数：创建具有特定能力的工作智能体\n",
        "\n",
        "    参数:\n",
        "        llm (ChatOpenAI): 语言模型实例\n",
        "        system_prompt (str): 系统提示词，定义智能体的角色和行为规范\n",
        "        tools (list): 智能体可使用的工具列表\n",
        "\n",
        "    返回:\n",
        "        AgentExecutor: 配置完成的智能体执行器\n",
        "\n",
        "    🔄 工作流程:\n",
        "    1. 构建提示模板（包含系统角色、对话历史、工具使用记录）\n",
        "    2. 创建支持工具调用的 OpenAI 智能体\n",
        "    3. 包装为执行器，处理工具调用和状态管理\n",
        "    \"\"\"\n",
        "    # 📋 构建智能体的提示模板\n",
        "    # 包含三个关键部分：系统角色、对话历史、工具使用记录\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        # 🎭 系统消息：定义智能体的角色、能力和行为规范\n",
        "        (\"system\", system_prompt),\n",
        "        # 💬 消息历史：保存与用户和其他智能体的对话记录\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        # 🔧 工具记录：记录智能体使用工具的过程和结果\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "\n",
        "    # 🤖 创建支持 OpenAI 工具调用的智能体\n",
        "    # 这个智能体能够理解何时需要使用工具，以及如何解释工具的返回结果\n",
        "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "    # 🎮 创建智能体执行器\n",
        "    # 执行器负责：工具调用、错误处理、状态管理、结果整合\n",
        "    executor = AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        verbose=True,  # 显示详细的执行过程，便于调试\n",
        "        handle_parsing_errors=True  # 自动处理解析错误，提高稳定性\n",
        "    )\n",
        "\n",
        "    return executor\n",
        "\n",
        "def agent_node(state, agent, name):\n",
        "    \"\"\"\n",
        "    🔄 智能体节点适配器：将智能体包装为 LangGraph 节点\n",
        "\n",
        "    参数:\n",
        "        state: 当前的图状态，包含消息历史和其他上下文信息\n",
        "        agent: 智能体执行器实例\n",
        "        name: 智能体的名称，用于在多智能体系统中标识消息来源\n",
        "\n",
        "    返回:\n",
        "        dict: 包含智能体响应的状态更新\n",
        "\n",
        "    🔄 适配过程:\n",
        "    1. 调用智能体处理当前状态\n",
        "    2. 提取智能体的输出结果\n",
        "    3. 包装为带有发送者身份的消息\n",
        "    4. 返回状态更新\n",
        "    \"\"\"\n",
        "    # 📤 调用智能体处理当前状态\n",
        "    # agent.invoke() 会处理对话历史，决定是否使用工具，并生成最终回复\n",
        "    result = agent.invoke(state)\n",
        "\n",
        "    # 🏷️ 将智能体的输出包装为带有身份标识的消息\n",
        "    # name 参数让系统知道这条消息来自哪个智能体\n",
        "    return {\n",
        "        \"messages\": [HumanMessage(\n",
        "            content=result[\"output\"],  # 智能体生成的文本内容\n",
        "            name=name  # 消息发送者的身份标识\n",
        "        )]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74bZqwU6FCOa"
      },
      "source": [
        "### 🎯 创建智能体监督者\n",
        "\n",
        "#### 📋 监督者的核心职责\n",
        "智能体监督者是多智能体系统的\"大脑\"，负责：\n",
        "\n",
        "- 🧠 **任务理解**：分析用户请求，理解任务的性质和需求\n",
        "- 🎯 **智能体选择**：根据任务特点选择最适合的工作智能体\n",
        "- 🔄 **流程控制**：决定何时切换智能体，何时结束处理流程\n",
        "- 📊 **结果整合**：汇总各个智能体的工作成果\n",
        "\n",
        "#### 🔧 技术实现方式\n",
        "监督者使用 **函数调用（Function Calling）** 技术来实现决策：\n",
        "\n",
        "- 📞 **函数调用**：通过结构化的函数调用来表达决策结果\n",
        "- 🎛️ **选择机制**：在可用的工作节点中选择下一个执行者\n",
        "- 🏁 **终止条件**：判断何时任务已完成，可以结束处理流程\n",
        "\n",
        "#### 💡 设计优势\n",
        "- **精确控制**：避免随机或不确定的路由决策\n",
        "- **可解释性**：每个决策都有明确的逻辑依据\n",
        "- **可扩展性**：容易添加新的工作智能体和决策规则"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Hu8MzgihrHdF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "members = [\"Researcher\", \"CurrentTime\"]\n",
        "system_prompt = (\n",
        "    \"你是一名监督者，\"\n",
        "    \" 负责管理以下工作人员之间的对话：{members}。\"\n",
        "    \" 根据以下用户请求，回复下一个要采取行动的工作人员。\"\n",
        "    \" 每个工作人员将执行一项任务，并回复其结果和状态。\"\n",
        "    \" 完成后，回复 FINISH。\"\n",
        ")\n",
        "# 🧭 监督者节点由 LLM 扮演，负责选择下一位执行的智能体并判断流程是否结束\n",
        "options = [\"FINISH\"] + members\n",
        "\n",
        "# 🔁 使用 OpenAI Function Calling，可让结构化输出和解析更加稳定\n",
        "function_def = {\n",
        "    \"name\": \"route\",\n",
        "    \"description\": \"选择下一个角色\",\n",
        "    \"parameters\": {\n",
        "        \"title\": \"routeSchema\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"next\": {\n",
        "                \"title\": \"Next\",\n",
        "                \"anyOf\": [\n",
        "                    {\"enum\": options},\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"next\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# 📜 构建监督者提示模板\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"system\",\n",
        "            \"根据上面的对话，接下来谁应该行动？\"\n",
        "            \" 或者我们应该FINISH吗？请从以下选项中选择一个：{options}\",\n",
        "        ),\n",
        "    ]\n",
        ").partial(options=str(options), members=\", \".join(members))\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# 🔗 构建监督者智能体的执行链\n",
        "supervisor_chain = (\n",
        "    prompt\n",
        "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "    | JsonOutputFunctionsParser()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognuMaIeFVh7"
      },
      "source": [
        "### 构建图形结构\n",
        "\n",
        "现在可以开始搭建整张图。下面使用刚刚定义的函数指定状态和各个工作节点，并连接图中的所有边。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_LwtCmw_rHVz"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "from typing import Sequence, TypedDict\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "# 🗂️ 智能体状态会作为每个节点的输入数据\n",
        "class AgentState(TypedDict):\n",
        "    # Annotated 告诉图：新的消息会追加到现有消息列表中\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    # next 字段指示下一步要跳转到哪个节点\n",
        "    next: str\n",
        "\n",
        "# 🧑‍💻 使用辅助函数创建研究智能体\n",
        "research_agent = create_agent(llm, \"您是一位网络研究员。\", [wikipedia_tool])\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "# 🕰️ 创建报时智能体\n",
        "currenttime_agent = create_agent(llm, \"Y您是一位报时助手，负责告知当前时间。\", [datetime_tool])\n",
        "currenttime_node = functools.partial(agent_node, agent=currenttime_agent, name=\"CurrentTime\")\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# 📦 注册节点：节点代表具体的工作单元，通常是 Python 函数\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"CurrentTime\", currenttime_node)\n",
        "workflow.add_node(\"supervisor\", supervisor_chain)\n",
        "\n",
        "# 🔂 强制所有工作节点在完成后回到监督者\n",
        "for member in members:\n",
        "    workflow.add_edge(member, \"supervisor\")\n",
        "\n",
        "# 🔀 条件边根据当前状态决定后续路由\n",
        "# 该函数读取状态并返回要执行的下一个节点名称\n",
        "conditional_map = {k: k for k in members}\n",
        "conditional_map[\"FINISH\"] = END\n",
        "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
        "\n",
        "# 🚪 设置入口节点，确定图在运行时从哪里开始\n",
        "workflow.add_edge(START, \"supervisor\")\n",
        "\n",
        "# ⚙️ 编译图形，得到可调用的 CompiledGraph\n",
        "graph_2 = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3xfJLJyFwBG"
      },
      "source": [
        "### 在调用中挂载 Langfuse 回调\n",
        "\n",
        "在执行 `graph_2.stream` 时增加 [Langfuse 回调处理器](https://langfuse.com/integrations/frameworks/langchain)：`config={\"callbacks\": [langfuse_handler]}`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "QsX1gw9kryGP",
        "outputId": "3cfc2f5e-de82-40a7-f115-d58b13a9f252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'supervisor': {'next': 'Researcher'}}\n",
            "----\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-920772648.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 🔗 将回调处理器挂载到图的 stream 调用中；可选的 run_name 会作为追踪名称展示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m for s in graph_2.stream({\"messages\": [HumanMessage(content=\"光合作用是如何进行的？\")]},\n\u001b[0m\u001b[1;32m      8\u001b[0m                        config={\"callbacks\": [langfuse_handler]}):\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2648\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1676007668.py\u001b[0m in \u001b[0;36magent_node\u001b[0;34m(state, agent, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# 📤 调用智能体处理当前状态\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# agent.invoke() 会处理对话历史，决定是否使用工具，并生成最终回复\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# 🏷️ 将智能体的输出包装为带有身份标识的消息\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1626\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     ) -> Union[AgentFinish, list[tuple[AgentAction, str]]]:\n\u001b[1;32m   1324\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1325\u001b[0;31m             list(\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 self._iter_next_step(\n\u001b[1;32m   1327\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             output = self._action_agent.plan(\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# Because the response from the plan is not a generator, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3472\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3473\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3457\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3459\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3460\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2231\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m                         \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mfinal_output_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, inputs, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3419\u001b[0m                 \u001b[0mfinal_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3421\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m     async def _atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \"\"\"\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     async def astream(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     ) -> T:\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    198\u001b[0m                 lambda inner_input: self.parse_result(\n\u001b[1;32m    199\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                 output = cast(\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1954\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 198\u001b[0;31m                 lambda inner_input: self.parse_result(\n\u001b[0m\u001b[1;32m    199\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: TRY004\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparse_ai_message_to_openai_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAgentAction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_openai_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     18\u001b[0m ) -> Union[list[AgentAction], AgentFinish]:\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"\"\"Parse an AI message potentially containing tool_calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtool_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ai_message_to_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtool_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\nInvoking: `{function_name}` with `{tool_input}`\\n{content_msg}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         actions.append(\n\u001b[0;32m---> 69\u001b[0;31m             ToolAgentAction(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/agents.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tool, tool_input, log, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdditional\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
          ]
        }
      ],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 📡 初始化 Langfuse 回调处理器，用于记录 LangChain 的执行轨迹\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# 🔗 将回调处理器挂载到图的 stream 调用中；可选的 run_name 会作为追踪名称展示\n",
        "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"光合作用是如何进行的？\")]},\n",
        "                       config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AqJnMtP5HDql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "94ebabe7-dae6-4cba-916d-0f2d5c42f006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'supervisor': {'next': 'CurrentTime'}}\n",
            "----\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3674562739.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 🔗 同样地，为其他查询挂载 Langfuse 回调\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m for s in graph_2.stream({\"messages\": [HumanMessage(content=\"现在的准确时间是多少？\")]},\n\u001b[0m\u001b[1;32m      3\u001b[0m                        config={\"callbacks\": [langfuse_handler]}):\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2648\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1676007668.py\u001b[0m in \u001b[0;36magent_node\u001b[0;34m(state, agent, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# 📤 调用智能体处理当前状态\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# agent.invoke() 会处理对话历史，决定是否使用工具，并生成最终回复\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# 🏷️ 将智能体的输出包装为带有身份标识的消息\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1626\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     ) -> Union[AgentFinish, list[tuple[AgentAction, str]]]:\n\u001b[1;32m   1324\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1325\u001b[0;31m             list(\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 self._iter_next_step(\n\u001b[1;32m   1327\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             output = self._action_agent.plan(\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# Because the response from the plan is not a generator, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3472\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3473\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3457\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3459\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3460\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2231\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m                         \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mfinal_output_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, inputs, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3419\u001b[0m                 \u001b[0mfinal_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3421\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m     async def _atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \"\"\"\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     async def astream(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     ) -> T:\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    198\u001b[0m                 lambda inner_input: self.parse_result(\n\u001b[1;32m    199\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                 output = cast(\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1954\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 198\u001b[0;31m                 lambda inner_input: self.parse_result(\n\u001b[0m\u001b[1;32m    199\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: TRY004\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparse_ai_message_to_openai_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAgentAction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_openai_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     18\u001b[0m ) -> Union[list[AgentAction], AgentFinish]:\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"\"\"Parse an AI message potentially containing tool_calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtool_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ai_message_to_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtool_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\nInvoking: `{function_name}` with `{tool_input}`\\n{content_msg}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         actions.append(\n\u001b[0;32m---> 69\u001b[0;31m             ToolAgentAction(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/agents.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tool, tool_input, log, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdditional\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
          ]
        }
      ],
      "source": [
        "# 🔗 同样地，为其他查询挂载 Langfuse 回调\n",
        "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"现在的准确时间是多少？\")]},\n",
        "                       config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n",
        "    print(\"----\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4XjtNenH9GF"
      },
      "source": [
        "### 在 Langfuse 中查看多智能体追踪\n",
        "\n",
        "以下链接展示了本节多智能体示例在 Langfuse 中生成的追踪记录：\n",
        "\n",
        "1. [光合作用是如何进行的？](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7d5f970573b8214d1ca891251e42282c)\n",
        "2. [现在几点？](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/3a69fe4998df50d42054f8944bd6a8d9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-5EEBZAIbwc"
      },
      "source": [
        "![在 Langfuse 中查看多智能体追踪](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_multiagent_traces.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCEzabn_jhbf"
      },
      "source": [
        "### 可视化该智能体\n",
        "\n",
        "你可以使用 `get_graph` 方法配合相应的 “draw” 方法进行图形可视化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "notlPjnl-HXV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "ff176a31-c163-4a0e-bb8a-41b4a2227208"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph_2.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESkG2IJS8OY"
      },
      "source": [
        "```mermaid\n",
        "graph TD;\n",
        "\t__start__([__start__]):::first\n",
        "\tResearcher(Researcher)\n",
        "\tCurrentTime(CurrentTime)\n",
        "\tsupervisor(supervisor)\n",
        "\t__end__([__end__]):::last\n",
        "\tCurrentTime --> supervisor;\n",
        "\tResearcher --> supervisor;\n",
        "\t__start__ --> supervisor;\n",
        "\tsupervisor -.-> Researcher;\n",
        "\tsupervisor -.-> CurrentTime;\n",
        "\tsupervisor -. &nbspFINISH&nbsp .-> __end__;\n",
        "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
        "\tclassDef first fill-opacity:0\n",
        "\tclassDef last fill:#bfb6fc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKULkc6g-BE"
      },
      "source": [
        "## 多个 LangGraph 智能体的协同\n",
        "\n",
        "在某些架构中，一个 LangGraph 智能体会调用一个或多个其他 LangGraph 智能体。若想让整套执行链在 Langfuse 中聚合为同一条追踪，可显式传入自定义的 `trace_id`。\n",
        "\n",
        "首先生成一个共享的 `trace_id`，供主智能体与子智能体共用，以便在 Langfuse 中合并为同一条记录。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TS8hQBHVg-BE"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client, Langfuse\n",
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# 🔐 从外部系统生成一个确定性的 trace_id，便于跨服务聚合\n",
        "predefined_trace_id = Langfuse.create_trace_id()\n",
        "\n",
        "# 📡 初始化 Langfuse 回调处理器，用于采集 LangChain 的执行数据\n",
        "langfuse_handler = CallbackHandler()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73necyiUg-BE"
      },
      "source": [
        "接下来，构建子智能体的逻辑。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LWS82VWsg-BE"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "sub_agent = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIcpIMEPg-BF"
      },
      "source": [
        "随后，将该子智能体封装成工具，供主流程调用并复用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "R0KC8Gvzg-BF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def langgraph_research(question):\n",
        "  \"\"\"Conducts research for various topics.\"\"\"\n",
        "\n",
        "  with langfuse.start_as_current_span(\n",
        "      name=\"🤖-sub-research-agent\",\n",
        "      trace_context={\"trace_id\": predefined_trace_id}\n",
        "  ) as span:\n",
        "      span.update_trace(input=question)\n",
        "\n",
        "      response = sub_agent.invoke({\"messages\": [HumanMessage(content = question)]},\n",
        "                        config={\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "      span.update_trace(output= response[\"messages\"][1].content)\n",
        "\n",
        "  return response[\"messages\"][1].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PpMQXiEg-BF"
      },
      "source": [
        "最后，创建第二个 LangGraph 智能体，通过前面新增的 `langgraph_research` 工具完成协作。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lhNPp4pmg-BF"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
        "\n",
        "main_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[langgraph_research]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jyeGvSf3g-BF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eea87a5-7156-4a76-f426-acb373c7d54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trace ID: 54931f31967873bb6fb46e5580b8e193\n"
          ]
        }
      ],
      "source": [
        "user_question = \"什么是 Langfuse？\"\n",
        "\n",
        "# 🧭 使用预生成的 trace_id（通过 trace_context 注入）\n",
        "with langfuse.start_as_current_span(\n",
        "    name=\"🤖-main-agent\",\n",
        "    trace_context={\"trace_id\": predefined_trace_id}\n",
        ") as span:\n",
        "    span.update_trace(input=user_question)\n",
        "\n",
        "    # 此处的 LangChain 执行都会归属于同一条追踪\n",
        "    response = main_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_question}]},\n",
        "                            config={\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "    span.update_trace(output=response[\"messages\"][1].content)\n",
        "\n",
        "print(f\"Trace ID: {predefined_trace_id}\")  # 可在后续评分或排查时使用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzPZIqUWg-BF"
      },
      "source": [
        "### 在 Langfuse 中查看多智能体追踪\n",
        "\n",
        "![多智能体追踪示例](https://langfuse.com/images/cookbook/integration-langgraph/a2a_langgraph.png)\n",
        "\n",
        "示例追踪链接：https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/85b0c53c4414f22ed8bfc9eb35f917c4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uybP4h8wGvWw"
      },
      "source": [
        "## 为追踪添加评分\n",
        "\n",
        "[评分（Score）](https://langfuse.com/docs/scores/overview) 用于评价单个观测（observation）或整条追踪（trace），可帮助你在运行时执行自定义质量检查，或配合人工审核流程。\n",
        "\n",
        "下面的示例演示如何：\n",
        "\n",
        "- 为某个 span 记录一个数值型评分（如 `relevance`）\n",
        "- 为整条追踪记录一个分类型评分（如 `feedback`）\n",
        "\n",
        "这有助于系统化地评估与改进应用质量。\n",
        "\n",
        "**→ 想深入了解？请参阅 [Langfuse 自定义评分指南](https://langfuse.com/docs/scores/custom)。**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pgAqYnQuGwCL"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# 方案一：使用上下文管理器返回的 span 对象进行评分\n",
        "with langfuse.start_as_current_span(\n",
        "    name=\"langgraph-request\") as span:\n",
        "    # ... 此处执行 LangGraph 逻辑 ...\n",
        "\n",
        "    # 直接通过 span.score_trace 记录评分\n",
        "    span.score_trace(\n",
        "        name=\"user-feedback\",\n",
        "        value=1,\n",
        "        data_type=\"NUMERIC\",\n",
        "        comment=\"This was correct, thank you\"\n",
        "    )\n",
        "\n",
        "# 方案二：在仍位于上下文时调用 score_current_trace()\n",
        "with langfuse.start_as_current_span(name=\"langgraph-request\") as span:\n",
        "    # ... LangGraph execution ...\n",
        "\n",
        "    langfuse.score_current_trace(\n",
        "        name=\"user-feedback\",\n",
        "        value=1,\n",
        "        data_type=\"NUMERIC\"\n",
        "    )\n",
        "\n",
        "# 方案三：若已离开上下文，可使用 trace_id 直接创建评分\n",
        "langfuse.create_score(\n",
        "    trace_id=predefined_trace_id,\n",
        "    name=\"user-feedback\",\n",
        "    value=1,\n",
        "    data_type=\"NUMERIC\",\n",
        "    comment=\"This was correct, thank you\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq_DeCcXSxwq"
      },
      "source": [
        "### 在 Langfuse 中查看带评分的追踪\n",
        "\n",
        "示例追踪：https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e60a078b828d4fdc7ea22c73193b0fe4\n",
        "\n",
        "![包含评分的追踪展示](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_score.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cIQVrYZJVMO"
      },
      "source": [
        "## 使用 Langfuse 管理提示词\n",
        "\n",
        "通过 [Langfuse Prompt Management](https://langfuse.com/docs/prompts/example-langchain) 可以对提示词进行统一的版本管理。在本示例中，我们演示如何通过 SDK 新增一条提示词；在实际生产环境中，更推荐直接在 Langfuse UI 中创建和发布。\n",
        "\n",
        "Langfuse 的提示词管理相当于一个“提示词内容管理系统（Prompt CMS）”。你可以在 UI 中编辑、预览与发布；也可在代码中通过 SDK 读取或更新。\n",
        "\n",
        "配置提示词时通常需要指定：\n",
        "\n",
        "* `name`：在 Langfuse 中唯一标识该提示词的名称\n",
        "* `prompt`：包含模板占位符（如 `{{input variables}}`）的文本内容\n",
        "* `labels`：可设置为 `production`，让该版本立即成为默认选项\n",
        "\n",
        "在本例中，我们创建一个系统提示词，让助手将所有用户输入翻译成西班牙语。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "H0J8-nbhUUz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7258e14c-4d9f-4be6-83a5-0249dd1d39da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langfuse.model.TextPromptClient at 0x7b98b9112ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "langfuse.create_prompt(\n",
        "    name=\"translator_system-prompt\",\n",
        "    prompt=\"You are a translator that translates every input text into Spanish.\",\n",
        "    labels=[\"production\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dullp4XDXhzg"
      },
      "source": [
        "![在 Langfuse UI 中查看提示词](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_prompt_example.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNboOjf2YQpD"
      },
      "source": [
        "使用工具方法 `.get_langchain_prompt()` 可以将 Langfuse 中的提示词转换为 LangChain 可直接使用的字符串。\n",
        "\n",
        "**背景说明：** Langfuse 在提示模板中使用双花括号（`{{input variable}}`）声明变量；而 LangChain 的 `PromptTemplate` 使用单花括号（`{input variable}`）。`.get_langchain_prompt()` 会自动完成格式转换。当前示例的提示词没有占位变量，但仍可以统一通过该方法处理。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "z49I82blYeXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da017b5a-c52a-46eb-838c-8ba2372b74af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a translator that translates every input text into Spanish.\n"
          ]
        }
      ],
      "source": [
        "# 读取生产环境中最新的提示词版本，并转换为 LangChain 可直接使用的字符串\n",
        "langfuse_system_prompt = langfuse.get_prompt(\"translator_system-prompt\")\n",
        "langchain_system_prompt = langfuse_system_prompt.get_langchain_prompt()\n",
        "\n",
        "print(langchain_system_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3zBULfCt0Wq"
      },
      "source": [
        "现在可以使用新的系统提示词字符串，更新我们的翻译助手。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oGQhulyMmvZD"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# 🧩 将系统提示词注入到聊天节点，确保助手先遵循翻译指令\n",
        "system_prompt = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": langchain_system_prompt\n",
        "}\n",
        "\n",
        "def chatbot(state: State):\n",
        "    messages_with_system_prompt = [system_prompt] + state[\"messages\"]\n",
        "    response = llm.invoke(messages_with_system_prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "graph = graph_builder.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YYd7wbttm2ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab21aac2-8975-402d-d41a-c7215c6b6553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chatbot': {'messages': [AIMessage(content='¿Qué es Langfuse?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 40, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-CIXxtA1hNoEtKEDz19si1R4S8hQiB', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f3f48a24-1ff4-4907-ba00-efa76a9bc7f9-0', usage_metadata={'input_tokens': 40, 'output_tokens': 7, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
          ]
        }
      ],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 📡 初始化 Langfuse 回调处理器（用于追踪翻译助手的调用）\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# 🔗 将回调挂载到图的 stream 方法中，实时查看翻译结果与追踪记录\n",
        "for s in graph.stream({\"messages\": [HumanMessage(content=\"请把“Langfuse 是什么？”翻译成西班牙语。\")]},\n",
        "                      config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}