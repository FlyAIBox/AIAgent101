{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/01_04_integration_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlCI9KeX4Zn4"
      },
      "source": [
        "## ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ\n",
        "\n",
        "[LangGraph](https://langchain-ai.github.io/langgraph/) æ˜¯ç”± LangChain å›¢é˜Ÿå¼€æºçš„æ¡†æ¶ï¼Œç”¨äºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºå¤æ‚ã€æœ‰çŠ¶æ€çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ã€‚LangGraph å†…ç½®äº†æŒä¹…åŒ–èƒ½åŠ›ï¼Œå¯ä¿å­˜ä¸æ¢å¤çŠ¶æ€ï¼Œä»è€Œæ”¯æŒé”™è¯¯æ¢å¤ä¸åŒ…å«â€œäººæœºäº¤äº’â€ï¼ˆHuman-in-the-loop, HITLï¼‰çš„å·¥ä½œæµã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o8L1qPcaZeC"
      },
      "source": [
        "## æœ¬å®è·µæ‰‹å†Œçš„ç›®æ ‡\n",
        "\n",
        "æœ¬æ‰‹å†Œæ¼”ç¤ºå¦‚ä½•å€ŸåŠ© [Langfuse](https://langfuse.com/docs)ï¼Œé€šè¿‡å…¶ä¸ [LangChain çš„é›†æˆ](https://langfuse.com/integrations/frameworks/langchain)ï¼Œå¯¹ä½ çš„ LangGraph åº”ç”¨è¿›è¡Œè°ƒè¯•ã€åˆ†æä¸è¿­ä»£ä¼˜åŒ–ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPTaMtxH4eHV"
      },
      "source": [
        "**å®Œæˆæœ¬æ‰‹å†Œåï¼Œä½ å°†èƒ½å¤Ÿï¼š**\n",
        "\n",
        "- è‡ªåŠ¨é€šè¿‡ Langfuse é›†æˆå¯¹ LangGraph åº”ç”¨è¿›è¡Œè¿½è¸ªï¼ˆtracingï¼‰\n",
        "- ç›‘æ§å¤æ‚çš„å¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰æ–¹æ¡ˆ\n",
        "- æ·»åŠ è¯„åˆ†ï¼ˆä¾‹å¦‚ç”¨æˆ·åé¦ˆï¼‰\n",
        "- ä½¿ç”¨ Langfuse ç®¡ç† LangGraph ä¸­ä½¿ç”¨çš„æç¤ºè¯ï¼ˆpromptï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sSIS88y9Ewm"
      },
      "source": [
        "## åˆå§‹åŒ– Langfuse\n",
        "\n",
        "åœ¨ Langfuse æ§åˆ¶å°é¡¹ç›®è®¾ç½®é¡µè·å–ä½ çš„ [API å¯†é’¥](https://langfuse.com/faq/all/where-are-langfuse-api-keys)ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ°è¿è¡Œç¯å¢ƒå˜é‡ä¸­ä»¥åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ã€‚\n",
        "\n",
        "<!-- CALLOUT_START type: \"info\" emoji: \"âš ï¸\" -->\n",
        "_**æ³¨æ„ï¼š** æœ¬ç¬”è®°ä½¿ç”¨ Langfuse Python SDK v3ã€‚_\n",
        "<!-- CALLOUT_END -->\n",
        "\n",
        "<!-- CALLOUT_START type: \"info\" emoji: \"â„¹ï¸\" -->\n",
        "_**æ³¨æ„ï¼š** éœ€è¦è‡³å°‘ Python 3.11ï¼ˆå‚è§ [GitHub Issue](https://github.com/langfuse/langfuse/issues/1926)ï¼‰ã€‚_\n",
        "<!-- CALLOUT_END -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C85BK1vJ5yD3",
        "outputId": "618fb8cc-9395-45e0-ee15-549cf7ac3c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse==3.3.0\n",
            "  Downloading langfuse-3.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai==0.3.31\n",
            "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_community==0.3.27\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langgraph==0.6.7\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting backoff>=1.10.0 (from langfuse==3.3.0)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.3.27)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph==0.6.7)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph==0.6.7)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph==0.6.7)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langfuse-3.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: ormsgpack, opentelemetry-proto, mypy-extensions, marshmallow, backoff, typing-inspect, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, langgraph-sdk, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langfuse, langgraph, langchain_community\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.36.0\n",
            "    Uninstalling opentelemetry-api-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.36.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.36.0\n",
            "    Uninstalling opentelemetry-sdk-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
            "Successfully installed backoff-2.2.1 dataclasses-json-0.6.7 langchain-openai-0.3.31 langchain_community-0.3.27 langfuse-3.3.0 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 marshmallow-3.26.1 mypy-extensions-1.1.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 ormsgpack-1.10.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langchain_community==0.3.27 langgraph==0.6.7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨ Langfuse æ§åˆ¶å°çš„é¡¹ç›®è®¾ç½®é¡µè·å– API Keyï¼Œåˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ï¼Œå¹¶å°†å…¶è®¾ç½®åˆ°ç¯å¢ƒå˜é‡ä¸­ã€‚"
      ],
      "metadata": {
        "id": "sUbRmJ-Kh0rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ” ç¯å¢ƒå˜é‡é…ç½® - å®‰å…¨å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
        "# ç¯å¢ƒå˜é‡æ˜¯å­˜å‚¨APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯çš„æœ€ä½³å®è·µ\n",
        "# é¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥ï¼Œé˜²æ­¢æ³„éœ²\n",
        "\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
        "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
        "    ä½¿ç”¨getpassæ¨¡å—éšè—è¾“å…¥å†…å®¹ï¼Œé˜²æ­¢å¯†ç æ³„éœ²\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "# ğŸ¤– OpenAI API é…ç½®\n",
        "# OpenAI APIå¯†é’¥ï¼šä» https://platform.openai.com/api-keys è·å–\n",
        "# è¿™æ˜¯è°ƒç”¨GPTæ¨¡å‹å¿…éœ€çš„è®¤è¯ä¿¡æ¯\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "\n",
        "# APIä»£ç†åœ°å€ï¼šå¦‚æœä½ ä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ï¼ˆå¦‚å›½å†…ä»£ç†ï¼‰\n",
        "# ç¤ºä¾‹ï¼šhttps://api.apiyi.com/v1\n",
        "# å¦‚æœç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹APIï¼Œå¯ä»¥ç•™ç©º\n",
        "_set_env(\"OPENAI_BASE_URL\")\n",
        "\n",
        "# ğŸŒ Langfuse é…ç½®\n",
        "# Langfuseæ˜¯ä¸€ä¸ªå¯è§‚æµ‹æ€§å¹³å°ï¼Œéœ€è¦æ³¨å†Œè´¦æˆ·è·å–å¯†é’¥\n",
        "# æ³¨å†Œåœ°å€ï¼šhttps://cloud.langfuse.com\n",
        "\n",
        "# å…¬å¼€å¯†é’¥ï¼šç”¨äºæ ‡è¯†ä½ çš„é¡¹ç›®\n",
        "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
        "\n",
        "# ç§˜å¯†å¯†é’¥ï¼šç”¨äºè®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡\n",
        "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
        "\n",
        "# æœåŠ¡å™¨åœ°å€ï¼šé€‰æ‹©ç¦»ä½ æœ€è¿‘çš„åŒºåŸŸ\n",
        "# ğŸ‡ªğŸ‡º æ¬§ç›ŸåŒºåŸŸ(æ¨è) https://cloud.langfuse.com\n",
        "# ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸï¼ˆä¸æ¨èï¼‰ https://us.cloud.langfuse.com\n",
        "_set_env(\"LANGFUSE_HOST\")\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
        "# 1. ç¯å¢ƒå˜é‡å­˜å‚¨åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œé‡å¯åéœ€è¦é‡æ–°è®¾ç½®\n",
        "# 2. ç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®ä½¿ç”¨.envæ–‡ä»¶æˆ–äº‘æœåŠ¡é…ç½®\n",
        "# 3. æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥ï¼\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vku6l5CLhwdC",
        "outputId": "2b08d8c8-36b9-496a-8bfd-247a64893f8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "OPENAI_BASE_URL: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_PUBLIC_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_SECRET_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_HOST: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agy0r3Byg-Aw"
      },
      "source": [
        "åœ¨ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆåï¼Œæˆ‘ä»¬å³å¯åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ã€‚`get_client()` ä¼šä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­æä¾›çš„å‡­æ®æ¥åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVLs2A8g-Ax",
        "outputId": "4cf4f89d-2ff0-4e97-d627-2043009554eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Langfuse å®¢æˆ·ç«¯å·²é€šè¿‡èº«ä»½éªŒè¯ï¼Œå‡†å¤‡å°±ç»ªï¼\n",
            "ğŸ”§ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨è¿½è¸ªåŠŸèƒ½äº†\n"
          ]
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "# ğŸš€ åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯\n",
        "# get_client() ä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„é…ç½®ä¿¡æ¯\n",
        "langfuse = get_client()\n",
        "\n",
        "# ğŸ” éªŒè¯å®¢æˆ·ç«¯è¿æ¥çŠ¶æ€\n",
        "# è¿™ä¸ªæ­¥éª¤éå¸¸é‡è¦ï¼Œç¡®ä¿åç»­çš„è¿½è¸ªåŠŸèƒ½èƒ½å¤Ÿæ­£å¸¸å·¥ä½œ\n",
        "if langfuse.auth_check():\n",
        "    print(\"âœ… Langfuse å®¢æˆ·ç«¯å·²é€šè¿‡èº«ä»½éªŒè¯ï¼Œå‡†å¤‡å°±ç»ªï¼\")\n",
        "    print(\"ğŸ”§ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨è¿½è¸ªåŠŸèƒ½äº†\")\n",
        "else:\n",
        "    print(\"âŒ èº«ä»½éªŒè¯å¤±è´¥ï¼\")\n",
        "    print(\"ğŸ” è¯·æ£€æŸ¥ä»¥ä¸‹é…ç½®é¡¹ï¼š\")\n",
        "    print(\"   - LANGFUSE_PUBLIC_KEY æ˜¯å¦æ­£ç¡®\")\n",
        "    print(\"   - LANGFUSE_SECRET_KEY æ˜¯å¦æ­£ç¡®\")\n",
        "    print(\"   - LANGFUSE_HOST æ˜¯å¦å¯è®¿é—®\")\n",
        "    print(\"   - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqYMmi6n9Nh1"
      },
      "source": [
        "## ç¤ºä¾‹ 1ï¼šä½¿ç”¨ LangGraph æ„å»ºç®€å•èŠå¤©åº”ç”¨\n",
        "\n",
        "**æœ¬èŠ‚å°†å®Œæˆï¼š**\n",
        "\n",
        "- åœ¨ LangGraph ä¸­æ„å»ºä¸€ä¸ªå¯å›ç­”å¸¸è§é—®é¢˜çš„å®¢æœèŠå¤©æœºå™¨äºº\n",
        "- ä½¿ç”¨ Langfuse å¯¹æœºå™¨äººçš„è¾“å…¥ä¸è¾“å‡ºè¿›è¡Œè¿½è¸ªï¼ˆtracingï¼‰\n",
        "\n",
        "æˆ‘ä»¬å…ˆä»ä¸€ä¸ªåŸºç¡€æœºå™¨äººå…¥æ‰‹ï¼Œéšååœ¨ä¸‹ä¸€èŠ‚æ‰©å±•ä¸ºæ›´é«˜çº§çš„å¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰è®¾ç½®ï¼Œå¹¶åœ¨è¿‡ç¨‹ä¸­ä»‹ç»å…³é”®çš„ LangGraph æ¦‚å¿µã€‚\n",
        "\n",
        "### åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆAgentï¼‰\n",
        "\n",
        "é¦–å…ˆåˆ›å»ºä¸€ä¸ª `StateGraph`ã€‚`StateGraph` å®šä¹‰äº†èŠå¤©æœºå™¨äººçš„çŠ¶æ€æœºç»“æ„ã€‚æˆ‘ä»¬ä¼šæ·»åŠ èŠ‚ç‚¹æ¥è¡¨ç¤º LLM ä»¥åŠæœºå™¨äººå¯è°ƒç”¨çš„å‡½æ•°ï¼Œå¹¶é€šè¿‡è¾¹ï¼ˆedgeï¼‰å®šä¹‰æœºå™¨äººåœ¨è¿™äº›å‡½æ•°ä¹‹é—´çš„çŠ¶æ€æµè½¬ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aGIxgPww6VX6"
      },
      "outputs": [],
      "source": [
        "# ğŸ”§ å¯¼å…¥ LangGraph æ„å»ºæ™ºèƒ½ä½“æ‰€éœ€çš„æ ¸å¿ƒæ¨¡å—\n",
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI  # OpenAI èŠå¤©æ¨¡å‹\n",
        "from langchain_core.messages import HumanMessage  # äººç±»æ¶ˆæ¯ç±»å‹\n",
        "from typing_extensions import TypedDict  # ç±»å‹åŒ–å­—å…¸\n",
        "from langgraph.graph import StateGraph  # LangGraph çŠ¶æ€å›¾\n",
        "from langgraph.graph.message import add_messages  # æ¶ˆæ¯æ·»åŠ å‡½æ•°\n",
        "\n",
        "# ğŸ“‹ å®šä¹‰æ™ºèƒ½ä½“çš„çŠ¶æ€ç»“æ„\n",
        "# State æ˜¯ä¸€ä¸ªç±»å‹åŒ–å­—å…¸ï¼Œå®šä¹‰äº†æ™ºèƒ½ä½“åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­éœ€è¦ç»´æŠ¤çš„çŠ¶æ€ä¿¡æ¯\n",
        "class State(TypedDict):\n",
        "    # ğŸ’¬ æ¶ˆæ¯åˆ—è¡¨ï¼šå­˜å‚¨å¯¹è¯å†å²\n",
        "    # Annotated[list, add_messages] çš„å«ä¹‰ï¼š\n",
        "    # - list: æ¶ˆæ¯çš„æ•°æ®ç±»å‹æ˜¯åˆ—è¡¨\n",
        "    # - add_messages: æŒ‡å®šçŠ¶æ€æ›´æ–°ç­–ç•¥ï¼Œæ–°æ¶ˆæ¯ä¼šè¿½åŠ åˆ°åˆ—è¡¨æœ«å°¾è€Œä¸æ˜¯è¦†ç›–æ•´ä¸ªåˆ—è¡¨\n",
        "    # è¿™ç§è®¾è®¡ç¡®ä¿äº†å¯¹è¯å†å²çš„å®Œæ•´ä¿å­˜\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# ğŸ—ï¸ åˆ›å»ºçŠ¶æ€å›¾æ„å»ºå™¨\n",
        "# StateGraph æ˜¯ LangGraph çš„æ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºå®šä¹‰æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# ğŸ¤– åˆå§‹åŒ–è¯­è¨€æ¨¡å‹\n",
        "# é€‰æ‹© GPT-4o æ¨¡å‹ï¼Œtemperature=0.2 ç¡®ä¿è¾“å‡ºç›¸å¯¹ç¨³å®šä½†ä»æœ‰ä¸€å®šåˆ›é€ æ€§\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# ğŸ”„ å®šä¹‰èŠå¤©æœºå™¨äººèŠ‚ç‚¹å‡½æ•°\n",
        "# è¿™æ˜¯ LangGraph èŠ‚ç‚¹å‡½æ•°çš„åŸºæœ¬æ¨¡å¼ï¼šæ¥æ”¶å½“å‰çŠ¶æ€ï¼Œè¿”å›æ›´æ–°åçš„çŠ¶æ€\n",
        "def chatbot(state: State):\n",
        "    \"\"\"\n",
        "    èŠå¤©æœºå™¨äººèŠ‚ç‚¹çš„æ ¸å¿ƒé€»è¾‘\n",
        "\n",
        "    å‚æ•°:\n",
        "        state (State): å½“å‰çš„æ™ºèƒ½ä½“çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å†å²\n",
        "\n",
        "    è¿”å›:\n",
        "        dict: åŒ…å«æ–°ç”Ÿæˆæ¶ˆæ¯çš„çŠ¶æ€æ›´æ–°\n",
        "\n",
        "    å·¥ä½œæµç¨‹:\n",
        "    1. è·å–å½“å‰çš„æ¶ˆæ¯å†å²\n",
        "    2. å°†æ¶ˆæ¯å†å²å‘é€ç»™è¯­è¨€æ¨¡å‹\n",
        "    3. æ¥æ”¶æ¨¡å‹ç”Ÿæˆçš„å›å¤\n",
        "    4. å°†å›å¤åŒ…è£…æˆçŠ¶æ€æ›´æ–°è¿”å›\n",
        "    \"\"\"\n",
        "    # è°ƒç”¨è¯­è¨€æ¨¡å‹å¤„ç†å½“å‰å¯¹è¯å†å²ï¼Œç”Ÿæˆå›å¤\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "\n",
        "    # è¿”å›çŠ¶æ€æ›´æ–°ï¼šå°†æ¨¡å‹çš„å›å¤æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# ğŸ”— å‘å›¾ä¸­æ·»åŠ \"chatbot\"èŠ‚ç‚¹\n",
        "# èŠ‚ç‚¹ä»£è¡¨å·¥ä½œå•å…ƒï¼Œé€šå¸¸æ˜¯æ™®é€šçš„ Python å‡½æ•°\n",
        "# æ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£ç‰¹å®šçš„å¤„ç†é€»è¾‘ï¼Œå¦‚è°ƒç”¨ LLMã€å¤„ç†å·¥å…·ã€æ•°æ®è½¬æ¢ç­‰\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# ğŸš€ è®¾ç½®å›¾çš„å…¥å£ç‚¹\n",
        "# å‘Šè¯‰å›¾æ¯æ¬¡è¿è¡Œæ—¶ä»å“ªä¸ªèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ\n",
        "# åœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ç›´æ¥ä» chatbot èŠ‚ç‚¹å¼€å§‹\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "\n",
        "# ğŸ è®¾ç½®å›¾çš„ç»“æŸç‚¹\n",
        "# æŒ‡ç¤ºå›¾\"å½“è¿™ä¸ªèŠ‚ç‚¹è¿è¡Œå®Œæˆåï¼Œå¯ä»¥é€€å‡ºæ‰§è¡Œ\"\n",
        "# å¯¹äºç®€å•çš„å•è½®å¯¹è¯ï¼Œchatbot èŠ‚ç‚¹æ‰§è¡Œå®Œå°±å¯ä»¥ç»“æŸ\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "\n",
        "# âš™ï¸ ç¼–è¯‘å›¾å½¢ä¸ºå¯æ‰§è¡Œå¯¹è±¡\n",
        "# compile() æ–¹æ³•å°†å›¾æ„å»ºå™¨è½¬æ¢ä¸º CompiledGraph\n",
        "# CompiledGraph æ˜¯å¯ä»¥å®é™…è¿è¡Œçš„å›¾å½¢å¯¹è±¡ï¼Œæ”¯æŒ invokeã€stream ç­‰æ–¹æ³•\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# ğŸ’¡ ç†è§£ LangGraph çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n",
        "# ğŸ—ï¸ StateGraph: å®šä¹‰æ™ºèƒ½ä½“çš„çŠ¶æ€å’Œå·¥ä½œæµç¨‹\n",
        "# ğŸ”„ Node: æ‰§è¡Œå…·ä½“ä»»åŠ¡çš„å‡½æ•°ï¼Œå¦‚è°ƒç”¨ LLMã€ä½¿ç”¨å·¥å…·ç­‰\n",
        "# ğŸ”— Edge: è¿æ¥èŠ‚ç‚¹ï¼Œå®šä¹‰æ‰§è¡Œé¡ºåºå’Œæ¡ä»¶è·³è½¬\n",
        "# ğŸ“Š State: æ™ºèƒ½ä½“è¿è¡Œè¿‡ç¨‹ä¸­ç»´æŠ¤çš„æ•°æ®ç»“æ„\n",
        "# âš™ï¸ CompiledGraph: ç¼–è¯‘åçš„å¯æ‰§è¡Œå›¾å½¢å¯¹è±¡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW2SJcRgh7Xo"
      },
      "source": [
        "### åœ¨è°ƒç”¨æ—¶æ·»åŠ  Langfuse å›è°ƒ\n",
        "\n",
        "ç°åœ¨ï¼Œä¸ºäº†è¿½è¸ªåº”ç”¨æ‰§è¡Œè¿‡ç¨‹ï¼Œæˆ‘ä»¬å°†æ·»åŠ  [é¢å‘ LangChain çš„ Langfuse å›è°ƒå¤„ç†å™¨](https://langfuse.com/integrations/frameworks/langchain)ï¼š`config={\"callbacks\": [langfuse_handler]}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PxEc455-KYM",
        "outputId": "b4c73185-7d54-4e1d-b140-80685ea5b9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¤– æ™ºèƒ½ä½“å¼€å§‹è¿è¡Œï¼Œæ­£åœ¨å¤„ç†é—®é¢˜â€¦â€¦\n",
            "â“ ç”¨æˆ·æé—®ï¼šä»€ä¹ˆæ˜¯ Langfuseï¼Ÿ\n",
            "ğŸ“‹ æ‰§è¡Œè¿‡ç¨‹:\n",
            "ğŸ“¤ èŠ‚ç‚¹æ‰§è¡Œç»“æœï¼š{'chatbot': {'messages': [AIMessage(content='Langfuse æ˜¯ä¸€ä¸ªä¸“æ³¨äºè¯­è¨€æ¨¡å‹å’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰åº”ç”¨çš„å·¥å…·æˆ–å¹³å°ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…å’Œä¼ä¸šæ›´æœ‰æ•ˆåœ°æ„å»ºã€ç®¡ç†å’Œä¼˜åŒ–åŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚è™½ç„¶å…·ä½“çš„åŠŸèƒ½å’Œåº”ç”¨åœºæ™¯å¯èƒ½ä¼šå› ç‰ˆæœ¬å’Œå…·ä½“å®ç°è€Œæœ‰æ‰€ä¸åŒï¼Œä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½çš„ä¸»è¦åŠŸèƒ½å’Œå…¸å‹åº”ç”¨åœºæ™¯ï¼š\\n\\n### ä¸»è¦åŠŸèƒ½\\n\\n1. **æ¨¡å‹ç®¡ç†**ï¼š\\n   - æä¾›å¯¹å¤šç§è¯­è¨€æ¨¡å‹çš„æ”¯æŒï¼ŒåŒ…æ‹¬å¼€æºæ¨¡å‹å’Œå•†ä¸šæ¨¡å‹ã€‚\\n   - å…è®¸ç”¨æˆ·ä¸Šä¼ å’Œç®¡ç†è‡ªå®šä¹‰æ¨¡å‹ã€‚\\n\\n2. **æ•°æ®å¤„ç†ä¸åˆ†æ**ï¼š\\n   - æä¾›æ•°æ®é¢„å¤„ç†å·¥å…·ï¼Œä»¥ä¾¿æ›´å¥½åœ°å‡†å¤‡è®­ç»ƒæ•°æ®ã€‚\\n   - æä¾›åˆ†æå·¥å…·æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ŒåŒ…æ‹¬å‡†ç¡®æ€§ã€å¬å›ç‡ã€F1åˆ†æ•°ç­‰ã€‚\\n\\n3. **è®­ç»ƒä¸ä¼˜åŒ–**ï¼š\\n   - æ”¯æŒæ¨¡å‹è®­ç»ƒå’Œå¾®è°ƒï¼Œå¸®åŠ©ç”¨æˆ·æ ¹æ®ç‰¹å®šéœ€æ±‚ä¼˜åŒ–æ¨¡å‹ã€‚\\n   - æä¾›è¶…å‚æ•°è°ƒä¼˜å·¥å…·ï¼Œä»¥æé«˜æ¨¡å‹çš„æ•ˆç‡å’Œæ•ˆæœã€‚\\n\\n4. **éƒ¨ç½²ä¸é›†æˆ**ï¼š\\n   - æä¾›ç®€å•çš„APIæ¥å£ï¼Œæ–¹ä¾¿å°†æ¨¡å‹é›†æˆåˆ°ç°æœ‰åº”ç”¨ä¸­ã€‚\\n   - æ”¯æŒäº‘ç«¯å’Œæœ¬åœ°éƒ¨ç½²ï¼Œæ»¡è¶³ä¸åŒçš„ä¸šåŠ¡éœ€æ±‚ã€‚\\n\\n5. **ç›‘æ§ä¸æ—¥å¿—**ï¼š\\n   - æä¾›å®æ—¶ç›‘æ§å·¥å…·ï¼Œå¸®åŠ©ç”¨æˆ·è·Ÿè¸ªæ¨¡å‹çš„ä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½ã€‚\\n   - æä¾›æ—¥å¿—è®°å½•åŠŸèƒ½ï¼Œä»¥ä¾¿è¿›è¡Œæ•…éšœæ’æŸ¥å’Œæ€§èƒ½åˆ†æã€‚\\n\\n6. **å®‰å…¨ä¸åˆè§„**ï¼š\\n   - æä¾›æ•°æ®åŠ å¯†å’Œè®¿é—®æ§åˆ¶ï¼Œç¡®ä¿æ•°æ®å®‰å…¨ã€‚\\n   - ç¡®ä¿å¹³å°ç¬¦åˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œå¦‚GDPRç­‰ã€‚\\n\\n### å…¸å‹åº”ç”¨åœºæ™¯\\n\\n1. **å®¢æœä¸èŠå¤©æœºå™¨äºº**ï¼š\\n   - ä½¿ç”¨Langfuseæ„å»ºæ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œèƒ½å¤Ÿç†è§£å’Œå“åº”å®¢æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€‚\\n   - æä¾›24/7çš„å®¢æˆ·æ”¯æŒï¼Œæé«˜å®¢æˆ·æ»¡æ„åº¦ã€‚\\n\\n2. **å†…å®¹ç”Ÿæˆä¸ç¼–è¾‘**ï¼š\\n   - å¸®åŠ©å†…å®¹åˆ›ä½œè€…ç”Ÿæˆé«˜è´¨é‡çš„æ–‡æœ¬å†…å®¹ï¼Œå¦‚æ–‡ç« ã€æŠ¥å‘Šç­‰ã€‚\\n   - æä¾›è‡ªåŠ¨åŒ–çš„æ–‡æœ¬æ ¡å¯¹å’Œç¼–è¾‘åŠŸèƒ½ã€‚\\n\\n3. **ç¿»è¯‘ä¸è¯­è¨€è½¬æ¢**ï¼š\\n   - æä¾›é«˜æ•ˆçš„æœºå™¨ç¿»è¯‘æœåŠ¡ï¼Œæ”¯æŒå¤šè¯­è¨€è½¬æ¢ã€‚\\n   - å¸®åŠ©ä¼ä¸šå®ç°å…¨çƒåŒ–è¿è¥ï¼Œæ”¯æŒå¤šè¯­è¨€å®¢æˆ·ã€‚\\n\\n4. **æƒ…æ„Ÿåˆ†æä¸å¸‚åœºè°ƒç ”**ï¼š\\n   - åˆ†æç¤¾äº¤åª’ä½“ã€å®¢æˆ·åé¦ˆä¸­çš„æƒ…æ„Ÿå€¾å‘ï¼Œå¸®åŠ©ä¼ä¸šäº†è§£å¸‚åœºåŠ¨æ€ã€‚\\n   - æä¾›æ•°æ®é©±åŠ¨çš„å¸‚åœºå†³ç­–æ”¯æŒã€‚\\n\\n5. **ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ**ï¼š\\n   - åŸºäºç”¨æˆ·çš„å†å²è¡Œä¸ºå’Œåå¥½ï¼Œæä¾›ä¸ªæ€§åŒ–çš„äº§å“æˆ–å†…å®¹æ¨èã€‚\\n   - æé«˜ç”¨æˆ·å‚ä¸åº¦å’Œè½¬åŒ–ç‡ã€‚\\n\\nLangfuse ä½œä¸ºä¸€ä¸ªç»¼åˆæ€§çš„å¹³å°ï¼Œèƒ½å¤Ÿä¸ºå„ç§éœ€è¦è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨æä¾›æ”¯æŒï¼Œä»è€Œå¸®åŠ©ä¼ä¸šå’Œå¼€å‘è€…æ›´é«˜æ•ˆåœ°åˆ©ç”¨è¯­è¨€æ¨¡å‹çš„å¼ºå¤§åŠŸèƒ½ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 624, 'prompt_tokens': 26, 'total_tokens': 650, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-CIXdYUV27bcw2APXT9Ho5L9hZ9Hzb', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--94ba4345-2e2b-46ac-8d71-6f41ec1598de-0', usage_metadata={'input_tokens': 26, 'output_tokens': 624, 'total_tokens': 650, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "âœ… æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆï¼\n",
            "ğŸ” è¯·å‰å¾€ Langfuse æ§åˆ¶å°æŸ¥çœ‹å®Œæ•´çš„è¿½è¸ªè®°å½•ã€‚\n"
          ]
        }
      ],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# ğŸ›ï¸ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨\n",
        "# è¯¥å¤„ç†å™¨ä¼šè‡ªåŠ¨æ•è· LangChain/LangGraph çš„æ‰§è¡Œç»†èŠ‚ï¼Œç”¨äºï¼š\n",
        "# - ğŸ•’ è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„è€—æ—¶ä¸å»¶è¿Ÿ\n",
        "# - ğŸ“ ä¿å­˜è¾“å…¥ã€è¾“å‡ºåŠä¸­é—´çŠ¶æ€\n",
        "# - ğŸ’° ç»Ÿè®¡ token æ¶ˆè€—å’Œ API è°ƒç”¨æˆæœ¬\n",
        "# - ğŸ æ”¶é›†å¼‚å¸¸ä¿¡æ¯ï¼Œä¾¿äºæ’é”™\n",
        "# - ğŸ“ˆ åœ¨ Langfuse ä¸­ç”Ÿæˆå¯è§†åŒ–è°ƒç”¨é“¾\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# ğŸš€ è¿è¡Œæ™ºèƒ½ä½“å¹¶å¯ç”¨ Langfuse è¿½è¸ª\n",
        "print(\"ğŸ¤– æ™ºèƒ½ä½“å¼€å§‹è¿è¡Œï¼Œæ­£åœ¨å¤„ç†é—®é¢˜â€¦â€¦\")\n",
        "print(\"â“ ç”¨æˆ·æé—®ï¼šä»€ä¹ˆæ˜¯ Langfuseï¼Ÿ\")\n",
        "print(\"ğŸ“‹ æ‰§è¡Œè¿‡ç¨‹:\")\n",
        "\n",
        "# ä½¿ç”¨ stream æ–¹æ³•å¯ä»¥å®æ—¶æŸ¥çœ‹æ™ºèƒ½ä½“çš„æ‰§è¡Œæ­¥éª¤\n",
        "for step_result in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"ä»€ä¹ˆæ˜¯ Langfuseï¼Ÿè¯·è¯¦ç»†ä»‹ç»å…¶ä¸»è¦åŠŸèƒ½å’Œå…¸å‹åº”ç”¨åœºæ™¯ã€‚\")]},\n",
        "    config={\"callbacks\": [langfuse_handler]}\n",
        "):\n",
        "    print(f\"ğŸ“¤ èŠ‚ç‚¹æ‰§è¡Œç»“æœï¼š{step_result}\")\n",
        "\n",
        "print(\n",
        "\"âœ… æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆï¼\")\n",
        "print(\"ğŸ” è¯·å‰å¾€ Langfuse æ§åˆ¶å°æŸ¥çœ‹å®Œæ•´çš„è¿½è¸ªè®°å½•ã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdf3ZRnWGZ0N"
      },
      "source": [
        "### åœ¨ Langfuse ä¸­æŸ¥çœ‹è¿½è¸ªç»“æœ\n",
        "\n",
        "ç¤ºä¾‹è¿½è¸ªï¼šhttps://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=cbc8503a9a111fc5eadb5e914be3fa7a&timestamp=2025-09-22T03%3A48%3A16.647Z&observation=47245ec86916a5d1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Aq7u6_LBR6"
      },
      "source": [
        "![åœ¨ Langfuse ä¸­æŸ¥çœ‹èŠå¤©åº”ç”¨çš„è¿½è¸ª](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509221150147.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3yyVtGKhMPU"
      },
      "source": [
        "### å¯è§†åŒ–èŠå¤©åº”ç”¨\n",
        "\n",
        "ä½ å¯ä»¥ä½¿ç”¨ `get_graph` æ–¹æ³•é…åˆç›¸åº”çš„ â€œdrawâ€ æ–¹æ³•å¯¹å›¾è¿›è¡Œå¯è§†åŒ–ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "MKkM6mw47kIy",
        "outputId": "8eae221d-3838-4fbe-ac94-8fe2c1e18513"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY0HW5xISntw"
      },
      "source": [
        "```mermaid\n",
        "graph TD;\n",
        "\t__start__([__start__]):::first\n",
        "\tchatbot(chatbot)\n",
        "\t__end__([__end__]):::last\n",
        "\t__start__ --> chatbot;\n",
        "\tchatbot --> __end__;\n",
        "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
        "\tclassDef first fill-opacity:0\n",
        "\tclassDef last fill:#bfb6fc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F4Tt_E4g-A0"
      },
      "source": [
        "### åœ¨ LangGraph Server ä¸­ä½¿ç”¨ Langfuse\n",
        "\n",
        "#### ğŸ–¥ï¸ LangGraph Server ç®€ä»‹\n",
        "\n",
        "[LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) æ˜¯ LangGraph æä¾›çš„æœåŠ¡å™¨éƒ¨ç½²æ–¹æ¡ˆï¼Œç”¨äºå°†æœ¬åœ°æ„å»ºçš„å›¾å·¥ä½œæµå‘å¸ƒä¸ºå¯æ‰©å±•çš„åœ¨çº¿æœåŠ¡ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
        "\n",
        "- ğŸŒ **HTTP API æ¥å£**ï¼šå°† LangGraph æ™ºèƒ½ä½“å°è£…ä¸º REST APIï¼Œä¾¿äºä¸ä¸šåŠ¡ç³»ç»Ÿé›†æˆ\n",
        "- ğŸš€ **ç”Ÿäº§çº§è¿è¡Œ**ï¼šæ”¯æŒé«˜å¹¶å‘ã€è´Ÿè½½å‡è¡¡ä¸å®¹å™¨åŒ–äº¤ä»˜\n",
        "- ğŸ”§ **è¿ç»´å‹å¥½**ï¼šè‡ªåŠ¨å¤„ç†è¯·æ±‚è·¯ç”±ã€çŠ¶æ€æ¢å¤ä¸é”™è¯¯é‡è¯•\n",
        "- ğŸ“Š **ç›‘æ§é›†æˆ**ï¼šå…¼å®¹ä¸»æµç›‘æ§ä¸è¿½è¸ªä½“ç³»ï¼Œä¾¿äºè§‚æµ‹è¿è¡ŒçŠ¶å†µ\n",
        "- ğŸ”’ **å®‰å…¨ç®¡æ§**ï¼šå†…ç½®èº«ä»½è®¤è¯ä¸æˆæƒæœºåˆ¶ï¼Œæ»¡è¶³ä¼ä¸šå®‰å…¨éœ€æ±‚\n",
        "\n",
        "#### ğŸ’¡ ä¸ºä»€ä¹ˆè¦åœ¨ Server ç¯å¢ƒæ¥å…¥ Langfuseï¼Ÿ\n",
        "\n",
        "- ğŸ­ **ç”Ÿäº§å¯è§‚æµ‹æ€§**ï¼šå®æ—¶æŸ¥çœ‹çº¿ä¸Šè¯·æ±‚çš„è°ƒç”¨é“¾ä¸çŠ¶æ€\n",
        "- ğŸ› **è¿œç¨‹è°ƒè¯•**ï¼šæ— éœ€å¤ç°åœºæ™¯å³å¯è¿˜åŸé—®é¢˜ç»†èŠ‚\n",
        "- ğŸ“ˆ **æ€§èƒ½æ´å¯Ÿ**ï¼šé‡åŒ–æ¯ä¸ªèŠ‚ç‚¹çš„è€—æ—¶ä¸æˆæœ¬\n",
        "- ğŸ’° **è´¹ç”¨æ²»ç†**ï¼šå‡†ç¡®ç»Ÿè®¡ç¬¬ä¸‰æ–¹ API çš„è°ƒç”¨é‡ä¸è´¹ç”¨\n",
        "- ğŸ‘¥ **å›¢é˜Ÿåä½œ**ï¼šå…±äº«è¿½è¸ªè®°å½•ï¼Œæ”¯æŒè·¨èŒèƒ½ååŒæ’æŸ¥\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTW_X4rFg-A0"
      },
      "source": [
        "#### ğŸ”§ é…ç½®æ–¹æ³•è¯´æ˜\n",
        "\n",
        "ä½¿ç”¨ LangGraph Server æ—¶ï¼Œæ™ºèƒ½ä½“å›¾çš„è°ƒç”¨ç”±æœåŠ¡å™¨è‡ªåŠ¨å¤„ç†ï¼Œç”¨æˆ·æ— æ³•åœ¨æ¯æ¬¡è¯·æ±‚æ—¶æ‰‹åŠ¨æŒ‡å®šå›è°ƒå¤„ç†å™¨ã€‚\n",
        "\n",
        "**å…³é”®å·®å¼‚ï¼š**\n",
        "- ğŸ  **æœ¬åœ°å¼€å‘**ï¼šå¯ä»¥åœ¨æ¯æ¬¡è°ƒç”¨æ—¶æ·»åŠ  `config={\"callbacks\": [langfuse_handler]}`\n",
        "- ğŸ–¥ï¸ **æœåŠ¡å™¨éƒ¨ç½²**ï¼šéœ€è¦åœ¨å›¾ç¼–è¯‘æ—¶é¢„å…ˆé…ç½®å›è°ƒå¤„ç†å™¨\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼š**\n",
        "åœ¨å£°æ˜å’Œç¼–è¯‘å›¾æ—¶å°±æ·»åŠ  Langfuse å›è°ƒï¼Œè¿™æ ·æœåŠ¡å™¨ä¸Šçš„æ‰€æœ‰è¯·æ±‚éƒ½ä¼šè‡ªåŠ¨å¯ç”¨è¿½è¸ªåŠŸèƒ½ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J5UKXzbUg-A0"
      },
      "outputs": [],
      "source": [
        "# ğŸ”§ å¯¼å…¥æœåŠ¡å™¨éƒ¨ç½²æ‰€éœ€çš„æ¨¡å—\n",
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# ğŸ“‹ å®šä¹‰ä¸å‰æ–‡ä¸€è‡´çš„æ™ºèƒ½ä½“çŠ¶æ€ç»“æ„\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# ğŸ—ï¸ æ„å»ºå›¾å½¢ç»“æ„\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# ğŸ¤– åˆå§‹åŒ–è¯­è¨€æ¨¡å‹\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# ğŸ”„ å®šä¹‰èŠå¤©æœºå™¨äººèŠ‚ç‚¹\n",
        "def chatbot(state: State):\n",
        "    \"\"\"å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤ã€‚\"\"\"\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# ğŸ”— ç»„è£…å›¾å½¢ç»“æ„\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "\n",
        "# ğŸ”„ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼ˆæœåŠ¡å™¨æ¨¡å¼ï¼‰\n",
        "# åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­ï¼Œæ­¤å¤„ç†å™¨ä¼šè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰è¯·æ±‚çš„æ‰§è¡Œæƒ…å†µ\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# âš™ï¸ ç¼–è¯‘å›¾å½¢å¹¶é¢„é…ç½®å›è°ƒå¤„ç†å™¨\n",
        "# ğŸ¯ æ ¸å¿ƒæ–¹æ³•ï¼šwith_config()\n",
        "# - compile()ï¼šç¼–è¯‘å›¾å½¢ï¼Œç”Ÿæˆå¯æ‰§è¡Œçš„ CompiledGraph\n",
        "# - with_config()ï¼šä¸ºç¼–è¯‘åçš„å›¾å½¢è®¾ç½®é»˜è®¤é…ç½®ï¼ˆå¦‚å›è°ƒå¤„ç†å™¨ï¼‰\n",
        "#\n",
        "# ğŸ’¡ å·¥ä½œæµç¨‹ï¼š\n",
        "# 1. ç¼–è¯‘å›¾å½¢å¾—åˆ° CompiledGraph å¯¹è±¡\n",
        "# 2. è°ƒç”¨ with_config() æ³¨å…¥ Langfuse å›è°ƒ\n",
        "# 3. è¿”å›ä¸€ä¸ªå·²å†…ç½®è¿½è¸ªèƒ½åŠ›çš„æ–°å›¾å¯¹è±¡\n",
        "#\n",
        "# ğŸš€ ä¼˜åŠ¿ï¼š\n",
        "# - æ— éœ€åœ¨æ¯æ¬¡è¯·æ±‚æ—¶æ‰‹åŠ¨æ·»åŠ å›è°ƒé…ç½®\n",
        "# - æ‰€æœ‰ API è¯·æ±‚éƒ½ä¼šè‡ªåŠ¨å†™å…¥ Langfuse è¿½è¸ª\n",
        "# - ç®€åŒ–ç”Ÿäº§ç¯å¢ƒçš„éƒ¨ç½²ä¸è¿ç»´\n",
        "graph = graph_builder.compile().with_config({\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "# ğŸ’¡ éƒ¨ç½²æç¤ºï¼š\n",
        "# åœ¨ LangGraph Server ä¸­ç›´æ¥å¼•ç”¨æ­¤ graphï¼Œå³å¯ç«‹å³è·å¾—å®Œæ•´çš„è¿½è¸ªæ•°æ®\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2W94eY19TR1"
      },
      "source": [
        "## ç¤ºä¾‹ 2ï¼šåŸºäº LangGraph çš„å¤šæ™ºèƒ½ä½“åº”ç”¨\n",
        "\n",
        "**æœ¬èŠ‚å°†å®Œæˆï¼š**\n",
        "\n",
        "- æ„å»º 2 ä¸ªæ‰§è¡Œæ™ºèƒ½ä½“ï¼šä¸€ä¸ªç ”ç©¶æ™ºèƒ½ä½“ä½¿ç”¨ LangChain çš„ WikipediaAPIWrapper æœç´¢ç»´åŸºç™¾ç§‘ï¼Œå¦ä¸€ä¸ªä½¿ç”¨è‡ªå®šä¹‰å·¥å…·è·å–å½“å‰æ—¶é—´\n",
        "- æ„å»ºä¸€ä¸ªæ™ºèƒ½ä½“ç›‘ç£è€…ï¼ˆsupervisorï¼‰ï¼Œç”¨äºå°†ç”¨æˆ·é—®é¢˜åˆ†é…ç»™ä¸Šè¿°æ™ºèƒ½ä½“\n",
        "- æ·»åŠ  Langfuse å›è°ƒä»¥è¿½è¸ªç›‘ç£è€…ä¸æ‰§è¡Œæ™ºèƒ½ä½“çš„æ­¥éª¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WfnrswDdjYTV",
        "outputId": "4da1756a-98bd-43a4-fdb0-c0314c1aaaaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langfuse==3.3.0 in /usr/local/lib/python3.12/dist-packages (3.3.0)\n",
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai==0.3.31 in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langgraph==0.6.7 in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Collecting langchain_experimental\n",
            "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.2.1)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7) (3.5.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_experimental) (0.3.27)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=a0cfe403b04fc6787680c1491497e5a56409f7981aeb7d862e3ef66fdcb371bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia, langchain_experimental\n",
            "Successfully installed langchain_experimental-0.3.4 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langgraph==0.6.7 langchain_experimental==0.3.4 pandas==2.2.2 wikipedia==1.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show langchain_experimental pandas wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDwN3meK4vHk",
        "outputId": "6d2b5be8-7c7b-4fa4-93ef-c6c3822b75d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain-experimental\n",
            "Version: 0.3.4\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain-experimental\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: langchain-community, langchain-core\n",
            "Required-by: \n",
            "---\n",
            "Name: pandas\n",
            "Version: 2.2.2\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: \n",
            "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
            "License: BSD 3-Clause License\n",
            "\n",
            "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
            "All rights reserved.\n",
            "\n",
            "Copyright (c) 2011-2023, Open source contributors.\n",
            "\n",
            "Redistribution and use in source and binary forms, with or without\n",
            "modification, are permitted provided that the following conditions are met:\n",
            "\n",
            "* Redistributions of source code must retain the above copyright notice, this\n",
            "  list of conditions and the following disclaimer.\n",
            "\n",
            "* Redistributions in binary form must reproduce the above copyright notice,\n",
            "  this list of conditions and the following disclaimer in the documentation\n",
            "  and/or other materials provided with the distribution.\n",
            "\n",
            "* Neither the name of the copyright holder nor the names of its\n",
            "  contributors may be used to endorse or promote products derived from\n",
            "  this software without specific prior written permission.\n",
            "\n",
            "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
            "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
            "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
            "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
            "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
            "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
            "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
            "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
            "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
            "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz, tzdata\n",
            "Required-by: arviz, bigframes, bigquery-magics, bokeh, bqplot, cmdstanpy, cudf-cu12, cufflinks, dask-cuda, dask-cudf-cu12, datasets, db-dtypes, dopamine_rl, fastai, geemap, geopandas, google-colab, gradio, gspread-dataframe, holoviews, libpysal, mizani, mlxtend, pandas-datareader, pandas-gbq, panel, plotnine, prophet, pymc, seaborn, shap, sklearn-pandas, statsmodels, tensorflow_decision_forests, tsfresh, vega-datasets, xarray, yfinance\n",
            "---\n",
            "Name: wikipedia\n",
            "Version: 1.4.0\n",
            "Summary: Wikipedia API for Python\n",
            "Home-page: https://github.com/goldsmith/Wikipedia\n",
            "Author: Jonathan Goldsmith\n",
            "Author-email: jhghank@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: beautifulsoup4, requests\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tciUQ62IEVec"
      },
      "source": [
        "### åˆ›å»ºå·¥å…·\n",
        "\n",
        "åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªç”¨äºç»´åŸºç™¾ç§‘æ£€ç´¢çš„æ™ºèƒ½ä½“ï¼Œä»¥åŠä¸€ä¸ªç”¨äºå‘ŠçŸ¥å½“å‰æ—¶é—´çš„æ™ºèƒ½ä½“ã€‚å…ˆå®šä¹‰å®ƒä»¬å°†ä½¿ç”¨çš„å·¥å…·ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cet0loyp9p-T"
      },
      "outputs": [],
      "source": [
        "# ğŸ”§ å¯¼å…¥å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ‰€éœ€çš„å·¥å…·å’Œæ¨¡å—\n",
        "from typing import Annotated\n",
        "from langchain_community.tools import WikipediaQueryRun  # ç»´åŸºç™¾ç§‘æŸ¥è¯¢å·¥å…·\n",
        "from langchain_community.utilities import WikipediaAPIWrapper  # ç»´åŸºç™¾ç§‘ API å°è£…\n",
        "from datetime import datetime  # æ—¶é—´å¤„ç†æ¨¡å—\n",
        "from langchain.tools import Tool  # é€šç”¨å·¥å…·å®šä¹‰ç±»\n",
        "\n",
        "# ğŸ” å®šä¹‰ç»´åŸºç™¾ç§‘æœç´¢å·¥å…·\n",
        "# åŠŸèƒ½ï¼šæ ¹æ®æŸ¥è¯¢è¯åœ¨ç»´åŸºç™¾ç§‘ä¸­æœç´¢ç›¸å…³ä¿¡æ¯\n",
        "# é€‚ç”¨åœºæ™¯ï¼šå›ç­”ç™¾ç§‘çŸ¥è¯†ã€å†å²äº‹ä»¶ã€äººç‰©ä¼ è®°ç­‰é—®é¢˜\n",
        "wikipedia_tool = WikipediaQueryRun(\n",
        "    api_wrapper=WikipediaAPIWrapper(\n",
        "        top_k_results=2,  # è¿”å›æœ€ç›¸å…³çš„2ä¸ªæœç´¢ç»“æœ\n",
        "        doc_content_chars_max=1000  # é™åˆ¶æ¯ä¸ªç»“æœçš„å­—ç¬¦æ•°ï¼Œé¿å…ä¿¡æ¯è¿‡è½½\n",
        "    )\n",
        ")\n",
        "\n",
        "# â° å®šä¹‰å½“å‰æ—¶é—´æŸ¥è¯¢å·¥å…·\n",
        "# åŠŸèƒ½ï¼šè¿”å›å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´ä¿¡æ¯\n",
        "# é€‚ç”¨åœºæ™¯ï¼šå›ç­”\"ç°åœ¨å‡ ç‚¹\"ã€\"ä»Šå¤©æ˜¯ä»€ä¹ˆæ—¥æœŸ\"ç­‰æ—¶é—´ç›¸å…³é—®é¢˜\n",
        "datetime_tool = Tool(\n",
        "    name=\"Datetime\",  # å·¥å…·åç§°ï¼Œæ™ºèƒ½ä½“ä¼šé€šè¿‡è¿™ä¸ªåç§°è°ƒç”¨å·¥å…·\n",
        "    func=lambda x: datetime.now().isoformat(),  # å·¥å…·å‡½æ•°ï¼šè¿”å› ISO æ ¼å¼çš„å½“å‰æ—¶é—´\n",
        "    description=\"è¿”å›å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´ä¿¡æ¯ï¼ˆISO æ ¼å¼ï¼‰\",  # å·¥å…·æè¿°ï¼Œå¸®åŠ©æ™ºèƒ½ä½“ç†è§£ä½•æ—¶ä½¿ç”¨æ­¤å·¥å…·\n",
        ")\n",
        "\n",
        "# ğŸ’¡ å·¥å…·è®¾è®¡åŸåˆ™ï¼š\n",
        "# 1. ğŸ¯ å•ä¸€èŒè´£ï¼šæ¯ä¸ªå·¥å…·åªè´Ÿè´£ä¸€ä¸ªç‰¹å®šåŠŸèƒ½\n",
        "# 2. ğŸ“ æ¸…æ™°æè¿°ï¼šdescription è¦å‡†ç¡®æè¿°å·¥å…·çš„åŠŸèƒ½å’Œä½¿ç”¨åœºæ™¯\n",
        "# 3. ğŸ”’ é”™è¯¯å¤„ç†ï¼šç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥æ·»åŠ å¼‚å¸¸å¤„ç†é€»è¾‘\n",
        "# 4. âš¡ æ€§èƒ½è€ƒè™‘ï¼šé™åˆ¶è¿”å›æ•°æ®çš„å¤§å°ï¼Œé¿å…å½±å“æ•´ä½“æ€§èƒ½"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31uhDy_mEqr6"
      },
      "source": [
        "### ğŸ› ï¸ è¾…åŠ©å·¥å…·å‡½æ•°\n",
        "\n",
        "#### ğŸ“ åŠŸèƒ½è¯´æ˜\n",
        "ä¸‹é¢å®šä¹‰çš„è¾…åŠ©å‡½æ•°ç”¨äºç®€åŒ–æ·»åŠ æ–°çš„æ™ºèƒ½ä½“å·¥ä½œèŠ‚ç‚¹ã€‚è¿™äº›å‡½æ•°å°è£…äº†åˆ›å»ºæ™ºèƒ½ä½“å’ŒèŠ‚ç‚¹çš„é€šç”¨é€»è¾‘ï¼Œæé«˜ä»£ç çš„å¯é‡ç”¨æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚\n",
        "\n",
        "#### ğŸ¯ è®¾è®¡ç›®æ ‡\n",
        "- **å‡å°‘é‡å¤ä»£ç **ï¼šé¿å…ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“é‡å¤ç¼–å†™ç›¸åŒçš„åˆå§‹åŒ–é€»è¾‘\n",
        "- **æ ‡å‡†åŒ–æ¥å£**ï¼šç¡®ä¿æ‰€æœ‰æ™ºèƒ½ä½“èŠ‚ç‚¹å…·æœ‰ä¸€è‡´çš„è¾“å…¥è¾“å‡ºæ ¼å¼\n",
        "- **ç®€åŒ–æ‰©å±•**ï¼šæ–°å¢æ™ºèƒ½ä½“æ—¶åªéœ€å…³æ³¨ä¸šåŠ¡é€»è¾‘ï¼Œæ— éœ€å¤„ç†æ¡†æ¶ç»†èŠ‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "75atiExdqd4P"
      },
      "outputs": [],
      "source": [
        "# ğŸ”§ å¯¼å…¥æ™ºèƒ½ä½“æ„å»ºæ‰€éœ€çš„æ ¸å¿ƒç»„ä»¶\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent  # æ™ºèƒ½ä½“æ‰§è¡Œå™¨å’Œåˆ›å»ºå‡½æ•°\n",
        "from langchain_core.messages import BaseMessage, HumanMessage  # æ¶ˆæ¯åŸºç±»å’Œäººç±»æ¶ˆæ¯\n",
        "from langchain_openai import ChatOpenAI  # OpenAI èŠå¤©æ¨¡å‹\n",
        "\n",
        "def create_agent(llm: ChatOpenAI, system_prompt: str, tools: list):\n",
        "    \"\"\"\n",
        "    ğŸ­ æ™ºèƒ½ä½“å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå…·æœ‰ç‰¹å®šèƒ½åŠ›çš„å·¥ä½œæ™ºèƒ½ä½“\n",
        "\n",
        "    å‚æ•°:\n",
        "        llm (ChatOpenAI): è¯­è¨€æ¨¡å‹å®ä¾‹\n",
        "        system_prompt (str): ç³»ç»Ÿæç¤ºè¯ï¼Œå®šä¹‰æ™ºèƒ½ä½“çš„è§’è‰²å’Œè¡Œä¸ºè§„èŒƒ\n",
        "        tools (list): æ™ºèƒ½ä½“å¯ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨\n",
        "\n",
        "    è¿”å›:\n",
        "        AgentExecutor: é…ç½®å®Œæˆçš„æ™ºèƒ½ä½“æ‰§è¡Œå™¨\n",
        "\n",
        "    ğŸ”„ å·¥ä½œæµç¨‹:\n",
        "    1. æ„å»ºæç¤ºæ¨¡æ¿ï¼ˆåŒ…å«ç³»ç»Ÿè§’è‰²ã€å¯¹è¯å†å²ã€å·¥å…·ä½¿ç”¨è®°å½•ï¼‰\n",
        "    2. åˆ›å»ºæ”¯æŒå·¥å…·è°ƒç”¨çš„ OpenAI æ™ºèƒ½ä½“\n",
        "    3. åŒ…è£…ä¸ºæ‰§è¡Œå™¨ï¼Œå¤„ç†å·¥å…·è°ƒç”¨å’ŒçŠ¶æ€ç®¡ç†\n",
        "    \"\"\"\n",
        "    # ğŸ“‹ æ„å»ºæ™ºèƒ½ä½“çš„æç¤ºæ¨¡æ¿\n",
        "    # åŒ…å«ä¸‰ä¸ªå…³é”®éƒ¨åˆ†ï¼šç³»ç»Ÿè§’è‰²ã€å¯¹è¯å†å²ã€å·¥å…·ä½¿ç”¨è®°å½•\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        # ğŸ­ ç³»ç»Ÿæ¶ˆæ¯ï¼šå®šä¹‰æ™ºèƒ½ä½“çš„è§’è‰²ã€èƒ½åŠ›å’Œè¡Œä¸ºè§„èŒƒ\n",
        "        (\"system\", system_prompt),\n",
        "        # ğŸ’¬ æ¶ˆæ¯å†å²ï¼šä¿å­˜ä¸ç”¨æˆ·å’Œå…¶ä»–æ™ºèƒ½ä½“çš„å¯¹è¯è®°å½•\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        # ğŸ”§ å·¥å…·è®°å½•ï¼šè®°å½•æ™ºèƒ½ä½“ä½¿ç”¨å·¥å…·çš„è¿‡ç¨‹å’Œç»“æœ\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "\n",
        "    # ğŸ¤– åˆ›å»ºæ”¯æŒ OpenAI å·¥å…·è°ƒç”¨çš„æ™ºèƒ½ä½“\n",
        "    # è¿™ä¸ªæ™ºèƒ½ä½“èƒ½å¤Ÿç†è§£ä½•æ—¶éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œä»¥åŠå¦‚ä½•è§£é‡Šå·¥å…·çš„è¿”å›ç»“æœ\n",
        "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "    # ğŸ® åˆ›å»ºæ™ºèƒ½ä½“æ‰§è¡Œå™¨\n",
        "    # æ‰§è¡Œå™¨è´Ÿè´£ï¼šå·¥å…·è°ƒç”¨ã€é”™è¯¯å¤„ç†ã€çŠ¶æ€ç®¡ç†ã€ç»“æœæ•´åˆ\n",
        "    executor = AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        verbose=True,  # æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œè¿‡ç¨‹ï¼Œä¾¿äºè°ƒè¯•\n",
        "        handle_parsing_errors=True  # è‡ªåŠ¨å¤„ç†è§£æé”™è¯¯ï¼Œæé«˜ç¨³å®šæ€§\n",
        "    )\n",
        "\n",
        "    return executor\n",
        "\n",
        "def agent_node(state, agent, name):\n",
        "    \"\"\"\n",
        "    ğŸ”„ æ™ºèƒ½ä½“èŠ‚ç‚¹é€‚é…å™¨ï¼šå°†æ™ºèƒ½ä½“åŒ…è£…ä¸º LangGraph èŠ‚ç‚¹\n",
        "\n",
        "    å‚æ•°:\n",
        "        state: å½“å‰çš„å›¾çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å†å²å’Œå…¶ä»–ä¸Šä¸‹æ–‡ä¿¡æ¯\n",
        "        agent: æ™ºèƒ½ä½“æ‰§è¡Œå™¨å®ä¾‹\n",
        "        name: æ™ºèƒ½ä½“çš„åç§°ï¼Œç”¨äºåœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­æ ‡è¯†æ¶ˆæ¯æ¥æº\n",
        "\n",
        "    è¿”å›:\n",
        "        dict: åŒ…å«æ™ºèƒ½ä½“å“åº”çš„çŠ¶æ€æ›´æ–°\n",
        "\n",
        "    ğŸ”„ é€‚é…è¿‡ç¨‹:\n",
        "    1. è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†å½“å‰çŠ¶æ€\n",
        "    2. æå–æ™ºèƒ½ä½“çš„è¾“å‡ºç»“æœ\n",
        "    3. åŒ…è£…ä¸ºå¸¦æœ‰å‘é€è€…èº«ä»½çš„æ¶ˆæ¯\n",
        "    4. è¿”å›çŠ¶æ€æ›´æ–°\n",
        "    \"\"\"\n",
        "    # ğŸ“¤ è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†å½“å‰çŠ¶æ€\n",
        "    # agent.invoke() ä¼šå¤„ç†å¯¹è¯å†å²ï¼Œå†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·ï¼Œå¹¶ç”Ÿæˆæœ€ç»ˆå›å¤\n",
        "    result = agent.invoke(state)\n",
        "\n",
        "    # ğŸ·ï¸ å°†æ™ºèƒ½ä½“çš„è¾“å‡ºåŒ…è£…ä¸ºå¸¦æœ‰èº«ä»½æ ‡è¯†çš„æ¶ˆæ¯\n",
        "    # name å‚æ•°è®©ç³»ç»ŸçŸ¥é“è¿™æ¡æ¶ˆæ¯æ¥è‡ªå“ªä¸ªæ™ºèƒ½ä½“\n",
        "    return {\n",
        "        \"messages\": [HumanMessage(\n",
        "            content=result[\"output\"],  # æ™ºèƒ½ä½“ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹\n",
        "            name=name  # æ¶ˆæ¯å‘é€è€…çš„èº«ä»½æ ‡è¯†\n",
        "        )]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74bZqwU6FCOa"
      },
      "source": [
        "### ğŸ¯ åˆ›å»ºæ™ºèƒ½ä½“ç›‘ç£è€…\n",
        "\n",
        "#### ğŸ“‹ ç›‘ç£è€…çš„æ ¸å¿ƒèŒè´£\n",
        "æ™ºèƒ½ä½“ç›‘ç£è€…æ˜¯å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„\"å¤§è„‘\"ï¼Œè´Ÿè´£ï¼š\n",
        "\n",
        "- ğŸ§  **ä»»åŠ¡ç†è§£**ï¼šåˆ†æç”¨æˆ·è¯·æ±‚ï¼Œç†è§£ä»»åŠ¡çš„æ€§è´¨å’Œéœ€æ±‚\n",
        "- ğŸ¯ **æ™ºèƒ½ä½“é€‰æ‹©**ï¼šæ ¹æ®ä»»åŠ¡ç‰¹ç‚¹é€‰æ‹©æœ€é€‚åˆçš„å·¥ä½œæ™ºèƒ½ä½“\n",
        "- ğŸ”„ **æµç¨‹æ§åˆ¶**ï¼šå†³å®šä½•æ—¶åˆ‡æ¢æ™ºèƒ½ä½“ï¼Œä½•æ—¶ç»“æŸå¤„ç†æµç¨‹\n",
        "- ğŸ“Š **ç»“æœæ•´åˆ**ï¼šæ±‡æ€»å„ä¸ªæ™ºèƒ½ä½“çš„å·¥ä½œæˆæœ\n",
        "\n",
        "#### ğŸ”§ æŠ€æœ¯å®ç°æ–¹å¼\n",
        "ç›‘ç£è€…ä½¿ç”¨ **å‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰** æŠ€æœ¯æ¥å®ç°å†³ç­–ï¼š\n",
        "\n",
        "- ğŸ“ **å‡½æ•°è°ƒç”¨**ï¼šé€šè¿‡ç»“æ„åŒ–çš„å‡½æ•°è°ƒç”¨æ¥è¡¨è¾¾å†³ç­–ç»“æœ\n",
        "- ğŸ›ï¸ **é€‰æ‹©æœºåˆ¶**ï¼šåœ¨å¯ç”¨çš„å·¥ä½œèŠ‚ç‚¹ä¸­é€‰æ‹©ä¸‹ä¸€ä¸ªæ‰§è¡Œè€…\n",
        "- ğŸ **ç»ˆæ­¢æ¡ä»¶**ï¼šåˆ¤æ–­ä½•æ—¶ä»»åŠ¡å·²å®Œæˆï¼Œå¯ä»¥ç»“æŸå¤„ç†æµç¨‹\n",
        "\n",
        "#### ğŸ’¡ è®¾è®¡ä¼˜åŠ¿\n",
        "- **ç²¾ç¡®æ§åˆ¶**ï¼šé¿å…éšæœºæˆ–ä¸ç¡®å®šçš„è·¯ç”±å†³ç­–\n",
        "- **å¯è§£é‡Šæ€§**ï¼šæ¯ä¸ªå†³ç­–éƒ½æœ‰æ˜ç¡®çš„é€»è¾‘ä¾æ®\n",
        "- **å¯æ‰©å±•æ€§**ï¼šå®¹æ˜“æ·»åŠ æ–°çš„å·¥ä½œæ™ºèƒ½ä½“å’Œå†³ç­–è§„åˆ™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Hu8MzgihrHdF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "members = [\"Researcher\", \"CurrentTime\"]\n",
        "system_prompt = (\n",
        "    \"ä½ æ˜¯ä¸€åç›‘ç£è€…ï¼Œ\"\n",
        "    \" è´Ÿè´£ç®¡ç†ä»¥ä¸‹å·¥ä½œäººå‘˜ä¹‹é—´çš„å¯¹è¯ï¼š{members}ã€‚\"\n",
        "    \" æ ¹æ®ä»¥ä¸‹ç”¨æˆ·è¯·æ±‚ï¼Œå›å¤ä¸‹ä¸€ä¸ªè¦é‡‡å–è¡ŒåŠ¨çš„å·¥ä½œäººå‘˜ã€‚\"\n",
        "    \" æ¯ä¸ªå·¥ä½œäººå‘˜å°†æ‰§è¡Œä¸€é¡¹ä»»åŠ¡ï¼Œå¹¶å›å¤å…¶ç»“æœå’ŒçŠ¶æ€ã€‚\"\n",
        "    \" å®Œæˆåï¼Œå›å¤ FINISHã€‚\"\n",
        ")\n",
        "# ğŸ§­ ç›‘ç£è€…èŠ‚ç‚¹ç”± LLM æ‰®æ¼”ï¼Œè´Ÿè´£é€‰æ‹©ä¸‹ä¸€ä½æ‰§è¡Œçš„æ™ºèƒ½ä½“å¹¶åˆ¤æ–­æµç¨‹æ˜¯å¦ç»“æŸ\n",
        "options = [\"FINISH\"] + members\n",
        "\n",
        "# ğŸ” ä½¿ç”¨ OpenAI Function Callingï¼Œå¯è®©ç»“æ„åŒ–è¾“å‡ºå’Œè§£ææ›´åŠ ç¨³å®š\n",
        "function_def = {\n",
        "    \"name\": \"route\",\n",
        "    \"description\": \"é€‰æ‹©ä¸‹ä¸€ä¸ªè§’è‰²\",\n",
        "    \"parameters\": {\n",
        "        \"title\": \"routeSchema\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"next\": {\n",
        "                \"title\": \"Next\",\n",
        "                \"anyOf\": [\n",
        "                    {\"enum\": options},\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"next\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# ğŸ“œ æ„å»ºç›‘ç£è€…æç¤ºæ¨¡æ¿\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"system\",\n",
        "            \"æ ¹æ®ä¸Šé¢çš„å¯¹è¯ï¼Œæ¥ä¸‹æ¥è°åº”è¯¥è¡ŒåŠ¨ï¼Ÿ\"\n",
        "            \" æˆ–è€…æˆ‘ä»¬åº”è¯¥FINISHå—ï¼Ÿè¯·ä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š{options}\",\n",
        "        ),\n",
        "    ]\n",
        ").partial(options=str(options), members=\", \".join(members))\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# ğŸ”— æ„å»ºç›‘ç£è€…æ™ºèƒ½ä½“çš„æ‰§è¡Œé“¾\n",
        "supervisor_chain = (\n",
        "    prompt\n",
        "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "    | JsonOutputFunctionsParser()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognuMaIeFVh7"
      },
      "source": [
        "### æ„å»ºå›¾å½¢ç»“æ„\n",
        "\n",
        "ç°åœ¨å¯ä»¥å¼€å§‹æ­å»ºæ•´å¼ å›¾ã€‚ä¸‹é¢ä½¿ç”¨åˆšåˆšå®šä¹‰çš„å‡½æ•°æŒ‡å®šçŠ¶æ€å’Œå„ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œå¹¶è¿æ¥å›¾ä¸­çš„æ‰€æœ‰è¾¹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_LwtCmw_rHVz"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "from typing import Sequence, TypedDict\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "# ğŸ—‚ï¸ æ™ºèƒ½ä½“çŠ¶æ€ä¼šä½œä¸ºæ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥æ•°æ®\n",
        "class AgentState(TypedDict):\n",
        "    # Annotated å‘Šè¯‰å›¾ï¼šæ–°çš„æ¶ˆæ¯ä¼šè¿½åŠ åˆ°ç°æœ‰æ¶ˆæ¯åˆ—è¡¨ä¸­\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    # next å­—æ®µæŒ‡ç¤ºä¸‹ä¸€æ­¥è¦è·³è½¬åˆ°å“ªä¸ªèŠ‚ç‚¹\n",
        "    next: str\n",
        "\n",
        "# ğŸ§‘â€ğŸ’» ä½¿ç”¨è¾…åŠ©å‡½æ•°åˆ›å»ºç ”ç©¶æ™ºèƒ½ä½“\n",
        "research_agent = create_agent(llm, \"æ‚¨æ˜¯ä¸€ä½ç½‘ç»œç ”ç©¶å‘˜ã€‚\", [wikipedia_tool])\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "# ğŸ•°ï¸ åˆ›å»ºæŠ¥æ—¶æ™ºèƒ½ä½“\n",
        "currenttime_agent = create_agent(llm, \"Yæ‚¨æ˜¯ä¸€ä½æŠ¥æ—¶åŠ©æ‰‹ï¼Œè´Ÿè´£å‘ŠçŸ¥å½“å‰æ—¶é—´ã€‚\", [datetime_tool])\n",
        "currenttime_node = functools.partial(agent_node, agent=currenttime_agent, name=\"CurrentTime\")\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# ğŸ“¦ æ³¨å†ŒèŠ‚ç‚¹ï¼šèŠ‚ç‚¹ä»£è¡¨å…·ä½“çš„å·¥ä½œå•å…ƒï¼Œé€šå¸¸æ˜¯ Python å‡½æ•°\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"CurrentTime\", currenttime_node)\n",
        "workflow.add_node(\"supervisor\", supervisor_chain)\n",
        "\n",
        "# ğŸ”‚ å¼ºåˆ¶æ‰€æœ‰å·¥ä½œèŠ‚ç‚¹åœ¨å®Œæˆåå›åˆ°ç›‘ç£è€…\n",
        "for member in members:\n",
        "    workflow.add_edge(member, \"supervisor\")\n",
        "\n",
        "# ğŸ”€ æ¡ä»¶è¾¹æ ¹æ®å½“å‰çŠ¶æ€å†³å®šåç»­è·¯ç”±\n",
        "# è¯¥å‡½æ•°è¯»å–çŠ¶æ€å¹¶è¿”å›è¦æ‰§è¡Œçš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°\n",
        "conditional_map = {k: k for k in members}\n",
        "conditional_map[\"FINISH\"] = END\n",
        "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
        "\n",
        "# ğŸšª è®¾ç½®å…¥å£èŠ‚ç‚¹ï¼Œç¡®å®šå›¾åœ¨è¿è¡Œæ—¶ä»å“ªé‡Œå¼€å§‹\n",
        "workflow.add_edge(START, \"supervisor\")\n",
        "\n",
        "# âš™ï¸ ç¼–è¯‘å›¾å½¢ï¼Œå¾—åˆ°å¯è°ƒç”¨çš„ CompiledGraph\n",
        "graph_2 = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3xfJLJyFwBG"
      },
      "source": [
        "### åœ¨è°ƒç”¨ä¸­æŒ‚è½½ Langfuse å›è°ƒ\n",
        "\n",
        "åœ¨æ‰§è¡Œ `graph_2.stream` æ—¶å¢åŠ  [Langfuse å›è°ƒå¤„ç†å™¨](https://langfuse.com/integrations/frameworks/langchain)ï¼š`config={\"callbacks\": [langfuse_handler]}`ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "QsX1gw9kryGP",
        "outputId": "357b67b7-f525-4332-fdbb-3bd9420b08b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'supervisor': {'next': 'Researcher'}}\n",
            "----\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-920772648.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# ğŸ”— å°†å›è°ƒå¤„ç†å™¨æŒ‚è½½åˆ°å›¾çš„ stream è°ƒç”¨ä¸­ï¼›å¯é€‰çš„ run_name ä¼šä½œä¸ºè¿½è¸ªåç§°å±•ç¤º\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m for s in graph_2.stream({\"messages\": [HumanMessage(content=\"å…‰åˆä½œç”¨æ˜¯å¦‚ä½•è¿›è¡Œçš„ï¼Ÿ\")]},\n\u001b[0m\u001b[1;32m      8\u001b[0m                        config={\"callbacks\": [langfuse_handler]}):\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2648\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1676007668.py\u001b[0m in \u001b[0;36magent_node\u001b[0;34m(state, agent, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# ğŸ“¤ è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†å½“å‰çŠ¶æ€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# agent.invoke() ä¼šå¤„ç†å¯¹è¯å†å²ï¼Œå†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·ï¼Œå¹¶ç”Ÿæˆæœ€ç»ˆå›å¤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# ğŸ·ï¸ å°†æ™ºèƒ½ä½“çš„è¾“å‡ºåŒ…è£…ä¸ºå¸¦æœ‰èº«ä»½æ ‡è¯†çš„æ¶ˆæ¯\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1626\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     ) -> Union[AgentFinish, list[tuple[AgentAction, str]]]:\n\u001b[1;32m   1324\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1325\u001b[0;31m             list(\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 self._iter_next_step(\n\u001b[1;32m   1327\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             output = self._action_agent.plan(\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# Because the response from the plan is not a generator, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3472\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3473\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3457\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3459\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3460\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2231\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m                         \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mfinal_output_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, inputs, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3419\u001b[0m                 \u001b[0mfinal_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3421\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m     async def _atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \"\"\"\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     async def astream(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     ) -> T:\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    198\u001b[0m                 lambda inner_input: self.parse_result(\n\u001b[1;32m    199\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                 output = cast(\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1954\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 198\u001b[0;31m                 lambda inner_input: self.parse_result(\n\u001b[0m\u001b[1;32m    199\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: TRY004\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparse_ai_message_to_openai_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAgentAction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_openai_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     18\u001b[0m ) -> Union[list[AgentAction], AgentFinish]:\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"\"\"Parse an AI message potentially containing tool_calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtool_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ai_message_to_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtool_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\nInvoking: `{function_name}` with `{tool_input}`\\n{content_msg}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         actions.append(\n\u001b[0;32m---> 69\u001b[0;31m             ToolAgentAction(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/agents.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tool, tool_input, log, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdditional\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
          ]
        }
      ],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# ğŸ“¡ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºè®°å½• LangChain çš„æ‰§è¡Œè½¨è¿¹\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# ğŸ”— å°†å›è°ƒå¤„ç†å™¨æŒ‚è½½åˆ°å›¾çš„ stream è°ƒç”¨ä¸­ï¼›å¯é€‰çš„ run_name ä¼šä½œä¸ºè¿½è¸ªåç§°å±•ç¤º\n",
        "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"å…‰åˆä½œç”¨æ˜¯å¦‚ä½•è¿›è¡Œçš„ï¼Ÿ\")]},\n",
        "                       config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqJnMtP5HDql"
      },
      "outputs": [],
      "source": [
        "# ğŸ”— åŒæ ·åœ°ï¼Œä¸ºå…¶ä»–æŸ¥è¯¢æŒ‚è½½ Langfuse å›è°ƒ\n",
        "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"ç°åœ¨çš„å‡†ç¡®æ—¶é—´æ˜¯å¤šå°‘ï¼Ÿ\")]},\n",
        "                       config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n",
        "    print(\"----\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4XjtNenH9GF"
      },
      "source": [
        "### åœ¨ Langfuse ä¸­æŸ¥çœ‹å¤šæ™ºèƒ½ä½“è¿½è¸ª\n",
        "\n",
        "ä»¥ä¸‹é“¾æ¥å±•ç¤ºäº†æœ¬èŠ‚å¤šæ™ºèƒ½ä½“ç¤ºä¾‹åœ¨ Langfuse ä¸­ç”Ÿæˆçš„è¿½è¸ªè®°å½•ï¼š\n",
        "\n",
        "1. [å…‰åˆä½œç”¨æ˜¯å¦‚ä½•è¿›è¡Œçš„ï¼Ÿ](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7d5f970573b8214d1ca891251e42282c)\n",
        "2. [ç°åœ¨å‡ ç‚¹ï¼Ÿ](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/3a69fe4998df50d42054f8944bd6a8d9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-5EEBZAIbwc"
      },
      "source": [
        "![åœ¨ Langfuse ä¸­æŸ¥çœ‹å¤šæ™ºèƒ½ä½“è¿½è¸ª](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_multiagent_traces.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCEzabn_jhbf"
      },
      "source": [
        "### å¯è§†åŒ–è¯¥æ™ºèƒ½ä½“\n",
        "\n",
        "ä½ å¯ä»¥ä½¿ç”¨ `get_graph` æ–¹æ³•é…åˆç›¸åº”çš„ â€œdrawâ€ æ–¹æ³•è¿›è¡Œå›¾å½¢å¯è§†åŒ–ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "notlPjnl-HXV"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph_2.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESkG2IJS8OY"
      },
      "source": [
        "```mermaid\n",
        "graph TD;\n",
        "\t__start__([__start__]):::first\n",
        "\tResearcher(Researcher)\n",
        "\tCurrentTime(CurrentTime)\n",
        "\tsupervisor(supervisor)\n",
        "\t__end__([__end__]):::last\n",
        "\tCurrentTime --> supervisor;\n",
        "\tResearcher --> supervisor;\n",
        "\t__start__ --> supervisor;\n",
        "\tsupervisor -.-> Researcher;\n",
        "\tsupervisor -.-> CurrentTime;\n",
        "\tsupervisor -. &nbspFINISH&nbsp .-> __end__;\n",
        "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
        "\tclassDef first fill-opacity:0\n",
        "\tclassDef last fill:#bfb6fc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKULkc6g-BE"
      },
      "source": [
        "## å¤šä¸ª LangGraph æ™ºèƒ½ä½“çš„ååŒ\n",
        "\n",
        "åœ¨æŸäº›æ¶æ„ä¸­ï¼Œä¸€ä¸ª LangGraph æ™ºèƒ½ä½“ä¼šè°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»– LangGraph æ™ºèƒ½ä½“ã€‚è‹¥æƒ³è®©æ•´å¥—æ‰§è¡Œé“¾åœ¨ Langfuse ä¸­èšåˆä¸ºåŒä¸€æ¡è¿½è¸ªï¼Œå¯æ˜¾å¼ä¼ å…¥è‡ªå®šä¹‰çš„ `trace_id`ã€‚\n",
        "\n",
        "é¦–å…ˆç”Ÿæˆä¸€ä¸ªå…±äº«çš„ `trace_id`ï¼Œä¾›ä¸»æ™ºèƒ½ä½“ä¸å­æ™ºèƒ½ä½“å…±ç”¨ï¼Œä»¥ä¾¿åœ¨ Langfuse ä¸­åˆå¹¶ä¸ºåŒä¸€æ¡è®°å½•ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS8hQBHVg-BE"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client, Langfuse\n",
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# ğŸ” ä»å¤–éƒ¨ç³»ç»Ÿç”Ÿæˆä¸€ä¸ªç¡®å®šæ€§çš„ trace_idï¼Œä¾¿äºè·¨æœåŠ¡èšåˆ\n",
        "predefined_trace_id = Langfuse.create_trace_id()\n",
        "\n",
        "# ğŸ“¡ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºé‡‡é›† LangChain çš„æ‰§è¡Œæ•°æ®\n",
        "langfuse_handler = CallbackHandler()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73necyiUg-BE"
      },
      "source": [
        "æ¥ä¸‹æ¥ï¼Œæ„å»ºå­æ™ºèƒ½ä½“çš„é€»è¾‘ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWS82VWsg-BE"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "sub_agent = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIcpIMEPg-BF"
      },
      "source": [
        "éšåï¼Œå°†è¯¥å­æ™ºèƒ½ä½“å°è£…æˆå·¥å…·ï¼Œä¾›ä¸»æµç¨‹è°ƒç”¨å¹¶å¤ç”¨ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0KC8Gvzg-BF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def langgraph_research(question):\n",
        "  \"\"\"Conducts research for various topics.\"\"\"\n",
        "\n",
        "  with langfuse.start_as_current_span(\n",
        "      name=\"ğŸ¤–-sub-research-agent\",\n",
        "      trace_context={\"trace_id\": predefined_trace_id}\n",
        "  ) as span:\n",
        "      span.update_trace(input=question)\n",
        "\n",
        "      response = sub_agent.invoke({\"messages\": [HumanMessage(content = question)]},\n",
        "                        config={\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "      span.update_trace(output= response[\"messages\"][1].content)\n",
        "\n",
        "  return response[\"messages\"][1].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PpMQXiEg-BF"
      },
      "source": [
        "æœ€åï¼Œåˆ›å»ºç¬¬äºŒä¸ª LangGraph æ™ºèƒ½ä½“ï¼Œé€šè¿‡å‰é¢æ–°å¢çš„ `langgraph_research` å·¥å…·å®Œæˆåä½œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhNPp4pmg-BF"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
        "\n",
        "main_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[langgraph_research]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyeGvSf3g-BF"
      },
      "outputs": [],
      "source": [
        "user_question = \"ä»€ä¹ˆæ˜¯ Langfuseï¼Ÿ\"\n",
        "\n",
        "# ğŸ§­ ä½¿ç”¨é¢„ç”Ÿæˆçš„ trace_idï¼ˆé€šè¿‡ trace_context æ³¨å…¥ï¼‰\n",
        "with langfuse.start_as_current_span(\n",
        "    name=\"ğŸ¤–-main-agent\",\n",
        "    trace_context={\"trace_id\": predefined_trace_id}\n",
        ") as span:\n",
        "    span.update_trace(input=user_question)\n",
        "\n",
        "    # æ­¤å¤„çš„ LangChain æ‰§è¡Œéƒ½ä¼šå½’å±äºåŒä¸€æ¡è¿½è¸ª\n",
        "    response = main_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_question}]},\n",
        "                            config={\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "    span.update_trace(output=response[\"messages\"][1].content)\n",
        "\n",
        "print(f\"Trace ID: {predefined_trace_id}\")  # å¯åœ¨åç»­è¯„åˆ†æˆ–æ’æŸ¥æ—¶ä½¿ç”¨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzPZIqUWg-BF"
      },
      "source": [
        "### åœ¨ Langfuse ä¸­æŸ¥çœ‹å¤šæ™ºèƒ½ä½“è¿½è¸ª\n",
        "\n",
        "![å¤šæ™ºèƒ½ä½“è¿½è¸ªç¤ºä¾‹](https://langfuse.com/images/cookbook/integration-langgraph/a2a_langgraph.png)\n",
        "\n",
        "ç¤ºä¾‹è¿½è¸ªé“¾æ¥ï¼šhttps://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/85b0c53c4414f22ed8bfc9eb35f917c4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uybP4h8wGvWw"
      },
      "source": [
        "## ä¸ºè¿½è¸ªæ·»åŠ è¯„åˆ†\n",
        "\n",
        "[è¯„åˆ†ï¼ˆScoreï¼‰](https://langfuse.com/docs/scores/overview) ç”¨äºè¯„ä»·å•ä¸ªè§‚æµ‹ï¼ˆobservationï¼‰æˆ–æ•´æ¡è¿½è¸ªï¼ˆtraceï¼‰ï¼Œå¯å¸®åŠ©ä½ åœ¨è¿è¡Œæ—¶æ‰§è¡Œè‡ªå®šä¹‰è´¨é‡æ£€æŸ¥ï¼Œæˆ–é…åˆäººå·¥å®¡æ ¸æµç¨‹ã€‚\n",
        "\n",
        "ä¸‹é¢çš„ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ï¼š\n",
        "\n",
        "- ä¸ºæŸä¸ª span è®°å½•ä¸€ä¸ªæ•°å€¼å‹è¯„åˆ†ï¼ˆå¦‚ `relevance`ï¼‰\n",
        "- ä¸ºæ•´æ¡è¿½è¸ªè®°å½•ä¸€ä¸ªåˆ†ç±»å‹è¯„åˆ†ï¼ˆå¦‚ `feedback`ï¼‰\n",
        "\n",
        "è¿™æœ‰åŠ©äºç³»ç»ŸåŒ–åœ°è¯„ä¼°ä¸æ”¹è¿›åº”ç”¨è´¨é‡ã€‚\n",
        "\n",
        "**â†’ æƒ³æ·±å…¥äº†è§£ï¼Ÿè¯·å‚é˜… [Langfuse è‡ªå®šä¹‰è¯„åˆ†æŒ‡å—](https://langfuse.com/docs/scores/custom)ã€‚**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgAqYnQuGwCL"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿”å›çš„ span å¯¹è±¡è¿›è¡Œè¯„åˆ†\n",
        "with langfuse.start_as_current_span(\n",
        "    name=\"langgraph-request\") as span:\n",
        "    # ... æ­¤å¤„æ‰§è¡Œ LangGraph é€»è¾‘ ...\n",
        "\n",
        "    # ç›´æ¥é€šè¿‡ span.score_trace è®°å½•è¯„åˆ†\n",
        "    span.score_trace(\n",
        "        name=\"user-feedback\",\n",
        "        value=1,\n",
        "        data_type=\"NUMERIC\",\n",
        "        comment=\"This was correct, thank you\"\n",
        "    )\n",
        "\n",
        "# æ–¹æ¡ˆäºŒï¼šåœ¨ä»ä½äºä¸Šä¸‹æ–‡æ—¶è°ƒç”¨ score_current_trace()\n",
        "with langfuse.start_as_current_span(name=\"langgraph-request\") as span:\n",
        "    # ... LangGraph execution ...\n",
        "\n",
        "    langfuse.score_current_trace(\n",
        "        name=\"user-feedback\",\n",
        "        value=1,\n",
        "        data_type=\"NUMERIC\"\n",
        "    )\n",
        "\n",
        "# æ–¹æ¡ˆä¸‰ï¼šè‹¥å·²ç¦»å¼€ä¸Šä¸‹æ–‡ï¼Œå¯ä½¿ç”¨ trace_id ç›´æ¥åˆ›å»ºè¯„åˆ†\n",
        "langfuse.create_score(\n",
        "    trace_id=predefined_trace_id,\n",
        "    name=\"user-feedback\",\n",
        "    value=1,\n",
        "    data_type=\"NUMERIC\",\n",
        "    comment=\"This was correct, thank you\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq_DeCcXSxwq"
      },
      "source": [
        "### åœ¨ Langfuse ä¸­æŸ¥çœ‹å¸¦è¯„åˆ†çš„è¿½è¸ª\n",
        "\n",
        "ç¤ºä¾‹è¿½è¸ªï¼šhttps://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e60a078b828d4fdc7ea22c73193b0fe4\n",
        "\n",
        "![åŒ…å«è¯„åˆ†çš„è¿½è¸ªå±•ç¤º](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_score.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cIQVrYZJVMO"
      },
      "source": [
        "## ä½¿ç”¨ Langfuse ç®¡ç†æç¤ºè¯\n",
        "\n",
        "é€šè¿‡ [Langfuse Prompt Management](https://langfuse.com/docs/prompts/example-langchain) å¯ä»¥å¯¹æç¤ºè¯è¿›è¡Œç»Ÿä¸€çš„ç‰ˆæœ¬ç®¡ç†ã€‚åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æ¼”ç¤ºå¦‚ä½•é€šè¿‡ SDK æ–°å¢ä¸€æ¡æç¤ºè¯ï¼›åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ›´æ¨èç›´æ¥åœ¨ Langfuse UI ä¸­åˆ›å»ºå’Œå‘å¸ƒã€‚\n",
        "\n",
        "Langfuse çš„æç¤ºè¯ç®¡ç†ç›¸å½“äºä¸€ä¸ªâ€œæç¤ºè¯å†…å®¹ç®¡ç†ç³»ç»Ÿï¼ˆPrompt CMSï¼‰â€ã€‚ä½ å¯ä»¥åœ¨ UI ä¸­ç¼–è¾‘ã€é¢„è§ˆä¸å‘å¸ƒï¼›ä¹Ÿå¯åœ¨ä»£ç ä¸­é€šè¿‡ SDK è¯»å–æˆ–æ›´æ–°ã€‚\n",
        "\n",
        "é…ç½®æç¤ºè¯æ—¶é€šå¸¸éœ€è¦æŒ‡å®šï¼š\n",
        "\n",
        "* `name`ï¼šåœ¨ Langfuse ä¸­å”¯ä¸€æ ‡è¯†è¯¥æç¤ºè¯çš„åç§°\n",
        "* `prompt`ï¼šåŒ…å«æ¨¡æ¿å ä½ç¬¦ï¼ˆå¦‚ `{{input variables}}`ï¼‰çš„æ–‡æœ¬å†…å®¹\n",
        "* `labels`ï¼šå¯è®¾ç½®ä¸º `production`ï¼Œè®©è¯¥ç‰ˆæœ¬ç«‹å³æˆä¸ºé»˜è®¤é€‰é¡¹\n",
        "\n",
        "åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç³»ç»Ÿæç¤ºè¯ï¼Œè®©åŠ©æ‰‹å°†æ‰€æœ‰ç”¨æˆ·è¾“å…¥ç¿»è¯‘æˆè¥¿ç­ç‰™è¯­ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0J8-nbhUUz6"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "langfuse.create_prompt(\n",
        "    name=\"translator_system-prompt\",\n",
        "    prompt=\"You are a translator that translates every input text into Spanish.\",\n",
        "    labels=[\"production\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dullp4XDXhzg"
      },
      "source": [
        "![åœ¨ Langfuse UI ä¸­æŸ¥çœ‹æç¤ºè¯](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_prompt_example.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNboOjf2YQpD"
      },
      "source": [
        "ä½¿ç”¨å·¥å…·æ–¹æ³• `.get_langchain_prompt()` å¯ä»¥å°† Langfuse ä¸­çš„æç¤ºè¯è½¬æ¢ä¸º LangChain å¯ç›´æ¥ä½¿ç”¨çš„å­—ç¬¦ä¸²ã€‚\n",
        "\n",
        "**èƒŒæ™¯è¯´æ˜ï¼š** Langfuse åœ¨æç¤ºæ¨¡æ¿ä¸­ä½¿ç”¨åŒèŠ±æ‹¬å·ï¼ˆ`{{input variable}}`ï¼‰å£°æ˜å˜é‡ï¼›è€Œ LangChain çš„ `PromptTemplate` ä½¿ç”¨å•èŠ±æ‹¬å·ï¼ˆ`{input variable}`ï¼‰ã€‚`.get_langchain_prompt()` ä¼šè‡ªåŠ¨å®Œæˆæ ¼å¼è½¬æ¢ã€‚å½“å‰ç¤ºä¾‹çš„æç¤ºè¯æ²¡æœ‰å ä½å˜é‡ï¼Œä½†ä»å¯ä»¥ç»Ÿä¸€é€šè¿‡è¯¥æ–¹æ³•å¤„ç†ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z49I82blYeXy"
      },
      "outputs": [],
      "source": [
        "# è¯»å–ç”Ÿäº§ç¯å¢ƒä¸­æœ€æ–°çš„æç¤ºè¯ç‰ˆæœ¬ï¼Œå¹¶è½¬æ¢ä¸º LangChain å¯ç›´æ¥ä½¿ç”¨çš„å­—ç¬¦ä¸²\n",
        "langfuse_system_prompt = langfuse.get_prompt(\"translator_system-prompt\")\n",
        "langchain_system_prompt = langfuse_system_prompt.get_langchain_prompt()\n",
        "\n",
        "print(langchain_system_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3zBULfCt0Wq"
      },
      "source": [
        "ç°åœ¨å¯ä»¥ä½¿ç”¨æ–°çš„ç³»ç»Ÿæç¤ºè¯å­—ç¬¦ä¸²ï¼Œæ›´æ–°æˆ‘ä»¬çš„ç¿»è¯‘åŠ©æ‰‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGQhulyMmvZD"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# ğŸ§© å°†ç³»ç»Ÿæç¤ºè¯æ³¨å…¥åˆ°èŠå¤©èŠ‚ç‚¹ï¼Œç¡®ä¿åŠ©æ‰‹å…ˆéµå¾ªç¿»è¯‘æŒ‡ä»¤\n",
        "system_prompt = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": langchain_system_prompt\n",
        "}\n",
        "\n",
        "def chatbot(state: State):\n",
        "    messages_with_system_prompt = [system_prompt] + state[\"messages\"]\n",
        "    response = llm.invoke(messages_with_system_prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "graph = graph_builder.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYd7wbttm2ec"
      },
      "outputs": [],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# ğŸ“¡ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼ˆç”¨äºè¿½è¸ªç¿»è¯‘åŠ©æ‰‹çš„è°ƒç”¨ï¼‰\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# ğŸ”— å°†å›è°ƒæŒ‚è½½åˆ°å›¾çš„ stream æ–¹æ³•ä¸­ï¼Œå®æ—¶æŸ¥çœ‹ç¿»è¯‘ç»“æœä¸è¿½è¸ªè®°å½•\n",
        "for s in graph.stream({\"messages\": [HumanMessage(content=\"è¯·æŠŠâ€œLangfuse æ˜¯ä»€ä¹ˆï¼Ÿâ€ç¿»è¯‘æˆè¥¿ç­ç‰™è¯­ã€‚\")]},\n",
        "                      config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsAfdodAg-BH"
      },
      "source": [
        "## åœ¨ LangGraph è¿½è¸ªä¸­æ·»åŠ è‡ªå®šä¹‰ Span\n",
        "\n",
        "æŸäº›åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è¿½è¸ªä¸­æ’å…¥è‡ªå®šä¹‰ spanï¼Œä»¥æ ‡è®°å…³é”®æ­¥éª¤æˆ–é™„åŠ é¢å¤–ä¸Šä¸‹æ–‡ã€‚å¯ä»¥å‚è€ƒè¿™ä¸ª [GitHub è®¨è®ºè´´](https://github.com/orgs/langfuse/discussions/2988#discussioncomment-11634600) ä¸­ç»™å‡ºçš„ç¤ºä¾‹å®ç°æ–¹å¼ã€‚\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}