{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPJsVa1O4TuL"
   },
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"LangGraph å¼€æºå¯è§‚æµ‹æ€§å®è·µ\" description: \"ä»‹ç»å¦‚ä½•åœ¨ LangGraphï¼ˆPythonï¼‰åº”ç”¨ä¸­ä½¿ç”¨ Langfuse æ„å»ºå¼€æºå¯è§‚æµ‹æ€§ä¸è¿½è¸ªèƒ½åŠ›ã€‚\" category: \"Integrations\" -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlCI9KeX4Zn4"
   },
   "source": [
    "## ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ\n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/) æ˜¯ç”± LangChain å›¢é˜Ÿå¼€æºçš„æ¡†æ¶ï¼Œç”¨äºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºå¤æ‚ã€æœ‰çŠ¶æ€çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ã€‚LangGraph å†…ç½®äº†æŒä¹…åŒ–èƒ½åŠ›ï¼Œå¯ä¿å­˜ä¸æ¢å¤çŠ¶æ€ï¼Œä»è€Œæ”¯æŒé”™è¯¯æ¢å¤ä¸åŒ…å«â€œäººç±»å‚ä¸â€ï¼ˆHuman-in-the-loop, HITLï¼‰çš„å·¥ä½œæµã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o8L1qPcaZeC"
   },
   "source": [
    "## æœ¬å®è·µæ‰‹å†Œçš„ç›®æ ‡\n",
    "\n",
    "æœ¬æ‰‹å†Œæ¼”ç¤ºå¦‚ä½•å€ŸåŠ© [Langfuse](https://langfuse.com/docs)ï¼Œé€šè¿‡å…¶ä¸ [LangChain çš„é›†æˆ](https://langfuse.com/integrations/frameworks/langchain)ï¼Œå¯¹ä½ çš„ LangGraph åº”ç”¨è¿›è¡Œè°ƒè¯•ã€åˆ†æä¸è¿­ä»£ä¼˜åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPTaMtxH4eHV"
   },
   "source": [
    "**å®Œæˆæœ¬æ‰‹å†Œåï¼Œä½ å°†èƒ½å¤Ÿï¼š**\n",
    "\n",
    "- è‡ªåŠ¨é€šè¿‡ Langfuse é›†æˆå¯¹ LangGraph åº”ç”¨è¿›è¡Œè¿½è¸ªï¼ˆtracingï¼‰\n",
    "- ç›‘æ§å¤æ‚çš„å¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰æ–¹æ¡ˆ\n",
    "- æ·»åŠ è¯„åˆ†ï¼ˆä¾‹å¦‚ç”¨æˆ·åé¦ˆï¼‰\n",
    "- ä½¿ç”¨ Langfuse ç®¡ç† LangGraph ä¸­ä½¿ç”¨çš„æç¤ºè¯ï¼ˆpromptï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sSIS88y9Ewm"
   },
   "source": [
    "## åˆå§‹åŒ– Langfuse\n",
    "\n",
    "åœ¨ Langfuse æ§åˆ¶å°é¡¹ç›®è®¾ç½®é¡µè·å–ä½ çš„ [API å¯†é’¥](https://langfuse.com/faq/all/where-are-langfuse-api-keys)ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ°è¿è¡Œç¯å¢ƒå˜é‡ä¸­ä»¥åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ã€‚\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"âš ï¸\" -->\n",
    "_**æ³¨æ„ï¼š** æœ¬ç¬”è®°ä½¿ç”¨ Langfuse Python SDK v3ã€‚è‹¥ä½ ä»åœ¨ä½¿ç”¨ v2ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„[æ—§ç‰ˆ LangGraph é›†æˆæŒ‡å—](https://github.com/langfuse/langfuse-docs/blob/662509b3296daddcddb292f14b10a62e7c39407d/cookbook/integration_langgraph.ipynb)ã€‚_\n",
    "<!-- CALLOUT_END -->\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"â„¹ï¸\" -->\n",
    "_**æ³¨æ„ï¼š** éœ€è¦è‡³å°‘ Python 3.11ï¼ˆå‚è§ [GitHub Issue](https://github.com/langfuse/langfuse/issues/1926)ï¼‰ã€‚_\n",
    "<!-- CALLOUT_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "C85BK1vJ5yD3",
    "outputId": "73f44b09-ae33-4bd0-8e92-9c1bfc8a1e7c"
   },
   "outputs": [],
   "source": [
    "%pip install langfuse langchain langgraph langchain_openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1yglQ464VD-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ğŸ”‘ ä»é¡¹ç›®è®¾ç½®é¡µé¢è·å–æ‚¨çš„ API å¯†é’¥ï¼šhttps://cloud.langfuse.com\n",
    "# ğŸ“‹ é…ç½®æ­¥éª¤ï¼š\n",
    "# 1. ç™»å½• Langfuse æ§åˆ¶å°\n",
    "# 2. é€‰æ‹©æˆ–åˆ›å»ºé¡¹ç›®\n",
    "# 3. è¿›å…¥é¡¹ç›®è®¾ç½®é¡µé¢\n",
    "# 4. å¤åˆ¶å…¬é’¥å’Œç§é’¥\n",
    "\n",
    "# Langfuse å…¬é’¥ï¼ˆç”¨äºå®¢æˆ·ç«¯èº«ä»½éªŒè¯ï¼‰\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "\n",
    "# Langfuse ç§é’¥ï¼ˆç”¨äºæœåŠ¡ç«¯èº«ä»½éªŒè¯ï¼Œè¯·å¦¥å–„ä¿ç®¡ï¼‰\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "\n",
    "# Langfuse æœåŠ¡å™¨åœ°å€ï¼ˆé€‰æ‹©ç¦»æ‚¨æœ€è¿‘çš„åŒºåŸŸä»¥è·å¾—æ›´å¥½æ€§èƒ½ï¼‰\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # ğŸ‡ªğŸ‡º æ¬§æ´²åŒºåŸŸ\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"  # ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸ\n",
    "\n",
    "# ğŸ¤– OpenAI API å¯†é’¥\n",
    "# ä» https://platform.openai.com/api-keys è·å–\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "\n",
    "# ğŸš¨ å®‰å…¨æé†’ï¼š\n",
    "# - ä¸è¦å°†çœŸå®å¯†é’¥æäº¤åˆ°å…¬å…±ä»£ç ä»“åº“\n",
    "# - ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼ˆ.envï¼‰æˆ–å¯†é’¥ç®¡ç†æœåŠ¡\n",
    "# - å®šæœŸè½®æ¢ API å¯†é’¥ä»¥æé«˜å®‰å…¨æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆåï¼Œæˆ‘ä»¬å³å¯åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ã€‚`get_client()` ä¼šä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­æä¾›çš„å‡­æ®æ¥åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "# ğŸš€ åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯\n",
    "# get_client() ä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„é…ç½®ä¿¡æ¯\n",
    "langfuse = get_client()\n",
    " \n",
    "# ğŸ” éªŒè¯å®¢æˆ·ç«¯è¿æ¥çŠ¶æ€\n",
    "# è¿™ä¸ªæ­¥éª¤éå¸¸é‡è¦ï¼Œç¡®ä¿åç»­çš„è¿½è¸ªåŠŸèƒ½èƒ½å¤Ÿæ­£å¸¸å·¥ä½œ\n",
    "if langfuse.auth_check():\n",
    "    print(\"âœ… Langfuse å®¢æˆ·ç«¯å·²é€šè¿‡èº«ä»½éªŒè¯ï¼Œå‡†å¤‡å°±ç»ªï¼\")\n",
    "    print(\"ğŸ”§ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨è¿½è¸ªåŠŸèƒ½äº†\")\n",
    "else:\n",
    "    print(\"âŒ èº«ä»½éªŒè¯å¤±è´¥ï¼\")\n",
    "    print(\"ğŸ” è¯·æ£€æŸ¥ä»¥ä¸‹é…ç½®é¡¹ï¼š\")\n",
    "    print(\"   - LANGFUSE_PUBLIC_KEY æ˜¯å¦æ­£ç¡®\")\n",
    "    print(\"   - LANGFUSE_SECRET_KEY æ˜¯å¦æ­£ç¡®\") \n",
    "    print(\"   - LANGFUSE_HOST æ˜¯å¦å¯è®¿é—®\")\n",
    "    print(\"   - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqYMmi6n9Nh1"
   },
   "source": [
    "## ç¤ºä¾‹ 1ï¼šä½¿ç”¨ LangGraph æ„å»ºç®€å•èŠå¤©åº”ç”¨\n",
    "\n",
    "**æœ¬èŠ‚å°†å®Œæˆï¼š**\n",
    "\n",
    "- åœ¨ LangGraph ä¸­æ„å»ºä¸€ä¸ªå¯å›ç­”å¸¸è§é—®é¢˜çš„å®¢æœèŠå¤©æœºå™¨äºº\n",
    "- ä½¿ç”¨ Langfuse å¯¹æœºå™¨äººçš„è¾“å…¥ä¸è¾“å‡ºè¿›è¡Œè¿½è¸ªï¼ˆtracingï¼‰\n",
    "\n",
    "æˆ‘ä»¬å…ˆä»ä¸€ä¸ªåŸºç¡€æœºå™¨äººå…¥æ‰‹ï¼Œéšååœ¨ä¸‹ä¸€èŠ‚æ‰©å±•ä¸ºæ›´é«˜çº§çš„å¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰è®¾ç½®ï¼Œå¹¶åœ¨è¿‡ç¨‹ä¸­ä»‹ç»å…³é”®çš„ LangGraph æ¦‚å¿µã€‚\n",
    "\n",
    "### åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆAgentï¼‰\n",
    "\n",
    "é¦–å…ˆåˆ›å»ºä¸€ä¸ª `StateGraph`ã€‚`StateGraph` å®šä¹‰äº†èŠå¤©æœºå™¨äººçš„çŠ¶æ€æœºç»“æ„ã€‚æˆ‘ä»¬ä¼šæ·»åŠ èŠ‚ç‚¹æ¥è¡¨ç¤º LLM ä»¥åŠæœºå™¨äººå¯è°ƒç”¨çš„å‡½æ•°ï¼Œå¹¶é€šè¿‡è¾¹ï¼ˆedgeï¼‰å®šä¹‰æœºå™¨äººåœ¨è¿™äº›å‡½æ•°ä¹‹é—´çš„çŠ¶æ€æµè½¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGIxgPww6VX6"
   },
   "outputs": [],
   "source": [
    "# ğŸ”§ å¯¼å…¥ LangGraph æ„å»ºæ™ºèƒ½ä½“æ‰€éœ€çš„æ ¸å¿ƒæ¨¡å—\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI  # OpenAI èŠå¤©æ¨¡å‹\n",
    "from langchain_core.messages import HumanMessage  # äººç±»æ¶ˆæ¯ç±»å‹\n",
    "from typing_extensions import TypedDict  # ç±»å‹åŒ–å­—å…¸\n",
    "from langgraph.graph import StateGraph  # LangGraph çŠ¶æ€å›¾\n",
    "from langgraph.graph.message import add_messages  # æ¶ˆæ¯æ·»åŠ å‡½æ•°\n",
    "\n",
    "# ğŸ“‹ å®šä¹‰æ™ºèƒ½ä½“çš„çŠ¶æ€ç»“æ„\n",
    "# State æ˜¯ä¸€ä¸ªç±»å‹åŒ–å­—å…¸ï¼Œå®šä¹‰äº†æ™ºèƒ½ä½“åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­éœ€è¦ç»´æŠ¤çš„çŠ¶æ€ä¿¡æ¯\n",
    "class State(TypedDict):\n",
    "    # ğŸ’¬ æ¶ˆæ¯åˆ—è¡¨ï¼šå­˜å‚¨å¯¹è¯å†å²\n",
    "    # Annotated[list, add_messages] çš„å«ä¹‰ï¼š\n",
    "    # - list: æ¶ˆæ¯çš„æ•°æ®ç±»å‹æ˜¯åˆ—è¡¨\n",
    "    # - add_messages: æŒ‡å®šçŠ¶æ€æ›´æ–°ç­–ç•¥ï¼Œæ–°æ¶ˆæ¯ä¼šè¿½åŠ åˆ°åˆ—è¡¨æœ«å°¾è€Œä¸æ˜¯è¦†ç›–æ•´ä¸ªåˆ—è¡¨\n",
    "    # è¿™ç§è®¾è®¡ç¡®ä¿äº†å¯¹è¯å†å²çš„å®Œæ•´ä¿å­˜\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ğŸ—ï¸ åˆ›å»ºçŠ¶æ€å›¾æ„å»ºå™¨\n",
    "# StateGraph æ˜¯ LangGraph çš„æ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºå®šä¹‰æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ğŸ¤– åˆå§‹åŒ–è¯­è¨€æ¨¡å‹\n",
    "# é€‰æ‹© GPT-4o æ¨¡å‹ï¼Œtemperature=0.2 ç¡®ä¿è¾“å‡ºç›¸å¯¹ç¨³å®šä½†ä»æœ‰ä¸€å®šåˆ›é€ æ€§\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# ğŸ”„ å®šä¹‰èŠå¤©æœºå™¨äººèŠ‚ç‚¹å‡½æ•°\n",
    "# è¿™æ˜¯ LangGraph èŠ‚ç‚¹å‡½æ•°çš„åŸºæœ¬æ¨¡å¼ï¼šæ¥æ”¶å½“å‰çŠ¶æ€ï¼Œè¿”å›æ›´æ–°åçš„çŠ¶æ€\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    èŠå¤©æœºå™¨äººèŠ‚ç‚¹çš„æ ¸å¿ƒé€»è¾‘\n",
    "    \n",
    "    å‚æ•°:\n",
    "        state (State): å½“å‰çš„æ™ºèƒ½ä½“çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å†å²\n",
    "    \n",
    "    è¿”å›:\n",
    "        dict: åŒ…å«æ–°ç”Ÿæˆæ¶ˆæ¯çš„çŠ¶æ€æ›´æ–°\n",
    "    \n",
    "    å·¥ä½œæµç¨‹:\n",
    "    1. è·å–å½“å‰çš„æ¶ˆæ¯å†å²\n",
    "    2. å°†æ¶ˆæ¯å†å²å‘é€ç»™è¯­è¨€æ¨¡å‹\n",
    "    3. æ¥æ”¶æ¨¡å‹ç”Ÿæˆçš„å›å¤\n",
    "    4. å°†å›å¤åŒ…è£…æˆçŠ¶æ€æ›´æ–°è¿”å›\n",
    "    \"\"\"\n",
    "    # è°ƒç”¨è¯­è¨€æ¨¡å‹å¤„ç†å½“å‰å¯¹è¯å†å²ï¼Œç”Ÿæˆå›å¤\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    \n",
    "    # è¿”å›çŠ¶æ€æ›´æ–°ï¼šå°†æ¨¡å‹çš„å›å¤æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ğŸ”— å‘å›¾ä¸­æ·»åŠ \"chatbot\"èŠ‚ç‚¹\n",
    "# èŠ‚ç‚¹ä»£è¡¨å·¥ä½œå•å…ƒï¼Œé€šå¸¸æ˜¯æ™®é€šçš„ Python å‡½æ•°\n",
    "# æ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£ç‰¹å®šçš„å¤„ç†é€»è¾‘ï¼Œå¦‚è°ƒç”¨ LLMã€å¤„ç†å·¥å…·ã€æ•°æ®è½¬æ¢ç­‰\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# ğŸš€ è®¾ç½®å›¾çš„å…¥å£ç‚¹\n",
    "# å‘Šè¯‰å›¾æ¯æ¬¡è¿è¡Œæ—¶ä»å“ªä¸ªèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ\n",
    "# åœ¨è¿™ä¸ªç®€å•ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ç›´æ¥ä» chatbot èŠ‚ç‚¹å¼€å§‹\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# ğŸ è®¾ç½®å›¾çš„ç»“æŸç‚¹\n",
    "# æŒ‡ç¤ºå›¾\"å½“è¿™ä¸ªèŠ‚ç‚¹è¿è¡Œå®Œæˆåï¼Œå¯ä»¥é€€å‡ºæ‰§è¡Œ\"\n",
    "# å¯¹äºç®€å•çš„å•è½®å¯¹è¯ï¼Œchatbot èŠ‚ç‚¹æ‰§è¡Œå®Œå°±å¯ä»¥ç»“æŸ\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# âš™ï¸ ç¼–è¯‘å›¾å½¢ä¸ºå¯æ‰§è¡Œå¯¹è±¡\n",
    "# compile() æ–¹æ³•å°†å›¾æ„å»ºå™¨è½¬æ¢ä¸º CompiledGraph\n",
    "# CompiledGraph æ˜¯å¯ä»¥å®é™…è¿è¡Œçš„å›¾å½¢å¯¹è±¡ï¼Œæ”¯æŒ invokeã€stream ç­‰æ–¹æ³•\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# ğŸ’¡ ç†è§£ LangGraph çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n",
    "# ğŸ—ï¸ StateGraph: å®šä¹‰æ™ºèƒ½ä½“çš„çŠ¶æ€å’Œå·¥ä½œæµç¨‹\n",
    "# ğŸ”„ Node: æ‰§è¡Œå…·ä½“ä»»åŠ¡çš„å‡½æ•°ï¼Œå¦‚è°ƒç”¨ LLMã€ä½¿ç”¨å·¥å…·ç­‰\n",
    "# ğŸ”— Edge: è¿æ¥èŠ‚ç‚¹ï¼Œå®šä¹‰æ‰§è¡Œé¡ºåºå’Œæ¡ä»¶è·³è½¬\n",
    "# ğŸ“Š State: æ™ºèƒ½ä½“è¿è¡Œè¿‡ç¨‹ä¸­ç»´æŠ¤çš„æ•°æ®ç»“æ„\n",
    "# âš™ï¸ CompiledGraph: ç¼–è¯‘åçš„å¯æ‰§è¡Œå›¾å½¢å¯¹è±¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW2SJcRgh7Xo"
   },
   "source": [
    "### åœ¨è°ƒç”¨æ—¶æ·»åŠ  Langfuse å›è°ƒ\n",
    "\n",
    "ç°åœ¨ï¼Œä¸ºäº†è¿½è¸ªåº”ç”¨æ‰§è¡Œè¿‡ç¨‹ï¼Œæˆ‘ä»¬å°†æ·»åŠ  [é¢å‘ LangChain çš„ Langfuse å›è°ƒå¤„ç†å™¨](https://langfuse.com/integrations/frameworks/langchain)ï¼š`config={\"callbacks\": [langfuse_handler]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PxEc455-KYM",
    "outputId": "0d1a6a04-a024-47b8-d320-72cd25b7aefd"
   },
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ›ï¸ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨\n",
    "# è¯¥å¤„ç†å™¨ä¼šè‡ªåŠ¨æ•è· LangChain/LangGraph çš„æ‰§è¡Œç»†èŠ‚ï¼Œç”¨äºï¼š\n",
    "# - ğŸ•’ è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„è€—æ—¶ä¸å»¶è¿Ÿ\n",
    "# - ğŸ“ ä¿å­˜è¾“å…¥ã€è¾“å‡ºåŠä¸­é—´çŠ¶æ€\n",
    "# - ğŸ’° ç»Ÿè®¡ token æ¶ˆè€—å’Œ API è°ƒç”¨æˆæœ¬\n",
    "# - ğŸ æ”¶é›†å¼‚å¸¸ä¿¡æ¯ï¼Œä¾¿äºæ’é”™\n",
    "# - ğŸ“ˆ åœ¨ Langfuse ä¸­ç”Ÿæˆå¯è§†åŒ–è°ƒç”¨é“¾\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ğŸš€ è¿è¡Œæ™ºèƒ½ä½“å¹¶å¯ç”¨ Langfuse è¿½è¸ª\n",
    "print(\"ğŸ¤– æ™ºèƒ½ä½“å¼€å§‹è¿è¡Œï¼Œæ­£åœ¨å¤„ç†é—®é¢˜â€¦â€¦\")\n",
    "print(\"â“ ç”¨æˆ·æé—®ï¼šä»€ä¹ˆæ˜¯ Langfuseï¼Ÿ\")\n",
    "print(\"\n",
    "ğŸ“‹ æ‰§è¡Œè¿‡ç¨‹ï¼š\")\n",
    "\n",
    "# ä½¿ç”¨ stream æ–¹æ³•å¯ä»¥å®æ—¶æŸ¥çœ‹æ™ºèƒ½ä½“çš„æ‰§è¡Œæ­¥éª¤\n",
    "for step_result in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"ä»€ä¹ˆæ˜¯ Langfuseï¼Ÿè¯·è¯¦ç»†ä»‹ç»å…¶ä¸»è¦åŠŸèƒ½å’Œå…¸å‹åº”ç”¨åœºæ™¯ã€‚\")]},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    print(f\"ğŸ“¤ èŠ‚ç‚¹æ‰§è¡Œç»“æœï¼š{step_result}\")\n",
    "\n",
    "print(\"\n",
    "âœ… æ™ºèƒ½ä½“æ‰§è¡Œå®Œæˆï¼\")\n",
    "print(\"ğŸ” è¯·å‰å¾€ Langfuse æ§åˆ¶å°æŸ¥çœ‹å®Œæ•´çš„è¿½è¸ªè®°å½•ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fdf3ZRnWGZ0N"
   },
   "source": [
    "### åœ¨ Langfuse ä¸­æŸ¥çœ‹è¿½è¸ªç»“æœ\n",
    "\n",
    "ç¤ºä¾‹è¿½è¸ªï¼š`https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/85b0c53c4414f22ed8bfc9eb35f917c4`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17Aq7u6_LBR6"
   },
   "source": [
    "![åœ¨ Langfuse ä¸­æŸ¥çœ‹èŠå¤©åº”ç”¨çš„è¿½è¸ª](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_chatapp_trace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3yyVtGKhMPU"
   },
   "source": [
    "### å¯è§†åŒ–èŠå¤©åº”ç”¨\n",
    "\n",
    "ä½ å¯ä»¥ä½¿ç”¨ `get_graph` æ–¹æ³•é…åˆç›¸åº”çš„ â€œdrawâ€ æ–¹æ³•å¯¹å›¾è¿›è¡Œå¯è§†åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "MKkM6mw47kIy",
    "outputId": "9cf8a453-05e0-4193-fc77-81cb176d9ef4"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY0HW5xISntw"
   },
   "source": [
    "```mermaid\n",
    "graph TD;\n",
    "\t__start__([__start__]):::first\n",
    "\tchatbot(chatbot)\n",
    "\t__end__([__end__]):::last\n",
    "\t__start__ --> chatbot;\n",
    "\tchatbot --> __end__;\n",
    "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
    "\tclassDef first fill-opacity:0\n",
    "\tclassDef last fill:#bfb6fc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åœ¨ LangGraph Server ä¸­ä½¿ç”¨ Langfuse\n",
    "\n",
    "#### ğŸ–¥ï¸ LangGraph Server ç®€ä»‹\n",
    "\n",
    "[LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) æ˜¯ LangGraph æä¾›çš„æœåŠ¡å™¨éƒ¨ç½²æ–¹æ¡ˆï¼Œç”¨äºå°†æœ¬åœ°æ„å»ºçš„å›¾å·¥ä½œæµå‘å¸ƒä¸ºå¯æ‰©å±•çš„åœ¨çº¿æœåŠ¡ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
    "\n",
    "- ğŸŒ **HTTP API æ¥å£**ï¼šå°† LangGraph æ™ºèƒ½ä½“å°è£…ä¸º REST APIï¼Œä¾¿äºä¸ä¸šåŠ¡ç³»ç»Ÿé›†æˆ\n",
    "- ğŸš€ **ç”Ÿäº§çº§è¿è¡Œ**ï¼šæ”¯æŒé«˜å¹¶å‘ã€è´Ÿè½½å‡è¡¡ä¸å®¹å™¨åŒ–äº¤ä»˜\n",
    "- ğŸ”§ **è¿ç»´å‹å¥½**ï¼šè‡ªåŠ¨å¤„ç†è¯·æ±‚è·¯ç”±ã€çŠ¶æ€æ¢å¤ä¸é”™è¯¯é‡è¯•\n",
    "- ğŸ“Š **ç›‘æ§é›†æˆ**ï¼šå…¼å®¹ä¸»æµç›‘æ§ä¸è¿½è¸ªä½“ç³»ï¼Œä¾¿äºè§‚æµ‹è¿è¡ŒçŠ¶å†µ\n",
    "- ğŸ”’ **å®‰å…¨ç®¡æ§**ï¼šå†…ç½®èº«ä»½è®¤è¯ä¸æˆæƒæœºåˆ¶ï¼Œæ»¡è¶³ä¼ä¸šå®‰å…¨éœ€æ±‚\n",
    "\n",
    "#### ğŸ’¡ ä¸ºä»€ä¹ˆè¦åœ¨ Server ç¯å¢ƒæ¥å…¥ Langfuseï¼Ÿ\n",
    "\n",
    "- ğŸ­ **ç”Ÿäº§å¯è§‚æµ‹æ€§**ï¼šå®æ—¶æŸ¥çœ‹çº¿ä¸Šè¯·æ±‚çš„è°ƒç”¨é“¾ä¸çŠ¶æ€\n",
    "- ğŸ› **è¿œç¨‹è°ƒè¯•**ï¼šæ— éœ€å¤ç°åœºæ™¯å³å¯è¿˜åŸé—®é¢˜ç»†èŠ‚\n",
    "- ğŸ“ˆ **æ€§èƒ½æ´å¯Ÿ**ï¼šé‡åŒ–æ¯ä¸ªèŠ‚ç‚¹çš„è€—æ—¶ä¸æˆæœ¬\n",
    "- ğŸ’° **è´¹ç”¨æ²»ç†**ï¼šå‡†ç¡®ç»Ÿè®¡ç¬¬ä¸‰æ–¹ API çš„è°ƒç”¨é‡ä¸è´¹ç”¨\n",
    "- ğŸ‘¥ **å›¢é˜Ÿåä½œ**ï¼šå…±äº«è¿½è¸ªè®°å½•ï¼Œæ”¯æŒè·¨èŒèƒ½ååŒæ’æŸ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ”§ é…ç½®æ–¹æ³•è¯´æ˜\n",
    "\n",
    "ä½¿ç”¨ LangGraph Server æ—¶ï¼Œæ™ºèƒ½ä½“å›¾çš„è°ƒç”¨ç”±æœåŠ¡å™¨è‡ªåŠ¨å¤„ç†ï¼Œç”¨æˆ·æ— æ³•åœ¨æ¯æ¬¡è¯·æ±‚æ—¶æ‰‹åŠ¨æŒ‡å®šå›è°ƒå¤„ç†å™¨ã€‚\n",
    "\n",
    "**å…³é”®å·®å¼‚ï¼š**\n",
    "- ğŸ  **æœ¬åœ°å¼€å‘**ï¼šå¯ä»¥åœ¨æ¯æ¬¡è°ƒç”¨æ—¶æ·»åŠ  `config={\"callbacks\": [langfuse_handler]}`\n",
    "- ğŸ–¥ï¸ **æœåŠ¡å™¨éƒ¨ç½²**ï¼šéœ€è¦åœ¨å›¾ç¼–è¯‘æ—¶é¢„å…ˆé…ç½®å›è°ƒå¤„ç†å™¨\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆï¼š**\n",
    "åœ¨å£°æ˜å’Œç¼–è¯‘å›¾æ—¶å°±æ·»åŠ  Langfuse å›è°ƒï¼Œè¿™æ ·æœåŠ¡å™¨ä¸Šçš„æ‰€æœ‰è¯·æ±‚éƒ½ä¼šè‡ªåŠ¨å¯ç”¨è¿½è¸ªåŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ å¯¼å…¥æœåŠ¡å™¨éƒ¨ç½²æ‰€éœ€çš„æ¨¡å—\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ“‹ å®šä¹‰ä¸å‰æ–‡ä¸€è‡´çš„æ™ºèƒ½ä½“çŠ¶æ€ç»“æ„\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ğŸ—ï¸ æ„å»ºå›¾å½¢ç»“æ„\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ğŸ¤– åˆå§‹åŒ–è¯­è¨€æ¨¡å‹\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# ğŸ”„ å®šä¹‰èŠå¤©æœºå™¨äººèŠ‚ç‚¹\n",
    "def chatbot(state: State):\n",
    "    \"\"\"å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤ã€‚\"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# ğŸ”— ç»„è£…å›¾å½¢ç»“æ„\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# ğŸ”„ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼ˆæœåŠ¡å™¨æ¨¡å¼ï¼‰\n",
    "# åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­ï¼Œæ­¤å¤„ç†å™¨ä¼šè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰è¯·æ±‚çš„æ‰§è¡Œæƒ…å†µ\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# âš™ï¸ ç¼–è¯‘å›¾å½¢å¹¶é¢„é…ç½®å›è°ƒå¤„ç†å™¨\n",
    "# ğŸ¯ æ ¸å¿ƒæ–¹æ³•ï¼šwith_config()\n",
    "# - compile()ï¼šç¼–è¯‘å›¾å½¢ï¼Œç”Ÿæˆå¯æ‰§è¡Œçš„ CompiledGraph\n",
    "# - with_config()ï¼šä¸ºç¼–è¯‘åçš„å›¾å½¢è®¾ç½®é»˜è®¤é…ç½®ï¼ˆå¦‚å›è°ƒå¤„ç†å™¨ï¼‰\n",
    "#\n",
    "# ğŸ’¡ å·¥ä½œæµç¨‹ï¼š\n",
    "# 1. ç¼–è¯‘å›¾å½¢å¾—åˆ° CompiledGraph å¯¹è±¡\n",
    "# 2. è°ƒç”¨ with_config() æ³¨å…¥ Langfuse å›è°ƒ\n",
    "# 3. è¿”å›ä¸€ä¸ªå·²å†…ç½®è¿½è¸ªèƒ½åŠ›çš„æ–°å›¾å¯¹è±¡\n",
    "#\n",
    "# ğŸš€ ä¼˜åŠ¿ï¼š\n",
    "# - æ— éœ€åœ¨æ¯æ¬¡è¯·æ±‚æ—¶æ‰‹åŠ¨æ·»åŠ å›è°ƒé…ç½®\n",
    "# - æ‰€æœ‰ API è¯·æ±‚éƒ½ä¼šè‡ªåŠ¨å†™å…¥ Langfuse è¿½è¸ª\n",
    "# - ç®€åŒ–ç”Ÿäº§ç¯å¢ƒçš„éƒ¨ç½²ä¸è¿ç»´\n",
    "graph = graph_builder.compile().with_config({\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# ğŸ’¡ éƒ¨ç½²æç¤ºï¼š\n",
    "# åœ¨ LangGraph Server ä¸­ç›´æ¥å¼•ç”¨æ­¤ graphï¼Œå³å¯ç«‹å³è·å¾—å®Œæ•´çš„è¿½è¸ªæ•°æ®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2W94eY19TR1"
   },
   "source": [
    "## ç¤ºä¾‹ 2ï¼šåŸºäº LangGraph çš„å¤šæ™ºèƒ½ä½“åº”ç”¨\n",
    "\n",
    "**æœ¬èŠ‚å°†å®Œæˆï¼š**\n",
    "\n",
    "- æ„å»º 2 ä¸ªæ‰§è¡Œæ™ºèƒ½ä½“ï¼šä¸€ä¸ªç ”ç©¶æ™ºèƒ½ä½“ä½¿ç”¨ LangChain çš„ WikipediaAPIWrapper æœç´¢ç»´åŸºç™¾ç§‘ï¼Œå¦ä¸€ä¸ªä½¿ç”¨è‡ªå®šä¹‰å·¥å…·è·å–å½“å‰æ—¶é—´\n",
    "- æ„å»ºä¸€ä¸ªæ™ºèƒ½ä½“ç›‘ç£è€…ï¼ˆsupervisorï¼‰ï¼Œç”¨äºå°†ç”¨æˆ·é—®é¢˜åˆ†é…ç»™ä¸Šè¿°æ™ºèƒ½ä½“\n",
    "- æ·»åŠ  Langfuse å›è°ƒä»¥è¿½è¸ªç›‘ç£è€…ä¸æ‰§è¡Œæ™ºèƒ½ä½“çš„æ­¥éª¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "WfnrswDdjYTV",
    "outputId": "0d938cb1-9fd2-4ed3-cfdd-c84a9ad3ed82"
   },
   "outputs": [],
   "source": [
    "%pip install langfuse langgraph langchain langchain_openai langchain_experimental pandas wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tciUQ62IEVec"
   },
   "source": [
    "### åˆ›å»ºå·¥å…·\n",
    "\n",
    "åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªç”¨äºç»´åŸºç™¾ç§‘æ£€ç´¢çš„æ™ºèƒ½ä½“ï¼Œä»¥åŠä¸€ä¸ªç”¨äºå‘ŠçŸ¥å½“å‰æ—¶é—´çš„æ™ºèƒ½ä½“ã€‚å…ˆå®šä¹‰å®ƒä»¬å°†ä½¿ç”¨çš„å·¥å…·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cet0loyp9p-T"
   },
   "outputs": [],
   "source": [
    "# ğŸ”§ å¯¼å…¥å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ‰€éœ€çš„å·¥å…·å’Œæ¨¡å—\n",
    "from typing import Annotated\n",
    "from langchain_community.tools import WikipediaQueryRun  # ç»´åŸºç™¾ç§‘æŸ¥è¯¢å·¥å…·\n",
    "from langchain_community.utilities import WikipediaAPIWrapper  # ç»´åŸºç™¾ç§‘ API å°è£…\n",
    "from datetime import datetime  # æ—¶é—´å¤„ç†æ¨¡å—\n",
    "from langchain.tools import Tool  # é€šç”¨å·¥å…·å®šä¹‰ç±»\n",
    "\n",
    "# ğŸ” å®šä¹‰ç»´åŸºç™¾ç§‘æœç´¢å·¥å…·\n",
    "# åŠŸèƒ½ï¼šæ ¹æ®æŸ¥è¯¢è¯åœ¨ç»´åŸºç™¾ç§‘ä¸­æœç´¢ç›¸å…³ä¿¡æ¯\n",
    "# é€‚ç”¨åœºæ™¯ï¼šå›ç­”ç™¾ç§‘çŸ¥è¯†ã€å†å²äº‹ä»¶ã€äººç‰©ä¼ è®°ç­‰é—®é¢˜\n",
    "wikipedia_tool = WikipediaQueryRun(\n",
    "    api_wrapper=WikipediaAPIWrapper(\n",
    "        top_k_results=2,  # è¿”å›æœ€ç›¸å…³çš„2ä¸ªæœç´¢ç»“æœ\n",
    "        doc_content_chars_max=1000  # é™åˆ¶æ¯ä¸ªç»“æœçš„å­—ç¬¦æ•°ï¼Œé¿å…ä¿¡æ¯è¿‡è½½\n",
    "    )\n",
    ")\n",
    "\n",
    "# â° å®šä¹‰å½“å‰æ—¶é—´æŸ¥è¯¢å·¥å…·  \n",
    "# åŠŸèƒ½ï¼šè¿”å›å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´ä¿¡æ¯\n",
    "# é€‚ç”¨åœºæ™¯ï¼šå›ç­”\"ç°åœ¨å‡ ç‚¹\"ã€\"ä»Šå¤©æ˜¯ä»€ä¹ˆæ—¥æœŸ\"ç­‰æ—¶é—´ç›¸å…³é—®é¢˜\n",
    "datetime_tool = Tool(\n",
    "    name=\"Datetime\",  # å·¥å…·åç§°ï¼Œæ™ºèƒ½ä½“ä¼šé€šè¿‡è¿™ä¸ªåç§°è°ƒç”¨å·¥å…·\n",
    "    func=lambda x: datetime.now().isoformat(),  # å·¥å…·å‡½æ•°ï¼šè¿”å› ISO æ ¼å¼çš„å½“å‰æ—¶é—´\n",
    "    description=\"è¿”å›å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´ä¿¡æ¯ï¼ˆISO æ ¼å¼ï¼‰\",  # å·¥å…·æè¿°ï¼Œå¸®åŠ©æ™ºèƒ½ä½“ç†è§£ä½•æ—¶ä½¿ç”¨æ­¤å·¥å…·\n",
    ")\n",
    "\n",
    "# ğŸ’¡ å·¥å…·è®¾è®¡åŸåˆ™ï¼š\n",
    "# 1. ğŸ¯ å•ä¸€èŒè´£ï¼šæ¯ä¸ªå·¥å…·åªè´Ÿè´£ä¸€ä¸ªç‰¹å®šåŠŸèƒ½\n",
    "# 2. ğŸ“ æ¸…æ™°æè¿°ï¼šdescription è¦å‡†ç¡®æè¿°å·¥å…·çš„åŠŸèƒ½å’Œä½¿ç”¨åœºæ™¯\n",
    "# 3. ğŸ”’ é”™è¯¯å¤„ç†ï¼šç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥æ·»åŠ å¼‚å¸¸å¤„ç†é€»è¾‘\n",
    "# 4. âš¡ æ€§èƒ½è€ƒè™‘ï¼šé™åˆ¶è¿”å›æ•°æ®çš„å¤§å°ï¼Œé¿å…å½±å“æ•´ä½“æ€§èƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31uhDy_mEqr6"
   },
   "source": [
    "### ğŸ› ï¸ è¾…åŠ©å·¥å…·å‡½æ•°\n",
    "\n",
    "#### ğŸ“ åŠŸèƒ½è¯´æ˜\n",
    "ä¸‹é¢å®šä¹‰çš„è¾…åŠ©å‡½æ•°ç”¨äºç®€åŒ–æ·»åŠ æ–°çš„æ™ºèƒ½ä½“å·¥ä½œèŠ‚ç‚¹ã€‚è¿™äº›å‡½æ•°å°è£…äº†åˆ›å»ºæ™ºèƒ½ä½“å’ŒèŠ‚ç‚¹çš„é€šç”¨é€»è¾‘ï¼Œæé«˜ä»£ç çš„å¯é‡ç”¨æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚\n",
    "\n",
    "#### ğŸ¯ è®¾è®¡ç›®æ ‡\n",
    "- **å‡å°‘é‡å¤ä»£ç **ï¼šé¿å…ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“é‡å¤ç¼–å†™ç›¸åŒçš„åˆå§‹åŒ–é€»è¾‘\n",
    "- **æ ‡å‡†åŒ–æ¥å£**ï¼šç¡®ä¿æ‰€æœ‰æ™ºèƒ½ä½“èŠ‚ç‚¹å…·æœ‰ä¸€è‡´çš„è¾“å…¥è¾“å‡ºæ ¼å¼\n",
    "- **ç®€åŒ–æ‰©å±•**ï¼šæ–°å¢æ™ºèƒ½ä½“æ—¶åªéœ€å…³æ³¨ä¸šåŠ¡é€»è¾‘ï¼Œæ— éœ€å¤„ç†æ¡†æ¶ç»†èŠ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75atiExdqd4P"
   },
   "outputs": [],
   "source": [
    "# ğŸ”§ å¯¼å…¥æ™ºèƒ½ä½“æ„å»ºæ‰€éœ€çš„æ ¸å¿ƒç»„ä»¶\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent  # æ™ºèƒ½ä½“æ‰§è¡Œå™¨å’Œåˆ›å»ºå‡½æ•°\n",
    "from langchain_core.messages import BaseMessage, HumanMessage  # æ¶ˆæ¯åŸºç±»å’Œäººç±»æ¶ˆæ¯\n",
    "from langchain_openai import ChatOpenAI  # OpenAI èŠå¤©æ¨¡å‹\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, system_prompt: str, tools: list):\n",
    "    \"\"\"\n",
    "    ğŸ­ æ™ºèƒ½ä½“å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå…·æœ‰ç‰¹å®šèƒ½åŠ›çš„å·¥ä½œæ™ºèƒ½ä½“\n",
    "    \n",
    "    å‚æ•°:\n",
    "        llm (ChatOpenAI): è¯­è¨€æ¨¡å‹å®ä¾‹\n",
    "        system_prompt (str): ç³»ç»Ÿæç¤ºè¯ï¼Œå®šä¹‰æ™ºèƒ½ä½“çš„è§’è‰²å’Œè¡Œä¸ºè§„èŒƒ\n",
    "        tools (list): æ™ºèƒ½ä½“å¯ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨\n",
    "    \n",
    "    è¿”å›:\n",
    "        AgentExecutor: é…ç½®å®Œæˆçš„æ™ºèƒ½ä½“æ‰§è¡Œå™¨\n",
    "    \n",
    "    ğŸ”„ å·¥ä½œæµç¨‹:\n",
    "    1. æ„å»ºæç¤ºæ¨¡æ¿ï¼ˆåŒ…å«ç³»ç»Ÿè§’è‰²ã€å¯¹è¯å†å²ã€å·¥å…·ä½¿ç”¨è®°å½•ï¼‰\n",
    "    2. åˆ›å»ºæ”¯æŒå·¥å…·è°ƒç”¨çš„ OpenAI æ™ºèƒ½ä½“\n",
    "    3. åŒ…è£…ä¸ºæ‰§è¡Œå™¨ï¼Œå¤„ç†å·¥å…·è°ƒç”¨å’ŒçŠ¶æ€ç®¡ç†\n",
    "    \"\"\"\n",
    "    # ğŸ“‹ æ„å»ºæ™ºèƒ½ä½“çš„æç¤ºæ¨¡æ¿\n",
    "    # åŒ…å«ä¸‰ä¸ªå…³é”®éƒ¨åˆ†ï¼šç³»ç»Ÿè§’è‰²ã€å¯¹è¯å†å²ã€å·¥å…·ä½¿ç”¨è®°å½•\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        # ğŸ­ ç³»ç»Ÿæ¶ˆæ¯ï¼šå®šä¹‰æ™ºèƒ½ä½“çš„è§’è‰²ã€èƒ½åŠ›å’Œè¡Œä¸ºè§„èŒƒ\n",
    "        (\"system\", system_prompt),\n",
    "        # ğŸ’¬ æ¶ˆæ¯å†å²ï¼šä¿å­˜ä¸ç”¨æˆ·å’Œå…¶ä»–æ™ºèƒ½ä½“çš„å¯¹è¯è®°å½•\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        # ğŸ”§ å·¥å…·è®°å½•ï¼šè®°å½•æ™ºèƒ½ä½“ä½¿ç”¨å·¥å…·çš„è¿‡ç¨‹å’Œç»“æœ\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    \n",
    "    # ğŸ¤– åˆ›å»ºæ”¯æŒ OpenAI å·¥å…·è°ƒç”¨çš„æ™ºèƒ½ä½“\n",
    "    # è¿™ä¸ªæ™ºèƒ½ä½“èƒ½å¤Ÿç†è§£ä½•æ—¶éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œä»¥åŠå¦‚ä½•è§£é‡Šå·¥å…·çš„è¿”å›ç»“æœ\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    \n",
    "    # ğŸ® åˆ›å»ºæ™ºèƒ½ä½“æ‰§è¡Œå™¨\n",
    "    # æ‰§è¡Œå™¨è´Ÿè´£ï¼šå·¥å…·è°ƒç”¨ã€é”™è¯¯å¤„ç†ã€çŠ¶æ€ç®¡ç†ã€ç»“æœæ•´åˆ\n",
    "    executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "        verbose=True,  # æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œè¿‡ç¨‹ï¼Œä¾¿äºè°ƒè¯•\n",
    "        handle_parsing_errors=True  # è‡ªåŠ¨å¤„ç†è§£æé”™è¯¯ï¼Œæé«˜ç¨³å®šæ€§\n",
    "    )\n",
    "    \n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    \"\"\"\n",
    "    ğŸ”„ æ™ºèƒ½ä½“èŠ‚ç‚¹é€‚é…å™¨ï¼šå°†æ™ºèƒ½ä½“åŒ…è£…ä¸º LangGraph èŠ‚ç‚¹\n",
    "    \n",
    "    å‚æ•°:\n",
    "        state: å½“å‰çš„å›¾çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å†å²å’Œå…¶ä»–ä¸Šä¸‹æ–‡ä¿¡æ¯\n",
    "        agent: æ™ºèƒ½ä½“æ‰§è¡Œå™¨å®ä¾‹\n",
    "        name: æ™ºèƒ½ä½“çš„åç§°ï¼Œç”¨äºåœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­æ ‡è¯†æ¶ˆæ¯æ¥æº\n",
    "    \n",
    "    è¿”å›:\n",
    "        dict: åŒ…å«æ™ºèƒ½ä½“å“åº”çš„çŠ¶æ€æ›´æ–°\n",
    "    \n",
    "    ğŸ”„ é€‚é…è¿‡ç¨‹:\n",
    "    1. è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†å½“å‰çŠ¶æ€\n",
    "    2. æå–æ™ºèƒ½ä½“çš„è¾“å‡ºç»“æœ\n",
    "    3. åŒ…è£…ä¸ºå¸¦æœ‰å‘é€è€…èº«ä»½çš„æ¶ˆæ¯\n",
    "    4. è¿”å›çŠ¶æ€æ›´æ–°\n",
    "    \"\"\"\n",
    "    # ğŸ“¤ è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†å½“å‰çŠ¶æ€\n",
    "    # agent.invoke() ä¼šå¤„ç†å¯¹è¯å†å²ï¼Œå†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·ï¼Œå¹¶ç”Ÿæˆæœ€ç»ˆå›å¤\n",
    "    result = agent.invoke(state)\n",
    "    \n",
    "    # ğŸ·ï¸ å°†æ™ºèƒ½ä½“çš„è¾“å‡ºåŒ…è£…ä¸ºå¸¦æœ‰èº«ä»½æ ‡è¯†çš„æ¶ˆæ¯\n",
    "    # name å‚æ•°è®©ç³»ç»ŸçŸ¥é“è¿™æ¡æ¶ˆæ¯æ¥è‡ªå“ªä¸ªæ™ºèƒ½ä½“\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=result[\"output\"],  # æ™ºèƒ½ä½“ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹\n",
    "            name=name  # æ¶ˆæ¯å‘é€è€…çš„èº«ä»½æ ‡è¯†\n",
    "        )]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74bZqwU6FCOa"
   },
   "source": [
    "### ğŸ¯ åˆ›å»ºæ™ºèƒ½ä½“ç›‘ç£è€…\n",
    "\n",
    "#### ğŸ“‹ ç›‘ç£è€…çš„æ ¸å¿ƒèŒè´£\n",
    "æ™ºèƒ½ä½“ç›‘ç£è€…æ˜¯å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„\"å¤§è„‘\"ï¼Œè´Ÿè´£ï¼š\n",
    "\n",
    "- ğŸ§  **ä»»åŠ¡ç†è§£**ï¼šåˆ†æç”¨æˆ·è¯·æ±‚ï¼Œç†è§£ä»»åŠ¡çš„æ€§è´¨å’Œéœ€æ±‚\n",
    "- ğŸ¯ **æ™ºèƒ½ä½“é€‰æ‹©**ï¼šæ ¹æ®ä»»åŠ¡ç‰¹ç‚¹é€‰æ‹©æœ€é€‚åˆçš„å·¥ä½œæ™ºèƒ½ä½“\n",
    "- ğŸ”„ **æµç¨‹æ§åˆ¶**ï¼šå†³å®šä½•æ—¶åˆ‡æ¢æ™ºèƒ½ä½“ï¼Œä½•æ—¶ç»“æŸå¤„ç†æµç¨‹\n",
    "- ğŸ“Š **ç»“æœæ•´åˆ**ï¼šæ±‡æ€»å„ä¸ªæ™ºèƒ½ä½“çš„å·¥ä½œæˆæœ\n",
    "\n",
    "#### ğŸ”§ æŠ€æœ¯å®ç°æ–¹å¼\n",
    "ç›‘ç£è€…ä½¿ç”¨ **å‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰** æŠ€æœ¯æ¥å®ç°å†³ç­–ï¼š\n",
    "\n",
    "- ğŸ“ **å‡½æ•°è°ƒç”¨**ï¼šé€šè¿‡ç»“æ„åŒ–çš„å‡½æ•°è°ƒç”¨æ¥è¡¨è¾¾å†³ç­–ç»“æœ\n",
    "- ğŸ›ï¸ **é€‰æ‹©æœºåˆ¶**ï¼šåœ¨å¯ç”¨çš„å·¥ä½œèŠ‚ç‚¹ä¸­é€‰æ‹©ä¸‹ä¸€ä¸ªæ‰§è¡Œè€…\n",
    "- ğŸ **ç»ˆæ­¢æ¡ä»¶**ï¼šåˆ¤æ–­ä½•æ—¶ä»»åŠ¡å·²å®Œæˆï¼Œå¯ä»¥ç»“æŸå¤„ç†æµç¨‹\n",
    "\n",
    "#### ğŸ’¡ è®¾è®¡ä¼˜åŠ¿\n",
    "- **ç²¾ç¡®æ§åˆ¶**ï¼šé¿å…éšæœºæˆ–ä¸ç¡®å®šçš„è·¯ç”±å†³ç­–\n",
    "- **å¯è§£é‡Šæ€§**ï¼šæ¯ä¸ªå†³ç­–éƒ½æœ‰æ˜ç¡®çš„é€»è¾‘ä¾æ®\n",
    "- **å¯æ‰©å±•æ€§**ï¼šå®¹æ˜“æ·»åŠ æ–°çš„å·¥ä½œæ™ºèƒ½ä½“å’Œå†³ç­–è§„åˆ™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hu8MzgihrHdF"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"Researcher\", \"CurrentTime\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# ğŸ§­ ç›‘ç£è€…èŠ‚ç‚¹ç”± LLM æ‰®æ¼”ï¼Œè´Ÿè´£é€‰æ‹©ä¸‹ä¸€ä½æ‰§è¡Œçš„æ™ºèƒ½ä½“å¹¶åˆ¤æ–­æµç¨‹æ˜¯å¦ç»“æŸ\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "# ğŸ” ä½¿ç”¨ OpenAI Function Callingï¼Œå¯è®©ç»“æ„åŒ–è¾“å‡ºå’Œè§£ææ›´åŠ ç¨³å®š\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# ğŸ“œ æ„å»ºç›‘ç£è€…æç¤ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# ğŸ”— æ„å»ºç›‘ç£è€…æ™ºèƒ½ä½“çš„æ‰§è¡Œé“¾\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ognuMaIeFVh7"
   },
   "source": [
    "### æ„å»ºå›¾å½¢ç»“æ„\n",
    "\n",
    "ç°åœ¨å¯ä»¥å¼€å§‹æ­å»ºæ•´å¼ å›¾ã€‚ä¸‹é¢ä½¿ç”¨åˆšåˆšå®šä¹‰çš„å‡½æ•°æŒ‡å®šçŠ¶æ€å’Œå„ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œå¹¶è¿æ¥å›¾ä¸­çš„æ‰€æœ‰è¾¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_LwtCmw_rHVz"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# ğŸ—‚ï¸ æ™ºèƒ½ä½“çŠ¶æ€ä¼šä½œä¸ºæ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥æ•°æ®\n",
    "class AgentState(TypedDict):\n",
    "    # Annotated å‘Šè¯‰å›¾ï¼šæ–°çš„æ¶ˆæ¯ä¼šè¿½åŠ åˆ°ç°æœ‰æ¶ˆæ¯åˆ—è¡¨ä¸­\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # next å­—æ®µæŒ‡ç¤ºä¸‹ä¸€æ­¥è¦è·³è½¬åˆ°å“ªä¸ªèŠ‚ç‚¹\n",
    "    next: str\n",
    "\n",
    "# ğŸ§‘â€ğŸ’» ä½¿ç”¨è¾…åŠ©å‡½æ•°åˆ›å»ºç ”ç©¶æ™ºèƒ½ä½“\n",
    "research_agent = create_agent(llm, \"You are a web researcher.\", [wikipedia_tool])\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# ğŸ•°ï¸ åˆ›å»ºæŠ¥æ—¶æ™ºèƒ½ä½“\n",
    "currenttime_agent = create_agent(llm, \"You are a time keeping assistant who tells the current time.\", [datetime_tool])\n",
    "currenttime_node = functools.partial(agent_node, agent=currenttime_agent, name=\"CurrentTime\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# ğŸ“¦ æ³¨å†ŒèŠ‚ç‚¹ï¼šèŠ‚ç‚¹ä»£è¡¨å…·ä½“çš„å·¥ä½œå•å…ƒï¼Œé€šå¸¸æ˜¯ Python å‡½æ•°\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"CurrentTime\", currenttime_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "# ğŸ”‚ å¼ºåˆ¶æ‰€æœ‰å·¥ä½œèŠ‚ç‚¹åœ¨å®Œæˆåå›åˆ°ç›‘ç£è€…\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "# ğŸ”€ æ¡ä»¶è¾¹æ ¹æ®å½“å‰çŠ¶æ€å†³å®šåç»­è·¯ç”±\n",
    "# è¯¥å‡½æ•°è¯»å–çŠ¶æ€å¹¶è¿”å›è¦æ‰§è¡Œçš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "# ğŸšª è®¾ç½®å…¥å£èŠ‚ç‚¹ï¼Œç¡®å®šå›¾åœ¨è¿è¡Œæ—¶ä»å“ªé‡Œå¼€å§‹\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# âš™ï¸ ç¼–è¯‘å›¾å½¢ï¼Œå¾—åˆ°å¯è°ƒç”¨çš„ CompiledGraph\n",
    "graph_2 = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3xfJLJyFwBG"
   },
   "source": [
    "### åœ¨è°ƒç”¨ä¸­æŒ‚è½½ Langfuse å›è°ƒ\n",
    "\n",
    "åœ¨æ‰§è¡Œ `graph_2.stream` æ—¶å¢åŠ  [Langfuse å›è°ƒå¤„ç†å™¨](https://langfuse.com/integrations/frameworks/langchain)ï¼š`config={\"callbacks\": [langfuse_handler]}`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsX1gw9kryGP",
    "outputId": "65d94f3c-17e7-4ad8-88b5-f837676d206b"
   },
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ“¡ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºè®°å½• LangChain çš„æ‰§è¡Œè½¨è¿¹\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ğŸ”— å°†å›è°ƒå¤„ç†å™¨æŒ‚è½½åˆ°å›¾çš„ stream è°ƒç”¨ä¸­ï¼›å¯é€‰çš„ run_name ä¼šä½œä¸ºè¿½è¸ªåç§°å±•ç¤º\n",
    "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"å…‰åˆä½œç”¨æ˜¯å¦‚ä½•è¿›è¡Œçš„ï¼Ÿ\")]},\n",
    "                       config={\"callbacks\": [langfuse_handler]}):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqJnMtP5HDql",
    "outputId": "69c3d5d6-d44c-4784-a484-c66e4748b522"
   },
   "outputs": [],
   "source": [
    "# ğŸ”— åŒæ ·åœ°ï¼Œä¸ºå…¶ä»–æŸ¥è¯¢æŒ‚è½½ Langfuse å›è°ƒ\n",
    "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"ç°åœ¨çš„å‡†ç¡®æ—¶é—´æ˜¯å¤šå°‘ï¼Ÿ\")]},\n",
    "                       config={\"callbacks\": [langfuse_handler]}):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4XjtNenH9GF"
   },
   "source": [
    "### åœ¨ Langfuse ä¸­æŸ¥çœ‹å¤šæ™ºèƒ½ä½“è¿½è¸ª\n",
    "\n",
    "ä»¥ä¸‹é“¾æ¥å±•ç¤ºäº†æœ¬èŠ‚å¤šæ™ºèƒ½ä½“ç¤ºä¾‹åœ¨ Langfuse ä¸­ç”Ÿæˆçš„è¿½è¸ªè®°å½•ï¼š\n",
    "\n",
    "1. [å…‰åˆä½œç”¨æ˜¯å¦‚ä½•è¿›è¡Œçš„ï¼Ÿ](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7d5f970573b8214d1ca891251e42282c)\n",
    "2. [ç°åœ¨å‡ ç‚¹ï¼Ÿ](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/3a69fe4998df50d42054f8944bd6a8d9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-5EEBZAIbwc"
   },
   "source": [
    "![åœ¨ Langfuse ä¸­æŸ¥çœ‹å¤šæ™ºèƒ½ä½“è¿½è¸ª](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_multiagent_traces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCEzabn_jhbf"
   },
   "source": [
    "### å¯è§†åŒ–è¯¥æ™ºèƒ½ä½“\n",
    "\n",
    "ä½ å¯ä»¥ä½¿ç”¨ `get_graph` æ–¹æ³•é…åˆç›¸åº”çš„ â€œdrawâ€ æ–¹æ³•è¿›è¡Œå›¾å½¢å¯è§†åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "notlPjnl-HXV",
    "outputId": "17d6c6db-92af-4a6e-b1af-61b68e9cc87a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph_2.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mESkG2IJS8OY"
   },
   "source": [
    "```mermaid\n",
    "graph TD;\n",
    "\t__start__([__start__]):::first\n",
    "\tResearcher(Researcher)\n",
    "\tCurrentTime(CurrentTime)\n",
    "\tsupervisor(supervisor)\n",
    "\t__end__([__end__]):::last\n",
    "\tCurrentTime --> supervisor;\n",
    "\tResearcher --> supervisor;\n",
    "\t__start__ --> supervisor;\n",
    "\tsupervisor -.-> Researcher;\n",
    "\tsupervisor -.-> CurrentTime;\n",
    "\tsupervisor -. &nbspFINISH&nbsp .-> __end__;\n",
    "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
    "\tclassDef first fill-opacity:0\n",
    "\tclassDef last fill:#bfb6fc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¤šä¸ª LangGraph æ™ºèƒ½ä½“çš„ååŒ\n",
    "\n",
    "åœ¨æŸäº›æ¶æ„ä¸­ï¼Œä¸€ä¸ª LangGraph æ™ºèƒ½ä½“ä¼šè°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»– LangGraph æ™ºèƒ½ä½“ã€‚è‹¥æƒ³è®©æ•´å¥—æ‰§è¡Œé“¾åœ¨ Langfuse ä¸­èšåˆä¸ºåŒä¸€æ¡è¿½è¸ªï¼Œå¯æ˜¾å¼ä¼ å…¥è‡ªå®šä¹‰çš„ `trace_id`ã€‚\n",
    "\n",
    "é¦–å…ˆç”Ÿæˆä¸€ä¸ªå…±äº«çš„ `trace_id`ï¼Œä¾›ä¸»æ™ºèƒ½ä½“ä¸å­æ™ºèƒ½ä½“å…±ç”¨ï¼Œä»¥ä¾¿åœ¨ Langfuse ä¸­åˆå¹¶ä¸ºåŒä¸€æ¡è®°å½•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client, Langfuse\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# ğŸ” ä»å¤–éƒ¨ç³»ç»Ÿç”Ÿæˆä¸€ä¸ªç¡®å®šæ€§çš„ trace_idï¼Œä¾¿äºè·¨æœåŠ¡èšåˆ\n",
    "predefined_trace_id = Langfuse.create_trace_id()\n",
    "\n",
    "# ğŸ“¡ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºé‡‡é›† LangChain çš„æ‰§è¡Œæ•°æ®\n",
    "langfuse_handler = CallbackHandler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæ„å»ºå­æ™ºèƒ½ä½“çš„é€»è¾‘ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "sub_agent = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "éšåï¼Œå°†è¯¥å­æ™ºèƒ½ä½“å°è£…æˆå·¥å…·ï¼Œä¾›ä¸»æµç¨‹è°ƒç”¨å¹¶å¤ç”¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def langgraph_research(question):\n",
    "  \"\"\"Conducts research for various topics.\"\"\"\n",
    "\n",
    "  with langfuse.start_as_current_span(\n",
    "      name=\"ğŸ¤–-sub-research-agent\",\n",
    "      trace_context={\"trace_id\": predefined_trace_id}\n",
    "  ) as span:\n",
    "      span.update_trace(input=question)\n",
    "\n",
    "      response = sub_agent.invoke({\"messages\": [HumanMessage(content = question)]},\n",
    "                        config={\"callbacks\": [langfuse_handler]})\n",
    "    \n",
    "      span.update_trace(output= response[\"messages\"][1].content)\n",
    "\n",
    "  return response[\"messages\"][1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€åï¼Œåˆ›å»ºç¬¬äºŒä¸ª LangGraph æ™ºèƒ½ä½“ï¼Œé€šè¿‡å‰é¢æ–°å¢çš„ `langgraph_research` å·¥å…·å®Œæˆåä½œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
    "\n",
    "main_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[langgraph_research]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"ä»€ä¹ˆæ˜¯ Langfuseï¼Ÿ\"\n",
    "\n",
    "# ğŸ§­ ä½¿ç”¨é¢„ç”Ÿæˆçš„ trace_idï¼ˆé€šè¿‡ trace_context æ³¨å…¥ï¼‰\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"ğŸ¤–-main-agent\",\n",
    "    trace_context={\"trace_id\": predefined_trace_id}\n",
    ") as span:\n",
    "    span.update_trace(input=user_question)\n",
    "\n",
    "    # æ­¤å¤„çš„ LangChain æ‰§è¡Œéƒ½ä¼šå½’å±äºåŒä¸€æ¡è¿½è¸ª\n",
    "    response = main_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_question}]},\n",
    "                            config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "    span.update_trace(output=response[\"messages\"][1].content)\n",
    "\n",
    "print(f\"Trace ID: {predefined_trace_id}\")  # å¯åœ¨åç»­è¯„åˆ†æˆ–æ’æŸ¥æ—¶ä½¿ç”¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åœ¨ Langfuse ä¸­æŸ¥çœ‹å¤šæ™ºèƒ½ä½“è¿½è¸ª\n",
    "\n",
    "![å¤šæ™ºèƒ½ä½“è¿½è¸ªç¤ºä¾‹](https://langfuse.com/images/cookbook/integration-langgraph/a2a_langgraph.png)\n",
    "\n",
    "ç¤ºä¾‹è¿½è¸ªé“¾æ¥ï¼šhttps://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/85b0c53c4414f22ed8bfc9eb35f917c4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uybP4h8wGvWw"
   },
   "source": [
    "## ä¸ºè¿½è¸ªæ·»åŠ è¯„åˆ†\n",
    "\n",
    "[è¯„åˆ†ï¼ˆScoreï¼‰](https://langfuse.com/docs/scores/overview) ç”¨äºè¯„ä»·å•ä¸ªè§‚æµ‹ï¼ˆobservationï¼‰æˆ–æ•´æ¡è¿½è¸ªï¼ˆtraceï¼‰ï¼Œå¯å¸®åŠ©ä½ åœ¨è¿è¡Œæ—¶æ‰§è¡Œè‡ªå®šä¹‰è´¨é‡æ£€æŸ¥ï¼Œæˆ–é…åˆäººå·¥å®¡æ ¸æµç¨‹ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ï¼š\n",
    "\n",
    "- ä¸ºæŸä¸ª span è®°å½•ä¸€ä¸ªæ•°å€¼å‹è¯„åˆ†ï¼ˆå¦‚ `relevance`ï¼‰\n",
    "- ä¸ºæ•´æ¡è¿½è¸ªè®°å½•ä¸€ä¸ªåˆ†ç±»å‹è¯„åˆ†ï¼ˆå¦‚ `feedback`ï¼‰\n",
    "\n",
    "è¿™æœ‰åŠ©äºç³»ç»ŸåŒ–åœ°è¯„ä¼°ä¸æ”¹è¿›åº”ç”¨è´¨é‡ã€‚\n",
    "\n",
    "**â†’ æƒ³æ·±å…¥äº†è§£ï¼Ÿè¯·å‚é˜… [Langfuse è‡ªå®šä¹‰è¯„åˆ†æŒ‡å—](https://langfuse.com/docs/scores/custom)ã€‚**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgAqYnQuGwCL",
    "outputId": "11e14766-b25b-44b4-c3d4-d980f3d111cc"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿”å›çš„ span å¯¹è±¡è¿›è¡Œè¯„åˆ†\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"langgraph-request\") as span:\n",
    "    # ... æ­¤å¤„æ‰§è¡Œ LangGraph é€»è¾‘ ...\n",
    "\n",
    "    # ç›´æ¥é€šè¿‡ span.score_trace è®°å½•è¯„åˆ†\n",
    "    span.score_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\",\n",
    "        comment=\"This was correct, thank you\"\n",
    "    )\n",
    "\n",
    "# æ–¹æ¡ˆäºŒï¼šåœ¨ä»ä½äºä¸Šä¸‹æ–‡æ—¶è°ƒç”¨ score_current_trace()\n",
    "with langfuse.start_as_current_span(name=\"langgraph-request\") as span:\n",
    "    # ... LangGraph execution ...\n",
    "\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\"\n",
    "    )\n",
    "\n",
    "# æ–¹æ¡ˆä¸‰ï¼šè‹¥å·²ç¦»å¼€ä¸Šä¸‹æ–‡ï¼Œå¯ä½¿ç”¨ trace_id ç›´æ¥åˆ›å»ºè¯„åˆ†\n",
    "langfuse.create_score(\n",
    "    trace_id=predefined_trace_id,\n",
    "    name=\"user-feedback\",\n",
    "    value=1,\n",
    "    data_type=\"NUMERIC\",\n",
    "    comment=\"This was correct, thank you\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq_DeCcXSxwq"
   },
   "source": [
    "### åœ¨ Langfuse ä¸­æŸ¥çœ‹å¸¦è¯„åˆ†çš„è¿½è¸ª\n",
    "\n",
    "ç¤ºä¾‹è¿½è¸ªï¼šhttps://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e60a078b828d4fdc7ea22c73193b0fe4\n",
    "\n",
    "![åŒ…å«è¯„åˆ†çš„è¿½è¸ªå±•ç¤º](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_score.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cIQVrYZJVMO"
   },
   "source": [
    "## ä½¿ç”¨ Langfuse ç®¡ç†æç¤ºè¯\n",
    "\n",
    "é€šè¿‡ [Langfuse Prompt Management](https://langfuse.com/docs/prompts/example-langchain) å¯ä»¥å¯¹æç¤ºè¯è¿›è¡Œç»Ÿä¸€çš„ç‰ˆæœ¬ç®¡ç†ã€‚åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æ¼”ç¤ºå¦‚ä½•é€šè¿‡ SDK æ–°å¢ä¸€æ¡æç¤ºè¯ï¼›åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ›´æ¨èç›´æ¥åœ¨ Langfuse UI ä¸­åˆ›å»ºå’Œå‘å¸ƒã€‚\n",
    "\n",
    "Langfuse çš„æç¤ºè¯ç®¡ç†ç›¸å½“äºä¸€ä¸ªâ€œæç¤ºè¯å†…å®¹ç®¡ç†ç³»ç»Ÿï¼ˆPrompt CMSï¼‰â€ã€‚ä½ å¯ä»¥åœ¨ UI ä¸­ç¼–è¾‘ã€é¢„è§ˆä¸å‘å¸ƒï¼›ä¹Ÿå¯åœ¨ä»£ç ä¸­é€šè¿‡ SDK è¯»å–æˆ–æ›´æ–°ã€‚\n",
    "\n",
    "é…ç½®æç¤ºè¯æ—¶é€šå¸¸éœ€è¦æŒ‡å®šï¼š\n",
    "\n",
    "* `name`ï¼šåœ¨ Langfuse ä¸­å”¯ä¸€æ ‡è¯†è¯¥æç¤ºè¯çš„åç§°\n",
    "* `prompt`ï¼šåŒ…å«æ¨¡æ¿å ä½ç¬¦ï¼ˆå¦‚ `{{input variables}}`ï¼‰çš„æ–‡æœ¬å†…å®¹\n",
    "* `labels`ï¼šå¯è®¾ç½®ä¸º `production`ï¼Œè®©è¯¥ç‰ˆæœ¬ç«‹å³æˆä¸ºé»˜è®¤é€‰é¡¹\n",
    "\n",
    "åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç³»ç»Ÿæç¤ºè¯ï¼Œè®©åŠ©æ‰‹å°†æ‰€æœ‰ç”¨æˆ·è¾“å…¥ç¿»è¯‘æˆè¥¿ç­ç‰™è¯­ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0J8-nbhUUz6",
    "outputId": "ee71e43d-9f77-451d-b71c-f77cd297b065"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    "\n",
    "langfuse.create_prompt(\n",
    "    name=\"translator_system-prompt\",\n",
    "    prompt=\"You are a translator that translates every input text into Spanish.\",\n",
    "    labels=[\"production\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dullp4XDXhzg"
   },
   "source": [
    "![åœ¨ Langfuse UI ä¸­æŸ¥çœ‹æç¤ºè¯](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_prompt_example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNboOjf2YQpD"
   },
   "source": [
    "ä½¿ç”¨å·¥å…·æ–¹æ³• `.get_langchain_prompt()` å¯ä»¥å°† Langfuse ä¸­çš„æç¤ºè¯è½¬æ¢ä¸º LangChain å¯ç›´æ¥ä½¿ç”¨çš„å­—ç¬¦ä¸²ã€‚\n",
    "\n",
    "**èƒŒæ™¯è¯´æ˜ï¼š** Langfuse åœ¨æç¤ºæ¨¡æ¿ä¸­ä½¿ç”¨åŒèŠ±æ‹¬å·ï¼ˆ`{{input variable}}`ï¼‰å£°æ˜å˜é‡ï¼›è€Œ LangChain çš„ `PromptTemplate` ä½¿ç”¨å•èŠ±æ‹¬å·ï¼ˆ`{input variable}`ï¼‰ã€‚`.get_langchain_prompt()` ä¼šè‡ªåŠ¨å®Œæˆæ ¼å¼è½¬æ¢ã€‚å½“å‰ç¤ºä¾‹çš„æç¤ºè¯æ²¡æœ‰å ä½å˜é‡ï¼Œä½†ä»å¯ä»¥ç»Ÿä¸€é€šè¿‡è¯¥æ–¹æ³•å¤„ç†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z49I82blYeXy",
    "outputId": "6cf7cd23-6dde-4e7b-ae50-e369db37c2d0"
   },
   "outputs": [],
   "source": [
    "# è¯»å–ç”Ÿäº§ç¯å¢ƒä¸­æœ€æ–°çš„æç¤ºè¯ç‰ˆæœ¬ï¼Œå¹¶è½¬æ¢ä¸º LangChain å¯ç›´æ¥ä½¿ç”¨çš„å­—ç¬¦ä¸²\n",
    "langfuse_system_prompt = langfuse.get_prompt(\"translator_system-prompt\")\n",
    "langchain_system_prompt = langfuse_system_prompt.get_langchain_prompt()\n",
    "\n",
    "print(langchain_system_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3zBULfCt0Wq"
   },
   "source": [
    "ç°åœ¨å¯ä»¥ä½¿ç”¨æ–°çš„ç³»ç»Ÿæç¤ºè¯å­—ç¬¦ä¸²ï¼Œæ›´æ–°æˆ‘ä»¬çš„ç¿»è¯‘åŠ©æ‰‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oGQhulyMmvZD"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# ğŸ§© å°†ç³»ç»Ÿæç¤ºè¯æ³¨å…¥åˆ°èŠå¤©èŠ‚ç‚¹ï¼Œç¡®ä¿åŠ©æ‰‹å…ˆéµå¾ªç¿»è¯‘æŒ‡ä»¤\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": langchain_system_prompt\n",
    "}\n",
    "\n",
    "def chatbot(state: State):\n",
    "    messages_with_system_prompt = [system_prompt] + state[\"messages\"]\n",
    "    response = llm.invoke(messages_with_system_prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYd7wbttm2ec",
    "outputId": "fdc18797-3b3b-4cae-9ebb-8b9d946494c1"
   },
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ“¡ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨ï¼ˆç”¨äºè¿½è¸ªç¿»è¯‘åŠ©æ‰‹çš„è°ƒç”¨ï¼‰\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ğŸ”— å°†å›è°ƒæŒ‚è½½åˆ°å›¾çš„ stream æ–¹æ³•ä¸­ï¼Œå®æ—¶æŸ¥çœ‹ç¿»è¯‘ç»“æœä¸è¿½è¸ªè®°å½•\n",
    "for s in graph.stream({\"messages\": [HumanMessage(content=\"è¯·æŠŠâ€œLangfuse æ˜¯ä»€ä¹ˆï¼Ÿâ€ç¿»è¯‘æˆè¥¿ç­ç‰™è¯­ã€‚\")]},\n",
    "                      config={\"callbacks\": [langfuse_handler]}):\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨ LangGraph è¿½è¸ªä¸­æ·»åŠ è‡ªå®šä¹‰ Span\n",
    "\n",
    "æŸäº›åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è¿½è¸ªä¸­æ’å…¥è‡ªå®šä¹‰ spanï¼Œä»¥æ ‡è®°å…³é”®æ­¥éª¤æˆ–é™„åŠ é¢å¤–ä¸Šä¸‹æ–‡ã€‚å¯ä»¥å‚è€ƒè¿™ä¸ª [GitHub è®¨è®ºè´´](https://github.com/orgs/langfuse/discussions/2988#discussioncomment-11634600) ä¸­ç»™å‡ºçš„ç¤ºä¾‹å®ç°æ–¹å¼ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}