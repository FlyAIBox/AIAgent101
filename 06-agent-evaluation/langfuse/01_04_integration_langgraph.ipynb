{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/01_04_integration_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlCI9KeX4Zn4"
      },
      "source": [
        "## 什么是 LangGraph？\n",
        "\n",
        "[LangGraph](https://langchain-ai.github.io/langgraph/) 是由 LangChain 团队开源的框架，用于基于大语言模型（LLM）构建复杂、有状态的多智能体应用。LangGraph 内置了持久化能力，可保存与恢复状态，从而支持错误恢复与包含“人机交互”（Human-in-the-loop, HITL）的工作流。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o8L1qPcaZeC"
      },
      "source": [
        "## 本实践手册的目标\n",
        "\n",
        "本手册演示如何借助 [Langfuse](https://langfuse.com/docs)，通过其与 [LangChain 的集成](https://langfuse.com/integrations/frameworks/langchain)，对你的 LangGraph 应用进行调试、分析与迭代优化。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPTaMtxH4eHV"
      },
      "source": [
        "**完成本手册后，你将能够：**\n",
        "\n",
        "- 自动通过 Langfuse 集成对 LangGraph 应用进行追踪（tracing）\n",
        "- 监控复杂的多智能体（multi-agent）方案\n",
        "- 添加评分（例如用户反馈）\n",
        "- 使用 Langfuse 管理 LangGraph 中使用的提示词（prompt）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sSIS88y9Ewm"
      },
      "source": [
        "## 初始化 Langfuse\n",
        "\n",
        "在 Langfuse 控制台项目设置页获取你的 [API 密钥](https://langfuse.com/faq/all/where-are-langfuse-api-keys)，并将其加入到运行环境变量中以初始化 Langfuse 客户端。\n",
        "\n",
        "<!-- CALLOUT_START type: \"info\" emoji: \"⚠️\" -->\n",
        "_**注意：** 本笔记使用 Langfuse Python SDK v3。_\n",
        "<!-- CALLOUT_END -->\n",
        "\n",
        "<!-- CALLOUT_START type: \"info\" emoji: \"ℹ️\" -->\n",
        "_**注意：** 需要至少 Python 3.11（参见 [GitHub Issue](https://github.com/langfuse/langfuse/issues/1926)）。_\n",
        "<!-- CALLOUT_END -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C85BK1vJ5yD3",
        "outputId": "0179bb37-1c92-4192-fceb-09898a340e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse==3.3.0\n",
            "  Downloading langfuse-3.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai==0.3.31\n",
            "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_community==0.3.27\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.2.1)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.5)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.0.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (1.1.0)\n",
            "Downloading langfuse-3.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai, langfuse, langchain_community\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 0.3.33\n",
            "    Uninstalling langchain-openai-0.3.33:\n",
            "      Successfully uninstalled langchain-openai-0.3.33\n",
            "  Attempting uninstall: langfuse\n",
            "    Found existing installation: langfuse 3.5.0\n",
            "    Uninstalling langfuse-3.5.0:\n",
            "      Successfully uninstalled langfuse-3.5.0\n",
            "  Attempting uninstall: langchain_community\n",
            "    Found existing installation: langchain-community 0.3.29\n",
            "    Uninstalling langchain-community-0.3.29:\n",
            "      Successfully uninstalled langchain-community-0.3.29\n",
            "Successfully installed langchain-openai-0.3.31 langchain_community-0.3.27 langfuse-3.3.0\n"
          ]
        }
      ],
      "source": [
        "# %pip install langfuse langchain  langchain_openai langchain_community\n",
        "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langchain_community==0.3.27 langgraph==0.6.7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 Langfuse 控制台的项目设置页获取 API Key，初始化 Langfuse 客户端，并将其设置到环境变量中。"
      ],
      "metadata": {
        "id": "sUbRmJ-Kh0rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔐 环境变量配置 - 安全存储敏感信息\n",
        "# 环境变量是存储API密钥等敏感信息的最佳实践\n",
        "# 避免在代码中硬编码密钥，防止泄露\n",
        "\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    安全地设置环境变量\n",
        "    如果环境变量不存在，会提示用户输入\n",
        "    使用getpass模块隐藏输入内容，防止密码泄露\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "# 🤖 OpenAI API 配置\n",
        "# OpenAI API密钥：从 https://platform.openai.com/api-keys 获取\n",
        "# 这是调用GPT模型必需的认证信息\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "\n",
        "# API代理地址：如果你使用第三方代理服务（如国内代理）\n",
        "# 示例：https://api.apiyi.com/v1\n",
        "# 如果直接使用OpenAI官方API，可以留空\n",
        "_set_env(\"OPENAI_BASE_URL\")\n",
        "\n",
        "# 🌐 Langfuse 配置\n",
        "# Langfuse是一个可观测性平台，需要注册账户获取密钥\n",
        "# 注册地址：https://cloud.langfuse.com\n",
        "\n",
        "# 公开密钥：用于标识你的项目\n",
        "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
        "\n",
        "# 秘密密钥：用于认证，请妥善保管\n",
        "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
        "\n",
        "# 服务器地址：选择离你最近的区域\n",
        "# 🇪🇺 欧盟区域(推荐) https://cloud.langfuse.com\n",
        "# 🇺🇸 美国区域（不推荐） https://us.cloud.langfuse.com\n",
        "_set_env(\"LANGFUSE_HOST\")\n",
        "\n",
        "# 💡 初学者提示：\n",
        "# 1. 环境变量存储在操作系统中，重启后需要重新设置\n",
        "# 2. 生产环境中建议使用.env文件或云服务配置\n",
        "# 3. 永远不要在代码中硬编码API密钥！\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vku6l5CLhwdC",
        "outputId": "30f2da6f-df05-4041-c81c-3bf4eeb3e473"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n",
            "OPENAI_BASE_URL: ··········\n",
            "LANGFUSE_PUBLIC_KEY: ··········\n",
            "LANGFUSE_SECRET_KEY: ··········\n",
            "LANGFUSE_HOST: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agy0r3Byg-Aw"
      },
      "source": [
        "在环境变量设置完成后，我们即可初始化 Langfuse 客户端。`get_client()` 会使用环境变量中提供的凭据来初始化 Langfuse 客户端。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVLs2A8g-Ax",
        "outputId": "3cdf5ed9-99eb-4e6d-ec67-69f119356e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Langfuse 客户端已通过身份验证，准备就绪！\n",
            "🔧 现在可以开始使用追踪功能了\n"
          ]
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "# 🚀 初始化 Langfuse 客户端\n",
        "# get_client() 会自动读取环境变量中的配置信息\n",
        "langfuse = get_client()\n",
        "\n",
        "# 🔍 验证客户端连接状态\n",
        "# 这个步骤非常重要，确保后续的追踪功能能够正常工作\n",
        "if langfuse.auth_check():\n",
        "    print(\"✅ Langfuse 客户端已通过身份验证，准备就绪！\")\n",
        "    print(\"🔧 现在可以开始使用追踪功能了\")\n",
        "else:\n",
        "    print(\"❌ 身份验证失败！\")\n",
        "    print(\"🔍 请检查以下配置项：\")\n",
        "    print(\"   - LANGFUSE_PUBLIC_KEY 是否正确\")\n",
        "    print(\"   - LANGFUSE_SECRET_KEY 是否正确\")\n",
        "    print(\"   - LANGFUSE_HOST 是否可访问\")\n",
        "    print(\"   - 网络连接是否正常\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqYMmi6n9Nh1"
      },
      "source": [
        "## 示例 1：使用 LangGraph 构建简单聊天应用\n",
        "\n",
        "**本节将完成：**\n",
        "\n",
        "- 在 LangGraph 中构建一个可回答常见问题的客服聊天机器人\n",
        "- 使用 Langfuse 对机器人的输入与输出进行追踪（tracing）\n",
        "\n",
        "我们先从一个基础机器人入手，随后在下一节扩展为更高级的多智能体（multi-agent）设置，并在过程中介绍关键的 LangGraph 概念。\n",
        "\n",
        "### 创建智能体（Agent）\n",
        "\n",
        "首先创建一个 `StateGraph`。`StateGraph` 定义了聊天机器人的状态机结构。我们会添加节点来表示 LLM 以及机器人可调用的函数，并通过边（edge）定义机器人在这些函数之间的状态流转。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aGIxgPww6VX6"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入 LangGraph 构建智能体所需的核心模块\n",
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI  # OpenAI 聊天模型\n",
        "from langchain_core.messages import HumanMessage  # 人类消息类型\n",
        "from typing_extensions import TypedDict  # 类型化字典\n",
        "from langgraph.graph import StateGraph  # LangGraph 状态图\n",
        "from langgraph.graph.message import add_messages  # 消息添加函数\n",
        "\n",
        "# 📋 定义智能体的状态结构\n",
        "# State 是一个类型化字典，定义了智能体在执行过程中需要维护的状态信息\n",
        "class State(TypedDict):\n",
        "    # 💬 消息列表：存储对话历史\n",
        "    # Annotated[list, add_messages] 的含义：\n",
        "    # - list: 消息的数据类型是列表\n",
        "    # - add_messages: 指定状态更新策略，新消息会追加到列表末尾而不是覆盖整个列表\n",
        "    # 这种设计确保了对话历史的完整保存\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# 🏗️ 创建状态图构建器\n",
        "# StateGraph 是 LangGraph 的核心组件，用于定义智能体的工作流程\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# 🤖 初始化语言模型\n",
        "# 选择 GPT-4o 模型，temperature=0.2 确保输出相对稳定但仍有一定创造性\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# 🔄 定义聊天机器人节点函数\n",
        "# 这是 LangGraph 节点函数的基本模式：接收当前状态，返回更新后的状态\n",
        "def chatbot(state: State):\n",
        "    \"\"\"\n",
        "    聊天机器人节点的核心逻辑\n",
        "\n",
        "    参数:\n",
        "        state (State): 当前的智能体状态，包含消息历史\n",
        "\n",
        "    返回:\n",
        "        dict: 包含新生成消息的状态更新\n",
        "\n",
        "    工作流程:\n",
        "    1. 获取当前的消息历史\n",
        "    2. 将消息历史发送给语言模型\n",
        "    3. 接收模型生成的回复\n",
        "    4. 将回复包装成状态更新返回\n",
        "    \"\"\"\n",
        "    # 调用语言模型处理当前对话历史，生成回复\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "\n",
        "    # 返回状态更新：将模型的回复添加到消息列表中\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# 🔗 向图中添加\"chatbot\"节点\n",
        "# 节点代表工作单元，通常是普通的 Python 函数\n",
        "# 每个节点负责特定的处理逻辑，如调用 LLM、处理工具、数据转换等\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# 🚀 设置图的入口点\n",
        "# 告诉图每次运行时从哪个节点开始执行\n",
        "# 在这个简单示例中，我们直接从 chatbot 节点开始\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "\n",
        "# 🏁 设置图的结束点\n",
        "# 指示图\"当这个节点运行完成后，可以退出执行\"\n",
        "# 对于简单的单轮对话，chatbot 节点执行完就可以结束\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "\n",
        "# ⚙️ 编译图形为可执行对象\n",
        "# compile() 方法将图构建器转换为 CompiledGraph\n",
        "# CompiledGraph 是可以实际运行的图形对象，支持 invoke、stream 等方法\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# 💡 理解 LangGraph 的核心概念：\n",
        "# 🏗️ StateGraph: 定义智能体的状态和工作流程\n",
        "# 🔄 Node: 执行具体任务的函数，如调用 LLM、使用工具等\n",
        "# 🔗 Edge: 连接节点，定义执行顺序和条件跳转\n",
        "# 📊 State: 智能体运行过程中维护的数据结构\n",
        "# ⚙️ CompiledGraph: 编译后的可执行图形对象"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW2SJcRgh7Xo"
      },
      "source": [
        "### 在调用时添加 Langfuse 回调\n",
        "\n",
        "现在，为了追踪应用执行过程，我们将添加 [面向 LangChain 的 Langfuse 回调处理器](https://langfuse.com/integrations/frameworks/langchain)：`config={\"callbacks\": [langfuse_handler]}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PxEc455-KYM",
        "outputId": "5fc8bb3d-0840-45ce-bdd9-916a54d91085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 智能体开始运行，正在处理问题……\n",
            "❓ 用户提问：什么是 Langfuse？\n",
            "📋 执行过程:\n",
            "📤 节点执行结果：{'chatbot': {'messages': [AIMessage(content='Langfuse 是一个专门用于监控和调试生成式 AI 应用程序的工具。它提供了一系列功能，帮助开发者和企业更好地理解和优化他们的 AI 模型和应用程序。以下是 Langfuse 的主要功能和典型应用场景：\\n\\n### 主要功能\\n\\n1. **请求跟踪和监控**：\\n   - Langfuse 可以实时跟踪和记录生成式 AI 应用程序的请求和响应。这包括输入数据、输出结果以及相关的元数据。\\n   - 提供详细的日志记录功能，帮助开发者识别和解决潜在的问题。\\n\\n2. **性能分析**：\\n   - 提供性能指标和分析工具，帮助用户了解模型的响应时间、准确性和资源使用情况。\\n   - 可以生成报告，帮助团队优化模型性能。\\n\\n3. **错误检测和调试**：\\n   - 自动检测异常和错误，提供详细的错误报告和调试信息。\\n   - 支持设置警报和通知，以便及时处理问题。\\n\\n4. **用户行为分析**：\\n   - 分析用户与生成式 AI 应用的交互行为，帮助优化用户体验。\\n   - 提供用户反馈收集功能，以便持续改进应用程序。\\n\\n5. **集成和扩展性**：\\n   - 支持与各种 AI 平台和工具集成，如 OpenAI、Hugging Face 等。\\n   - 提供 API 和 SDK，方便开发者将 Langfuse 集成到现有系统中。\\n\\n### 典型应用场景\\n\\n1. **生成式对话系统**：\\n   - 用于监控和优化聊天机器人或虚拟助手的性能和用户交互。\\n   - 帮助识别对话中的常见问题和用户反馈，以改进对话质量。\\n\\n2. **内容生成平台**：\\n   - 在自动化内容生成应用中使用 Langfuse 来确保生成内容的质量和一致性。\\n   - 分析生成内容的风格和主题，以满足用户需求。\\n\\n3. **推荐系统**：\\n   - 监控推荐算法的效果和用户满意度。\\n   - 通过行为分析优化推荐策略，提高用户参与度。\\n\\n4. **AI 驱动的产品开发**：\\n   - 在开发过程中使用 Langfuse 进行持续监控和调试，确保产品的稳定性和性能。\\n   - 收集用户反馈和使用数据，指导产品迭代和改进。\\n\\nLangfuse 的功能使其成为生成式 AI 应用开发和维护的重要工具，帮助团队提高效率、降低错误率，并增强用户体验。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 558, 'prompt_tokens': 26, 'total_tokens': 584, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-CIRpBh8jwlff10swx7tT27M4l486M', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--ae3361c2-75be-48b2-a21a-7ed72d9890be-0', usage_metadata={'input_tokens': 26, 'output_tokens': 558, 'total_tokens': 584, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "✅ 智能体执行完成！\n",
            "🔍 请前往 Langfuse 控制台查看完整的追踪记录。\n"
          ]
        }
      ],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 🛎️ 初始化 Langfuse 回调处理器\n",
        "# 该处理器会自动捕获 LangChain/LangGraph 的执行细节，用于：\n",
        "# - 🕒 记录每个节点的耗时与延迟\n",
        "# - 📝 保存输入、输出及中间状态\n",
        "# - 💰 统计 token 消耗和 API 调用成本\n",
        "# - 🐞 收集异常信息，便于排错\n",
        "# - 📈 在 Langfuse 中生成可视化调用链\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# 🚀 运行智能体并启用 Langfuse 追踪\n",
        "print(\"🤖 智能体开始运行，正在处理问题……\")\n",
        "print(\"❓ 用户提问：什么是 Langfuse？\")\n",
        "print(\"📋 执行过程:\")\n",
        "\n",
        "# 使用 stream 方法可以实时查看智能体的执行步骤\n",
        "for step_result in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"什么是 Langfuse？请详细介绍其主要功能和典型应用场景。\")]},\n",
        "    config={\"callbacks\": [langfuse_handler]}\n",
        "):\n",
        "    print(f\"📤 节点执行结果：{step_result}\")\n",
        "\n",
        "print(\n",
        "\"✅ 智能体执行完成！\")\n",
        "print(\"🔍 请前往 Langfuse 控制台查看完整的追踪记录。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdf3ZRnWGZ0N"
      },
      "source": [
        "### 在 Langfuse 中查看追踪结果\n",
        "\n",
        "示例追踪：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=cbc8503a9a111fc5eadb5e914be3fa7a&timestamp=2025-09-22T03%3A48%3A16.647Z&observation=47245ec86916a5d1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Aq7u6_LBR6"
      },
      "source": [
        "![在 Langfuse 中查看聊天应用的追踪](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509221150147.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3yyVtGKhMPU"
      },
      "source": [
        "### 可视化聊天应用\n",
        "\n",
        "你可以使用 `get_graph` 方法配合相应的 “draw” 方法对图进行可视化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "MKkM6mw47kIy",
        "outputId": "03518604-0387-4c76-d1d4-74dab18eb0be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAAAXNSR0IArs4c6QAAFo5JREFUeJztnXl8E2XewJ/JJGnOJm2a0jP0skBLwZIeHFY5yuECIsdyo+y+vCyg+KKrLOiKCop8VhDUVY5FXF63iCvLWZCir7CUu0BbhNKW3vRu0ua+Zibz/hG3djHJpH2SNu0+37+aeWYmv3z7zMwzzzPz/DCapgGip7D6OoD+DdIHBdIHBdIHBdIHBdIHBRty++Yai1FHWYyUxURRRP9oA+EcjCfAeUJcJMEHDebB7ArrWbuv+q6x6q6x8o5BLGUHBnN4QpwnZHG4/aMuEza7xWg3GymdmjBqyfiRorjhwphkYQ921W19rQ+tF75pJaz2IWmBCY+LpHJOD77Vf9C0EQ8K9WU39QF81vhfh8qjArq1eTf0UQR98Whbbakpc1rwsMzAHkXrv9y7qrtxVh2XInpqntzzrTzVZzZQp/Y1DhrMe2puN/bev6AI+uKxNlWDdcZ/R/BFuCebeKRP3WQ7uafh8fFBqROk3ojTr7n1fcedS9pZqyKCw7iMKzPrM2rJw9sfZs0OSRwl9l6Qfk3ZTf2VXNX8VxTCQIY6yHCtJG32k3sbR2RJ/nPcAQCGpImTx0hO7WugSIa6xaDv+tl2qZyTPiXYq+H1AzKmBouk7Bt57e5Xc6dPqyJKC/TZS8K8HVv/YMrSsPs3dPoO0s067vRdOq5KnxLM4WI+iK0fwOWxRk0Iyj/e5mYdl/q0KkLVZE0ZJ/FNbP2DEVnSllqrmwroUt+DQkPKOAnWP27DfAULBynjJA8K9S5XcFVQUawfPKwnt4EwjB8/vrm5ubtbHT58ePPmzb6JCAweJqgoMrgqda7PoCHNekoWztxu9CL19fUGg8tA3VBSUuKDcH5CHhWgayddHb/OO6yaaizdvXn2HJqmc3Jyzpw5U1tbGx8fP3r06FWrVt26dWv16tUAgBkzZowfP3779u0VFRVHjhwpKChobm6Oj4+fO3furFmzAADl5eWLFy/+6KOP3nnnndDQUD6fX1hYCAA4efLkoUOHEhMTvR5waFRA60OrOMiJK+f6rEaKL4btCnRFTk7OwYMHly9fHh8f39jY+Omnn0okkiVLluzcufPll1/Ozc0NCwsDAOzYsaOlpWXjxo0YhlVWVm7ZskWhUKSmpnK5XADA/v37f/Ob34wcOTIpKem5555LSEjYtGmTjwLmi3GriXJa5EKf2S7w7J65BxQVFQ0fPnzJkiWOj2lpaTab7Zerbdu2zWQyhYeHO9Y5duzY5cuXU1NTHaVjx45dtGiRjyJ8BL4It5rtTouc67PbaZzjq+ZeSkrK7t27t2zZolQqs7KyFAqFixjsOTk5V65cqaurcyxJSkrqLB02bJiPwvslHC7L1d2bc318Ia5qclIjvMLSpUvFYvH58+c3bdrEZrOffvrpl156KSgoqOs6FEWtXbuWpum1a9dmZGQIhcKlS5c6ijAMAwDweFCd7N3CpCdDo51/nXN9AjHbVG7yUTQ4js+ZM2fOnDmVlZU3btzYu3evxWJ5//33u65TUlJSWlq6d+9epVLpWNJ5Ue79p0pMOkogdn4qc1H7xLhZ7/xkCU9ubm5ycnJsbGx8fHx8fLxarf7+++87q5UDvV4PAJDLf+qaLSsrq6+v7zzxPULXDX2BUU8KAp2Lct7uk0cGqBqsdson/+fc3Nz169fn5+frdLr8/PyLFy+OGDECABAVFQUAOHfu3L179+Li4jAMy8nJMRgMVVVVH330UWZmZlNTk9MdRkZG3r179+bNmx0dHV6PliRoTSvhsglMu+DE7obKOwZXpTA0NTW98sorSqVSqVROnTp13759ZrPZUfTGG29kZmauWrWKpumzZ8/OmzdPqVTOmTOnpKTku+++UyqVixYtqq6uViqVBQUFnTssKCiYPXt2RkbGjRs3vB5tRZH+1L4GV6Uue5vvXtY2VlmmLBvk9f9n/yLvf5ujEwVJo50Pjbm8501Uih+Wm9z3dg149B1k/QPzY6572t2NdRRf1DRWWZ5e7ry7tKGhobPp+wgsFstud97OnD9//po1azyIvCesW7euqKjIaZFUKtVoNE6L3nvvvXHjxjktOnOgKeoxwYgsl7127vTZKfC3rTXjZsnjRzjperHb7Uaj0emGFovFVbuMw+H4rslmMpkoynmDgSAIDsf5iD6fz2eznVxYy2/pr55RP/dGjLteO/cnztaHln2vV7Y327x+SvZzVI3Wfa9Xtj60uF+NoTtUHhUwZWnY6c8bbRbnB+OAxGaxn97f+PTycMZuJ4+Gyctu6YsuaGasiBBKfNWP4D8YNOTpz5tSJ0g9GZv19CGNhkrz+a9bpywNC1X4qh/QH2its+Z92Zy9eFB4rEcn6G48IqRrJ0/ta4hNFmVMDWYPuOE3wkZf/1b9sMw0fUVEYLCnfZ3de0CNIuiS67qyW/rhYyXxI0ScgIEgkbDaK4oN967qkjIDXTWPXdHDxyOr7hqrfzQaNIQsPEAkZfOEOE+I95cRYcJGW4yUxUgZNKSqySoO4sSlCGN75/HIR2iqtrQ327QqQtNms5i8fHVWq9UAAJlM5t3d8oQsaQhXIufIwrhhMX3xcG7vsHfvXgzDVq5c2deBuOQ/exgcGqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCn98LWb69OkURdE0bTabAQBCoZCiKA6Hc/r06b4O7VF8NU0aDOHh4YWFhZ2T2zhesU9LS+vruJzgjwfvwoULpdJ/m55cJpN1zmHlV/ijvuzs7ISEhK5LYmJinnrqqb6LyCX+qM8xX4lE8tP0H1KpdPHixX0dkXP8VN+kSZNiYmIcfw8ePHjixIl9HZFz/FQfAGDBggVCoVAoFC5YsKCvY3FJt6+86iabxeiruem6khyXNSxmHI7jyXFZDRXmXvhGnhDv7mTBnrb7KIK+fEpdUWwQiHE2x3/rLAwkYTfryYRUcdazIR5u4pE+o446+nF99FCRcrKX34v3QwryVE0VxmdfjGJM1uGpvmOfNcjCeakTB747B7f/T61ptc5aFcG4JvNhWFdqMrST/znuAACjJsm0KqL+AfMJl1lfU41FkSTyUmD9hsHDRE3VFsbVmPVpVYQkpFcnr/cHJCFcTRvz1MvM+mga9I/ZbbwLBoAHs9IMzCZIr4H0QYH0QYH0QYH0QYH0QYH0QYH0QYH0QYH0QYH0QdF7+urqaiZMSissugmzk2dmTcg59IX3goKlH9S+mbPGt7R0O/NiVza99VpeXq73IvoZf9fX0NjDzItdKX9w30vhPIpPnnHR6rS7d+/MO5crkUjT0kav/t06mSyExWI5Moht+9PbeXm5ISHyp57MfvGF3zs2uXLl4g/n8+78WGgw6Icnj1y2dEVKyuO3Cwt+/+pqAMDCxTOeGDd+y+btGIuFYdiRfxzKy8ttam5ITxuzbt1GSaDE8SjMjg/fLb5zW6/XxQyOmz599jMz59I0PTE7HQCw7U9vF9y69sfX3/XuL/V+7SMIYsPGlwxG/Yc79qx98bXGxvoNG1/qTKPx14N705SjP9yxZ+6cRf84+tWlSxcc+T22bnuToqiNGza/9+5OuXzQ62+s0+l1o1LTt767EwBw+FDuls3bHekxTp46YjAY1qx55fUNW24UXPls94eOPa/f8GJrW8vW93b9/fCZMWOe3Lnr/YqKcgzDvj19CQCwYf3bXnfnk9p37fql0tJ7f/vyeGREFAAgPCzi2Im/azQ/5bAalZqePWkaACD18bQj/zhUVHzriSfG83i8v+z7SsAXSCRSAEBcbMKZb0+UlZWkp41+dO80LRSKlj//00zO0381+/iJv69/ddP165fv3btz8IsjCkUMAGD58yuvX7+Uc+jAW5u2ef0HdsX7+iorH4iEIoc7AEBSUkpSUgoAoL6+DgCQkvJzrjWhUESShONvk9G4f/+fi+/cVqtVjiXt//rj38CwjPSxnZ+SklK+OZKj0XTU1Fbx+XyHOwdDhiRdu37J67/uEbx/8BoM+gBn6XQc2Yu6prXBsJ+GSZubm/7n5RV2u/3NN7Z+l3ft9KmLLvdO0wLBz5PL8/kCAIBWq1G3q7oudxSZTL5KdNiJ92ufQCAwm7sX9w/n8yiK+sP6tx1pjNRO650DDLNYfh4/NJmMAACxOJDP4zv+7sRsNslknj4s0GO8X/uGDR1uMpnKH5Q6PtbUVK17ZWVdXY2bTYxGg0gk7kwBlX/ph86iRxIoYhhWUVHW+bG09B6PxwsOlg0dmmw2m6urKzuL7t+/GxsT772f5Rzv60tPHxMZGb1nz65Lly4U3Ly26+NtWq0mOnqwm01iYxNUqrbTZ46TJHnt2qWSkh9FIlFLazMAICIiCgBw/sK5+6X3HFfeisryo0cP2+32+6X3zn13esL4KTiOj858IiI88oMdW8rK77e3q/f95ZPyB6Xz5i1x5FKVyUJu3rpWVVXh9R/rfX1sNvuDP31KUuSbb726/g8vikWBW97Z7j4L56SJUxcvWv75gc8mTx194tSRtS++Nnny9C/+uueTT7crFDGTJk37/MBn+/f/GQBAELYF85cVFt2cNDnjtfVrRqWmr1q1zvGlWzbvEAqEq9c8t2TZrOI7t7e+uzNp2HDH/hcvXH79+uVDX3n/bo/5GZe8L1vCBgviRjLnPRpIVBbr22pNk5lyTPr7TZufg/RBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBgfRBwawPw4DfzXbQK2AeVC3mVaQhHH0H4Z2I+g/6dkIs4zCuxqwvJDKgudrnYy7+RlO1aVA0cxZ2Zn2Dhwoowl50od1LgfUDii+0Azsd40G+aI/eqNR3kMc/a5DIuWlTQsRBzFW6/6JTE7e+U+nUttkvRAolzMOQ3Xgd+kqu+n6Bji/E+aJemv3FTtMAAJbbcRIvYjaQZiOVlBE4ZroM53j0pd2eRUjVaLOaeuNlfADAqVOnAAAzZ87sna/rwcv43a5HIRG993YlJujAMCwygd9r39hdULMZCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCn/MTT5jxozGxkaapjunraNpOiIiwg9zk/tj7ZsxYwaO4ziOs/4Fm81+5pln+jouJ/ijvvnz50dFRXVdolAoFi5c2HcRucQf9QUHB0+bNq3zyMUwLDs7uzPXtl/hj/oAAPPmzYuOjnb8HRUVtWjRor6OyDl+qk8mk2VnZ2MYhmHYtGnTpFJpX0fkHD/V58hNrlAoIiMj/Tk3uRcaLkYtWVFs0KpJs56yGCmr1WstobbWNoABuVzurR0GBGA8IS4Q44EydsJIkSev27un5/oogr59XlNeqNepCWm4kB3Awbk4m4PjbP+t0RRpJwmKIijSRGhajIEy7rB00cgsqYev3v+SHuorv23IP9bGEXKDwgPFoYKefXefo2s1aZp0hNGWNVueOKonKZy7rc9qtuf+pVmrocISggVBTqb273cY280tFR2SYPyZleGcgO5Vw+7p07WTx/7cIJSLQ2L8sRUGQ1u1xtxhfHZ1RGBwN06I3dDXUmc5c6BFnigTBfnv3AwwGNSW1grVzBVh8ijm+YMceHqaN+mo0wdaIpJDB6o7AIBIxotIDs39vNmo83SmFY/0kQR97LOG0HhZgGiA53jnibjyeNmJPY0U6dFB6ZG+a2faBcEiUciArXddEcn4PIng+lmP5uxi1mfUUjUlpqDogXatcEOwQlp5x2TUkoxrMuv759E2SaSf3nL6DkmEJP+EmnE1Bn0Wo72+wiyW+2nDuEPT/OqbmSWl3s+IFRgqrC0xWowM1xAGfRXF+kA58zR2AxAMBA4SVt1lyO/IoO9BkVEY4qdVz9eIggUVRQzTZjK0sNseWuLHeq3D4xG0uraT3+6qffgjQViHPjZm8oQVIbIoAED+1a/P53/5u+WfHDy8obWtJjzssQlPLBs1cqpjq9t38vK+32uxGpOGZj2R+WvgmJ3WB/ClATU3XKc8A4Ch9pEETZK0j3pQKIrc88ULtQ9/nP/sH19d+xWfL/543287NM0AADaba7bojp/ZsWD2Hz/YfC15SNbXxzbrDe0AgKaWiq+OvJWZNmvDuiOpKVOOn/nQF7E5YHNxgnAk53OJOzVaFcEX+WqqzaqawjZV7aK5bycmZIhFwTOnrQvg8vOvfu0Y3CAI67RJqwZHp2AYpnz8aYoiGxrLAACXrn0THBQ58cnn+XxxYkJGxijfzozIE7C1KnezBrvTZ9CQ7ADcB1EBAEBN3R0uhxcfO8rxEcfxGMXImrpix6guAEARlewo4vFEAACL1QAAULfXDwqN7dxJVOQwAIDv5ubk8NkGjbvWn7tzH5uL+W4M3WI12gjLq29mdl0YJA0HAACa/mV+QIdTs1kvEgZ1LuSwAzqLfAFF0bjb+uNOn0CEU1bmlnfPEItkvADh8sUfdF3Ich8sADyeyEZYOj/aCPMvRXsR0koJAt3WMDdlfDHbZvHVLK/hYQkWqzFIGiYLjnQsUbXXB4oYknIGScPKK653Pr9RWn7Fp7WPMJMCsbv/qLtzH0/AYnNZhMUnFXBIQmZiQuY3J7ZqtC0GY0f+1a937X7+VvG37rcakTxJp1fl5n0CAHhQWXDt5nHgs4aLzURyeDiX504RQ7tPMVSgbzMFRwd6OzYAAFixbNfVgqNffv1G7cMfQ+UxmcpZY9Jnu98kaci4X0154VrBsX9ezgmShi+cs2n3gdV2u08OEb3KFDuc4Y6Lobe5sthw9aw2akSYt2PrB9QXN4+dIY1za5ChSRyVKNC2mm0mX11A/BabmdS1maMTGW5YGQ7eAD5riDKwuaojarjzWzeKIt/aNtVpEUna2DjXaassMjxx9W93u//qbvHme9m0i7QidjvFYjk5/Suiklc+/7GrHbZWtA9JD+RwGc6qzENFZgN1cEtNTFoEz0VPfXtHo9PlFovB0eL9JTjOkQR681baVQwAABth5XKcDP2w2dxAsfMLvUVvq73dtPytmAA+w9Hp0Uhb4YWO2+d1sekRLNx/nyDwFnbSXl3QmD5ZMiKLuZPYIx2PPymVR3Dq77b54ZO83oWm6Yd3WkIiOCnjPBqc8EgfxsJ+9dtwDk41lw3wpCdNpe1cLj39v8IxlkdtSU8PRjYHm70mApDWuqIWu2eDeP0LO0nXFbVgdtvsNZFsj58Y6t5DGhRJf/vX5pY6myI1jMPrpaQnvQBhIWtvN0fEBUxdNghnd+MepidPWN0813Hzh44QhSRYIWHhvZTKxUdQFN1eq1HX6dImB6VlB3mwxb/RwwfUOlqIwn9qqu8aBVIBXxogkvHZXF/1DPoC0kIZOswmrdXcYYpLEaaOl0rlPekYhnq6lCTomnum8iLjw/sGGmA8EYcr4LAD/PSgpmlA2UibibAYbRgNFEmix1KFCSOgxhG99laRQUNq2gitivBkcL5vwIAwkC0J4UjlHJHUO/9jf3wpqx8x8O8ifArSBwXSBwXSBwXSBwXSB8X/A86fhONOxhYmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY0HW5xISntw"
      },
      "source": [
        "```mermaid\n",
        "graph TD;\n",
        "\t__start__([__start__]):::first\n",
        "\tchatbot(chatbot)\n",
        "\t__end__([__end__]):::last\n",
        "\t__start__ --> chatbot;\n",
        "\tchatbot --> __end__;\n",
        "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
        "\tclassDef first fill-opacity:0\n",
        "\tclassDef last fill:#bfb6fc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F4Tt_E4g-A0"
      },
      "source": [
        "### 在 LangGraph Server 中使用 Langfuse\n",
        "\n",
        "#### 🖥️ LangGraph Server 简介\n",
        "\n",
        "[LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) 是 LangGraph 提供的服务器部署方案，用于将本地构建的图工作流发布为可扩展的在线服务，具备以下能力：\n",
        "\n",
        "- 🌐 **HTTP API 接口**：将 LangGraph 智能体封装为 REST API，便于与业务系统集成\n",
        "- 🚀 **生产级运行**：支持高并发、负载均衡与容器化交付\n",
        "- 🔧 **运维友好**：自动处理请求路由、状态恢复与错误重试\n",
        "- 📊 **监控集成**：兼容主流监控与追踪体系，便于观测运行状况\n",
        "- 🔒 **安全管控**：内置身份认证与授权机制，满足企业安全需求\n",
        "\n",
        "#### 💡 为什么要在 Server 环境接入 Langfuse？\n",
        "\n",
        "- 🏭 **生产可观测性**：实时查看线上请求的调用链与状态\n",
        "- 🐛 **远程调试**：无需复现场景即可还原问题细节\n",
        "- 📈 **性能洞察**：量化每个节点的耗时与成本\n",
        "- 💰 **费用治理**：准确统计第三方 API 的调用量与费用\n",
        "- 👥 **团队协作**：共享追踪记录，支持跨职能协同排查\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTW_X4rFg-A0"
      },
      "source": [
        "#### 🔧 配置方法说明\n",
        "\n",
        "使用 LangGraph Server 时，智能体图的调用由服务器自动处理，用户无法在每次请求时手动指定回调处理器。\n",
        "\n",
        "**关键差异：**\n",
        "- 🏠 **本地开发**：可以在每次调用时添加 `config={\"callbacks\": [langfuse_handler]}`\n",
        "- 🖥️ **服务器部署**：需要在图编译时预先配置回调处理器\n",
        "\n",
        "**解决方案：**\n",
        "在声明和编译图时就添加 Langfuse 回调，这样服务器上的所有请求都会自动启用追踪功能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J5UKXzbUg-A0"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入服务器部署所需的模块\n",
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 📋 定义与前文一致的智能体状态结构\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# 🏗️ 构建图形结构\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# 🤖 初始化语言模型\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# 🔄 定义聊天机器人节点\n",
        "def chatbot(state: State):\n",
        "    \"\"\"处理用户消息并生成回复。\"\"\"\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# 🔗 组装图形结构\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "\n",
        "# 🔄 初始化 Langfuse 回调处理器（服务器模式）\n",
        "# 在服务器环境中，此处理器会自动追踪所有请求的执行情况\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# ⚙️ 编译图形并预配置回调处理器\n",
        "# 🎯 核心方法：with_config()\n",
        "# - compile()：编译图形，生成可执行的 CompiledGraph\n",
        "# - with_config()：为编译后的图形设置默认配置（如回调处理器）\n",
        "#\n",
        "# 💡 工作流程：\n",
        "# 1. 编译图形得到 CompiledGraph 对象\n",
        "# 2. 调用 with_config() 注入 Langfuse 回调\n",
        "# 3. 返回一个已内置追踪能力的新图对象\n",
        "#\n",
        "# 🚀 优势：\n",
        "# - 无需在每次请求时手动添加回调配置\n",
        "# - 所有 API 请求都会自动写入 Langfuse 追踪\n",
        "# - 简化生产环境的部署与运维\n",
        "graph = graph_builder.compile().with_config({\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "# 💡 部署提示：\n",
        "# 在 LangGraph Server 中直接引用此 graph，即可立即获得完整的追踪数据\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2W94eY19TR1"
      },
      "source": [
        "## 示例 2：基于 LangGraph 的多智能体应用\n",
        "\n",
        "**本节将完成：**\n",
        "\n",
        "- 构建 2 个执行智能体：一个研究智能体使用 LangChain 的 WikipediaAPIWrapper 搜索维基百科，另一个使用自定义工具获取当前时间\n",
        "- 构建一个智能体监督者（supervisor），用于将用户问题分配给上述智能体\n",
        "- 添加 Langfuse 回调以追踪监督者与执行智能体的步骤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WfnrswDdjYTV",
        "outputId": "16e1273b-189b-4de2-89e5-b87ca0b83e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langfuse in /usr/local/lib/python3.12/dist-packages (3.3.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langfuse) (2.2.1)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse) (1.37.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse) (2.32.5)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse) (1.17.3)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_experimental) (0.3.27)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.16.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=6ec572a7ab1052346e4522f42f558d8c612784d5cc8796ae199d851a5ab8be2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia, langchain_experimental\n",
            "Successfully installed langchain_experimental-0.3.4 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse langgraph langchain langchain_openai langchain_experimental pandas wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tciUQ62IEVec"
      },
      "source": [
        "### 创建工具\n",
        "\n",
        "在本示例中，我们将构建一个用于维基百科检索的智能体，以及一个用于告知当前时间的智能体。先定义它们将使用的工具："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Cet0loyp9p-T"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入多智能体系统所需的工具和模块\n",
        "from typing import Annotated\n",
        "from langchain_community.tools import WikipediaQueryRun  # 维基百科查询工具\n",
        "from langchain_community.utilities import WikipediaAPIWrapper  # 维基百科 API 封装\n",
        "from datetime import datetime  # 时间处理模块\n",
        "from langchain.tools import Tool  # 通用工具定义类\n",
        "\n",
        "# 🔍 定义维基百科搜索工具\n",
        "# 功能：根据查询词在维基百科中搜索相关信息\n",
        "# 适用场景：回答百科知识、历史事件、人物传记等问题\n",
        "wikipedia_tool = WikipediaQueryRun(\n",
        "    api_wrapper=WikipediaAPIWrapper(\n",
        "        top_k_results=2,  # 返回最相关的2个搜索结果\n",
        "        doc_content_chars_max=1000  # 限制每个结果的字符数，避免信息过载\n",
        "    )\n",
        ")\n",
        "\n",
        "# ⏰ 定义当前时间查询工具\n",
        "# 功能：返回当前的日期和时间信息\n",
        "# 适用场景：回答\"现在几点\"、\"今天是什么日期\"等时间相关问题\n",
        "datetime_tool = Tool(\n",
        "    name=\"Datetime\",  # 工具名称，智能体会通过这个名称调用工具\n",
        "    func=lambda x: datetime.now().isoformat(),  # 工具函数：返回 ISO 格式的当前时间\n",
        "    description=\"返回当前的日期和时间信息（ISO 格式）\",  # 工具描述，帮助智能体理解何时使用此工具\n",
        ")\n",
        "\n",
        "# 💡 工具设计原则：\n",
        "# 1. 🎯 单一职责：每个工具只负责一个特定功能\n",
        "# 2. 📝 清晰描述：description 要准确描述工具的功能和使用场景\n",
        "# 3. 🔒 错误处理：生产环境中应该添加异常处理逻辑\n",
        "# 4. ⚡ 性能考虑：限制返回数据的大小，避免影响整体性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31uhDy_mEqr6"
      },
      "source": [
        "### 🛠️ 辅助工具函数\n",
        "\n",
        "#### 📝 功能说明\n",
        "下面定义的辅助函数用于简化添加新的智能体工作节点。这些函数封装了创建智能体和节点的通用逻辑，提高代码的可重用性和可维护性。\n",
        "\n",
        "#### 🎯 设计目标\n",
        "- **减少重复代码**：避免为每个智能体重复编写相同的初始化逻辑\n",
        "- **标准化接口**：确保所有智能体节点具有一致的输入输出格式\n",
        "- **简化扩展**：新增智能体时只需关注业务逻辑，无需处理框架细节"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "75atiExdqd4P"
      },
      "outputs": [],
      "source": [
        "# 🔧 导入智能体构建所需的核心组件\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent  # 智能体执行器和创建函数\n",
        "from langchain_core.messages import BaseMessage, HumanMessage  # 消息基类和人类消息\n",
        "from langchain_openai import ChatOpenAI  # OpenAI 聊天模型\n",
        "\n",
        "def create_agent(llm: ChatOpenAI, system_prompt: str, tools: list):\n",
        "    \"\"\"\n",
        "    🏭 智能体工厂函数：创建具有特定能力的工作智能体\n",
        "\n",
        "    参数:\n",
        "        llm (ChatOpenAI): 语言模型实例\n",
        "        system_prompt (str): 系统提示词，定义智能体的角色和行为规范\n",
        "        tools (list): 智能体可使用的工具列表\n",
        "\n",
        "    返回:\n",
        "        AgentExecutor: 配置完成的智能体执行器\n",
        "\n",
        "    🔄 工作流程:\n",
        "    1. 构建提示模板（包含系统角色、对话历史、工具使用记录）\n",
        "    2. 创建支持工具调用的 OpenAI 智能体\n",
        "    3. 包装为执行器，处理工具调用和状态管理\n",
        "    \"\"\"\n",
        "    # 📋 构建智能体的提示模板\n",
        "    # 包含三个关键部分：系统角色、对话历史、工具使用记录\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        # 🎭 系统消息：定义智能体的角色、能力和行为规范\n",
        "        (\"system\", system_prompt),\n",
        "        # 💬 消息历史：保存与用户和其他智能体的对话记录\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        # 🔧 工具记录：记录智能体使用工具的过程和结果\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "\n",
        "    # 🤖 创建支持 OpenAI 工具调用的智能体\n",
        "    # 这个智能体能够理解何时需要使用工具，以及如何解释工具的返回结果\n",
        "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "    # 🎮 创建智能体执行器\n",
        "    # 执行器负责：工具调用、错误处理、状态管理、结果整合\n",
        "    executor = AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        verbose=True,  # 显示详细的执行过程，便于调试\n",
        "        handle_parsing_errors=True  # 自动处理解析错误，提高稳定性\n",
        "    )\n",
        "\n",
        "    return executor\n",
        "\n",
        "def agent_node(state, agent, name):\n",
        "    \"\"\"\n",
        "    🔄 智能体节点适配器：将智能体包装为 LangGraph 节点\n",
        "\n",
        "    参数:\n",
        "        state: 当前的图状态，包含消息历史和其他上下文信息\n",
        "        agent: 智能体执行器实例\n",
        "        name: 智能体的名称，用于在多智能体系统中标识消息来源\n",
        "\n",
        "    返回:\n",
        "        dict: 包含智能体响应的状态更新\n",
        "\n",
        "    🔄 适配过程:\n",
        "    1. 调用智能体处理当前状态\n",
        "    2. 提取智能体的输出结果\n",
        "    3. 包装为带有发送者身份的消息\n",
        "    4. 返回状态更新\n",
        "    \"\"\"\n",
        "    # 📤 调用智能体处理当前状态\n",
        "    # agent.invoke() 会处理对话历史，决定是否使用工具，并生成最终回复\n",
        "    result = agent.invoke(state)\n",
        "\n",
        "    # 🏷️ 将智能体的输出包装为带有身份标识的消息\n",
        "    # name 参数让系统知道这条消息来自哪个智能体\n",
        "    return {\n",
        "        \"messages\": [HumanMessage(\n",
        "            content=result[\"output\"],  # 智能体生成的文本内容\n",
        "            name=name  # 消息发送者的身份标识\n",
        "        )]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74bZqwU6FCOa"
      },
      "source": [
        "### 🎯 创建智能体监督者\n",
        "\n",
        "#### 📋 监督者的核心职责\n",
        "智能体监督者是多智能体系统的\"大脑\"，负责：\n",
        "\n",
        "- 🧠 **任务理解**：分析用户请求，理解任务的性质和需求\n",
        "- 🎯 **智能体选择**：根据任务特点选择最适合的工作智能体\n",
        "- 🔄 **流程控制**：决定何时切换智能体，何时结束处理流程\n",
        "- 📊 **结果整合**：汇总各个智能体的工作成果\n",
        "\n",
        "#### 🔧 技术实现方式\n",
        "监督者使用 **函数调用（Function Calling）** 技术来实现决策：\n",
        "\n",
        "- 📞 **函数调用**：通过结构化的函数调用来表达决策结果\n",
        "- 🎛️ **选择机制**：在可用的工作节点中选择下一个执行者\n",
        "- 🏁 **终止条件**：判断何时任务已完成，可以结束处理流程\n",
        "\n",
        "#### 💡 设计优势\n",
        "- **精确控制**：避免随机或不确定的路由决策\n",
        "- **可解释性**：每个决策都有明确的逻辑依据\n",
        "- **可扩展性**：容易添加新的工作智能体和决策规则"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Hu8MzgihrHdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf85e2c-ec6b-4638-f2ab-fc856e396ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1811809048.py:52: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
            "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "members = [\"Researcher\", \"CurrentTime\"]\n",
        "system_prompt = (\n",
        "    \"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers:  {members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When finished,\"\n",
        "    \" respond with FINISH.\"\n",
        ")\n",
        "# 🧭 监督者节点由 LLM 扮演，负责选择下一位执行的智能体并判断流程是否结束\n",
        "options = [\"FINISH\"] + members\n",
        "\n",
        "# 🔁 使用 OpenAI Function Calling，可让结构化输出和解析更加稳定\n",
        "function_def = {\n",
        "    \"name\": \"route\",\n",
        "    \"description\": \"Select the next role.\",\n",
        "    \"parameters\": {\n",
        "        \"title\": \"routeSchema\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"next\": {\n",
        "                \"title\": \"Next\",\n",
        "                \"anyOf\": [\n",
        "                    {\"enum\": options},\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"next\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# 📜 构建监督者提示模板\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Given the conversation above, who should act next?\"\n",
        "            \" Or should we FINISH? Select one of: {options}\",\n",
        "        ),\n",
        "    ]\n",
        ").partial(options=str(options), members=\", \".join(members))\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# 🔗 构建监督者智能体的执行链\n",
        "supervisor_chain = (\n",
        "    prompt\n",
        "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "    | JsonOutputFunctionsParser()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognuMaIeFVh7"
      },
      "source": [
        "### 构建图形结构\n",
        "\n",
        "现在可以开始搭建整张图。下面使用刚刚定义的函数指定状态和各个工作节点，并连接图中的所有边。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_LwtCmw_rHVz"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "from typing import Sequence, TypedDict\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "# 🗂️ 智能体状态会作为每个节点的输入数据\n",
        "class AgentState(TypedDict):\n",
        "    # Annotated 告诉图：新的消息会追加到现有消息列表中\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    # next 字段指示下一步要跳转到哪个节点\n",
        "    next: str\n",
        "\n",
        "# 🧑‍💻 使用辅助函数创建研究智能体\n",
        "research_agent = create_agent(llm, \"You are a web researcher.\", [wikipedia_tool])\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "# 🕰️ 创建报时智能体\n",
        "currenttime_agent = create_agent(llm, \"You are a time keeping assistant who tells the current time.\", [datetime_tool])\n",
        "currenttime_node = functools.partial(agent_node, agent=currenttime_agent, name=\"CurrentTime\")\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# 📦 注册节点：节点代表具体的工作单元，通常是 Python 函数\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"CurrentTime\", currenttime_node)\n",
        "workflow.add_node(\"supervisor\", supervisor_chain)\n",
        "\n",
        "# 🔂 强制所有工作节点在完成后回到监督者\n",
        "for member in members:\n",
        "    workflow.add_edge(member, \"supervisor\")\n",
        "\n",
        "# 🔀 条件边根据当前状态决定后续路由\n",
        "# 该函数读取状态并返回要执行的下一个节点名称\n",
        "conditional_map = {k: k for k in members}\n",
        "conditional_map[\"FINISH\"] = END\n",
        "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
        "\n",
        "# 🚪 设置入口节点，确定图在运行时从哪里开始\n",
        "workflow.add_edge(START, \"supervisor\")\n",
        "\n",
        "# ⚙️ 编译图形，得到可调用的 CompiledGraph\n",
        "graph_2 = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3xfJLJyFwBG"
      },
      "source": [
        "### 在调用中挂载 Langfuse 回调\n",
        "\n",
        "在执行 `graph_2.stream` 时增加 [Langfuse 回调处理器](https://langfuse.com/integrations/frameworks/langchain)：`config={\"callbacks\": [langfuse_handler]}`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "QsX1gw9kryGP",
        "outputId": "83f860c1-94f0-42b4-cea4-7d39f2094782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'supervisor': {'next': 'Researcher'}}\n",
            "----\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-524958090.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 🔗 将回调处理器挂载到图的 stream 调用中；可选的 run_name 会作为追踪名称展示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m for s in graph_2.stream({\"messages\": [HumanMessage(content=\"光合作用是如何进行的？\")]},\n\u001b[0m\u001b[1;32m      8\u001b[0m                        config={\"callbacks\": [langfuse_handler]}):\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2648\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1040424903.py\u001b[0m in \u001b[0;36magent_node\u001b[0;34m(state, agent, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# 📤 调用智能体处理当前状态\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# agent.invoke() 会处理对话历史，决定是否使用工具，并生成最终回复\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# 🏷️ 将智能体的输出包装为带有身份标识的消息\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1626\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     ) -> Union[AgentFinish, list[tuple[AgentAction, str]]]:\n\u001b[1;32m   1324\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1325\u001b[0;31m             list(\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 self._iter_next_step(\n\u001b[1;32m   1327\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             output = self._action_agent.plan(\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# Because the response from the plan is not a generator, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3647\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3648\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3649\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3633\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 3635\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   3636\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2367\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2369\u001b[0;31m                         \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2370\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mfinal_output_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, inputs, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mfinal_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3594\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m     async def _atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \"\"\"\n\u001b[0;32m-> 1155\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     async def astream(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     ) -> T:\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    201\u001b[0m                 lambda inner_input: self.parse_result(\n\u001b[1;32m    202\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   2087\u001b[0m                 output = cast(\n\u001b[1;32m   2088\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2089\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   2090\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 201\u001b[0;31m                 lambda inner_input: self.parse_result(\n\u001b[0m\u001b[1;32m    202\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: TRY004\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparse_ai_message_to_openai_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAgentAction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/openai_tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_openai_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     18\u001b[0m ) -> Union[list[AgentAction], AgentFinish]:\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"\"\"Parse an AI message potentially containing tool_calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtool_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ai_message_to_tool_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtool_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/output_parsers/tools.py\u001b[0m in \u001b[0;36mparse_ai_message_to_tool_action\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\nInvoking: `{function_name}` with `{tool_input}`\\n{content_msg}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         actions.append(\n\u001b[0;32m---> 69\u001b[0;31m             ToolAgentAction(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/agents.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tool, tool_input, log, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdditional\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ToolAgentAction\ntool_call_id\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
          ]
        }
      ],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 📡 初始化 Langfuse 回调处理器，用于记录 LangChain 的执行轨迹\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# 🔗 将回调处理器挂载到图的 stream 调用中；可选的 run_name 会作为追踪名称展示\n",
        "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"光合作用是如何进行的？\")]},\n",
        "                       config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n",
        "    print(\"----\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqJnMtP5HDql"
      },
      "outputs": [],
      "source": [
        "# 🔗 同样地，为其他查询挂载 Langfuse 回调\n",
        "for s in graph_2.stream({\"messages\": [HumanMessage(content=\"现在的准确时间是多少？\")]},\n",
        "                       config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n",
        "    print(\"----\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4XjtNenH9GF"
      },
      "source": [
        "### 在 Langfuse 中查看多智能体追踪\n",
        "\n",
        "以下链接展示了本节多智能体示例在 Langfuse 中生成的追踪记录：\n",
        "\n",
        "1. [光合作用是如何进行的？](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7d5f970573b8214d1ca891251e42282c)\n",
        "2. [现在几点？](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/3a69fe4998df50d42054f8944bd6a8d9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-5EEBZAIbwc"
      },
      "source": [
        "![在 Langfuse 中查看多智能体追踪](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_multiagent_traces.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCEzabn_jhbf"
      },
      "source": [
        "### 可视化该智能体\n",
        "\n",
        "你可以使用 `get_graph` 方法配合相应的 “draw” 方法进行图形可视化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "notlPjnl-HXV"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph_2.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESkG2IJS8OY"
      },
      "source": [
        "```mermaid\n",
        "graph TD;\n",
        "\t__start__([__start__]):::first\n",
        "\tResearcher(Researcher)\n",
        "\tCurrentTime(CurrentTime)\n",
        "\tsupervisor(supervisor)\n",
        "\t__end__([__end__]):::last\n",
        "\tCurrentTime --> supervisor;\n",
        "\tResearcher --> supervisor;\n",
        "\t__start__ --> supervisor;\n",
        "\tsupervisor -.-> Researcher;\n",
        "\tsupervisor -.-> CurrentTime;\n",
        "\tsupervisor -. &nbspFINISH&nbsp .-> __end__;\n",
        "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
        "\tclassDef first fill-opacity:0\n",
        "\tclassDef last fill:#bfb6fc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKULkc6g-BE"
      },
      "source": [
        "## 多个 LangGraph 智能体的协同\n",
        "\n",
        "在某些架构中，一个 LangGraph 智能体会调用一个或多个其他 LangGraph 智能体。若想让整套执行链在 Langfuse 中聚合为同一条追踪，可显式传入自定义的 `trace_id`。\n",
        "\n",
        "首先生成一个共享的 `trace_id`，供主智能体与子智能体共用，以便在 Langfuse 中合并为同一条记录。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS8hQBHVg-BE"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client, Langfuse\n",
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# 🔐 从外部系统生成一个确定性的 trace_id，便于跨服务聚合\n",
        "predefined_trace_id = Langfuse.create_trace_id()\n",
        "\n",
        "# 📡 初始化 Langfuse 回调处理器，用于采集 LangChain 的执行数据\n",
        "langfuse_handler = CallbackHandler()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73necyiUg-BE"
      },
      "source": [
        "接下来，构建子智能体的逻辑。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWS82VWsg-BE"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "sub_agent = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIcpIMEPg-BF"
      },
      "source": [
        "随后，将该子智能体封装成工具，供主流程调用并复用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0KC8Gvzg-BF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def langgraph_research(question):\n",
        "  \"\"\"Conducts research for various topics.\"\"\"\n",
        "\n",
        "  with langfuse.start_as_current_span(\n",
        "      name=\"🤖-sub-research-agent\",\n",
        "      trace_context={\"trace_id\": predefined_trace_id}\n",
        "  ) as span:\n",
        "      span.update_trace(input=question)\n",
        "\n",
        "      response = sub_agent.invoke({\"messages\": [HumanMessage(content = question)]},\n",
        "                        config={\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "      span.update_trace(output= response[\"messages\"][1].content)\n",
        "\n",
        "  return response[\"messages\"][1].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PpMQXiEg-BF"
      },
      "source": [
        "最后，创建第二个 LangGraph 智能体，通过前面新增的 `langgraph_research` 工具完成协作。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhNPp4pmg-BF"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
        "\n",
        "main_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[langgraph_research]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyeGvSf3g-BF"
      },
      "outputs": [],
      "source": [
        "user_question = \"什么是 Langfuse？\"\n",
        "\n",
        "# 🧭 使用预生成的 trace_id（通过 trace_context 注入）\n",
        "with langfuse.start_as_current_span(\n",
        "    name=\"🤖-main-agent\",\n",
        "    trace_context={\"trace_id\": predefined_trace_id}\n",
        ") as span:\n",
        "    span.update_trace(input=user_question)\n",
        "\n",
        "    # 此处的 LangChain 执行都会归属于同一条追踪\n",
        "    response = main_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_question}]},\n",
        "                            config={\"callbacks\": [langfuse_handler]})\n",
        "\n",
        "    span.update_trace(output=response[\"messages\"][1].content)\n",
        "\n",
        "print(f\"Trace ID: {predefined_trace_id}\")  # 可在后续评分或排查时使用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzPZIqUWg-BF"
      },
      "source": [
        "### 在 Langfuse 中查看多智能体追踪\n",
        "\n",
        "![多智能体追踪示例](https://langfuse.com/images/cookbook/integration-langgraph/a2a_langgraph.png)\n",
        "\n",
        "示例追踪链接：https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/85b0c53c4414f22ed8bfc9eb35f917c4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uybP4h8wGvWw"
      },
      "source": [
        "## 为追踪添加评分\n",
        "\n",
        "[评分（Score）](https://langfuse.com/docs/scores/overview) 用于评价单个观测（observation）或整条追踪（trace），可帮助你在运行时执行自定义质量检查，或配合人工审核流程。\n",
        "\n",
        "下面的示例演示如何：\n",
        "\n",
        "- 为某个 span 记录一个数值型评分（如 `relevance`）\n",
        "- 为整条追踪记录一个分类型评分（如 `feedback`）\n",
        "\n",
        "这有助于系统化地评估与改进应用质量。\n",
        "\n",
        "**→ 想深入了解？请参阅 [Langfuse 自定义评分指南](https://langfuse.com/docs/scores/custom)。**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgAqYnQuGwCL"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# 方案一：使用上下文管理器返回的 span 对象进行评分\n",
        "with langfuse.start_as_current_span(\n",
        "    name=\"langgraph-request\") as span:\n",
        "    # ... 此处执行 LangGraph 逻辑 ...\n",
        "\n",
        "    # 直接通过 span.score_trace 记录评分\n",
        "    span.score_trace(\n",
        "        name=\"user-feedback\",\n",
        "        value=1,\n",
        "        data_type=\"NUMERIC\",\n",
        "        comment=\"This was correct, thank you\"\n",
        "    )\n",
        "\n",
        "# 方案二：在仍位于上下文时调用 score_current_trace()\n",
        "with langfuse.start_as_current_span(name=\"langgraph-request\") as span:\n",
        "    # ... LangGraph execution ...\n",
        "\n",
        "    langfuse.score_current_trace(\n",
        "        name=\"user-feedback\",\n",
        "        value=1,\n",
        "        data_type=\"NUMERIC\"\n",
        "    )\n",
        "\n",
        "# 方案三：若已离开上下文，可使用 trace_id 直接创建评分\n",
        "langfuse.create_score(\n",
        "    trace_id=predefined_trace_id,\n",
        "    name=\"user-feedback\",\n",
        "    value=1,\n",
        "    data_type=\"NUMERIC\",\n",
        "    comment=\"This was correct, thank you\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq_DeCcXSxwq"
      },
      "source": [
        "### 在 Langfuse 中查看带评分的追踪\n",
        "\n",
        "示例追踪：https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e60a078b828d4fdc7ea22c73193b0fe4\n",
        "\n",
        "![包含评分的追踪展示](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_score.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cIQVrYZJVMO"
      },
      "source": [
        "## 使用 Langfuse 管理提示词\n",
        "\n",
        "通过 [Langfuse Prompt Management](https://langfuse.com/docs/prompts/example-langchain) 可以对提示词进行统一的版本管理。在本示例中，我们演示如何通过 SDK 新增一条提示词；在实际生产环境中，更推荐直接在 Langfuse UI 中创建和发布。\n",
        "\n",
        "Langfuse 的提示词管理相当于一个“提示词内容管理系统（Prompt CMS）”。你可以在 UI 中编辑、预览与发布；也可在代码中通过 SDK 读取或更新。\n",
        "\n",
        "配置提示词时通常需要指定：\n",
        "\n",
        "* `name`：在 Langfuse 中唯一标识该提示词的名称\n",
        "* `prompt`：包含模板占位符（如 `{{input variables}}`）的文本内容\n",
        "* `labels`：可设置为 `production`，让该版本立即成为默认选项\n",
        "\n",
        "在本例中，我们创建一个系统提示词，让助手将所有用户输入翻译成西班牙语。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0J8-nbhUUz6"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "langfuse.create_prompt(\n",
        "    name=\"translator_system-prompt\",\n",
        "    prompt=\"You are a translator that translates every input text into Spanish.\",\n",
        "    labels=[\"production\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dullp4XDXhzg"
      },
      "source": [
        "![在 Langfuse UI 中查看提示词](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_prompt_example.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNboOjf2YQpD"
      },
      "source": [
        "使用工具方法 `.get_langchain_prompt()` 可以将 Langfuse 中的提示词转换为 LangChain 可直接使用的字符串。\n",
        "\n",
        "**背景说明：** Langfuse 在提示模板中使用双花括号（`{{input variable}}`）声明变量；而 LangChain 的 `PromptTemplate` 使用单花括号（`{input variable}`）。`.get_langchain_prompt()` 会自动完成格式转换。当前示例的提示词没有占位变量，但仍可以统一通过该方法处理。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z49I82blYeXy"
      },
      "outputs": [],
      "source": [
        "# 读取生产环境中最新的提示词版本，并转换为 LangChain 可直接使用的字符串\n",
        "langfuse_system_prompt = langfuse.get_prompt(\"translator_system-prompt\")\n",
        "langchain_system_prompt = langfuse_system_prompt.get_langchain_prompt()\n",
        "\n",
        "print(langchain_system_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3zBULfCt0Wq"
      },
      "source": [
        "现在可以使用新的系统提示词字符串，更新我们的翻译助手。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGQhulyMmvZD"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "# 🧩 将系统提示词注入到聊天节点，确保助手先遵循翻译指令\n",
        "system_prompt = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": langchain_system_prompt\n",
        "}\n",
        "\n",
        "def chatbot(state: State):\n",
        "    messages_with_system_prompt = [system_prompt] + state[\"messages\"]\n",
        "    response = llm.invoke(messages_with_system_prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "graph = graph_builder.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYd7wbttm2ec"
      },
      "outputs": [],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "# 📡 初始化 Langfuse 回调处理器（用于追踪翻译助手的调用）\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# 🔗 将回调挂载到图的 stream 方法中，实时查看翻译结果与追踪记录\n",
        "for s in graph.stream({\"messages\": [HumanMessage(content=\"请把“Langfuse 是什么？”翻译成西班牙语。\")]},\n",
        "                      config={\"callbacks\": [langfuse_handler]}):\n",
        "    print(s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsAfdodAg-BH"
      },
      "source": [
        "## 在 LangGraph 追踪中添加自定义 Span\n",
        "\n",
        "某些场景下，我们希望在追踪中插入自定义 span，以标记关键步骤或附加额外上下文。可以参考这个 [GitHub 讨论贴](https://github.com/orgs/langfuse/discussions/2988#discussioncomment-11634600) 中给出的示例实现方式。\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}