{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/01_langfuse_integration_openai_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki7E44X5ViQB"
      },
      "source": [
        "# OpenAI SDK集成Langfuse获得完整的可观测性\n",
        "---\n",
        "description: 只需替换 import 语句，就能用 Langfuse 版本的 OpenAI SDK 获得完整的可观测性\n",
        "category: Integrations\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfMAzJYcirtK"
      },
      "source": [
        "# 示例手册：OpenAI 集成（Python）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0A389k2irtK"
      },
      "source": [
        "这是一个示例手册，演示如何在 Python 项目中集成 Langfuse 与 OpenAI。\n",
        "\n",
        "Langfuse 会记录每次模型调用的输入输出，帮助你排查问题并评估质量。\n",
        "\n",
        "按照 [集成指南](https://langfuse.com/integrations/model-providers/openai-py) 将本集成添加到你的 OpenAI 项目中。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq04G_FSWjF-"
      },
      "source": [
        "## 环境准备\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYoil3FcOIQt"
      },
      "source": [
        "该集成适用于 OpenAI SDK `>=0.27.8`；若要使用异步函数和流式输出，请确保 SDK 版本 `>=1.0.0`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hVOOiBtUPtOO",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9a4742-d70e-4cbf-c7fe-63a25dad2bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse==3.3.0\n",
            "  Downloading langfuse-3.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Collecting backoff>=1.10.0 (from langfuse==3.3.0)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Downloading langfuse-3.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opentelemetry-proto, backoff, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, langfuse\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.36.0\n",
            "    Uninstalling opentelemetry-api-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.36.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.36.0\n",
            "    Uninstalling opentelemetry-sdk-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
            "Successfully installed backoff-2.2.1 langfuse-3.3.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse==3.3.0 openai==1.107.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 环境变量配置\n",
        "# 设置OpenAI API密钥，这是使用OpenAI模型所必需的\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    安全地设置环境变量\n",
        "    如果环境变量不存在，会提示用户输入\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "# 设置OpenAI API密钥\n",
        "# 您需要从 https://platform.openai.com/api-keys 获取API密钥\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
        "_set_env(\"OPENAI_BASE_URL\")\n",
        "\n",
        "\n",
        "# 在项目设置页获取密钥：https://cloud.langfuse.com,\n",
        "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-2cf6d992-461d-4b3c-a47e-96285c1e5526@FLYAIBOX\"\n",
        "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-55c2fa56-c913-44be-916b-85ba498dcb8a@FLYAIBOX\"\n",
        "# PUBLIC KEY\n",
        "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
        "# SECRET KEY\n",
        "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
        "# 🇪🇺 欧盟区域(推荐) https://cloud.langfuse.com\n",
        "# 🇺🇸 美国区域 https://us.cloud.langfuse.com\n",
        "_set_env(\"LANGFUSE_HOST\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K72KpSE2OiJY",
        "outputId": "e137b755-2a4e-4db8-fc97-d8da6754b1aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n",
            "OPENAI_BASE_URL: ··········\n",
            "LANGFUSE_PUBLIC_KEY: ··········\n",
            "LANGFUSE_SECRET_KEY: ··········\n",
            "LANGFUSE_HOST: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ldSEJ0bAP4sj"
      },
      "outputs": [],
      "source": [
        "# Langfuse 提供了对原生 OpenAI SDK 的封装，接口保持一致但会自动上报调用数据\n",
        "# 只需替换原本的 `import openai`，其余代码可以保持不变\n",
        "from langfuse.openai import openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ovnAAdbaLmD"
      },
      "source": [
        "## 示例\n",
        "\n",
        "### 文本聊天补全\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c8RhokKUP9I0"
      },
      "outputs": [],
      "source": [
        "# 示例：发起一次标准的聊天补全请求\n",
        "# Langfuse 会记录请求名称 (name)、模型 (model)、消息内容 (messages) 以及自定义元数据 (metadata)\n",
        "completion = openai.chat.completions.create(\n",
        "  name=\"test-chat\",  # 追踪名称，可在 Langfuse 中快速定位这次调用\n",
        "  model=\"gpt-4o\",  # 指定使用的模型\n",
        "  messages=[\n",
        "      {\"role\": \"system\", \"content\": \"您是一个非常精确的计算器。您只输出计算结果。\"},  # system 消息：定义助手的身份/行为\n",
        "      {\"role\": \"user\", \"content\": \"1 + 1 = \"}],  # user 消息：用户的真实输入\n",
        "  temperature=0,  # 温度越低越稳定，适合需要确定答案的场景\n",
        "  metadata={\"someMetadataKey\": \"someValue\"},  # 自定义元数据，会显示在 Langfuse 调试界面\n",
        ")\n",
        "\n",
        "# 如果需要查看模型响应，可使用 completion.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAqxBgOqKTzO"
      },
      "source": [
        "### 图像聊天补全\n",
        "\n",
        "这是一个演示 OpenAI 视觉能力的简单示例。你可以在 `user` 消息中直接传入图片。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_sM_Pe0YIfTT"
      },
      "outputs": [],
      "source": [
        "# 示例：向模型发送图像输入\n",
        "completion = openai.chat.completions.create(\n",
        "  name=\"test-url-image\",  # 追踪名称\n",
        "  model=\"gpt-4o-mini\",  # GPT-4o、GPT-4o mini、GPT-4 Turbo 均具备视觉能力\n",
        "  messages=[\n",
        "      {\"role\": \"system\", \"content\": \"您是一个被训练来描述和解释图像的AI。描述图像中的主要物体和动作。\"},  # 指定模型任务\n",
        "      {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"这幅画描绘了什么？\"},  # 文字提示\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://static.langfuse.com/langfuse-dev/langfuse-example-image.jpeg\",  # 示例图片 URL，Langfuse 会记录该链接\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,  # 图像描述多为事实陈述，建议设置较低温度\n",
        "  metadata={\"someMetadataKey\": \"someValue\"},  # 自定义元数据\n",
        ")\n",
        "\n",
        "# Langfuse 会将图片 URL 也记录在追踪详情中，方便复现问题\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4iJpqYQirtM"
      },
      "source": [
        "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看生成记录。\n",
        "\n",
        "![聊天补全截图](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211139659.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFYWEbD6IfTU"
      },
      "source": [
        "### 流式聊天补全\n",
        "\n",
        "这是一个演示 OpenAI 流式输出能力的简单示例。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b9gRlb2rKTaA",
        "outputId": "12be69ba-0f5b-46c7-afa0-b6390a9671c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "当然！你知道为什么数学书总是很忧郁吗？因为它有太多的问题！None"
          ]
        }
      ],
      "source": [
        "# 示例：开启流式输出，实时获取模型返回的 Token\n",
        "completion = openai.chat.completions.create(\n",
        "  name=\"test-chat\",  # 追踪名称\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "      {\"role\": \"system\", \"content\": \"您是一位专业的喜剧演员。\"},\n",
        "      {\"role\": \"user\", \"content\": \"讲一个笑话给我听。\"}],\n",
        "  temperature=0,  # 温度越高，笑话越发散；此处设为 0 方便演示\n",
        "  metadata={\"someMetadataKey\": \"someValue\"},\n",
        "  stream=True  # 打开流式模式后，API 会边生成边返回\n",
        ")\n",
        "\n",
        "# completion 变为一个生成器，依次产出增量内容；打印时记得取消换行\n",
        "for chunk in completion:\n",
        "  print(chunk.choices[0].delta.content, end=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2pvm0qLKg7Q"
      },
      "source": [
        "### 异步聊天补全\n",
        "\n",
        "该示例使用 OpenAI 的异步客户端。Langfuse 配置可通过环境变量或 `openai` 模块上的属性传入。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Hggwggv_MKpV"
      },
      "outputs": [],
      "source": [
        "# 异步示例：Langfuse 同样兼容 OpenAI 的 Async 客户端\n",
        "from langfuse.openai import AsyncOpenAI\n",
        "\n",
        "async_client = AsyncOpenAI()  # 实例化异步客户端，将自动复用环境变量中的 Langfuse 配置\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZIUKD8Z3KmvQ"
      },
      "outputs": [],
      "source": [
        "# 在异步函数内调用聊天补全接口，需要使用 await 等待结果\n",
        "completion = await async_client.chat.completions.create(\n",
        "  name=\"test-chat\",  # 为本次调用命名\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "      {\"role\": \"system\", \"content\": \"你是一个非常精确的计算器。你只输出计算结果。\"},\n",
        "      {\"role\": \"user\", \"content\": \"1 + 100 = \"}],\n",
        "  temperature=0,\n",
        "  metadata={\"someMetadataKey\": \"someValue\"},\n",
        ")\n",
        "\n",
        "# Langfuse 会自动关联异步调用上下文，不需要额外配置\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVbKbya4IfTX"
      },
      "source": [
        "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看生成记录。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky7CtCNzaSrn"
      },
      "source": [
        "### 函数调用\n",
        "\n",
        "该示例演示如何借助 Pydantic 构建函数模式。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jJfBdHowaRgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda9d41d-9a70-40a2-9625-93714c1f253c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic==2.11.9 in /usr/local/lib/python3.12/dist-packages (2.11.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install pydantic==2.11.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2gA-zGk7VYYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10430c87-cf69-4679-ea68-0aabb687de75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-414262564.py:9: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  schema = StepByStepAIResponse.schema()  # 返回 JSON Schema，供 OpenAI 函数调用使用\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# 定义函数调用返回值的数据结构，让模型生成结构化的 JSON\n",
        "class StepByStepAIResponse(BaseModel):\n",
        "    title: str  # 标题：例如“装机步骤”\n",
        "    steps: List[str]  # 步骤列表：每个元素是一句描述\n",
        "\n",
        "schema = StepByStepAIResponse.schema()  # 返回 JSON Schema，供 OpenAI 函数调用使用\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORtNcN4-afDC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# 示例：引导模型调用我们定义的函数，并返回结构化结果\n",
        "response = openai.chat.completions.create(\n",
        "    name=\"test-function\",\n",
        "    model=\"gpt-4o-0613\",  # 支持函数调用的模型版本\n",
        "    messages=[\n",
        "       {\"role\": \"user\", \"content\": \"如何组装一台电脑\"}\n",
        "    ],\n",
        "    functions=[\n",
        "        {\n",
        "          \"name\": \"get_answer_for_user_query\",  # 函数名称，需要与业务代码保持一致\n",
        "          \"description\": \"分步骤为用户提供答案\",  # 告诉模型函数的用途\n",
        "          \"parameters\": StepByStepAIResponse.schema()  # Pydantic 自动生成的参数定义\n",
        "        }\n",
        "    ],\n",
        "    function_call={\"name\": \"get_answer_for_user_query\"}  # 强制模型调用指定函数\n",
        ")\n",
        "\n",
        "# Langfuse 会记录函数调用的入参与出参，便于追踪\n",
        "output = json.loads(response.choices[0].message.function_call.arguments)  # 将字符串反序列化为 Python 字典\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qurrm-Ntp24O"
      },
      "source": [
        "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看生成记录。\n",
        "\n",
        "示例：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces/8942d39f62095985bf891156bbd563b9?timestamp=2025-09-21T03:42:03.721Z\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hMsPXFDIfTZ"
      },
      "source": [
        "## Langfuse 功能（用户、标签、元数据、会话）\n",
        "\n",
        "你可以在 OpenAI 请求中加入额外属性，以启用更多 Langfuse 功能。Langfuse 集成会自动解析这些字段。完整功能列表见 [文档](https://langfuse.com/integrations/model-providers/openai-py#custom-trace-properties)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7srTKGjaIfTZ"
      },
      "outputs": [],
      "source": [
        "result = openai.chat.completions.create(\n",
        "    name=\"test-chat-with-attributes\",  # trace 名称，对应 Langfuse 中的 Trace.name\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"您是一个非常精确的计算器。您只输出计算结果。\"},\n",
        "        {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
        "    temperature=0,\n",
        "    metadata={\n",
        "        \"langfuse_session_id\": \"session_123\", # 会话 ID，用于区分不同对话/请求\n",
        "        \"langfuse_user_id\": \"user_456\", # 业务用户 ID，让你在 Langfuse 中按用户聚合\n",
        "        \"langfuse_tags\": [\"calculator\"], # trace 标签，可用于 Langfuse 控制台筛选\n",
        "        \"someMetadataKey\": \"someValue\"  # trace 元数据，适合记录业务上下文\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPfrmgbEIfTZ"
      },
      "source": [
        "示例追踪：\n",
        "\n",
        "\n",
        "![image-20250921115506459](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211155197.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su1OaQq3rPPh"
      },
      "source": [
        "## 将多次生成归并为单个 Trace\n",
        "\n",
        "在实际应用中，往往需要多次调用 OpenAI。借助 `@observe()` 装饰器，可以把一次 API 调用中的所有 LLM 请求归入 Langfuse 中同一个 `trace`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zMDVxzS1ltWU",
        "outputId": "ce14c152-20f5-48f9-ffb4-60f934e8b85c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "在华夏大地的北方一隅，   \n",
            "长城以北，黄土以东，   \n",
            "古老与现代在此共舞，   \n",
            "北京，这座城市的心跳如钟。   \n",
            "\n",
            "紫禁城巍峨，诉说着往昔的传奇，   \n",
            "天安门广场，见证了历史的更替。   \n",
            "在胡同深处，岁月的足迹依稀，   \n",
            "四合院里，古老的韵味铭刻心底。   \n",
            "\n",
            "繁华的街道，车流如水，   \n",
            "霓虹灯下，城市的梦境无穷。   \n",
            "摩天大楼直插云霄，   \n",
            "孕育新的希望与光荣。   \n",
            "\n",
            "文人翰墨，在此挥洒千载，   \n",
            "创新创业，年轻的热血昂扬。   \n",
            "北京，不息的脉动中，   \n",
            "承载着中原儿女的\n"
          ]
        }
      ],
      "source": [
        "from langfuse.openai import openai\n",
        "from langfuse import observe\n",
        "\n",
        "# 【@observe 装饰器】会自动：\n",
        "# 1. 为 main 函数创建一个顶层 trace\n",
        "# 2. 捕获函数内部的所有 Langfuse/OpenAI 调用，并将它们串联为一个完整链路\n",
        "@observe()  # 装饰器会自动创建 trace 并嵌套各次生成\n",
        "def main(country: str, user_id: str, **kwargs) -> str:\n",
        "    # 嵌套调用 1：询问国家首都\n",
        "    capital = openai.chat.completions.create(\n",
        "      name=\"geography-teacher\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"您是一位地理老师，帮助学生学习国家的首都。当被问及时，只输出首都。\"},\n",
        "          {\"role\": \"user\", \"content\": country}],\n",
        "      temperature=0,\n",
        "    ).choices[0].message.content  # 读取模型回复\n",
        "\n",
        "    # 嵌套调用 2：请模型写一首关于首都的诗\n",
        "    poem = openai.chat.completions.create(\n",
        "      name=\"poet\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"你是一位诗人。创作一首关于城市的诗。\"},\n",
        "          {\"role\": \"user\", \"content\": capital}],\n",
        "      temperature=1,  # 提高温度，让诗歌更有创意\n",
        "      max_tokens=200,  # 控制输出长度\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    return poem\n",
        "\n",
        "# 直接调用 main 函数，Langfuse 会自动生成 trace 并可在控制台查看链路\n",
        "print(main(\"北京\", \"FLY\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehx2NZuIrPPh"
      },
      "source": [
        "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看完整链路。\n",
        "\n",
        "![多次 OpenAI 调用的追踪图](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211159038.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HeMqTWgK4xL"
      },
      "source": [
        "## 完整方案：与 Langfuse SDK 协同\n",
        "\n",
        "`trace` 是 Langfuse 的核心对象，你可以为它附加丰富的元数据。详见 [Python SDK 文档](https://langfuse.com/docs/sdk/python#traces-1)。\n",
        "\n",
        "自定义 trace 后可以实现以下能力：\n",
        "- 自定义名称，用来区分不同类型的链路\n",
        "- 以用户为粒度的追踪\n",
        "- 通过版本与发布信息进行实验管理\n",
        "- 保存自定义元数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "28to65wpK4xL",
        "outputId": "6eec4e7c-b210-4690-a50d-ed9909f46e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "在万里长城的臂弯间，  \n",
            "北平古都今正繁忙。  \n",
            "故宫琉璃辉映朝霞，  \n",
            "长安街头人潮涌荡。  \n",
            "\n",
            "曾闻胭脂车马喧闹，  \n",
            "如今高楼接天如影。  \n",
            "胡同深巷承载旧梦，  \n",
            "CBD内霓虹交映。  \n",
            "\n",
            "时光在四合院中流淌，  \n",
            "京腔胡同诉说历史。  \n",
            "香山红叶忆往事，  \n",
            "东单西单展新貌。  \n",
            "\n",
            "莲花池畔寻一丝宁静，  \n",
            "天坛祈福迎来朝暮。  \n",
            "在这古老而又现代的城，  \n",
            "岁月如歌，铭刻永恒。  \n"
          ]
        }
      ],
      "source": [
        "from langfuse.openai import openai\n",
        "from langfuse import observe, get_client\n",
        "\n",
        "langfuse = get_client()  # 获取底层 Langfuse 客户端，可在装饰器之外手动操作 trace\n",
        "\n",
        "@observe()  # 装饰器会自动创建 trace 并嵌套各次生成\n",
        "def main(country: str, user_id: str, **kwargs) -> str:\n",
        "    # 嵌套调用 1：获取国家首都\n",
        "    capital = openai.chat.completions.create(\n",
        "      name=\"geography-teacher\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"您是一位地理老师，帮助学生学习国家的首都。当被问及时，只输出首都。\"},\n",
        "          {\"role\": \"user\", \"content\": country}],\n",
        "      temperature=0,\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # 嵌套调用 2：根据首都生成诗歌\n",
        "    poem = openai.chat.completions.create(\n",
        "      name=\"poet\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"你是一位诗人。创作一首关于城市的诗。\"},\n",
        "          {\"role\": \"user\", \"content\": capital}],\n",
        "      temperature=1,\n",
        "      max_tokens=200,\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # 手动更新当前 trace 的属性，让仪表盘信息更完整\n",
        "    langfuse.update_current_trace(\n",
        "        name=\"City poem generator\",  # 自定义 trace 名称\n",
        "        session_id=\"1234\",  # 业务会话 ID\n",
        "        user_id=user_id,  # 业务用户 ID\n",
        "        tags=[\"tag1\", \"tag2\"],  # 标签，支持在 Langfuse 中搜索\n",
        "        public=True,  # 是否允许分享 Trace 链接\n",
        "        metadata = {\"env\": \"development\"}  # 自定义元数据，例如环境标记\n",
        "    )\n",
        "\n",
        "    return poem\n",
        "\n",
        "# create_trace_id() 会生成一个可复用的追踪 ID，你也可以改为自己的业务 ID\n",
        "trace_id = langfuse.create_trace_id()\n",
        "\n",
        "# 通过关键字参数 `langfuse_observation_id` 将 trace_id 传递给装饰器，方便串联上下游调用\n",
        "print(main(\"北京\", \"admin\", langfuse_observation_id=trace_id))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "示例：\n",
        "![image-20250921120555385](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211205931.png)"
      ],
      "metadata": {
        "id": "2u5n_RUic4nb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3jxed-VrPPi"
      },
      "source": [
        "## 以编程方式添加评分\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMO6tn53rPPi"
      },
      "source": [
        "你可以向 trace 添加 [评分](https://langfuse.com/docs/scores)，记录用户反馈或自动化评估结果。评分可用于在 Langfuse 中筛选追踪，并会显示在控制台中。详见评分文档。\n",
        "\n",
        "评分通过 `trace_id` 与对应的 trace 关联。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "J0argbJhrPPi"
      },
      "outputs": [],
      "source": [
        "from langfuse import observe, get_client\n",
        "\n",
        "langfuse = get_client()  # 获取底层客户端，用于主流程之外的操作\n",
        "\n",
        "@observe()  # 装饰器会自动创建 trace 并嵌套各次生成\n",
        "def main():\n",
        "    # 在装饰器内部，可随时获取当前 trace 的 ID\n",
        "    trace_id = langfuse.get_current_trace_id()\n",
        "\n",
        "    # TODO: 在此处编写你的业务逻辑，例如继续调用其他 API、处理用户输入等\n",
        "\n",
        "    return \"res\", trace_id\n",
        "\n",
        "# 执行被装饰的函数，Langfuse 会生成 trace\n",
        "_, trace_id = main()\n",
        "\n",
        "# 在 trace 上下文外部也可以继续操作，例如向这次 trace 添加评分\n",
        "langfuse.create_score(\n",
        "    trace_id=trace_id,  # 指定要打分的 trace\n",
        "    name=\"my-score-name\",  # 评分名称，用于区分不同指标\n",
        "    value=1  # 分值，可以是布尔、整数、浮点数，视业务场景而定\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "示例：![image-20250921120901924](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211209271.png)"
      ],
      "metadata": {
        "id": "Zp899q3edni6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}