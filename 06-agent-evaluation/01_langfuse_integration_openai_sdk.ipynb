{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki7E44X5ViQB"
   },
   "source": [
    "---\n",
    "description: 只需替换 import 语句，就能用 Langfuse 版本的 OpenAI SDK 获得完整的可观测性\n",
    "category: Integrations\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfMAzJYcirtK"
   },
   "source": [
    "# 示例手册：OpenAI 集成（Python）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0A389k2irtK"
   },
   "source": [
    "这是一个示例手册，演示如何在 Python 项目中集成 Langfuse 与 OpenAI。\n",
    "\n",
    "Langfuse 会记录每次模型调用的输入输出，帮助你排查问题并评估质量。\n",
    "\n",
    "按照 [集成指南](https://langfuse.com/integrations/model-providers/openai-py) 将本集成添加到你的 OpenAI 项目中。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq04G_FSWjF-"
   },
   "source": [
    "## 环境准备\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYoil3FcOIQt"
   },
   "source": [
    "该集成适用于 OpenAI SDK `>=0.27.8`；若要使用异步函数和流式输出，请确保 SDK 版本 `>=1.0.0`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVOOiBtUPtOO"
   },
   "outputs": [],
   "source": [
    "%pip install langfuse openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-s-hY3PPupC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Langfuse SDK 会通过环境变量读取鉴权信息，此处填入你在 Langfuse 控制台 Project Settings 中生成的密钥\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"  # 公钥：用于识别项目\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"  # 私钥：用于签名请求，务必妥善保管\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # 🇪🇺 欧盟区域默认服务端\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"  # 🇺🇸 如果你的项目在美国区域，请改用此地址\n",
    "\n",
    "# OpenAI SDK 也默认通过环境变量获取 API Key，此处示例填入占位符\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldSEJ0bAP4sj"
   },
   "outputs": [],
   "source": [
    "# Langfuse 提供了对原生 OpenAI SDK 的封装，接口保持一致但会自动上报调用数据\n",
    "# 只需替换原本的 `import openai`，其余代码可以保持不变\n",
    "from langfuse.openai import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ovnAAdbaLmD"
   },
   "source": [
    "## 示例\n",
    "\n",
    "### 文本聊天补全\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8RhokKUP9I0"
   },
   "outputs": [],
   "source": [
    "# 示例：发起一次标准的聊天补全请求\n",
    "# Langfuse 会记录请求名称 (name)、模型 (model)、消息内容 (messages) 以及自定义元数据 (metadata)\n",
    "completion = openai.chat.completions.create(\n",
    "  name=\"test-chat\",  # 追踪名称，可在 Langfuse 中快速定位这次调用\n",
    "  model=\"gpt-4o\",  # 指定使用的模型\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a very accurate calculator. You output only the result of the calculation.\"},  # system 消息：定义助手的身份/行为\n",
    "      {\"role\": \"user\", \"content\": \"1 + 1 = \"}],  # user 消息：用户的真实输入\n",
    "  temperature=0,  # 温度越低越稳定，适合需要确定答案的场景\n",
    "  metadata={\"someMetadataKey\": \"someValue\"},  # 自定义元数据，会显示在 Langfuse 调试界面\n",
    ")\n",
    "\n",
    "# 如果需要查看模型响应，可使用 completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAqxBgOqKTzO"
   },
   "source": [
    "### 图像聊天补全\n",
    "\n",
    "这是一个演示 OpenAI 视觉能力的简单示例。你可以在 `user` 消息中直接传入图片。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sM_Pe0YIfTT"
   },
   "outputs": [],
   "source": [
    "# 示例：向模型发送图像输入\n",
    "completion = openai.chat.completions.create(\n",
    "  name=\"test-url-image\",  # 追踪名称\n",
    "  model=\"gpt-4o-mini\",  # GPT-4o、GPT-4o mini、GPT-4 Turbo 均具备视觉能力\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are an AI trained to describe and interpret images. Describe the main objects and actions in the image.\"},  # 指定模型任务\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s depicted in this image?\"},  # 文字提示\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://static.langfuse.com/langfuse-dev/langfuse-example-image.jpeg\",  # 示例图片 URL，Langfuse 会记录该链接\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,  # 图像描述多为事实陈述，建议设置较低温度\n",
    "  metadata={\"someMetadataKey\": \"someValue\"},  # 自定义元数据\n",
    ")\n",
    "\n",
    "# Langfuse 会将图片 URL 也记录在追踪详情中，方便复现问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4iJpqYQirtM"
   },
   "source": [
    "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看生成记录。\n",
    "\n",
    "![聊天补全截图](https://langfuse.com/images/docs/multi-modal-trace.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFYWEbD6IfTU"
   },
   "source": [
    "### 流式聊天补全\n",
    "\n",
    "这是一个演示 OpenAI 流式输出能力的简单示例。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9gRlb2rKTaA",
    "outputId": "28ab4773-0ac2-498d-e7e5-8180d6ba3da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!None"
     ]
    }
   ],
   "source": [
    "# 示例：开启流式输出，实时获取模型返回的 Token\n",
    "completion = openai.chat.completions.create(\n",
    "  name=\"test-chat\",  # 追踪名称\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a professional comedian.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Tell me a joke.\"}],\n",
    "  temperature=0,  # 温度越高，笑话越发散；此处设为 0 方便演示\n",
    "  metadata={\"someMetadataKey\": \"someValue\"},\n",
    "  stream=True  # 打开流式模式后，API 会边生成边返回\n",
    ")\n",
    "\n",
    "# completion 变为一个生成器，依次产出增量内容；打印时记得取消换行\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta.content, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2pvm0qLKg7Q"
   },
   "source": [
    "### 异步聊天补全\n",
    "\n",
    "该示例使用 OpenAI 的异步客户端。Langfuse 配置可通过环境变量或 `openai` 模块上的属性传入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hggwggv_MKpV"
   },
   "outputs": [],
   "source": [
    "# 异步示例：Langfuse 同样兼容 OpenAI 的 Async 客户端\n",
    "from langfuse.openai import AsyncOpenAI\n",
    "\n",
    "async_client = AsyncOpenAI()  # 实例化异步客户端，将自动复用环境变量中的 Langfuse 配置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIUKD8Z3KmvQ"
   },
   "outputs": [],
   "source": [
    "# 在异步函数内调用聊天补全接口，需要使用 await 等待结果\n",
    "completion = await async_client.chat.completions.create(\n",
    "  name=\"test-chat\",  # 为本次调用命名\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a very accurate calculator. You output only the result of the calculation.\"},\n",
    "      {\"role\": \"user\", \"content\": \"1 + 100 = \"}],\n",
    "  temperature=0,\n",
    "  metadata={\"someMetadataKey\": \"someValue\"},\n",
    ")\n",
    "\n",
    "# Langfuse 会自动关联异步调用上下文，不需要额外配置\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVbKbya4IfTX"
   },
   "source": [
    "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看生成记录。\n",
    "\n",
    "![聊天补全仪表盘](https://langfuse.com/images/docs/openai-chat.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky7CtCNzaSrn"
   },
   "source": [
    "### 函数调用\n",
    "\n",
    "该示例演示如何借助 Pydantic 构建函数模式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJfBdHowaRgs"
   },
   "outputs": [],
   "source": [
    "%pip install pydantic --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gA-zGk7VYYp"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# 定义函数调用返回值的数据结构，让模型生成结构化的 JSON\n",
    "class StepByStepAIResponse(BaseModel):\n",
    "    title: str  # 标题：例如“装机步骤”\n",
    "    steps: List[str]  # 步骤列表：每个元素是一句描述\n",
    "\n",
    "schema = StepByStepAIResponse.schema()  # 返回 JSON Schema，供 OpenAI 函数调用使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORtNcN4-afDC"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 示例：引导模型调用我们定义的函数，并返回结构化结果\n",
    "response = openai.chat.completions.create(\n",
    "    name=\"test-function\",\n",
    "    model=\"gpt-4o-0613\",  # 支持函数调用的模型版本\n",
    "    messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Explain how to assemble a PC\"}\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"get_answer_for_user_query\",  # 函数名称，需要与业务代码保持一致\n",
    "          \"description\": \"Get user answer in series of steps\",  # 告诉模型函数的用途\n",
    "          \"parameters\": StepByStepAIResponse.schema()  # Pydantic 自动生成的参数定义\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_answer_for_user_query\"}  # 强制模型调用指定函数\n",
    ")\n",
    "\n",
    "# Langfuse 会记录函数调用的入参与出参，便于追踪\n",
    "output = json.loads(response.choices[0].message.function_call.arguments)  # 将字符串反序列化为 Python 字典\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qurrm-Ntp24O"
   },
   "source": [
    "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看生成记录。\n",
    "\n",
    "![函数调用示例](https://langfuse.com/images/docs/openai-function.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hMsPXFDIfTZ"
   },
   "source": [
    "## Langfuse 功能（用户、标签、元数据、会话）\n",
    "\n",
    "你可以在 OpenAI 请求中加入额外属性，以启用更多 Langfuse 功能。Langfuse 集成会自动解析这些字段。完整功能列表见 [文档](https://langfuse.com/integrations/model-providers/openai-py#custom-trace-properties)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7srTKGjaIfTZ"
   },
   "outputs": [],
   "source": [
    "# Langfuse 扩展字段示例：通过 metadata/tags/user_id/session_id 丰富追踪信息\n",
    "completion_with_attributes = openai.chat.completions.create(\n",
    "  name=\"test-chat-with-attributes\",  # trace 名称，对应 Langfuse 中的 Trace.name\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a very accurate calculator. You output only the result of the calculation.\"},\n",
    "      {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
    "  temperature=0,\n",
    "  metadata={\"someMetadataKey\": \"someValue\"},  # trace 元数据，适合记录业务上下文\n",
    "  tags=[\"tag1\", \"tag2\"],  # trace 标签，可用于 Langfuse 控制台筛选\n",
    "  user_id=\"user1234\",  # 业务用户 ID，让你在 Langfuse 中按用户聚合\n",
    "  session_id=\"session1234\",  # 会话 ID，用于区分不同对话/请求\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPfrmgbEIfTZ"
   },
   "source": [
    "示例追踪：https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/286c5c70-b077-4826-a493-36c510362a5a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hgk0dHnzIfTZ"
   },
   "source": [
    "## AzureOpenAI\n",
    "\n",
    "该集成同样支持 `AzureOpenAI` 与 `AsyncAzureOpenAI` 类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZKBDhiFIfTZ"
   },
   "outputs": [],
   "source": [
    "# Azure OpenAI 示例：在环境中填入 Azure 侧的密钥与部署信息\n",
    "AZURE_OPENAI_KEY=\"\"  # Azure 提供的 API Key\n",
    "AZURE_ENDPOINT=\"\"  # 你的 Azure OpenAI Endpoint，例如 https://xxx.openai.azure.com/\n",
    "AZURE_DEPLOYMENT_NAME=\"cookbook-gpt-4o-mini\"  # 在 Azure Portal 中预先创建的部署名称\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQALFqchIfTa"
   },
   "outputs": [],
   "source": [
    "# 将原生 AzureOpenAI 客户端替换为 Langfuse 提供的版本，自动接入观测能力\n",
    "from langfuse.openai import AzureOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18JzQ0bEIfTa"
   },
   "outputs": [],
   "source": [
    "# 实例化 AzureOpenAI 客户端；参数与官方 SDK 完全一致\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    api_version=\"2023-03-15-preview\",  # 指定 Azure API 版本\n",
    "    azure_endpoint=AZURE_ENDPOINT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeD8RpcJIfTa"
   },
   "outputs": [],
   "source": [
    "# 使用 Azure 部署的模型发起请求，Langfuse 会照常记录\n",
    "client.chat.completions.create(\n",
    "  name=\"test-chat-azure-openai\",\n",
    "  model=AZURE_DEPLOYMENT_NAME,  # Azure 部署名称映射到模型\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a very accurate calculator. You output only the result of the calculation.\"},\n",
    "      {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
    "  temperature=0,\n",
    "  metadata={\"someMetadataKey\": \"someValue\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJjdW90kIfTb"
   },
   "source": [
    "示例追踪：https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7ceb3ee3-0f2a-4f36-ad11-87ff636efd1e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su1OaQq3rPPh"
   },
   "source": [
    "## 将多次生成归并为单个 Trace\n",
    "\n",
    "在实际应用中，往往需要多次调用 OpenAI。借助 `@observe()` 装饰器，可以把一次 API 调用中的所有 LLM 请求归入 Langfuse 中同一个 `trace`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMDVxzS1ltWU",
    "outputId": "b2d29fc7-1d62-46b5-8ee5-2d2a27d544a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Sofia's embrace of time's gentle hand,  \n",
      "Where ancient whispers in the cobblestones stand,  \n",
      "The Vitosha's shadow kisses the town,  \n",
      "As golden sunsets tie the day down.  \n",
      "\n",
      "Streets sing with echoes of footsteps past,  \n",
      "Where stories linger, and memories cast,  \n",
      "Beneath the banyan sky so wide,  \n",
      "Cultures and histories peacefully collide.  \n",
      "\n",
      "The Alexander Nevsky, majestic and bold,  \n",
      "A guardian of faith with domes of gold,  \n",
      "Its silence speaks in volumes profound,  \n",
      "In the heart of a city where old truths are found.  \n",
      "\n",
      "The rose-laden gardens in Boris' park,  \n",
      "Perfume the air as day turns dark,  \n",
      "While laughter and life dance at night,  \n",
      "Under Sofia's tapestry of starlit light.  \n",
      "\n",
      "Markets bustle with the color of trade,  \n",
      "Where lively exchanges and histories fade,  \n",
      "A mosaic of tales in woven rhyme,  \n",
      "Sofia stands timeless through passage of time.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langfuse.openai import openai\n",
    "from langfuse import observe\n",
    "\n",
    "# @observe 装饰器会自动：\n",
    "# 1. 为 main 函数创建一个顶层 trace\n",
    "# 2. 捕获函数内部的所有 Langfuse/OpenAI 调用，并将它们串联为一个完整链路\n",
    "@observe()  # 装饰器会自动创建 trace 并嵌套各次生成\n",
    "def main(country: str, user_id: str, **kwargs) -> str:\n",
    "    # 嵌套调用 1：询问国家首都\n",
    "    capital = openai.chat.completions.create(\n",
    "      name=\"geography-teacher\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a Geography teacher helping students learn the capitals of countries. Output only the capital when being asked.\"},\n",
    "          {\"role\": \"user\", \"content\": country}],\n",
    "      temperature=0,\n",
    "    ).choices[0].message.content  # 读取模型回复\n",
    "\n",
    "    # 嵌套调用 2：请模型写一首关于首都的诗\n",
    "    poem = openai.chat.completions.create(\n",
    "      name=\"poet\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a poet. Create a poem about a city.\"},\n",
    "          {\"role\": \"user\", \"content\": capital}],\n",
    "      temperature=1,  # 提高温度，让诗歌更有创意\n",
    "      max_tokens=200,  # 控制输出长度\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return poem\n",
    "\n",
    "# 直接调用 main 函数，Langfuse 会自动生成 trace 并可在控制台查看链路\n",
    "print(main(\"Bulgaria\", \"admin\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ehx2NZuIrPPh"
   },
   "source": [
    "前往 https://cloud.langfuse.com 或你自建的实例，可以在 Langfuse 中查看完整链路。\n",
    "\n",
    "![多次 OpenAI 调用的追踪图](https://langfuse.com/images/docs/openai-trace-grouped.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HeMqTWgK4xL"
   },
   "source": [
    "## 完整方案：与 Langfuse SDK 协同\n",
    "\n",
    "`trace` 是 Langfuse 的核心对象，你可以为它附加丰富的元数据。详见 [Python SDK 文档](https://langfuse.com/docs/sdk/python#traces-1)。\n",
    "\n",
    "自定义 trace 后可以实现以下能力：\n",
    "- 自定义名称，用来区分不同类型的链路\n",
    "- 以用户为粒度的追踪\n",
    "- 通过版本与发布信息进行实验管理\n",
    "- 保存自定义元数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28to65wpK4xL",
    "outputId": "542e1a2e-520e-4dca-e954-8741bbf8c5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the cradle of Balkan hills, she lies,  \n",
      "A gem under cerulean skies,  \n",
      "Sofia, where the ancient whispers blend,  \n",
      "With modern souls, as time extends.\n",
      "\n",
      "Her heart beats with the rhythm of the past,  \n",
      "Where cobblestones and new dreams cast,  \n",
      "A tapestry of age and youth, entwined,  \n",
      "In every corner, stories unsigned.\n",
      "\n",
      "The Vitosha stands like a guardian old,  \n",
      "Whose peaks in winter snow enfold,  \n",
      "The city below, glowing warm and bright,  \n",
      "Under the embrace of evening light.\n",
      "\n",
      "St. Alexander’s domes in sunlight gleam,  \n",
      "Golden crowns of a Byzantine dream,  \n",
      "While beneath, a bustling world unfurls,  \n",
      "In markets vast, where culture swirls.\n",
      "\n",
      "Winding streets where whispers linger,  \n",
      "Liberty echoes from corner to finger,  \n",
      "In the shadow of Soviet grandiosity,  \n",
      "Bulgaria’s spirit claims its clarity.\n",
      "\n",
      "Cafés breathe tales in the aroma of brew,\n"
     ]
    }
   ],
   "source": [
    "from langfuse.openai import openai\n",
    "from langfuse import observe, get_client\n",
    "\n",
    "langfuse = get_client()  # 获取底层 Langfuse 客户端，可在装饰器之外手动操作 trace\n",
    "\n",
    "@observe()  # 装饰器会自动创建 trace 并嵌套各次生成\n",
    "def main(country: str, user_id: str, **kwargs) -> str:\n",
    "    # 嵌套调用 1：获取国家首都\n",
    "    capital = openai.chat.completions.create(\n",
    "      name=\"geography-teacher\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a Geography teacher helping students learn the capitals of countries. Output only the capital when being asked.\"},\n",
    "          {\"role\": \"user\", \"content\": country}],\n",
    "      temperature=0,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    # 嵌套调用 2：根据首都生成诗歌\n",
    "    poem = openai.chat.completions.create(\n",
    "      name=\"poet\",\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a poet. Create a poem about a city.\"},\n",
    "          {\"role\": \"user\", \"content\": capital}],\n",
    "      temperature=1,\n",
    "      max_tokens=200,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    # 手动更新当前 trace 的属性，让仪表盘信息更完整\n",
    "    langfuse.update_current_trace(\n",
    "        name=\"City poem generator\",  # 自定义 trace 名称\n",
    "        session_id=\"1234\",  # 业务会话 ID\n",
    "        user_id=user_id,  # 业务用户 ID\n",
    "        tags=[\"tag1\", \"tag2\"],  # 标签，支持在 Langfuse 中搜索\n",
    "        public=True,  # 是否允许分享 Trace 链接\n",
    "        metadata = {\"env\": \"development\"}  # 自定义元数据，例如环境标记\n",
    "    )\n",
    "\n",
    "    return poem\n",
    "\n",
    "# create_trace_id() 会生成一个可复用的追踪 ID，你也可以改为自己的业务 ID\n",
    "trace_id = langfuse.create_trace_id()\n",
    "\n",
    "# 通过关键字参数 `langfuse_observation_id` 将 trace_id 传递给装饰器，方便串联上下游调用\n",
    "print(main(\"Bulgaria\", \"admin\", langfuse_observation_id=trace_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3jxed-VrPPi"
   },
   "source": [
    "## 以编程方式添加评分\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMO6tn53rPPi"
   },
   "source": [
    "你可以向 trace 添加 [评分](https://langfuse.com/docs/scores)，记录用户反馈或自动化评估结果。评分可用于在 Langfuse 中筛选追踪，并会显示在控制台中。详见评分文档。\n",
    "\n",
    "评分通过 `trace_id` 与对应的 trace 关联。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0argbJhrPPi"
   },
   "outputs": [],
   "source": [
    "from langfuse import observe, get_client\n",
    "\n",
    "langfuse = get_client()  # 获取底层客户端，用于主流程之外的操作\n",
    "\n",
    "@observe()  # 装饰器会自动创建 trace 并嵌套各次生成\n",
    "def main():\n",
    "    # 在装饰器内部，可随时获取当前 trace 的 ID\n",
    "    trace_id = langfuse.get_current_trace_id()\n",
    "\n",
    "    # TODO: 在此处编写你的业务逻辑，例如继续调用其他 API、处理用户输入等\n",
    "\n",
    "    return \"res\", trace_id\n",
    "\n",
    "# 执行被装饰的函数，Langfuse 会生成 trace\n",
    "_, trace_id = main()\n",
    "\n",
    "# 在 trace 上下文外部也可以继续操作，例如向这次 trace 添加评分\n",
    "langfuse.create_score(\n",
    "    trace_id=trace_id,  # 指定要打分的 trace\n",
    "    name=\"my-score-name\",  # 评分名称，用于区分不同指标\n",
    "    value=1  # 分值，可以是布尔、整数、浮点数，视业务场景而定\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}